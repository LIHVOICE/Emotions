{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "#Deep learning\n",
    "\n",
    "### Plot imports ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns \n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8469,
     "status": "ok",
     "timestamp": 1596122880355,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "e4c2cacb-c175-4089-a491-53f2ef9ca990"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fearfull/03-01-06-02-02-01-24_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust/03-01-07-02-02-01-12_norm_outNoise.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry/03-01-05-02-01-02-06_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprised/03-01-08-01-01-01-20_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust/03-01-07-01-02-02-08_norm_outNoise.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              audio label\n",
       "0   fearfull/03-01-06-02-02-01-24_norm_outNoise.wav     0\n",
       "1    disgust/03-01-07-02-02-01-12_norm_outNoise.wav     1\n",
       "2      angry/03-01-05-02-01-02-06_norm_outNoise.wav     0\n",
       "3  surprised/03-01-08-01-01-01-20_norm_outNoise.wav     0\n",
       "4    disgust/03-01-07-01-02-02-08_norm_outNoise.wav     1"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"ravdess\" #audio data folder\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i[7] == '7':      ##this specifies that we class disgust emotion against the others\n",
    "                                    #7 represents the 7th column of the file name\n",
    "                                    # This number varies for each emotion(ex calm = '2', fearfull = '6')\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) #adding values to the defined df:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1596122913875,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "19abeff9-48cd-40d7-f109-592857ac8a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1053\n",
      "1     192\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1596122957340,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1596122987018,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "AjNAMwsfG2C8"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    fs, sig = scipy.io.wavfile.read(audio_path) \n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    spec =  fram_window(audio_path) \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)\n",
    "            \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "               \n",
    "    #gfccs = gfcc(sig= spec, fs=fs, num_ceps=13)    \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    #features.append(np.mean(gfccs))\n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3100082,
     "status": "ok",
     "timestamp": 1596126117243,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(parent_dir+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1596126325612,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "23d44afb-811e-4eed-c93c-9fb7b560b9ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1822,
     "status": "ok",
     "timestamp": 1596126463619,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 727,
     "status": "ok",
     "timestamp": 1596126482755,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1596126502294,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "79e630bc-7490-4bc7-e669-1e57fe64f5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 596\n",
      "After OverSampling, counts of label '0': 1053\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \" [1, 2, 3, 5, 8, 14, 20]   \" are deleted 900 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26999,
     "status": "ok",
     "timestamp": 1596126555540,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "8b047ead-7e49-4d7e-d0f1-1ee81f7dc2a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 5, 8, 14, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3, 5, 8, 14, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2, 3, 5, 8, 14, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 3, 5, 8, 14, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 2, 3, 5, 8, 14, 20]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration                X_removed\n",
       "0         1  [1, 2, 3, 5, 8, 14, 20]\n",
       "1         2  [1, 2, 3, 5, 8, 14, 20]\n",
       "2         3  [1, 2, 3, 5, 8, 14, 20]\n",
       "3         4  [1, 2, 3, 5, 8, 14, 20]\n",
       "4         5  [1, 2, 3, 5, 8, 14, 20]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5, 8, 14, 20]    900\n",
       "[1, 2, 3, 8, 14, 20]       100\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 895,
     "status": "ok",
     "timestamp": 1596127179691,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6sTQj5wDWdev"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0],  X[i][4], X[i][6], X[i][7], X[i][9], X[i][10],\n",
    "               X[i][11], X[i][12], X[i][13],  X[i][15], \n",
    "                X[i][16], X[i][17], X[i][18], X[i][19], X[i][21]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1596127208301,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "e1589f26-c1a5-4fe7-d154-8b7b438f8ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055\n",
      "330\n",
      "264\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1596127295242,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1596127306883,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "1dd0ad8d-daff-4941-e342-b17e970e8ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1055, 15, 1)\n",
      "(330, 15, 1)\n",
      "(264, 15, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1124,
     "status": "ok",
     "timestamp": 1596127330451,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "eb0157c2-b0bc-42b0-c357-b1805d5d5819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1055, 2)\n",
      "(330, 2)\n",
      "(264, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1596127369498,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (15,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1596127396573,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "a3903f94-e55d-4d3f-a48c-6a628b07a9a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 15, 1)]           0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 15, 128)           768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 3842      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 87,178\n",
      "Trainable params: 86,918\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN \n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1596127402275,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 171932,
     "status": "ok",
     "timestamp": 1596127596860,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "365bfc3e-0503-41ee-cf21-b13be010d9d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.8634 - accuracy: 0.5346 - auc: 0.5355 - val_loss: 0.6976 - val_accuracy: 0.5182 - val_auc: 0.5127\n",
      "Epoch 2/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.7815 - accuracy: 0.5526 - auc: 0.5761 - val_loss: 0.6823 - val_accuracy: 0.5727 - val_auc: 0.5804\n",
      "Epoch 3/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.7254 - accuracy: 0.5905 - auc: 0.6113 - val_loss: 0.6724 - val_accuracy: 0.5758 - val_auc: 0.6266\n",
      "Epoch 4/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6959 - accuracy: 0.5754 - auc: 0.6165 - val_loss: 0.6639 - val_accuracy: 0.5970 - val_auc: 0.6611\n",
      "Epoch 5/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6777 - accuracy: 0.6114 - auc: 0.6479 - val_loss: 0.6589 - val_accuracy: 0.6030 - val_auc: 0.6746\n",
      "Epoch 6/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6610 - accuracy: 0.6133 - auc: 0.6688 - val_loss: 0.6543 - val_accuracy: 0.6152 - val_auc: 0.6870\n",
      "Epoch 7/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6512 - accuracy: 0.6237 - auc: 0.6678 - val_loss: 0.6523 - val_accuracy: 0.6333 - val_auc: 0.6874\n",
      "Epoch 8/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6485 - accuracy: 0.6246 - auc: 0.6775 - val_loss: 0.6496 - val_accuracy: 0.6333 - val_auc: 0.6925\n",
      "Epoch 9/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6336 - accuracy: 0.6360 - auc: 0.6975 - val_loss: 0.6483 - val_accuracy: 0.6364 - val_auc: 0.6900\n",
      "Epoch 10/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6175 - accuracy: 0.6540 - auc: 0.7154 - val_loss: 0.6457 - val_accuracy: 0.6424 - val_auc: 0.6955\n",
      "Epoch 11/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.6216 - accuracy: 0.6540 - auc: 0.7108 - val_loss: 0.6435 - val_accuracy: 0.6424 - val_auc: 0.6961\n",
      "Epoch 12/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6178 - accuracy: 0.6616 - auc: 0.7147 - val_loss: 0.6429 - val_accuracy: 0.6394 - val_auc: 0.6943\n",
      "Epoch 13/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.6331 - accuracy: 0.6436 - auc: 0.6967 - val_loss: 0.6411 - val_accuracy: 0.6485 - val_auc: 0.6920\n",
      "Epoch 14/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6209 - accuracy: 0.6455 - auc: 0.7098 - val_loss: 0.6402 - val_accuracy: 0.6515 - val_auc: 0.6900\n",
      "Epoch 15/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6178 - accuracy: 0.6569 - auc: 0.7160 - val_loss: 0.6382 - val_accuracy: 0.6545 - val_auc: 0.6906\n",
      "Epoch 16/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.6034 - accuracy: 0.6427 - auc: 0.7311 - val_loss: 0.6370 - val_accuracy: 0.6485 - val_auc: 0.6897\n",
      "Epoch 17/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.6175 - accuracy: 0.6379 - auc: 0.7093 - val_loss: 0.6350 - val_accuracy: 0.6485 - val_auc: 0.6916\n",
      "Epoch 18/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6061 - accuracy: 0.6607 - auc: 0.7230 - val_loss: 0.6352 - val_accuracy: 0.6424 - val_auc: 0.6890\n",
      "Epoch 19/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6074 - accuracy: 0.6588 - auc: 0.7302 - val_loss: 0.6337 - val_accuracy: 0.6455 - val_auc: 0.6901\n",
      "Epoch 20/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6112 - accuracy: 0.6483 - auc: 0.7214 - val_loss: 0.6342 - val_accuracy: 0.6394 - val_auc: 0.6865\n",
      "Epoch 21/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6159 - accuracy: 0.6455 - auc: 0.7163 - val_loss: 0.6343 - val_accuracy: 0.6424 - val_auc: 0.6847\n",
      "Epoch 22/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.6012 - accuracy: 0.6626 - auc: 0.7361 - val_loss: 0.6332 - val_accuracy: 0.6333 - val_auc: 0.6867\n",
      "Epoch 23/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6042 - accuracy: 0.6701 - auc: 0.7326 - val_loss: 0.6305 - val_accuracy: 0.6303 - val_auc: 0.6906\n",
      "Epoch 24/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6074 - accuracy: 0.6682 - auc: 0.7270 - val_loss: 0.6308 - val_accuracy: 0.6303 - val_auc: 0.6893\n",
      "Epoch 25/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5953 - accuracy: 0.6701 - auc: 0.7399 - val_loss: 0.6302 - val_accuracy: 0.6333 - val_auc: 0.6904\n",
      "Epoch 26/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5860 - accuracy: 0.6787 - auc: 0.7510 - val_loss: 0.6300 - val_accuracy: 0.6303 - val_auc: 0.6911\n",
      "Epoch 27/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5974 - accuracy: 0.6692 - auc: 0.7406 - val_loss: 0.6299 - val_accuracy: 0.6364 - val_auc: 0.6916\n",
      "Epoch 28/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6000 - accuracy: 0.6645 - auc: 0.7358 - val_loss: 0.6292 - val_accuracy: 0.6394 - val_auc: 0.6929\n",
      "Epoch 29/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6047 - accuracy: 0.6588 - auc: 0.7301 - val_loss: 0.6294 - val_accuracy: 0.6424 - val_auc: 0.6930\n",
      "Epoch 30/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5959 - accuracy: 0.6645 - auc: 0.7369 - val_loss: 0.6288 - val_accuracy: 0.6394 - val_auc: 0.6944\n",
      "Epoch 31/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5965 - accuracy: 0.6512 - auc: 0.7386 - val_loss: 0.6277 - val_accuracy: 0.6394 - val_auc: 0.6962\n",
      "Epoch 32/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5943 - accuracy: 0.6654 - auc: 0.7453 - val_loss: 0.6273 - val_accuracy: 0.6364 - val_auc: 0.6967\n",
      "Epoch 33/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5926 - accuracy: 0.6815 - auc: 0.7463 - val_loss: 0.6264 - val_accuracy: 0.6364 - val_auc: 0.6978\n",
      "Epoch 34/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5941 - accuracy: 0.6588 - auc: 0.7400 - val_loss: 0.6248 - val_accuracy: 0.6424 - val_auc: 0.7001\n",
      "Epoch 35/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5856 - accuracy: 0.6863 - auc: 0.7535 - val_loss: 0.6245 - val_accuracy: 0.6394 - val_auc: 0.7016\n",
      "Epoch 36/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5804 - accuracy: 0.6825 - auc: 0.7577 - val_loss: 0.6225 - val_accuracy: 0.6394 - val_auc: 0.7035\n",
      "Epoch 37/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5848 - accuracy: 0.6796 - auc: 0.7518 - val_loss: 0.6208 - val_accuracy: 0.6394 - val_auc: 0.7052\n",
      "Epoch 38/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5882 - accuracy: 0.6682 - auc: 0.7474 - val_loss: 0.6202 - val_accuracy: 0.6424 - val_auc: 0.7063\n",
      "Epoch 39/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5916 - accuracy: 0.6711 - auc: 0.7432 - val_loss: 0.6199 - val_accuracy: 0.6424 - val_auc: 0.7067\n",
      "Epoch 40/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5943 - accuracy: 0.6626 - auc: 0.7416 - val_loss: 0.6195 - val_accuracy: 0.6455 - val_auc: 0.7076\n",
      "Epoch 41/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5946 - accuracy: 0.6777 - auc: 0.7410 - val_loss: 0.6181 - val_accuracy: 0.6576 - val_auc: 0.7094\n",
      "Epoch 42/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5800 - accuracy: 0.6986 - auc: 0.7580 - val_loss: 0.6180 - val_accuracy: 0.6576 - val_auc: 0.7096\n",
      "Epoch 43/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5909 - accuracy: 0.6825 - auc: 0.7456 - val_loss: 0.6173 - val_accuracy: 0.6576 - val_auc: 0.7103\n",
      "Epoch 44/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5956 - accuracy: 0.6645 - auc: 0.7397 - val_loss: 0.6187 - val_accuracy: 0.6485 - val_auc: 0.7094\n",
      "Epoch 45/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5874 - accuracy: 0.6711 - auc: 0.7474 - val_loss: 0.6186 - val_accuracy: 0.6455 - val_auc: 0.7092\n",
      "Epoch 46/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5752 - accuracy: 0.6891 - auc: 0.7616 - val_loss: 0.6171 - val_accuracy: 0.6515 - val_auc: 0.7117\n",
      "Epoch 47/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5837 - accuracy: 0.6635 - auc: 0.7509 - val_loss: 0.6174 - val_accuracy: 0.6455 - val_auc: 0.7111\n",
      "Epoch 48/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5820 - accuracy: 0.6834 - auc: 0.7560 - val_loss: 0.6166 - val_accuracy: 0.6455 - val_auc: 0.7118\n",
      "Epoch 49/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5814 - accuracy: 0.6900 - auc: 0.7576 - val_loss: 0.6175 - val_accuracy: 0.6455 - val_auc: 0.7112\n",
      "Epoch 50/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5848 - accuracy: 0.6711 - auc: 0.7504 - val_loss: 0.6165 - val_accuracy: 0.6455 - val_auc: 0.7118\n",
      "Epoch 51/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5827 - accuracy: 0.6872 - auc: 0.7550 - val_loss: 0.6153 - val_accuracy: 0.6485 - val_auc: 0.7128\n",
      "Epoch 52/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5787 - accuracy: 0.6834 - auc: 0.7570 - val_loss: 0.6141 - val_accuracy: 0.6576 - val_auc: 0.7141\n",
      "Epoch 53/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5831 - accuracy: 0.6616 - auc: 0.7527 - val_loss: 0.6136 - val_accuracy: 0.6515 - val_auc: 0.7139\n",
      "Epoch 54/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5825 - accuracy: 0.6682 - auc: 0.7522 - val_loss: 0.6123 - val_accuracy: 0.6576 - val_auc: 0.7156\n",
      "Epoch 55/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5881 - accuracy: 0.6777 - auc: 0.7461 - val_loss: 0.6121 - val_accuracy: 0.6576 - val_auc: 0.7153\n",
      "Epoch 56/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5781 - accuracy: 0.6806 - auc: 0.7610 - val_loss: 0.6112 - val_accuracy: 0.6606 - val_auc: 0.7165\n",
      "Epoch 57/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5826 - accuracy: 0.6787 - auc: 0.7541 - val_loss: 0.6115 - val_accuracy: 0.6606 - val_auc: 0.7167\n",
      "Epoch 58/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5788 - accuracy: 0.6872 - auc: 0.7618 - val_loss: 0.6108 - val_accuracy: 0.6606 - val_auc: 0.7174\n",
      "Epoch 59/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5862 - accuracy: 0.6768 - auc: 0.7494 - val_loss: 0.6124 - val_accuracy: 0.6606 - val_auc: 0.7156\n",
      "Epoch 60/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5724 - accuracy: 0.6986 - auc: 0.7658 - val_loss: 0.6105 - val_accuracy: 0.6606 - val_auc: 0.7173\n",
      "Epoch 61/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5810 - accuracy: 0.6834 - auc: 0.7566 - val_loss: 0.6104 - val_accuracy: 0.6606 - val_auc: 0.7178\n",
      "Epoch 62/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5687 - accuracy: 0.6844 - auc: 0.7675 - val_loss: 0.6103 - val_accuracy: 0.6606 - val_auc: 0.7179\n",
      "Epoch 63/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5819 - accuracy: 0.6900 - auc: 0.7580 - val_loss: 0.6109 - val_accuracy: 0.6636 - val_auc: 0.7171\n",
      "Epoch 64/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5707 - accuracy: 0.7043 - auc: 0.7709 - val_loss: 0.6111 - val_accuracy: 0.6515 - val_auc: 0.7169\n",
      "Epoch 65/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5766 - accuracy: 0.6919 - auc: 0.7625 - val_loss: 0.6122 - val_accuracy: 0.6545 - val_auc: 0.7154\n",
      "Epoch 66/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5821 - accuracy: 0.6825 - auc: 0.7536 - val_loss: 0.6124 - val_accuracy: 0.6485 - val_auc: 0.7153\n",
      "Epoch 67/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5780 - accuracy: 0.6834 - auc: 0.7578 - val_loss: 0.6108 - val_accuracy: 0.6515 - val_auc: 0.7174\n",
      "Epoch 68/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5666 - accuracy: 0.6834 - auc: 0.7708 - val_loss: 0.6088 - val_accuracy: 0.6545 - val_auc: 0.7199\n",
      "Epoch 69/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5784 - accuracy: 0.6815 - auc: 0.7579 - val_loss: 0.6093 - val_accuracy: 0.6515 - val_auc: 0.7189\n",
      "Epoch 70/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5759 - accuracy: 0.6948 - auc: 0.7617 - val_loss: 0.6086 - val_accuracy: 0.6545 - val_auc: 0.7199\n",
      "Epoch 71/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5749 - accuracy: 0.6834 - auc: 0.7615 - val_loss: 0.6086 - val_accuracy: 0.6545 - val_auc: 0.7200\n",
      "Epoch 72/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5759 - accuracy: 0.6919 - auc: 0.7613 - val_loss: 0.6094 - val_accuracy: 0.6515 - val_auc: 0.7194\n",
      "Epoch 73/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5715 - accuracy: 0.6796 - auc: 0.7650 - val_loss: 0.6091 - val_accuracy: 0.6545 - val_auc: 0.7196\n",
      "Epoch 74/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5775 - accuracy: 0.6844 - auc: 0.7591 - val_loss: 0.6091 - val_accuracy: 0.6515 - val_auc: 0.7198\n",
      "Epoch 75/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5766 - accuracy: 0.6919 - auc: 0.7619 - val_loss: 0.6089 - val_accuracy: 0.6485 - val_auc: 0.7197\n",
      "Epoch 76/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5679 - accuracy: 0.7033 - auc: 0.7726 - val_loss: 0.6077 - val_accuracy: 0.6545 - val_auc: 0.7210\n",
      "Epoch 77/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5692 - accuracy: 0.6910 - auc: 0.7696 - val_loss: 0.6066 - val_accuracy: 0.6545 - val_auc: 0.7220\n",
      "Epoch 78/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5735 - accuracy: 0.6825 - auc: 0.7646 - val_loss: 0.6063 - val_accuracy: 0.6545 - val_auc: 0.7220\n",
      "Epoch 79/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5808 - accuracy: 0.6720 - auc: 0.7525 - val_loss: 0.6072 - val_accuracy: 0.6545 - val_auc: 0.7212\n",
      "Epoch 80/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5697 - accuracy: 0.6768 - auc: 0.7637 - val_loss: 0.6074 - val_accuracy: 0.6485 - val_auc: 0.7211\n",
      "Epoch 81/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5698 - accuracy: 0.6882 - auc: 0.7696 - val_loss: 0.6074 - val_accuracy: 0.6485 - val_auc: 0.7207\n",
      "Epoch 82/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5736 - accuracy: 0.6863 - auc: 0.7618 - val_loss: 0.6079 - val_accuracy: 0.6485 - val_auc: 0.7203\n",
      "Epoch 83/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5765 - accuracy: 0.6825 - auc: 0.7593 - val_loss: 0.6084 - val_accuracy: 0.6455 - val_auc: 0.7199\n",
      "Epoch 84/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5748 - accuracy: 0.6863 - auc: 0.7652 - val_loss: 0.6074 - val_accuracy: 0.6485 - val_auc: 0.7210\n",
      "Epoch 85/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5686 - accuracy: 0.6929 - auc: 0.7696 - val_loss: 0.6069 - val_accuracy: 0.6485 - val_auc: 0.7218\n",
      "Epoch 86/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5786 - accuracy: 0.6882 - auc: 0.7590 - val_loss: 0.6054 - val_accuracy: 0.6515 - val_auc: 0.7233\n",
      "Epoch 87/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5751 - accuracy: 0.6853 - auc: 0.7599 - val_loss: 0.6050 - val_accuracy: 0.6515 - val_auc: 0.7234\n",
      "Epoch 88/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5741 - accuracy: 0.6825 - auc: 0.7625 - val_loss: 0.6050 - val_accuracy: 0.6515 - val_auc: 0.7238\n",
      "Epoch 89/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5763 - accuracy: 0.6910 - auc: 0.7618 - val_loss: 0.6058 - val_accuracy: 0.6485 - val_auc: 0.7228\n",
      "Epoch 90/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5703 - accuracy: 0.6796 - auc: 0.7663 - val_loss: 0.6068 - val_accuracy: 0.6485 - val_auc: 0.7221\n",
      "Epoch 91/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5719 - accuracy: 0.6834 - auc: 0.7641 - val_loss: 0.6064 - val_accuracy: 0.6485 - val_auc: 0.7224\n",
      "Epoch 92/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5680 - accuracy: 0.7005 - auc: 0.7703 - val_loss: 0.6055 - val_accuracy: 0.6485 - val_auc: 0.7228\n",
      "Epoch 93/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5772 - accuracy: 0.6948 - auc: 0.7618 - val_loss: 0.6056 - val_accuracy: 0.6515 - val_auc: 0.7228\n",
      "Epoch 94/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5623 - accuracy: 0.7014 - auc: 0.7784 - val_loss: 0.6060 - val_accuracy: 0.6485 - val_auc: 0.7223\n",
      "Epoch 95/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5739 - accuracy: 0.6863 - auc: 0.7635 - val_loss: 0.6073 - val_accuracy: 0.6485 - val_auc: 0.7212\n",
      "Epoch 96/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5733 - accuracy: 0.6701 - auc: 0.7615 - val_loss: 0.6062 - val_accuracy: 0.6485 - val_auc: 0.7223\n",
      "Epoch 97/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5677 - accuracy: 0.6910 - auc: 0.7706 - val_loss: 0.6069 - val_accuracy: 0.6485 - val_auc: 0.7209\n",
      "Epoch 98/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5700 - accuracy: 0.6929 - auc: 0.7669 - val_loss: 0.6058 - val_accuracy: 0.6485 - val_auc: 0.7225\n",
      "Epoch 99/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5708 - accuracy: 0.6834 - auc: 0.7648 - val_loss: 0.6047 - val_accuracy: 0.6515 - val_auc: 0.7235\n",
      "Epoch 100/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5736 - accuracy: 0.6929 - auc: 0.7636 - val_loss: 0.6041 - val_accuracy: 0.6545 - val_auc: 0.7242\n",
      "Epoch 101/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5729 - accuracy: 0.6882 - auc: 0.7640 - val_loss: 0.6035 - val_accuracy: 0.6515 - val_auc: 0.7250\n",
      "Epoch 102/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5712 - accuracy: 0.6863 - auc: 0.7642 - val_loss: 0.6024 - val_accuracy: 0.6576 - val_auc: 0.7259\n",
      "Epoch 103/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5668 - accuracy: 0.6815 - auc: 0.7695 - val_loss: 0.6033 - val_accuracy: 0.6545 - val_auc: 0.7253\n",
      "Epoch 104/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5740 - accuracy: 0.6882 - auc: 0.7631 - val_loss: 0.6035 - val_accuracy: 0.6545 - val_auc: 0.7246\n",
      "Epoch 105/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5700 - accuracy: 0.6957 - auc: 0.7675 - val_loss: 0.6014 - val_accuracy: 0.6576 - val_auc: 0.7269\n",
      "Epoch 106/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5616 - accuracy: 0.7005 - auc: 0.7784 - val_loss: 0.6015 - val_accuracy: 0.6576 - val_auc: 0.7265\n",
      "Epoch 107/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5772 - accuracy: 0.6891 - auc: 0.7613 - val_loss: 0.6010 - val_accuracy: 0.6576 - val_auc: 0.7274\n",
      "Epoch 108/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5684 - accuracy: 0.6938 - auc: 0.7685 - val_loss: 0.6025 - val_accuracy: 0.6545 - val_auc: 0.7256\n",
      "Epoch 109/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5611 - accuracy: 0.7033 - auc: 0.7782 - val_loss: 0.6026 - val_accuracy: 0.6545 - val_auc: 0.7253\n",
      "Epoch 110/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5692 - accuracy: 0.6919 - auc: 0.7681 - val_loss: 0.6024 - val_accuracy: 0.6545 - val_auc: 0.7252\n",
      "Epoch 111/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5683 - accuracy: 0.6938 - auc: 0.7692 - val_loss: 0.6027 - val_accuracy: 0.6545 - val_auc: 0.7249\n",
      "Epoch 112/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5715 - accuracy: 0.6938 - auc: 0.7684 - val_loss: 0.6023 - val_accuracy: 0.6515 - val_auc: 0.7252\n",
      "Epoch 113/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5750 - accuracy: 0.6900 - auc: 0.7634 - val_loss: 0.6029 - val_accuracy: 0.6515 - val_auc: 0.7248\n",
      "Epoch 114/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5622 - accuracy: 0.7043 - auc: 0.7770 - val_loss: 0.6017 - val_accuracy: 0.6515 - val_auc: 0.7260\n",
      "Epoch 115/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5599 - accuracy: 0.6995 - auc: 0.7792 - val_loss: 0.6005 - val_accuracy: 0.6545 - val_auc: 0.7270\n",
      "Epoch 116/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5745 - accuracy: 0.6929 - auc: 0.7624 - val_loss: 0.6020 - val_accuracy: 0.6515 - val_auc: 0.7258\n",
      "Epoch 117/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5793 - accuracy: 0.6806 - auc: 0.7581 - val_loss: 0.6009 - val_accuracy: 0.6515 - val_auc: 0.7268\n",
      "Epoch 118/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5551 - accuracy: 0.6872 - auc: 0.7819 - val_loss: 0.6004 - val_accuracy: 0.6515 - val_auc: 0.7271\n",
      "Epoch 119/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5596 - accuracy: 0.6995 - auc: 0.7772 - val_loss: 0.6004 - val_accuracy: 0.6515 - val_auc: 0.7273\n",
      "Epoch 120/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5614 - accuracy: 0.6976 - auc: 0.7757 - val_loss: 0.5995 - val_accuracy: 0.6545 - val_auc: 0.7282\n",
      "Epoch 121/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5587 - accuracy: 0.6929 - auc: 0.7776 - val_loss: 0.5991 - val_accuracy: 0.6545 - val_auc: 0.7288\n",
      "Epoch 122/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5567 - accuracy: 0.6967 - auc: 0.7823 - val_loss: 0.5985 - val_accuracy: 0.6545 - val_auc: 0.7293\n",
      "Epoch 123/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5522 - accuracy: 0.7081 - auc: 0.7884 - val_loss: 0.5980 - val_accuracy: 0.6545 - val_auc: 0.7297\n",
      "Epoch 124/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5649 - accuracy: 0.6910 - auc: 0.7727 - val_loss: 0.5974 - val_accuracy: 0.6576 - val_auc: 0.7310\n",
      "Epoch 125/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5662 - accuracy: 0.6900 - auc: 0.7715 - val_loss: 0.5960 - val_accuracy: 0.6545 - val_auc: 0.7323\n",
      "Epoch 126/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5629 - accuracy: 0.7100 - auc: 0.7753 - val_loss: 0.5954 - val_accuracy: 0.6576 - val_auc: 0.7326\n",
      "Epoch 127/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5637 - accuracy: 0.6891 - auc: 0.7721 - val_loss: 0.5944 - val_accuracy: 0.6576 - val_auc: 0.7337\n",
      "Epoch 128/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5713 - accuracy: 0.6844 - auc: 0.7644 - val_loss: 0.5965 - val_accuracy: 0.6545 - val_auc: 0.7318\n",
      "Epoch 129/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5571 - accuracy: 0.7081 - auc: 0.7807 - val_loss: 0.5968 - val_accuracy: 0.6515 - val_auc: 0.7314\n",
      "Epoch 130/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5564 - accuracy: 0.6976 - auc: 0.7807 - val_loss: 0.5965 - val_accuracy: 0.6545 - val_auc: 0.7322\n",
      "Epoch 131/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5657 - accuracy: 0.7062 - auc: 0.7730 - val_loss: 0.5972 - val_accuracy: 0.6515 - val_auc: 0.7315\n",
      "Epoch 132/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5613 - accuracy: 0.6957 - auc: 0.7753 - val_loss: 0.5963 - val_accuracy: 0.6545 - val_auc: 0.7321\n",
      "Epoch 133/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5640 - accuracy: 0.6872 - auc: 0.7725 - val_loss: 0.5976 - val_accuracy: 0.6515 - val_auc: 0.7306\n",
      "Epoch 134/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5576 - accuracy: 0.7090 - auc: 0.7817 - val_loss: 0.5986 - val_accuracy: 0.6515 - val_auc: 0.7291\n",
      "Epoch 135/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5648 - accuracy: 0.6938 - auc: 0.7728 - val_loss: 0.5983 - val_accuracy: 0.6485 - val_auc: 0.7299\n",
      "Epoch 136/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5604 - accuracy: 0.7014 - auc: 0.7792 - val_loss: 0.5986 - val_accuracy: 0.6485 - val_auc: 0.7293\n",
      "Epoch 137/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5635 - accuracy: 0.6957 - auc: 0.7749 - val_loss: 0.5992 - val_accuracy: 0.6515 - val_auc: 0.7284\n",
      "Epoch 138/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5718 - accuracy: 0.6825 - auc: 0.7650 - val_loss: 0.6011 - val_accuracy: 0.6485 - val_auc: 0.7265\n",
      "Epoch 139/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5587 - accuracy: 0.7043 - auc: 0.7794 - val_loss: 0.6001 - val_accuracy: 0.6485 - val_auc: 0.7272\n",
      "Epoch 140/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5593 - accuracy: 0.7033 - auc: 0.7807 - val_loss: 0.5982 - val_accuracy: 0.6515 - val_auc: 0.7294\n",
      "Epoch 141/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5542 - accuracy: 0.7033 - auc: 0.7833 - val_loss: 0.5959 - val_accuracy: 0.6515 - val_auc: 0.7321\n",
      "Epoch 142/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5680 - accuracy: 0.6957 - auc: 0.7700 - val_loss: 0.5967 - val_accuracy: 0.6515 - val_auc: 0.7312\n",
      "Epoch 143/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5665 - accuracy: 0.7024 - auc: 0.7715 - val_loss: 0.5968 - val_accuracy: 0.6545 - val_auc: 0.7305\n",
      "Epoch 144/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5586 - accuracy: 0.6976 - auc: 0.7798 - val_loss: 0.5951 - val_accuracy: 0.6515 - val_auc: 0.7332\n",
      "Epoch 145/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5564 - accuracy: 0.7024 - auc: 0.7818 - val_loss: 0.5954 - val_accuracy: 0.6515 - val_auc: 0.7327\n",
      "Epoch 146/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5637 - accuracy: 0.6815 - auc: 0.7726 - val_loss: 0.5952 - val_accuracy: 0.6515 - val_auc: 0.7327\n",
      "Epoch 147/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5628 - accuracy: 0.7062 - auc: 0.7756 - val_loss: 0.5955 - val_accuracy: 0.6485 - val_auc: 0.7329\n",
      "Epoch 148/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5673 - accuracy: 0.6910 - auc: 0.7691 - val_loss: 0.5935 - val_accuracy: 0.6515 - val_auc: 0.7345\n",
      "Epoch 149/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5664 - accuracy: 0.6976 - auc: 0.7730 - val_loss: 0.5955 - val_accuracy: 0.6545 - val_auc: 0.7328\n",
      "Epoch 150/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5613 - accuracy: 0.7033 - auc: 0.7771 - val_loss: 0.5961 - val_accuracy: 0.6515 - val_auc: 0.7312\n",
      "Epoch 151/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5551 - accuracy: 0.7005 - auc: 0.7823 - val_loss: 0.5958 - val_accuracy: 0.6515 - val_auc: 0.7317\n",
      "Epoch 152/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5604 - accuracy: 0.6900 - auc: 0.7777 - val_loss: 0.5948 - val_accuracy: 0.6515 - val_auc: 0.7334\n",
      "Epoch 153/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5692 - accuracy: 0.6701 - auc: 0.7646 - val_loss: 0.5946 - val_accuracy: 0.6545 - val_auc: 0.7332\n",
      "Epoch 154/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5679 - accuracy: 0.6929 - auc: 0.7709 - val_loss: 0.5965 - val_accuracy: 0.6485 - val_auc: 0.7315\n",
      "Epoch 155/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5616 - accuracy: 0.6919 - auc: 0.7747 - val_loss: 0.5957 - val_accuracy: 0.6455 - val_auc: 0.7319\n",
      "Epoch 156/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5630 - accuracy: 0.6872 - auc: 0.7752 - val_loss: 0.5953 - val_accuracy: 0.6424 - val_auc: 0.7319\n",
      "Epoch 157/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5594 - accuracy: 0.6976 - auc: 0.7773 - val_loss: 0.5941 - val_accuracy: 0.6455 - val_auc: 0.7333\n",
      "Epoch 158/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5605 - accuracy: 0.6929 - auc: 0.7769 - val_loss: 0.5924 - val_accuracy: 0.6576 - val_auc: 0.7358\n",
      "Epoch 159/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5615 - accuracy: 0.6882 - auc: 0.7742 - val_loss: 0.5921 - val_accuracy: 0.6545 - val_auc: 0.7357\n",
      "Epoch 160/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5650 - accuracy: 0.6967 - auc: 0.7740 - val_loss: 0.5924 - val_accuracy: 0.6545 - val_auc: 0.7353\n",
      "Epoch 161/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5485 - accuracy: 0.7156 - auc: 0.7910 - val_loss: 0.5927 - val_accuracy: 0.6576 - val_auc: 0.7347\n",
      "Epoch 162/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5610 - accuracy: 0.6967 - auc: 0.7746 - val_loss: 0.5943 - val_accuracy: 0.6455 - val_auc: 0.7330\n",
      "Epoch 163/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5523 - accuracy: 0.7194 - auc: 0.7891 - val_loss: 0.5927 - val_accuracy: 0.6515 - val_auc: 0.7347\n",
      "Epoch 164/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5625 - accuracy: 0.7137 - auc: 0.7794 - val_loss: 0.5918 - val_accuracy: 0.6636 - val_auc: 0.7353\n",
      "Epoch 165/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5560 - accuracy: 0.6891 - auc: 0.7799 - val_loss: 0.5904 - val_accuracy: 0.6667 - val_auc: 0.7368\n",
      "Epoch 166/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5639 - accuracy: 0.7033 - auc: 0.7760 - val_loss: 0.5918 - val_accuracy: 0.6485 - val_auc: 0.7356\n",
      "Epoch 167/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5603 - accuracy: 0.6872 - auc: 0.7730 - val_loss: 0.5917 - val_accuracy: 0.6515 - val_auc: 0.7358\n",
      "Epoch 168/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5632 - accuracy: 0.7005 - auc: 0.7748 - val_loss: 0.5916 - val_accuracy: 0.6515 - val_auc: 0.7361\n",
      "Epoch 169/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5551 - accuracy: 0.7062 - auc: 0.7851 - val_loss: 0.5912 - val_accuracy: 0.6515 - val_auc: 0.7362\n",
      "Epoch 170/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5586 - accuracy: 0.7014 - auc: 0.7789 - val_loss: 0.5918 - val_accuracy: 0.6515 - val_auc: 0.7355\n",
      "Epoch 171/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5557 - accuracy: 0.6891 - auc: 0.7809 - val_loss: 0.5917 - val_accuracy: 0.6545 - val_auc: 0.7356\n",
      "Epoch 172/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5593 - accuracy: 0.7052 - auc: 0.7804 - val_loss: 0.5909 - val_accuracy: 0.6545 - val_auc: 0.7358\n",
      "Epoch 173/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5653 - accuracy: 0.6910 - auc: 0.7739 - val_loss: 0.5921 - val_accuracy: 0.6545 - val_auc: 0.7354\n",
      "Epoch 174/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5645 - accuracy: 0.7014 - auc: 0.7733 - val_loss: 0.5920 - val_accuracy: 0.6515 - val_auc: 0.7354\n",
      "Epoch 175/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5536 - accuracy: 0.7062 - auc: 0.7838 - val_loss: 0.5921 - val_accuracy: 0.6515 - val_auc: 0.7351\n",
      "Epoch 176/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5579 - accuracy: 0.6938 - auc: 0.7797 - val_loss: 0.5904 - val_accuracy: 0.6545 - val_auc: 0.7369\n",
      "Epoch 177/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5499 - accuracy: 0.6957 - auc: 0.7893 - val_loss: 0.5893 - val_accuracy: 0.6515 - val_auc: 0.7384\n",
      "Epoch 178/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5531 - accuracy: 0.6995 - auc: 0.7824 - val_loss: 0.5903 - val_accuracy: 0.6515 - val_auc: 0.7372\n",
      "Epoch 179/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5545 - accuracy: 0.7033 - auc: 0.7827 - val_loss: 0.5903 - val_accuracy: 0.6485 - val_auc: 0.7372\n",
      "Epoch 180/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5554 - accuracy: 0.7109 - auc: 0.7811 - val_loss: 0.5913 - val_accuracy: 0.6515 - val_auc: 0.7361\n",
      "Epoch 181/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5496 - accuracy: 0.7100 - auc: 0.7903 - val_loss: 0.5900 - val_accuracy: 0.6515 - val_auc: 0.7376\n",
      "Epoch 182/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5511 - accuracy: 0.7137 - auc: 0.7883 - val_loss: 0.5878 - val_accuracy: 0.6576 - val_auc: 0.7399\n",
      "Epoch 183/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5579 - accuracy: 0.7005 - auc: 0.7797 - val_loss: 0.5891 - val_accuracy: 0.6576 - val_auc: 0.7381\n",
      "Epoch 184/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5493 - accuracy: 0.7147 - auc: 0.7933 - val_loss: 0.5897 - val_accuracy: 0.6576 - val_auc: 0.7377\n",
      "Epoch 185/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5521 - accuracy: 0.7052 - auc: 0.7880 - val_loss: 0.5904 - val_accuracy: 0.6545 - val_auc: 0.7372\n",
      "Epoch 186/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5547 - accuracy: 0.7052 - auc: 0.7825 - val_loss: 0.5888 - val_accuracy: 0.6606 - val_auc: 0.7382\n",
      "Epoch 187/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5610 - accuracy: 0.7081 - auc: 0.7782 - val_loss: 0.5890 - val_accuracy: 0.6606 - val_auc: 0.7378\n",
      "Epoch 188/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5454 - accuracy: 0.7128 - auc: 0.7917 - val_loss: 0.5882 - val_accuracy: 0.6606 - val_auc: 0.7386\n",
      "Epoch 189/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5533 - accuracy: 0.7137 - auc: 0.7871 - val_loss: 0.5876 - val_accuracy: 0.6606 - val_auc: 0.7401\n",
      "Epoch 190/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5525 - accuracy: 0.7118 - auc: 0.7863 - val_loss: 0.5875 - val_accuracy: 0.6576 - val_auc: 0.7395\n",
      "Epoch 191/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5508 - accuracy: 0.7005 - auc: 0.7860 - val_loss: 0.5871 - val_accuracy: 0.6636 - val_auc: 0.7395\n",
      "Epoch 192/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5606 - accuracy: 0.6995 - auc: 0.7786 - val_loss: 0.5886 - val_accuracy: 0.6576 - val_auc: 0.7383\n",
      "Epoch 193/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5545 - accuracy: 0.6986 - auc: 0.7829 - val_loss: 0.5881 - val_accuracy: 0.6606 - val_auc: 0.7388\n",
      "Epoch 194/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5519 - accuracy: 0.7147 - auc: 0.7865 - val_loss: 0.5875 - val_accuracy: 0.6606 - val_auc: 0.7387\n",
      "Epoch 195/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5484 - accuracy: 0.7033 - auc: 0.7884 - val_loss: 0.5866 - val_accuracy: 0.6606 - val_auc: 0.7400\n",
      "Epoch 196/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5498 - accuracy: 0.7090 - auc: 0.7889 - val_loss: 0.5860 - val_accuracy: 0.6636 - val_auc: 0.7408\n",
      "Epoch 197/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5511 - accuracy: 0.7128 - auc: 0.7883 - val_loss: 0.5853 - val_accuracy: 0.6606 - val_auc: 0.7415\n",
      "Epoch 198/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5529 - accuracy: 0.7223 - auc: 0.7885 - val_loss: 0.5859 - val_accuracy: 0.6606 - val_auc: 0.7406\n",
      "Epoch 199/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5624 - accuracy: 0.6976 - auc: 0.7749 - val_loss: 0.5899 - val_accuracy: 0.6636 - val_auc: 0.7370\n",
      "Epoch 200/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5518 - accuracy: 0.7033 - auc: 0.7861 - val_loss: 0.5893 - val_accuracy: 0.6606 - val_auc: 0.7373\n",
      "Epoch 201/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5559 - accuracy: 0.7100 - auc: 0.7852 - val_loss: 0.5906 - val_accuracy: 0.6606 - val_auc: 0.7366\n",
      "Epoch 202/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5484 - accuracy: 0.7185 - auc: 0.7913 - val_loss: 0.5896 - val_accuracy: 0.6636 - val_auc: 0.7370\n",
      "Epoch 203/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5538 - accuracy: 0.7062 - auc: 0.7840 - val_loss: 0.5883 - val_accuracy: 0.6606 - val_auc: 0.7385\n",
      "Epoch 204/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5442 - accuracy: 0.7223 - auc: 0.7940 - val_loss: 0.5867 - val_accuracy: 0.6606 - val_auc: 0.7399\n",
      "Epoch 205/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5591 - accuracy: 0.6976 - auc: 0.7776 - val_loss: 0.5877 - val_accuracy: 0.6576 - val_auc: 0.7388\n",
      "Epoch 206/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5446 - accuracy: 0.7128 - auc: 0.7922 - val_loss: 0.5873 - val_accuracy: 0.6606 - val_auc: 0.7396\n",
      "Epoch 207/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5573 - accuracy: 0.6910 - auc: 0.7788 - val_loss: 0.5876 - val_accuracy: 0.6636 - val_auc: 0.7386\n",
      "Epoch 208/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5500 - accuracy: 0.7014 - auc: 0.7864 - val_loss: 0.5870 - val_accuracy: 0.6636 - val_auc: 0.7397\n",
      "Epoch 209/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5525 - accuracy: 0.7194 - auc: 0.7857 - val_loss: 0.5874 - val_accuracy: 0.6636 - val_auc: 0.7393\n",
      "Epoch 210/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5585 - accuracy: 0.7081 - auc: 0.7810 - val_loss: 0.5881 - val_accuracy: 0.6545 - val_auc: 0.7387\n",
      "Epoch 211/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5449 - accuracy: 0.7090 - auc: 0.7929 - val_loss: 0.5853 - val_accuracy: 0.6606 - val_auc: 0.7415\n",
      "Epoch 212/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5589 - accuracy: 0.6957 - auc: 0.7804 - val_loss: 0.5853 - val_accuracy: 0.6606 - val_auc: 0.7413\n",
      "Epoch 213/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5611 - accuracy: 0.6986 - auc: 0.7749 - val_loss: 0.5856 - val_accuracy: 0.6636 - val_auc: 0.7413\n",
      "Epoch 214/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5477 - accuracy: 0.7062 - auc: 0.7888 - val_loss: 0.5865 - val_accuracy: 0.6636 - val_auc: 0.7400\n",
      "Epoch 215/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5524 - accuracy: 0.7100 - auc: 0.7877 - val_loss: 0.5861 - val_accuracy: 0.6606 - val_auc: 0.7405\n",
      "Epoch 216/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5434 - accuracy: 0.7128 - auc: 0.7944 - val_loss: 0.5855 - val_accuracy: 0.6576 - val_auc: 0.7419\n",
      "Epoch 217/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5538 - accuracy: 0.7062 - auc: 0.7864 - val_loss: 0.5856 - val_accuracy: 0.6606 - val_auc: 0.7419\n",
      "Epoch 218/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5393 - accuracy: 0.7213 - auc: 0.7997 - val_loss: 0.5841 - val_accuracy: 0.6636 - val_auc: 0.7429\n",
      "Epoch 219/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5562 - accuracy: 0.7100 - auc: 0.7828 - val_loss: 0.5831 - val_accuracy: 0.6636 - val_auc: 0.7437\n",
      "Epoch 220/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5534 - accuracy: 0.7081 - auc: 0.7836 - val_loss: 0.5831 - val_accuracy: 0.6636 - val_auc: 0.7436\n",
      "Epoch 221/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5417 - accuracy: 0.7081 - auc: 0.7957 - val_loss: 0.5837 - val_accuracy: 0.6576 - val_auc: 0.7431\n",
      "Epoch 222/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5614 - accuracy: 0.6986 - auc: 0.7774 - val_loss: 0.5841 - val_accuracy: 0.6576 - val_auc: 0.7426\n",
      "Epoch 223/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5550 - accuracy: 0.7043 - auc: 0.7824 - val_loss: 0.5855 - val_accuracy: 0.6606 - val_auc: 0.7414\n",
      "Epoch 224/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5399 - accuracy: 0.7100 - auc: 0.7965 - val_loss: 0.5835 - val_accuracy: 0.6636 - val_auc: 0.7435\n",
      "Epoch 225/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5614 - accuracy: 0.6872 - auc: 0.7765 - val_loss: 0.5834 - val_accuracy: 0.6636 - val_auc: 0.7432\n",
      "Epoch 226/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5487 - accuracy: 0.7052 - auc: 0.7894 - val_loss: 0.5830 - val_accuracy: 0.6576 - val_auc: 0.7443\n",
      "Epoch 227/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5421 - accuracy: 0.7147 - auc: 0.7961 - val_loss: 0.5828 - val_accuracy: 0.6606 - val_auc: 0.7444\n",
      "Epoch 228/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5489 - accuracy: 0.7081 - auc: 0.7913 - val_loss: 0.5828 - val_accuracy: 0.6606 - val_auc: 0.7445\n",
      "Epoch 229/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5498 - accuracy: 0.6995 - auc: 0.7881 - val_loss: 0.5830 - val_accuracy: 0.6606 - val_auc: 0.7442\n",
      "Epoch 230/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5491 - accuracy: 0.7166 - auc: 0.7907 - val_loss: 0.5836 - val_accuracy: 0.6606 - val_auc: 0.7435\n",
      "Epoch 231/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5482 - accuracy: 0.7109 - auc: 0.7902 - val_loss: 0.5823 - val_accuracy: 0.6576 - val_auc: 0.7448\n",
      "Epoch 232/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5428 - accuracy: 0.7109 - auc: 0.7951 - val_loss: 0.5827 - val_accuracy: 0.6606 - val_auc: 0.7445\n",
      "Epoch 233/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5485 - accuracy: 0.7128 - auc: 0.7901 - val_loss: 0.5826 - val_accuracy: 0.6636 - val_auc: 0.7444\n",
      "Epoch 234/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5457 - accuracy: 0.7185 - auc: 0.7919 - val_loss: 0.5832 - val_accuracy: 0.6606 - val_auc: 0.7437\n",
      "Epoch 235/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5506 - accuracy: 0.7109 - auc: 0.7870 - val_loss: 0.5827 - val_accuracy: 0.6606 - val_auc: 0.7445\n",
      "Epoch 236/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5482 - accuracy: 0.7109 - auc: 0.7896 - val_loss: 0.5825 - val_accuracy: 0.6636 - val_auc: 0.7450\n",
      "Epoch 237/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5537 - accuracy: 0.7005 - auc: 0.7847 - val_loss: 0.5828 - val_accuracy: 0.6636 - val_auc: 0.7442\n",
      "Epoch 238/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5504 - accuracy: 0.7128 - auc: 0.7864 - val_loss: 0.5829 - val_accuracy: 0.6606 - val_auc: 0.7440\n",
      "Epoch 239/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5489 - accuracy: 0.7147 - auc: 0.7908 - val_loss: 0.5830 - val_accuracy: 0.6606 - val_auc: 0.7440\n",
      "Epoch 240/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5544 - accuracy: 0.7071 - auc: 0.7853 - val_loss: 0.5825 - val_accuracy: 0.6606 - val_auc: 0.7444\n",
      "Epoch 241/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5505 - accuracy: 0.7071 - auc: 0.7890 - val_loss: 0.5824 - val_accuracy: 0.6606 - val_auc: 0.7446\n",
      "Epoch 242/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5478 - accuracy: 0.7071 - auc: 0.7936 - val_loss: 0.5819 - val_accuracy: 0.6606 - val_auc: 0.7447\n",
      "Epoch 243/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5553 - accuracy: 0.6882 - auc: 0.7812 - val_loss: 0.5809 - val_accuracy: 0.6576 - val_auc: 0.7464\n",
      "Epoch 244/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5492 - accuracy: 0.7109 - auc: 0.7874 - val_loss: 0.5824 - val_accuracy: 0.6576 - val_auc: 0.7446\n",
      "Epoch 245/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5497 - accuracy: 0.7137 - auc: 0.7889 - val_loss: 0.5835 - val_accuracy: 0.6636 - val_auc: 0.7430\n",
      "Epoch 246/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5411 - accuracy: 0.7175 - auc: 0.7971 - val_loss: 0.5838 - val_accuracy: 0.6576 - val_auc: 0.7430\n",
      "Epoch 247/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5426 - accuracy: 0.7071 - auc: 0.7972 - val_loss: 0.5826 - val_accuracy: 0.6606 - val_auc: 0.7444\n",
      "Epoch 248/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5303 - accuracy: 0.7355 - auc: 0.8084 - val_loss: 0.5825 - val_accuracy: 0.6606 - val_auc: 0.7444\n",
      "Epoch 249/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5407 - accuracy: 0.6910 - auc: 0.7955 - val_loss: 0.5835 - val_accuracy: 0.6576 - val_auc: 0.7429\n",
      "Epoch 250/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5428 - accuracy: 0.7261 - auc: 0.7970 - val_loss: 0.5841 - val_accuracy: 0.6606 - val_auc: 0.7424\n",
      "Epoch 251/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5406 - accuracy: 0.7156 - auc: 0.7993 - val_loss: 0.5847 - val_accuracy: 0.6576 - val_auc: 0.7421\n",
      "Epoch 252/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5440 - accuracy: 0.7232 - auc: 0.7938 - val_loss: 0.5855 - val_accuracy: 0.6576 - val_auc: 0.7411\n",
      "Epoch 253/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5464 - accuracy: 0.7147 - auc: 0.7919 - val_loss: 0.5843 - val_accuracy: 0.6606 - val_auc: 0.7425\n",
      "Epoch 254/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5590 - accuracy: 0.7014 - auc: 0.7797 - val_loss: 0.5845 - val_accuracy: 0.6636 - val_auc: 0.7422\n",
      "Epoch 255/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5473 - accuracy: 0.7147 - auc: 0.7908 - val_loss: 0.5821 - val_accuracy: 0.6606 - val_auc: 0.7448\n",
      "Epoch 256/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5486 - accuracy: 0.7071 - auc: 0.7897 - val_loss: 0.5809 - val_accuracy: 0.6636 - val_auc: 0.7466\n",
      "Epoch 257/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5490 - accuracy: 0.7071 - auc: 0.7926 - val_loss: 0.5801 - val_accuracy: 0.6606 - val_auc: 0.7474\n",
      "Epoch 258/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5356 - accuracy: 0.7213 - auc: 0.8025 - val_loss: 0.5794 - val_accuracy: 0.6636 - val_auc: 0.7477\n",
      "Epoch 259/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5391 - accuracy: 0.7175 - auc: 0.7986 - val_loss: 0.5772 - val_accuracy: 0.6606 - val_auc: 0.7499\n",
      "Epoch 260/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5422 - accuracy: 0.7204 - auc: 0.7972 - val_loss: 0.5785 - val_accuracy: 0.6606 - val_auc: 0.7486\n",
      "Epoch 261/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5466 - accuracy: 0.7024 - auc: 0.7907 - val_loss: 0.5790 - val_accuracy: 0.6606 - val_auc: 0.7482\n",
      "Epoch 262/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5350 - accuracy: 0.7232 - auc: 0.8044 - val_loss: 0.5794 - val_accuracy: 0.6667 - val_auc: 0.7474\n",
      "Epoch 263/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5451 - accuracy: 0.7071 - auc: 0.7931 - val_loss: 0.5811 - val_accuracy: 0.6606 - val_auc: 0.7459\n",
      "Epoch 264/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5454 - accuracy: 0.7175 - auc: 0.7940 - val_loss: 0.5797 - val_accuracy: 0.6636 - val_auc: 0.7472\n",
      "Epoch 265/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5457 - accuracy: 0.7109 - auc: 0.7938 - val_loss: 0.5776 - val_accuracy: 0.6545 - val_auc: 0.7492\n",
      "Epoch 266/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5412 - accuracy: 0.7204 - auc: 0.7968 - val_loss: 0.5786 - val_accuracy: 0.6606 - val_auc: 0.7488\n",
      "Epoch 267/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5344 - accuracy: 0.7280 - auc: 0.8051 - val_loss: 0.5787 - val_accuracy: 0.6636 - val_auc: 0.7484\n",
      "Epoch 268/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5423 - accuracy: 0.7071 - auc: 0.7946 - val_loss: 0.5778 - val_accuracy: 0.6576 - val_auc: 0.7496\n",
      "Epoch 269/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5452 - accuracy: 0.7109 - auc: 0.7932 - val_loss: 0.5779 - val_accuracy: 0.6606 - val_auc: 0.7491\n",
      "Epoch 270/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5501 - accuracy: 0.7062 - auc: 0.7869 - val_loss: 0.5771 - val_accuracy: 0.6636 - val_auc: 0.7501\n",
      "Epoch 271/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5435 - accuracy: 0.7175 - auc: 0.7954 - val_loss: 0.5772 - val_accuracy: 0.6636 - val_auc: 0.7498\n",
      "Epoch 272/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5411 - accuracy: 0.7175 - auc: 0.7969 - val_loss: 0.5775 - val_accuracy: 0.6667 - val_auc: 0.7493\n",
      "Epoch 273/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5415 - accuracy: 0.7071 - auc: 0.7980 - val_loss: 0.5793 - val_accuracy: 0.6667 - val_auc: 0.7476\n",
      "Epoch 274/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5408 - accuracy: 0.7081 - auc: 0.7956 - val_loss: 0.5787 - val_accuracy: 0.6667 - val_auc: 0.7480\n",
      "Epoch 275/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5360 - accuracy: 0.7232 - auc: 0.8013 - val_loss: 0.5790 - val_accuracy: 0.6667 - val_auc: 0.7480\n",
      "Epoch 276/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5480 - accuracy: 0.7043 - auc: 0.7905 - val_loss: 0.5786 - val_accuracy: 0.6697 - val_auc: 0.7489\n",
      "Epoch 277/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5421 - accuracy: 0.7109 - auc: 0.7945 - val_loss: 0.5796 - val_accuracy: 0.6636 - val_auc: 0.7480\n",
      "Epoch 278/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5380 - accuracy: 0.7280 - auc: 0.8013 - val_loss: 0.5797 - val_accuracy: 0.6636 - val_auc: 0.7478\n",
      "Epoch 279/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5418 - accuracy: 0.7128 - auc: 0.7974 - val_loss: 0.5803 - val_accuracy: 0.6636 - val_auc: 0.7468\n",
      "Epoch 280/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5443 - accuracy: 0.7156 - auc: 0.7956 - val_loss: 0.5805 - val_accuracy: 0.6636 - val_auc: 0.7467\n",
      "Epoch 281/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5415 - accuracy: 0.7118 - auc: 0.7961 - val_loss: 0.5790 - val_accuracy: 0.6636 - val_auc: 0.7487\n",
      "Epoch 282/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5353 - accuracy: 0.7213 - auc: 0.8024 - val_loss: 0.5784 - val_accuracy: 0.6636 - val_auc: 0.7489\n",
      "Epoch 283/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5349 - accuracy: 0.7213 - auc: 0.8034 - val_loss: 0.5795 - val_accuracy: 0.6636 - val_auc: 0.7475\n",
      "Epoch 284/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5458 - accuracy: 0.7137 - auc: 0.7917 - val_loss: 0.5794 - val_accuracy: 0.6636 - val_auc: 0.7477\n",
      "Epoch 285/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5400 - accuracy: 0.7118 - auc: 0.7969 - val_loss: 0.5775 - val_accuracy: 0.6697 - val_auc: 0.7497\n",
      "Epoch 286/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5404 - accuracy: 0.7156 - auc: 0.7956 - val_loss: 0.5783 - val_accuracy: 0.6636 - val_auc: 0.7489\n",
      "Epoch 287/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5480 - accuracy: 0.7118 - auc: 0.7865 - val_loss: 0.5793 - val_accuracy: 0.6697 - val_auc: 0.7480\n",
      "Epoch 288/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5339 - accuracy: 0.7280 - auc: 0.8057 - val_loss: 0.5786 - val_accuracy: 0.6667 - val_auc: 0.7482\n",
      "Epoch 289/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5427 - accuracy: 0.7156 - auc: 0.7955 - val_loss: 0.5784 - val_accuracy: 0.6758 - val_auc: 0.7484\n",
      "Epoch 290/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5462 - accuracy: 0.7071 - auc: 0.7906 - val_loss: 0.5774 - val_accuracy: 0.6758 - val_auc: 0.7500\n",
      "Epoch 291/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5428 - accuracy: 0.7185 - auc: 0.7930 - val_loss: 0.5789 - val_accuracy: 0.6727 - val_auc: 0.7484\n",
      "Epoch 292/700\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.5341 - accuracy: 0.7156 - auc: 0.8041 - val_loss: 0.5782 - val_accuracy: 0.6667 - val_auc: 0.7487\n",
      "Epoch 293/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5403 - accuracy: 0.7166 - auc: 0.7966 - val_loss: 0.5779 - val_accuracy: 0.6697 - val_auc: 0.7495\n",
      "Epoch 294/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5501 - accuracy: 0.7118 - auc: 0.7886 - val_loss: 0.5780 - val_accuracy: 0.6697 - val_auc: 0.7489\n",
      "Epoch 295/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5445 - accuracy: 0.7137 - auc: 0.7931 - val_loss: 0.5779 - val_accuracy: 0.6697 - val_auc: 0.7491\n",
      "Epoch 296/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5469 - accuracy: 0.7242 - auc: 0.7929 - val_loss: 0.5777 - val_accuracy: 0.6727 - val_auc: 0.7493\n",
      "Epoch 297/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5419 - accuracy: 0.7062 - auc: 0.7946 - val_loss: 0.5773 - val_accuracy: 0.6697 - val_auc: 0.7499\n",
      "Epoch 298/700\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.5392 - accuracy: 0.7280 - auc: 0.8010 - val_loss: 0.5761 - val_accuracy: 0.6758 - val_auc: 0.7511\n",
      "Epoch 299/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5427 - accuracy: 0.7100 - auc: 0.7952 - val_loss: 0.5788 - val_accuracy: 0.6727 - val_auc: 0.7480\n",
      "Epoch 300/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5392 - accuracy: 0.7071 - auc: 0.7976 - val_loss: 0.5791 - val_accuracy: 0.6697 - val_auc: 0.7479\n",
      "Epoch 301/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5443 - accuracy: 0.7147 - auc: 0.7927 - val_loss: 0.5762 - val_accuracy: 0.6727 - val_auc: 0.7510\n",
      "Epoch 302/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5365 - accuracy: 0.7270 - auc: 0.8043 - val_loss: 0.5755 - val_accuracy: 0.6727 - val_auc: 0.7517\n",
      "Epoch 303/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5298 - accuracy: 0.7204 - auc: 0.8062 - val_loss: 0.5755 - val_accuracy: 0.6758 - val_auc: 0.7515\n",
      "Epoch 304/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5313 - accuracy: 0.7251 - auc: 0.8075 - val_loss: 0.5755 - val_accuracy: 0.6667 - val_auc: 0.7515\n",
      "Epoch 305/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5451 - accuracy: 0.7118 - auc: 0.7921 - val_loss: 0.5754 - val_accuracy: 0.6727 - val_auc: 0.7518\n",
      "Epoch 306/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5402 - accuracy: 0.7251 - auc: 0.8018 - val_loss: 0.5755 - val_accuracy: 0.6758 - val_auc: 0.7513\n",
      "Epoch 307/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5327 - accuracy: 0.7242 - auc: 0.8041 - val_loss: 0.5755 - val_accuracy: 0.6727 - val_auc: 0.7514\n",
      "Epoch 308/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5445 - accuracy: 0.7223 - auc: 0.7944 - val_loss: 0.5767 - val_accuracy: 0.6697 - val_auc: 0.7507\n",
      "Epoch 309/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5490 - accuracy: 0.7204 - auc: 0.7916 - val_loss: 0.5779 - val_accuracy: 0.6697 - val_auc: 0.7490\n",
      "Epoch 310/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5451 - accuracy: 0.7128 - auc: 0.7950 - val_loss: 0.5772 - val_accuracy: 0.6727 - val_auc: 0.7502\n",
      "Epoch 311/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5344 - accuracy: 0.7128 - auc: 0.8022 - val_loss: 0.5751 - val_accuracy: 0.6758 - val_auc: 0.7519\n",
      "Epoch 312/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5406 - accuracy: 0.7147 - auc: 0.7991 - val_loss: 0.5755 - val_accuracy: 0.6697 - val_auc: 0.7517\n",
      "Epoch 313/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5333 - accuracy: 0.7213 - auc: 0.8052 - val_loss: 0.5752 - val_accuracy: 0.6636 - val_auc: 0.7519\n",
      "Epoch 314/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5363 - accuracy: 0.7289 - auc: 0.8027 - val_loss: 0.5754 - val_accuracy: 0.6667 - val_auc: 0.7517\n",
      "Epoch 315/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5409 - accuracy: 0.6995 - auc: 0.7970 - val_loss: 0.5748 - val_accuracy: 0.6667 - val_auc: 0.7519\n",
      "Epoch 316/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5378 - accuracy: 0.7223 - auc: 0.8024 - val_loss: 0.5740 - val_accuracy: 0.6667 - val_auc: 0.7530\n",
      "Epoch 317/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5361 - accuracy: 0.7194 - auc: 0.7994 - val_loss: 0.5761 - val_accuracy: 0.6697 - val_auc: 0.7512\n",
      "Epoch 318/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5413 - accuracy: 0.7147 - auc: 0.7957 - val_loss: 0.5747 - val_accuracy: 0.6758 - val_auc: 0.7526\n",
      "Epoch 319/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5389 - accuracy: 0.7033 - auc: 0.7966 - val_loss: 0.5745 - val_accuracy: 0.6788 - val_auc: 0.7527\n",
      "Epoch 320/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5433 - accuracy: 0.7128 - auc: 0.7941 - val_loss: 0.5756 - val_accuracy: 0.6727 - val_auc: 0.7519\n",
      "Epoch 321/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5346 - accuracy: 0.7232 - auc: 0.8043 - val_loss: 0.5761 - val_accuracy: 0.6727 - val_auc: 0.7513\n",
      "Epoch 322/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5513 - accuracy: 0.7128 - auc: 0.7891 - val_loss: 0.5748 - val_accuracy: 0.6727 - val_auc: 0.7525\n",
      "Epoch 323/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5367 - accuracy: 0.7137 - auc: 0.8020 - val_loss: 0.5746 - val_accuracy: 0.6758 - val_auc: 0.7523\n",
      "Epoch 324/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5359 - accuracy: 0.7118 - auc: 0.8009 - val_loss: 0.5733 - val_accuracy: 0.6788 - val_auc: 0.7540\n",
      "Epoch 325/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5321 - accuracy: 0.7232 - auc: 0.8046 - val_loss: 0.5727 - val_accuracy: 0.6788 - val_auc: 0.7546\n",
      "Epoch 326/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5304 - accuracy: 0.7109 - auc: 0.8050 - val_loss: 0.5727 - val_accuracy: 0.6788 - val_auc: 0.7542\n",
      "Epoch 327/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5293 - accuracy: 0.7327 - auc: 0.8106 - val_loss: 0.5707 - val_accuracy: 0.6758 - val_auc: 0.7566\n",
      "Epoch 328/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5250 - accuracy: 0.7374 - auc: 0.8146 - val_loss: 0.5711 - val_accuracy: 0.6818 - val_auc: 0.7560\n",
      "Epoch 329/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5351 - accuracy: 0.7384 - auc: 0.8039 - val_loss: 0.5718 - val_accuracy: 0.6818 - val_auc: 0.7552\n",
      "Epoch 330/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5313 - accuracy: 0.7185 - auc: 0.8064 - val_loss: 0.5731 - val_accuracy: 0.6758 - val_auc: 0.7540\n",
      "Epoch 331/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5401 - accuracy: 0.7175 - auc: 0.7983 - val_loss: 0.5720 - val_accuracy: 0.6788 - val_auc: 0.7553\n",
      "Epoch 332/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5319 - accuracy: 0.7308 - auc: 0.8087 - val_loss: 0.5736 - val_accuracy: 0.6758 - val_auc: 0.7531\n",
      "Epoch 333/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5394 - accuracy: 0.7043 - auc: 0.7958 - val_loss: 0.5738 - val_accuracy: 0.6758 - val_auc: 0.7528\n",
      "Epoch 334/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5410 - accuracy: 0.7223 - auc: 0.7970 - val_loss: 0.5758 - val_accuracy: 0.6788 - val_auc: 0.7508\n",
      "Epoch 335/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5359 - accuracy: 0.7194 - auc: 0.7999 - val_loss: 0.5741 - val_accuracy: 0.6758 - val_auc: 0.7528\n",
      "Epoch 336/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5375 - accuracy: 0.7090 - auc: 0.8003 - val_loss: 0.5722 - val_accuracy: 0.6818 - val_auc: 0.7547\n",
      "Epoch 337/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5376 - accuracy: 0.7365 - auc: 0.8049 - val_loss: 0.5730 - val_accuracy: 0.6818 - val_auc: 0.7537\n",
      "Epoch 338/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5370 - accuracy: 0.7156 - auc: 0.8014 - val_loss: 0.5723 - val_accuracy: 0.6788 - val_auc: 0.7544\n",
      "Epoch 339/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5452 - accuracy: 0.7100 - auc: 0.7911 - val_loss: 0.5731 - val_accuracy: 0.6758 - val_auc: 0.7536\n",
      "Epoch 340/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5283 - accuracy: 0.7251 - auc: 0.8084 - val_loss: 0.5738 - val_accuracy: 0.6758 - val_auc: 0.7528\n",
      "Epoch 341/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5373 - accuracy: 0.7204 - auc: 0.8012 - val_loss: 0.5712 - val_accuracy: 0.6788 - val_auc: 0.7563\n",
      "Epoch 342/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5263 - accuracy: 0.7308 - auc: 0.8116 - val_loss: 0.5716 - val_accuracy: 0.6788 - val_auc: 0.7555\n",
      "Epoch 343/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5332 - accuracy: 0.7261 - auc: 0.8056 - val_loss: 0.5707 - val_accuracy: 0.6818 - val_auc: 0.7563\n",
      "Epoch 344/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5383 - accuracy: 0.7213 - auc: 0.8017 - val_loss: 0.5709 - val_accuracy: 0.6848 - val_auc: 0.7562\n",
      "Epoch 345/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5277 - accuracy: 0.7318 - auc: 0.8084 - val_loss: 0.5698 - val_accuracy: 0.6788 - val_auc: 0.7574\n",
      "Epoch 346/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5271 - accuracy: 0.7374 - auc: 0.8103 - val_loss: 0.5697 - val_accuracy: 0.6818 - val_auc: 0.7577\n",
      "Epoch 347/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5395 - accuracy: 0.7090 - auc: 0.7989 - val_loss: 0.5697 - val_accuracy: 0.6818 - val_auc: 0.7572\n",
      "Epoch 348/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5324 - accuracy: 0.7346 - auc: 0.8056 - val_loss: 0.5694 - val_accuracy: 0.6758 - val_auc: 0.7576\n",
      "Epoch 349/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5350 - accuracy: 0.7166 - auc: 0.8006 - val_loss: 0.5686 - val_accuracy: 0.6788 - val_auc: 0.7584\n",
      "Epoch 350/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5266 - accuracy: 0.7355 - auc: 0.8115 - val_loss: 0.5716 - val_accuracy: 0.6727 - val_auc: 0.7554\n",
      "Epoch 351/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5391 - accuracy: 0.7213 - auc: 0.7989 - val_loss: 0.5710 - val_accuracy: 0.6758 - val_auc: 0.7555\n",
      "Epoch 352/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5379 - accuracy: 0.7204 - auc: 0.8001 - val_loss: 0.5696 - val_accuracy: 0.6758 - val_auc: 0.7581\n",
      "Epoch 353/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5380 - accuracy: 0.7223 - auc: 0.8008 - val_loss: 0.5711 - val_accuracy: 0.6727 - val_auc: 0.7555\n",
      "Epoch 354/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5320 - accuracy: 0.7336 - auc: 0.8050 - val_loss: 0.5708 - val_accuracy: 0.6727 - val_auc: 0.7557\n",
      "Epoch 355/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5362 - accuracy: 0.7213 - auc: 0.8006 - val_loss: 0.5718 - val_accuracy: 0.6727 - val_auc: 0.7554\n",
      "Epoch 356/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5302 - accuracy: 0.7137 - auc: 0.8048 - val_loss: 0.5734 - val_accuracy: 0.6727 - val_auc: 0.7530\n",
      "Epoch 357/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5246 - accuracy: 0.7194 - auc: 0.8132 - val_loss: 0.5726 - val_accuracy: 0.6727 - val_auc: 0.7541\n",
      "Epoch 358/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5350 - accuracy: 0.7261 - auc: 0.8064 - val_loss: 0.5735 - val_accuracy: 0.6758 - val_auc: 0.7532\n",
      "Epoch 359/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5366 - accuracy: 0.7166 - auc: 0.7997 - val_loss: 0.5742 - val_accuracy: 0.6758 - val_auc: 0.7529\n",
      "Epoch 360/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5386 - accuracy: 0.7299 - auc: 0.7997 - val_loss: 0.5758 - val_accuracy: 0.6697 - val_auc: 0.7516\n",
      "Epoch 361/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5365 - accuracy: 0.7118 - auc: 0.8003 - val_loss: 0.5745 - val_accuracy: 0.6636 - val_auc: 0.7528\n",
      "Epoch 362/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5336 - accuracy: 0.7166 - auc: 0.8042 - val_loss: 0.5740 - val_accuracy: 0.6667 - val_auc: 0.7531\n",
      "Epoch 363/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5392 - accuracy: 0.7052 - auc: 0.7971 - val_loss: 0.5741 - val_accuracy: 0.6727 - val_auc: 0.7528\n",
      "Epoch 364/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5299 - accuracy: 0.7289 - auc: 0.8081 - val_loss: 0.5714 - val_accuracy: 0.6727 - val_auc: 0.7560\n",
      "Epoch 365/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5238 - accuracy: 0.7441 - auc: 0.8141 - val_loss: 0.5713 - val_accuracy: 0.6697 - val_auc: 0.7563\n",
      "Epoch 366/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5363 - accuracy: 0.7318 - auc: 0.8029 - val_loss: 0.5732 - val_accuracy: 0.6667 - val_auc: 0.7543\n",
      "Epoch 367/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5324 - accuracy: 0.7223 - auc: 0.8066 - val_loss: 0.5716 - val_accuracy: 0.6697 - val_auc: 0.7554\n",
      "Epoch 368/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5261 - accuracy: 0.7251 - auc: 0.8110 - val_loss: 0.5716 - val_accuracy: 0.6727 - val_auc: 0.7556\n",
      "Epoch 369/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5411 - accuracy: 0.7090 - auc: 0.7971 - val_loss: 0.5717 - val_accuracy: 0.6727 - val_auc: 0.7552\n",
      "Epoch 370/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5381 - accuracy: 0.7232 - auc: 0.8008 - val_loss: 0.5723 - val_accuracy: 0.6727 - val_auc: 0.7549\n",
      "Epoch 371/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5380 - accuracy: 0.7194 - auc: 0.7984 - val_loss: 0.5702 - val_accuracy: 0.6788 - val_auc: 0.7570\n",
      "Epoch 372/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5358 - accuracy: 0.7109 - auc: 0.8024 - val_loss: 0.5722 - val_accuracy: 0.6697 - val_auc: 0.7551\n",
      "Epoch 373/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5329 - accuracy: 0.7194 - auc: 0.8041 - val_loss: 0.5708 - val_accuracy: 0.6758 - val_auc: 0.7559\n",
      "Epoch 374/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5379 - accuracy: 0.7062 - auc: 0.7991 - val_loss: 0.5724 - val_accuracy: 0.6727 - val_auc: 0.7542\n",
      "Epoch 375/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5341 - accuracy: 0.7137 - auc: 0.8018 - val_loss: 0.5717 - val_accuracy: 0.6758 - val_auc: 0.7550\n",
      "Epoch 376/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5391 - accuracy: 0.7213 - auc: 0.7992 - val_loss: 0.5721 - val_accuracy: 0.6758 - val_auc: 0.7552\n",
      "Epoch 377/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5348 - accuracy: 0.7175 - auc: 0.8048 - val_loss: 0.5715 - val_accuracy: 0.6727 - val_auc: 0.7562\n",
      "Epoch 378/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5282 - accuracy: 0.7213 - auc: 0.8084 - val_loss: 0.5734 - val_accuracy: 0.6788 - val_auc: 0.7537\n",
      "Epoch 379/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5321 - accuracy: 0.7185 - auc: 0.8054 - val_loss: 0.5720 - val_accuracy: 0.6727 - val_auc: 0.7547\n",
      "Epoch 00379: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('disgust_ravdess.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1596127689964,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1596127702897,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "be2740c6-f70e-4814-f540-50bd614fca49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5685762763023376\n",
      "accuracy :  0.678787887096405\n",
      "auc :  0.7584205865859985\n",
      "\n",
      "(True Negatives):  129\n",
      "(False Positives):  72\n",
      "(False Negatives):  34\n",
      "(True Positives):  95\n",
      "Total emotions_happy:  129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71       201\n",
      "           1       0.57      0.74      0.64       129\n",
      "\n",
      "    accuracy                           0.68       330\n",
      "   macro avg       0.68      0.69      0.68       330\n",
      "weighted avg       0.70      0.68      0.68       330\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('disgust_ravdess.hdf5')\n",
    "test_predictions_baseline = model.predict(X_test)\n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1596127742778,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "ab1a296d-f575-4e54-fe3d-7409fba6a9ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5591848492622375\n",
      "accuracy :  0.7121211886405945\n",
      "auc :  0.7826848030090332\n",
      "\n",
      "(True Negatives):  125\n",
      "(False Positives):  60\n",
      "(False Negatives):  16\n",
      "(True Positives):  63\n",
      "Total emotions_happy:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.68      0.77       185\n",
      "           1       0.51      0.80      0.62        79\n",
      "\n",
      "    accuracy                           0.71       264\n",
      "   macro avg       0.70      0.74      0.70       264\n",
      "weighted avg       0.77      0.71      0.72       264\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val)\n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyObaf+cF4lwAS7v4nIAna4A",
   "name": "deep_disgust_RAVDESS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
