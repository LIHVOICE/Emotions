{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "#Deep learning\n",
    "\n",
    "### Plot imports ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns \n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11652,
     "status": "ok",
     "timestamp": 1596536207293,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "6e0ad854-7ac8-4b2c-fbc6-3f88fdd61733"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad/03-01-04-02-01-01-02_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry/03-01-05-01-01-01-12_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fearfull/03-01-06-02-01-01-03_norm_outNoise.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprised/03-01-08-01-02-02-05_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprised/03-01-08-02-02-02-12_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              audio label\n",
       "0        sad/03-01-04-02-01-01-02_norm_outNoise.wav     0\n",
       "1      angry/03-01-05-01-01-01-12_norm_outNoise.wav     0\n",
       "2   fearfull/03-01-06-02-01-01-03_norm_outNoise.wav     1\n",
       "3  surprised/03-01-08-01-02-02-05_norm_outNoise.wav     0\n",
       "4  surprised/03-01-08-02-02-02-12_norm_outNoise.wav     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"ravdess\" #audio data folder\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i[7] == '6':   ##this specifies that we class fearfull emotion against the others\n",
    "                                    #6 represents the 7th column of the file name\n",
    "                                    # This number varies for each emotion(ex calm = '2', disgust = '7')\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) #adding values to the defined df:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1596536211341,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "c10dcadb-7e56-40e6-a153-689ff6991e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1053\n",
      "1     192\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjNAMwsfG2C8"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    fs, sig = scipy.io.wavfile.read(audio_path) \n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    spec =  fram_window(audio_path) \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)\n",
    "            \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "               \n",
    "    #gfccs = gfcc(sig= spec, fs=fs, num_ceps=13)    \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    #features.append(np.mean(gfccs))\n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(parent_dir+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 787,
     "status": "ok",
     "timestamp": 1596539410658,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "43c5a242-d589-42f4-8163-5dca8466cff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1596123214565,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "7f9157d2-17c8-4c30-c9a9-9aec42d6f89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 601\n",
      "After OverSampling, counts of label '0': 1053\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \" [1, 2, 3, 5, 8, 18, 19, 21]  \" are deleted 432 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28548,
     "status": "ok",
     "timestamp": 1596123276508,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "a7baa426-5cf0-4ebe-fe0e-905fc7ca1dfe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 5, 8, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 2, 3, 5, 8, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 2, 3, 5, 8, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 3, 5, 8, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1, 2, 3, 5, 8, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration                       X_removed\n",
       "0         1     [1, 2, 3, 5, 8, 18, 19, 21]\n",
       "1         2  [0, 1, 2, 3, 5, 8, 18, 19, 21]\n",
       "2         3  [0, 1, 2, 3, 5, 8, 18, 19, 21]\n",
       "3         4     [1, 2, 3, 5, 8, 18, 19, 21]\n",
       "4         5  [0, 1, 2, 3, 5, 8, 18, 19, 21]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5, 8, 18, 19, 21]           432\n",
       "[0, 1, 2, 3, 5, 8, 18, 19, 21]        346\n",
       "[1, 2, 3, 5, 8, 14, 18, 19, 21]       154\n",
       "[0, 1, 2, 3, 5, 8, 14, 18, 19, 21]     68\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sTQj5wDWdev"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0],  X[i][4], X[i][6], X[i][7], X[i][9], X[i][10],\n",
    "               X[i][11], X[i][12], X[i][13],  X[i][14], \n",
    "                X[i][15], X[i][16], X[i][17], X[i][20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 739,
     "status": "ok",
     "timestamp": 1596123597639,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "2fab1c81-f4ed-4e49-bc2e-3e3d24a34852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1058\n",
      "331\n",
      "265\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1596123656845,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "cb9d884d-672d-44cf-c3cf-1f2c899b2690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1058, 14, 1)\n",
      "(331, 14, 1)\n",
      "(265, 14, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1596123684486,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "6180d7af-8192-446a-cdbe-26e438393771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1058, 2)\n",
      "(331, 2)\n",
      "(265, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (14,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1037,
     "status": "ok",
     "timestamp": 1596123739790,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "ed3df0a0-1c23-48b2-ec05-553a7efcf6f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 14, 1)]           0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 14, 128)           768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 14, 128)           512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 14, 128)           82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 3586      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 86,922\n",
      "Trainable params: 86,662\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 195665,
     "status": "ok",
     "timestamp": 1596123970109,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "a99ffb5f-c3eb-4397-a5b7-144d6c503ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.8106 - accuracy: 0.5246 - auc: 0.5524 - val_loss: 0.6772 - val_accuracy: 0.6042 - val_auc: 0.6349\n",
      "Epoch 2/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.7664 - accuracy: 0.5548 - auc: 0.5787 - val_loss: 0.6675 - val_accuracy: 0.6435 - val_auc: 0.6956\n",
      "Epoch 3/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.7479 - accuracy: 0.5699 - auc: 0.6028 - val_loss: 0.6614 - val_accuracy: 0.6828 - val_auc: 0.7246\n",
      "Epoch 4/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.7434 - accuracy: 0.5614 - auc: 0.5903 - val_loss: 0.6561 - val_accuracy: 0.6949 - val_auc: 0.7414\n",
      "Epoch 5/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.7151 - accuracy: 0.5870 - auc: 0.6108 - val_loss: 0.6526 - val_accuracy: 0.7009 - val_auc: 0.7553\n",
      "Epoch 6/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.6973 - accuracy: 0.5964 - auc: 0.6218 - val_loss: 0.6516 - val_accuracy: 0.6918 - val_auc: 0.7541\n",
      "Epoch 7/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6904 - accuracy: 0.6144 - auc: 0.6422 - val_loss: 0.6509 - val_accuracy: 0.6949 - val_auc: 0.7538\n",
      "Epoch 8/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6852 - accuracy: 0.5945 - auc: 0.6325 - val_loss: 0.6504 - val_accuracy: 0.6858 - val_auc: 0.7461\n",
      "Epoch 9/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6713 - accuracy: 0.5945 - auc: 0.6453 - val_loss: 0.6492 - val_accuracy: 0.6677 - val_auc: 0.7374\n",
      "Epoch 10/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6851 - accuracy: 0.5898 - auc: 0.6306 - val_loss: 0.6476 - val_accuracy: 0.6677 - val_auc: 0.7330\n",
      "Epoch 11/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6711 - accuracy: 0.6144 - auc: 0.6466 - val_loss: 0.6470 - val_accuracy: 0.6798 - val_auc: 0.7262\n",
      "Epoch 12/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6739 - accuracy: 0.5945 - auc: 0.6377 - val_loss: 0.6465 - val_accuracy: 0.6586 - val_auc: 0.7212\n",
      "Epoch 13/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6604 - accuracy: 0.6238 - auc: 0.6653 - val_loss: 0.6452 - val_accuracy: 0.6586 - val_auc: 0.7185\n",
      "Epoch 14/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6590 - accuracy: 0.6210 - auc: 0.6602 - val_loss: 0.6453 - val_accuracy: 0.6375 - val_auc: 0.7069\n",
      "Epoch 15/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6550 - accuracy: 0.6172 - auc: 0.6692 - val_loss: 0.6438 - val_accuracy: 0.6465 - val_auc: 0.7086\n",
      "Epoch 16/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6461 - accuracy: 0.6465 - auc: 0.6863 - val_loss: 0.6427 - val_accuracy: 0.6375 - val_auc: 0.7053\n",
      "Epoch 17/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6508 - accuracy: 0.6352 - auc: 0.6764 - val_loss: 0.6418 - val_accuracy: 0.6314 - val_auc: 0.7003\n",
      "Epoch 18/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6465 - accuracy: 0.6172 - auc: 0.6780 - val_loss: 0.6403 - val_accuracy: 0.6314 - val_auc: 0.6989\n",
      "Epoch 19/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6446 - accuracy: 0.6352 - auc: 0.6867 - val_loss: 0.6397 - val_accuracy: 0.6375 - val_auc: 0.6966\n",
      "Epoch 20/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6445 - accuracy: 0.6389 - auc: 0.6845 - val_loss: 0.6381 - val_accuracy: 0.6405 - val_auc: 0.6979\n",
      "Epoch 21/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6428 - accuracy: 0.6380 - auc: 0.6886 - val_loss: 0.6365 - val_accuracy: 0.6405 - val_auc: 0.6988\n",
      "Epoch 22/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6435 - accuracy: 0.6437 - auc: 0.6827 - val_loss: 0.6346 - val_accuracy: 0.6284 - val_auc: 0.6996\n",
      "Epoch 23/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6371 - accuracy: 0.6512 - auc: 0.6964 - val_loss: 0.6316 - val_accuracy: 0.6375 - val_auc: 0.7034\n",
      "Epoch 24/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6408 - accuracy: 0.6456 - auc: 0.6874 - val_loss: 0.6288 - val_accuracy: 0.6435 - val_auc: 0.7068\n",
      "Epoch 25/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6356 - accuracy: 0.6380 - auc: 0.6960 - val_loss: 0.6277 - val_accuracy: 0.6375 - val_auc: 0.7075\n",
      "Epoch 26/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.6395 - accuracy: 0.6569 - auc: 0.7002 - val_loss: 0.6253 - val_accuracy: 0.6435 - val_auc: 0.7105\n",
      "Epoch 27/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6385 - accuracy: 0.6550 - auc: 0.6943 - val_loss: 0.6232 - val_accuracy: 0.6495 - val_auc: 0.7127\n",
      "Epoch 28/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6322 - accuracy: 0.6597 - auc: 0.7075 - val_loss: 0.6219 - val_accuracy: 0.6465 - val_auc: 0.7143\n",
      "Epoch 29/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6378 - accuracy: 0.6484 - auc: 0.6921 - val_loss: 0.6204 - val_accuracy: 0.6526 - val_auc: 0.7163\n",
      "Epoch 30/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6410 - accuracy: 0.6427 - auc: 0.6886 - val_loss: 0.6194 - val_accuracy: 0.6495 - val_auc: 0.7163\n",
      "Epoch 31/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6289 - accuracy: 0.6597 - auc: 0.7042 - val_loss: 0.6171 - val_accuracy: 0.6586 - val_auc: 0.7207\n",
      "Epoch 32/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6400 - accuracy: 0.6503 - auc: 0.6962 - val_loss: 0.6166 - val_accuracy: 0.6556 - val_auc: 0.7207\n",
      "Epoch 33/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6263 - accuracy: 0.6597 - auc: 0.7117 - val_loss: 0.6154 - val_accuracy: 0.6556 - val_auc: 0.7219\n",
      "Epoch 34/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6342 - accuracy: 0.6560 - auc: 0.6974 - val_loss: 0.6136 - val_accuracy: 0.6495 - val_auc: 0.7258\n",
      "Epoch 35/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6354 - accuracy: 0.6456 - auc: 0.6975 - val_loss: 0.6112 - val_accuracy: 0.6556 - val_auc: 0.7300\n",
      "Epoch 36/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6296 - accuracy: 0.6682 - auc: 0.7109 - val_loss: 0.6097 - val_accuracy: 0.6616 - val_auc: 0.7318\n",
      "Epoch 37/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6273 - accuracy: 0.6569 - auc: 0.7074 - val_loss: 0.6084 - val_accuracy: 0.6616 - val_auc: 0.7337\n",
      "Epoch 38/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6331 - accuracy: 0.6626 - auc: 0.7091 - val_loss: 0.6077 - val_accuracy: 0.6677 - val_auc: 0.7345\n",
      "Epoch 39/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6326 - accuracy: 0.6616 - auc: 0.7009 - val_loss: 0.6068 - val_accuracy: 0.6677 - val_auc: 0.7357\n",
      "Epoch 40/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6317 - accuracy: 0.6333 - auc: 0.6996 - val_loss: 0.6068 - val_accuracy: 0.6647 - val_auc: 0.7352\n",
      "Epoch 41/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6236 - accuracy: 0.6767 - auc: 0.7146 - val_loss: 0.6060 - val_accuracy: 0.6647 - val_auc: 0.7358\n",
      "Epoch 42/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6350 - accuracy: 0.6560 - auc: 0.6991 - val_loss: 0.6060 - val_accuracy: 0.6556 - val_auc: 0.7357\n",
      "Epoch 43/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6211 - accuracy: 0.6664 - auc: 0.7185 - val_loss: 0.6061 - val_accuracy: 0.6616 - val_auc: 0.7350\n",
      "Epoch 44/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6208 - accuracy: 0.6749 - auc: 0.7184 - val_loss: 0.6063 - val_accuracy: 0.6647 - val_auc: 0.7350\n",
      "Epoch 45/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6326 - accuracy: 0.6512 - auc: 0.7023 - val_loss: 0.6053 - val_accuracy: 0.6616 - val_auc: 0.7362\n",
      "Epoch 46/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6194 - accuracy: 0.6597 - auc: 0.7176 - val_loss: 0.6061 - val_accuracy: 0.6616 - val_auc: 0.7341\n",
      "Epoch 47/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6202 - accuracy: 0.6720 - auc: 0.7219 - val_loss: 0.6072 - val_accuracy: 0.6647 - val_auc: 0.7324\n",
      "Epoch 48/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6271 - accuracy: 0.6749 - auc: 0.7164 - val_loss: 0.6057 - val_accuracy: 0.6586 - val_auc: 0.7350\n",
      "Epoch 49/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6235 - accuracy: 0.6815 - auc: 0.7171 - val_loss: 0.6067 - val_accuracy: 0.6616 - val_auc: 0.7335\n",
      "Epoch 50/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6328 - accuracy: 0.6550 - auc: 0.7013 - val_loss: 0.6058 - val_accuracy: 0.6616 - val_auc: 0.7354\n",
      "Epoch 51/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6272 - accuracy: 0.6635 - auc: 0.7109 - val_loss: 0.6058 - val_accuracy: 0.6586 - val_auc: 0.7347\n",
      "Epoch 52/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6279 - accuracy: 0.6588 - auc: 0.7093 - val_loss: 0.6045 - val_accuracy: 0.6586 - val_auc: 0.7368\n",
      "Epoch 53/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6292 - accuracy: 0.6682 - auc: 0.7106 - val_loss: 0.6033 - val_accuracy: 0.6616 - val_auc: 0.7387\n",
      "Epoch 54/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6180 - accuracy: 0.6749 - auc: 0.7268 - val_loss: 0.6033 - val_accuracy: 0.6616 - val_auc: 0.7389\n",
      "Epoch 55/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6246 - accuracy: 0.6673 - auc: 0.7150 - val_loss: 0.6024 - val_accuracy: 0.6647 - val_auc: 0.7408\n",
      "Epoch 56/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6198 - accuracy: 0.6560 - auc: 0.7194 - val_loss: 0.6021 - val_accuracy: 0.6677 - val_auc: 0.7412\n",
      "Epoch 57/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6244 - accuracy: 0.6645 - auc: 0.7163 - val_loss: 0.6031 - val_accuracy: 0.6616 - val_auc: 0.7394\n",
      "Epoch 58/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6225 - accuracy: 0.6626 - auc: 0.7145 - val_loss: 0.6024 - val_accuracy: 0.6677 - val_auc: 0.7401\n",
      "Epoch 59/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6236 - accuracy: 0.6711 - auc: 0.7151 - val_loss: 0.6022 - val_accuracy: 0.6616 - val_auc: 0.7399\n",
      "Epoch 60/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6148 - accuracy: 0.6824 - auc: 0.7270 - val_loss: 0.6025 - val_accuracy: 0.6677 - val_auc: 0.7399\n",
      "Epoch 61/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6187 - accuracy: 0.6739 - auc: 0.7202 - val_loss: 0.6032 - val_accuracy: 0.6616 - val_auc: 0.7385\n",
      "Epoch 62/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6179 - accuracy: 0.6701 - auc: 0.7216 - val_loss: 0.6030 - val_accuracy: 0.6677 - val_auc: 0.7378\n",
      "Epoch 63/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6296 - accuracy: 0.6654 - auc: 0.7112 - val_loss: 0.6026 - val_accuracy: 0.6737 - val_auc: 0.7382\n",
      "Epoch 64/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6163 - accuracy: 0.6730 - auc: 0.7233 - val_loss: 0.6025 - val_accuracy: 0.6707 - val_auc: 0.7387\n",
      "Epoch 65/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6191 - accuracy: 0.6664 - auc: 0.7193 - val_loss: 0.6020 - val_accuracy: 0.6677 - val_auc: 0.7397\n",
      "Epoch 66/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6164 - accuracy: 0.6692 - auc: 0.7220 - val_loss: 0.6027 - val_accuracy: 0.6647 - val_auc: 0.7387\n",
      "Epoch 67/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6271 - accuracy: 0.6578 - auc: 0.7066 - val_loss: 0.6025 - val_accuracy: 0.6677 - val_auc: 0.7399\n",
      "Epoch 68/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6262 - accuracy: 0.6664 - auc: 0.7147 - val_loss: 0.6021 - val_accuracy: 0.6677 - val_auc: 0.7406\n",
      "Epoch 69/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6240 - accuracy: 0.6607 - auc: 0.7190 - val_loss: 0.6016 - val_accuracy: 0.6677 - val_auc: 0.7408\n",
      "Epoch 70/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6137 - accuracy: 0.6786 - auc: 0.7263 - val_loss: 0.6009 - val_accuracy: 0.6707 - val_auc: 0.7417\n",
      "Epoch 71/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6154 - accuracy: 0.6815 - auc: 0.7251 - val_loss: 0.6015 - val_accuracy: 0.6616 - val_auc: 0.7412\n",
      "Epoch 72/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6095 - accuracy: 0.6796 - auc: 0.7362 - val_loss: 0.6012 - val_accuracy: 0.6677 - val_auc: 0.7416\n",
      "Epoch 73/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6164 - accuracy: 0.6701 - auc: 0.7207 - val_loss: 0.6003 - val_accuracy: 0.6677 - val_auc: 0.7429\n",
      "Epoch 74/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6120 - accuracy: 0.6682 - auc: 0.7297 - val_loss: 0.6005 - val_accuracy: 0.6737 - val_auc: 0.7423\n",
      "Epoch 75/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6194 - accuracy: 0.6701 - auc: 0.7180 - val_loss: 0.6007 - val_accuracy: 0.6737 - val_auc: 0.7426\n",
      "Epoch 76/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6280 - accuracy: 0.6626 - auc: 0.7099 - val_loss: 0.6003 - val_accuracy: 0.6737 - val_auc: 0.7432\n",
      "Epoch 77/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.6157 - accuracy: 0.6853 - auc: 0.7281 - val_loss: 0.5999 - val_accuracy: 0.6707 - val_auc: 0.7434\n",
      "Epoch 78/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6208 - accuracy: 0.6720 - auc: 0.7171 - val_loss: 0.6001 - val_accuracy: 0.6737 - val_auc: 0.7429\n",
      "Epoch 79/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6129 - accuracy: 0.6739 - auc: 0.7269 - val_loss: 0.6000 - val_accuracy: 0.6767 - val_auc: 0.7426\n",
      "Epoch 80/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6126 - accuracy: 0.6749 - auc: 0.7247 - val_loss: 0.6003 - val_accuracy: 0.6828 - val_auc: 0.7429\n",
      "Epoch 81/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6173 - accuracy: 0.6588 - auc: 0.7193 - val_loss: 0.5992 - val_accuracy: 0.6828 - val_auc: 0.7445\n",
      "Epoch 82/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6114 - accuracy: 0.6767 - auc: 0.7299 - val_loss: 0.5994 - val_accuracy: 0.6798 - val_auc: 0.7433\n",
      "Epoch 83/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6202 - accuracy: 0.6692 - auc: 0.7209 - val_loss: 0.5986 - val_accuracy: 0.6737 - val_auc: 0.7448\n",
      "Epoch 84/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6147 - accuracy: 0.6730 - auc: 0.7245 - val_loss: 0.5989 - val_accuracy: 0.6737 - val_auc: 0.7437\n",
      "Epoch 85/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6100 - accuracy: 0.6881 - auc: 0.7340 - val_loss: 0.5984 - val_accuracy: 0.6798 - val_auc: 0.7442\n",
      "Epoch 86/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6060 - accuracy: 0.6805 - auc: 0.7391 - val_loss: 0.5981 - val_accuracy: 0.6798 - val_auc: 0.7453\n",
      "Epoch 87/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6131 - accuracy: 0.6994 - auc: 0.7306 - val_loss: 0.5980 - val_accuracy: 0.6798 - val_auc: 0.7459\n",
      "Epoch 88/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6189 - accuracy: 0.6824 - auc: 0.7236 - val_loss: 0.5988 - val_accuracy: 0.6798 - val_auc: 0.7444\n",
      "Epoch 89/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6211 - accuracy: 0.6739 - auc: 0.7229 - val_loss: 0.5992 - val_accuracy: 0.6737 - val_auc: 0.7435\n",
      "Epoch 90/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6024 - accuracy: 0.6966 - auc: 0.7450 - val_loss: 0.5991 - val_accuracy: 0.6767 - val_auc: 0.7434\n",
      "Epoch 91/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6053 - accuracy: 0.6900 - auc: 0.7400 - val_loss: 0.5997 - val_accuracy: 0.6707 - val_auc: 0.7427\n",
      "Epoch 92/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6057 - accuracy: 0.6777 - auc: 0.7376 - val_loss: 0.5995 - val_accuracy: 0.6767 - val_auc: 0.7436\n",
      "Epoch 93/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6170 - accuracy: 0.6701 - auc: 0.7224 - val_loss: 0.5997 - val_accuracy: 0.6677 - val_auc: 0.7426\n",
      "Epoch 94/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6110 - accuracy: 0.6824 - auc: 0.7352 - val_loss: 0.6001 - val_accuracy: 0.6707 - val_auc: 0.7415\n",
      "Epoch 95/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6126 - accuracy: 0.6692 - auc: 0.7307 - val_loss: 0.6002 - val_accuracy: 0.6677 - val_auc: 0.7423\n",
      "Epoch 96/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6057 - accuracy: 0.6701 - auc: 0.7343 - val_loss: 0.5999 - val_accuracy: 0.6677 - val_auc: 0.7422\n",
      "Epoch 97/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6146 - accuracy: 0.6758 - auc: 0.7268 - val_loss: 0.5997 - val_accuracy: 0.6677 - val_auc: 0.7432\n",
      "Epoch 98/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6156 - accuracy: 0.6777 - auc: 0.7250 - val_loss: 0.5988 - val_accuracy: 0.6737 - val_auc: 0.7444\n",
      "Epoch 99/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6070 - accuracy: 0.6966 - auc: 0.7386 - val_loss: 0.5985 - val_accuracy: 0.6737 - val_auc: 0.7453\n",
      "Epoch 100/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6125 - accuracy: 0.6843 - auc: 0.7290 - val_loss: 0.5985 - val_accuracy: 0.6767 - val_auc: 0.7449\n",
      "Epoch 101/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6145 - accuracy: 0.6635 - auc: 0.7254 - val_loss: 0.5988 - val_accuracy: 0.6767 - val_auc: 0.7443\n",
      "Epoch 102/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6189 - accuracy: 0.6730 - auc: 0.7223 - val_loss: 0.5989 - val_accuracy: 0.6677 - val_auc: 0.7439\n",
      "Epoch 103/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6121 - accuracy: 0.6758 - auc: 0.7281 - val_loss: 0.5991 - val_accuracy: 0.6707 - val_auc: 0.7432\n",
      "Epoch 104/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6086 - accuracy: 0.6834 - auc: 0.7359 - val_loss: 0.5980 - val_accuracy: 0.6737 - val_auc: 0.7462\n",
      "Epoch 105/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6053 - accuracy: 0.6834 - auc: 0.7416 - val_loss: 0.5962 - val_accuracy: 0.6767 - val_auc: 0.7486\n",
      "Epoch 106/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6079 - accuracy: 0.6900 - auc: 0.7342 - val_loss: 0.5964 - val_accuracy: 0.6798 - val_auc: 0.7482\n",
      "Epoch 107/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6092 - accuracy: 0.6975 - auc: 0.7357 - val_loss: 0.5967 - val_accuracy: 0.6798 - val_auc: 0.7476\n",
      "Epoch 108/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6068 - accuracy: 0.6739 - auc: 0.7355 - val_loss: 0.5965 - val_accuracy: 0.6767 - val_auc: 0.7484\n",
      "Epoch 109/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6129 - accuracy: 0.6853 - auc: 0.7305 - val_loss: 0.5962 - val_accuracy: 0.6798 - val_auc: 0.7487\n",
      "Epoch 110/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6103 - accuracy: 0.6786 - auc: 0.7309 - val_loss: 0.5961 - val_accuracy: 0.6798 - val_auc: 0.7492\n",
      "Epoch 111/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6212 - accuracy: 0.6730 - auc: 0.7196 - val_loss: 0.5962 - val_accuracy: 0.6737 - val_auc: 0.7487\n",
      "Epoch 112/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6052 - accuracy: 0.6786 - auc: 0.7369 - val_loss: 0.5960 - val_accuracy: 0.6767 - val_auc: 0.7492\n",
      "Epoch 113/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6055 - accuracy: 0.6767 - auc: 0.7354 - val_loss: 0.5962 - val_accuracy: 0.6767 - val_auc: 0.7483\n",
      "Epoch 114/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6074 - accuracy: 0.6975 - auc: 0.7363 - val_loss: 0.5955 - val_accuracy: 0.6828 - val_auc: 0.7492\n",
      "Epoch 115/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6086 - accuracy: 0.6730 - auc: 0.7290 - val_loss: 0.5957 - val_accuracy: 0.6858 - val_auc: 0.7490\n",
      "Epoch 116/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6053 - accuracy: 0.6871 - auc: 0.7383 - val_loss: 0.5954 - val_accuracy: 0.6858 - val_auc: 0.7494\n",
      "Epoch 117/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6084 - accuracy: 0.6862 - auc: 0.7359 - val_loss: 0.5955 - val_accuracy: 0.6828 - val_auc: 0.7494\n",
      "Epoch 118/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6055 - accuracy: 0.6966 - auc: 0.7389 - val_loss: 0.5962 - val_accuracy: 0.6918 - val_auc: 0.7487\n",
      "Epoch 119/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6071 - accuracy: 0.6805 - auc: 0.7355 - val_loss: 0.5955 - val_accuracy: 0.6888 - val_auc: 0.7490\n",
      "Epoch 120/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6083 - accuracy: 0.6947 - auc: 0.7379 - val_loss: 0.5960 - val_accuracy: 0.6918 - val_auc: 0.7487\n",
      "Epoch 121/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6129 - accuracy: 0.6682 - auc: 0.7283 - val_loss: 0.5965 - val_accuracy: 0.6858 - val_auc: 0.7483\n",
      "Epoch 122/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5994 - accuracy: 0.6767 - auc: 0.7445 - val_loss: 0.5965 - val_accuracy: 0.6828 - val_auc: 0.7480\n",
      "Epoch 123/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6049 - accuracy: 0.6749 - auc: 0.7417 - val_loss: 0.5965 - val_accuracy: 0.6858 - val_auc: 0.7482\n",
      "Epoch 124/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5977 - accuracy: 0.6966 - auc: 0.7504 - val_loss: 0.5963 - val_accuracy: 0.6888 - val_auc: 0.7487\n",
      "Epoch 125/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6099 - accuracy: 0.6890 - auc: 0.7354 - val_loss: 0.5956 - val_accuracy: 0.6888 - val_auc: 0.7494\n",
      "Epoch 126/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5963 - accuracy: 0.6928 - auc: 0.7463 - val_loss: 0.5948 - val_accuracy: 0.6858 - val_auc: 0.7503\n",
      "Epoch 127/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6024 - accuracy: 0.6909 - auc: 0.7419 - val_loss: 0.5951 - val_accuracy: 0.6888 - val_auc: 0.7493\n",
      "Epoch 128/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6080 - accuracy: 0.6871 - auc: 0.7341 - val_loss: 0.5959 - val_accuracy: 0.6918 - val_auc: 0.7492\n",
      "Epoch 129/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5964 - accuracy: 0.7004 - auc: 0.7504 - val_loss: 0.5955 - val_accuracy: 0.6888 - val_auc: 0.7494\n",
      "Epoch 130/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6012 - accuracy: 0.6938 - auc: 0.7439 - val_loss: 0.5954 - val_accuracy: 0.6918 - val_auc: 0.7490\n",
      "Epoch 131/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6082 - accuracy: 0.6796 - auc: 0.7332 - val_loss: 0.5956 - val_accuracy: 0.6918 - val_auc: 0.7494\n",
      "Epoch 132/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6010 - accuracy: 0.6947 - auc: 0.7409 - val_loss: 0.5957 - val_accuracy: 0.6888 - val_auc: 0.7496\n",
      "Epoch 133/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5999 - accuracy: 0.7004 - auc: 0.7465 - val_loss: 0.5955 - val_accuracy: 0.6888 - val_auc: 0.7495\n",
      "Epoch 134/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6032 - accuracy: 0.6909 - auc: 0.7406 - val_loss: 0.5948 - val_accuracy: 0.6918 - val_auc: 0.7507\n",
      "Epoch 135/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6054 - accuracy: 0.6909 - auc: 0.7399 - val_loss: 0.5948 - val_accuracy: 0.6888 - val_auc: 0.7505\n",
      "Epoch 136/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6025 - accuracy: 0.6975 - auc: 0.7437 - val_loss: 0.5947 - val_accuracy: 0.6888 - val_auc: 0.7505\n",
      "Epoch 137/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6062 - accuracy: 0.6824 - auc: 0.7375 - val_loss: 0.5948 - val_accuracy: 0.6888 - val_auc: 0.7496\n",
      "Epoch 138/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6113 - accuracy: 0.6767 - auc: 0.7334 - val_loss: 0.5954 - val_accuracy: 0.6798 - val_auc: 0.7493\n",
      "Epoch 139/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6061 - accuracy: 0.6975 - auc: 0.7398 - val_loss: 0.5947 - val_accuracy: 0.6888 - val_auc: 0.7504\n",
      "Epoch 140/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6046 - accuracy: 0.6815 - auc: 0.7389 - val_loss: 0.5952 - val_accuracy: 0.6858 - val_auc: 0.7503\n",
      "Epoch 141/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5954 - accuracy: 0.7051 - auc: 0.7513 - val_loss: 0.5958 - val_accuracy: 0.6798 - val_auc: 0.7490\n",
      "Epoch 142/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6076 - accuracy: 0.6758 - auc: 0.7328 - val_loss: 0.5950 - val_accuracy: 0.6828 - val_auc: 0.7498\n",
      "Epoch 143/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6113 - accuracy: 0.6711 - auc: 0.7296 - val_loss: 0.5937 - val_accuracy: 0.6918 - val_auc: 0.7520\n",
      "Epoch 144/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6051 - accuracy: 0.6871 - auc: 0.7417 - val_loss: 0.5942 - val_accuracy: 0.6858 - val_auc: 0.7511\n",
      "Epoch 145/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6022 - accuracy: 0.6966 - auc: 0.7442 - val_loss: 0.5941 - val_accuracy: 0.6858 - val_auc: 0.7510\n",
      "Epoch 146/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6052 - accuracy: 0.6957 - auc: 0.7382 - val_loss: 0.5935 - val_accuracy: 0.6888 - val_auc: 0.7520\n",
      "Epoch 147/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5937 - accuracy: 0.7079 - auc: 0.7549 - val_loss: 0.5934 - val_accuracy: 0.6858 - val_auc: 0.7523\n",
      "Epoch 148/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6108 - accuracy: 0.6767 - auc: 0.7330 - val_loss: 0.5930 - val_accuracy: 0.6858 - val_auc: 0.7531\n",
      "Epoch 149/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5976 - accuracy: 0.6919 - auc: 0.7470 - val_loss: 0.5925 - val_accuracy: 0.6858 - val_auc: 0.7539\n",
      "Epoch 150/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6071 - accuracy: 0.6881 - auc: 0.7383 - val_loss: 0.5923 - val_accuracy: 0.6858 - val_auc: 0.7540\n",
      "Epoch 151/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6021 - accuracy: 0.6881 - auc: 0.7398 - val_loss: 0.5916 - val_accuracy: 0.6918 - val_auc: 0.7550\n",
      "Epoch 152/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6071 - accuracy: 0.6890 - auc: 0.7366 - val_loss: 0.5923 - val_accuracy: 0.6828 - val_auc: 0.7535\n",
      "Epoch 153/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5983 - accuracy: 0.7004 - auc: 0.7482 - val_loss: 0.5919 - val_accuracy: 0.6798 - val_auc: 0.7548\n",
      "Epoch 154/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5922 - accuracy: 0.6909 - auc: 0.7542 - val_loss: 0.5923 - val_accuracy: 0.6828 - val_auc: 0.7537\n",
      "Epoch 155/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6091 - accuracy: 0.6862 - auc: 0.7356 - val_loss: 0.5922 - val_accuracy: 0.6828 - val_auc: 0.7537\n",
      "Epoch 156/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5982 - accuracy: 0.6938 - auc: 0.7482 - val_loss: 0.5915 - val_accuracy: 0.6858 - val_auc: 0.7554\n",
      "Epoch 157/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5946 - accuracy: 0.7004 - auc: 0.7528 - val_loss: 0.5911 - val_accuracy: 0.6888 - val_auc: 0.7564\n",
      "Epoch 158/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5923 - accuracy: 0.6890 - auc: 0.7496 - val_loss: 0.5905 - val_accuracy: 0.6918 - val_auc: 0.7567\n",
      "Epoch 159/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5944 - accuracy: 0.6919 - auc: 0.7492 - val_loss: 0.5917 - val_accuracy: 0.6858 - val_auc: 0.7547\n",
      "Epoch 160/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6021 - accuracy: 0.6711 - auc: 0.7400 - val_loss: 0.5913 - val_accuracy: 0.6858 - val_auc: 0.7557\n",
      "Epoch 161/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6000 - accuracy: 0.6985 - auc: 0.7463 - val_loss: 0.5908 - val_accuracy: 0.6858 - val_auc: 0.7565\n",
      "Epoch 162/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5932 - accuracy: 0.6928 - auc: 0.7486 - val_loss: 0.5903 - val_accuracy: 0.6828 - val_auc: 0.7572\n",
      "Epoch 163/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6088 - accuracy: 0.6928 - auc: 0.7324 - val_loss: 0.5903 - val_accuracy: 0.6828 - val_auc: 0.7568\n",
      "Epoch 164/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5991 - accuracy: 0.6777 - auc: 0.7451 - val_loss: 0.5907 - val_accuracy: 0.6858 - val_auc: 0.7559\n",
      "Epoch 165/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6018 - accuracy: 0.6909 - auc: 0.7443 - val_loss: 0.5913 - val_accuracy: 0.6858 - val_auc: 0.7551\n",
      "Epoch 166/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6017 - accuracy: 0.6938 - auc: 0.7402 - val_loss: 0.5912 - val_accuracy: 0.6888 - val_auc: 0.7552\n",
      "Epoch 167/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5946 - accuracy: 0.6994 - auc: 0.7505 - val_loss: 0.5909 - val_accuracy: 0.6888 - val_auc: 0.7556\n",
      "Epoch 168/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6049 - accuracy: 0.6862 - auc: 0.7410 - val_loss: 0.5896 - val_accuracy: 0.6858 - val_auc: 0.7580\n",
      "Epoch 169/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6000 - accuracy: 0.7004 - auc: 0.7440 - val_loss: 0.5896 - val_accuracy: 0.6858 - val_auc: 0.7575\n",
      "Epoch 170/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5987 - accuracy: 0.6900 - auc: 0.7484 - val_loss: 0.5899 - val_accuracy: 0.6858 - val_auc: 0.7573\n",
      "Epoch 171/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5992 - accuracy: 0.6985 - auc: 0.7438 - val_loss: 0.5903 - val_accuracy: 0.6858 - val_auc: 0.7569\n",
      "Epoch 172/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6024 - accuracy: 0.6843 - auc: 0.7391 - val_loss: 0.5896 - val_accuracy: 0.6858 - val_auc: 0.7574\n",
      "Epoch 173/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5967 - accuracy: 0.6957 - auc: 0.7498 - val_loss: 0.5895 - val_accuracy: 0.6858 - val_auc: 0.7575\n",
      "Epoch 174/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5958 - accuracy: 0.6966 - auc: 0.7496 - val_loss: 0.5889 - val_accuracy: 0.6858 - val_auc: 0.7591\n",
      "Epoch 175/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5911 - accuracy: 0.7004 - auc: 0.7555 - val_loss: 0.5894 - val_accuracy: 0.6858 - val_auc: 0.7580\n",
      "Epoch 176/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6011 - accuracy: 0.7023 - auc: 0.7423 - val_loss: 0.5899 - val_accuracy: 0.6888 - val_auc: 0.7575\n",
      "Epoch 177/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5975 - accuracy: 0.6947 - auc: 0.7495 - val_loss: 0.5896 - val_accuracy: 0.6888 - val_auc: 0.7580\n",
      "Epoch 178/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5940 - accuracy: 0.6900 - auc: 0.7519 - val_loss: 0.5892 - val_accuracy: 0.6888 - val_auc: 0.7586\n",
      "Epoch 179/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5940 - accuracy: 0.6975 - auc: 0.7508 - val_loss: 0.5895 - val_accuracy: 0.6888 - val_auc: 0.7580\n",
      "Epoch 180/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6077 - accuracy: 0.6805 - auc: 0.7334 - val_loss: 0.5898 - val_accuracy: 0.6888 - val_auc: 0.7577\n",
      "Epoch 181/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5985 - accuracy: 0.6890 - auc: 0.7472 - val_loss: 0.5892 - val_accuracy: 0.6888 - val_auc: 0.7583\n",
      "Epoch 182/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6032 - accuracy: 0.6862 - auc: 0.7390 - val_loss: 0.5888 - val_accuracy: 0.6858 - val_auc: 0.7594\n",
      "Epoch 183/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5918 - accuracy: 0.6966 - auc: 0.7521 - val_loss: 0.5885 - val_accuracy: 0.6888 - val_auc: 0.7595\n",
      "Epoch 184/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5938 - accuracy: 0.6938 - auc: 0.7514 - val_loss: 0.5889 - val_accuracy: 0.6888 - val_auc: 0.7590\n",
      "Epoch 185/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5979 - accuracy: 0.6909 - auc: 0.7470 - val_loss: 0.5892 - val_accuracy: 0.6828 - val_auc: 0.7582\n",
      "Epoch 186/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6018 - accuracy: 0.6957 - auc: 0.7416 - val_loss: 0.5890 - val_accuracy: 0.6828 - val_auc: 0.7589\n",
      "Epoch 187/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5902 - accuracy: 0.7004 - auc: 0.7510 - val_loss: 0.5891 - val_accuracy: 0.6828 - val_auc: 0.7592\n",
      "Epoch 188/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6047 - accuracy: 0.6834 - auc: 0.7360 - val_loss: 0.5894 - val_accuracy: 0.6828 - val_auc: 0.7584\n",
      "Epoch 189/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5939 - accuracy: 0.7023 - auc: 0.7549 - val_loss: 0.5882 - val_accuracy: 0.6858 - val_auc: 0.7601\n",
      "Epoch 190/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6035 - accuracy: 0.6881 - auc: 0.7406 - val_loss: 0.5879 - val_accuracy: 0.6858 - val_auc: 0.7610\n",
      "Epoch 191/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5831 - accuracy: 0.6985 - auc: 0.7627 - val_loss: 0.5873 - val_accuracy: 0.6858 - val_auc: 0.7617\n",
      "Epoch 192/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5903 - accuracy: 0.7070 - auc: 0.7555 - val_loss: 0.5878 - val_accuracy: 0.6858 - val_auc: 0.7609\n",
      "Epoch 193/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5902 - accuracy: 0.7060 - auc: 0.7577 - val_loss: 0.5878 - val_accuracy: 0.6858 - val_auc: 0.7608\n",
      "Epoch 194/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6017 - accuracy: 0.6938 - auc: 0.7389 - val_loss: 0.5880 - val_accuracy: 0.6858 - val_auc: 0.7599\n",
      "Epoch 195/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6023 - accuracy: 0.6843 - auc: 0.7404 - val_loss: 0.5886 - val_accuracy: 0.6858 - val_auc: 0.7593\n",
      "Epoch 196/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6005 - accuracy: 0.6871 - auc: 0.7455 - val_loss: 0.5887 - val_accuracy: 0.6828 - val_auc: 0.7595\n",
      "Epoch 197/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5973 - accuracy: 0.6824 - auc: 0.7448 - val_loss: 0.5889 - val_accuracy: 0.6828 - val_auc: 0.7593\n",
      "Epoch 198/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5886 - accuracy: 0.6919 - auc: 0.7581 - val_loss: 0.5880 - val_accuracy: 0.6858 - val_auc: 0.7603\n",
      "Epoch 199/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5915 - accuracy: 0.7032 - auc: 0.7538 - val_loss: 0.5877 - val_accuracy: 0.6888 - val_auc: 0.7609\n",
      "Epoch 200/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5983 - accuracy: 0.6985 - auc: 0.7477 - val_loss: 0.5867 - val_accuracy: 0.6888 - val_auc: 0.7623\n",
      "Epoch 201/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6079 - accuracy: 0.6730 - auc: 0.7347 - val_loss: 0.5882 - val_accuracy: 0.6918 - val_auc: 0.7603\n",
      "Epoch 202/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5937 - accuracy: 0.6975 - auc: 0.7488 - val_loss: 0.5873 - val_accuracy: 0.6888 - val_auc: 0.7615\n",
      "Epoch 203/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5953 - accuracy: 0.7013 - auc: 0.7477 - val_loss: 0.5873 - val_accuracy: 0.6918 - val_auc: 0.7620\n",
      "Epoch 204/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6030 - accuracy: 0.6758 - auc: 0.7392 - val_loss: 0.5874 - val_accuracy: 0.6888 - val_auc: 0.7616\n",
      "Epoch 205/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5947 - accuracy: 0.6834 - auc: 0.7511 - val_loss: 0.5872 - val_accuracy: 0.6888 - val_auc: 0.7623\n",
      "Epoch 206/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5937 - accuracy: 0.6928 - auc: 0.7520 - val_loss: 0.5876 - val_accuracy: 0.6888 - val_auc: 0.7617\n",
      "Epoch 207/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5870 - accuracy: 0.7089 - auc: 0.7621 - val_loss: 0.5883 - val_accuracy: 0.6888 - val_auc: 0.7609\n",
      "Epoch 208/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5965 - accuracy: 0.7023 - auc: 0.7537 - val_loss: 0.5877 - val_accuracy: 0.6888 - val_auc: 0.7620\n",
      "Epoch 209/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5970 - accuracy: 0.6786 - auc: 0.7489 - val_loss: 0.5873 - val_accuracy: 0.6888 - val_auc: 0.7619\n",
      "Epoch 210/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5876 - accuracy: 0.7079 - auc: 0.7590 - val_loss: 0.5872 - val_accuracy: 0.6888 - val_auc: 0.7624\n",
      "Epoch 211/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6021 - accuracy: 0.6881 - auc: 0.7436 - val_loss: 0.5879 - val_accuracy: 0.6888 - val_auc: 0.7608\n",
      "Epoch 212/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5957 - accuracy: 0.6928 - auc: 0.7516 - val_loss: 0.5869 - val_accuracy: 0.6918 - val_auc: 0.7625\n",
      "Epoch 213/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5969 - accuracy: 0.6909 - auc: 0.7465 - val_loss: 0.5866 - val_accuracy: 0.6918 - val_auc: 0.7629\n",
      "Epoch 214/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5916 - accuracy: 0.6871 - auc: 0.7524 - val_loss: 0.5870 - val_accuracy: 0.6888 - val_auc: 0.7626\n",
      "Epoch 215/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5865 - accuracy: 0.7032 - auc: 0.7592 - val_loss: 0.5864 - val_accuracy: 0.6888 - val_auc: 0.7634\n",
      "Epoch 216/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5931 - accuracy: 0.6815 - auc: 0.7523 - val_loss: 0.5858 - val_accuracy: 0.6918 - val_auc: 0.7646\n",
      "Epoch 217/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5978 - accuracy: 0.6796 - auc: 0.7448 - val_loss: 0.5867 - val_accuracy: 0.6828 - val_auc: 0.7628\n",
      "Epoch 218/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5940 - accuracy: 0.6957 - auc: 0.7532 - val_loss: 0.5864 - val_accuracy: 0.6828 - val_auc: 0.7636\n",
      "Epoch 219/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5903 - accuracy: 0.6909 - auc: 0.7554 - val_loss: 0.5863 - val_accuracy: 0.6858 - val_auc: 0.7640\n",
      "Epoch 220/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5854 - accuracy: 0.6909 - auc: 0.7580 - val_loss: 0.5856 - val_accuracy: 0.6918 - val_auc: 0.7651\n",
      "Epoch 221/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5931 - accuracy: 0.6975 - auc: 0.7529 - val_loss: 0.5852 - val_accuracy: 0.6918 - val_auc: 0.7656\n",
      "Epoch 222/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5856 - accuracy: 0.7023 - auc: 0.7643 - val_loss: 0.5848 - val_accuracy: 0.6949 - val_auc: 0.7664\n",
      "Epoch 223/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5843 - accuracy: 0.7004 - auc: 0.7634 - val_loss: 0.5836 - val_accuracy: 0.7009 - val_auc: 0.7684\n",
      "Epoch 224/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5979 - accuracy: 0.7004 - auc: 0.7506 - val_loss: 0.5836 - val_accuracy: 0.6979 - val_auc: 0.7680\n",
      "Epoch 225/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5935 - accuracy: 0.6890 - auc: 0.7509 - val_loss: 0.5842 - val_accuracy: 0.6979 - val_auc: 0.7668\n",
      "Epoch 226/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5981 - accuracy: 0.6928 - auc: 0.7462 - val_loss: 0.5859 - val_accuracy: 0.6858 - val_auc: 0.7642\n",
      "Epoch 227/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5964 - accuracy: 0.6947 - auc: 0.7475 - val_loss: 0.5854 - val_accuracy: 0.6888 - val_auc: 0.7649\n",
      "Epoch 228/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5860 - accuracy: 0.7070 - auc: 0.7599 - val_loss: 0.5852 - val_accuracy: 0.6888 - val_auc: 0.7652\n",
      "Epoch 229/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5979 - accuracy: 0.6966 - auc: 0.7482 - val_loss: 0.5847 - val_accuracy: 0.6918 - val_auc: 0.7659\n",
      "Epoch 230/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5897 - accuracy: 0.6824 - auc: 0.7533 - val_loss: 0.5844 - val_accuracy: 0.6918 - val_auc: 0.7659\n",
      "Epoch 231/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5873 - accuracy: 0.6966 - auc: 0.7602 - val_loss: 0.5839 - val_accuracy: 0.7009 - val_auc: 0.7669\n",
      "Epoch 232/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5892 - accuracy: 0.7079 - auc: 0.7549 - val_loss: 0.5845 - val_accuracy: 0.6949 - val_auc: 0.7663\n",
      "Epoch 233/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5852 - accuracy: 0.7089 - auc: 0.7596 - val_loss: 0.5846 - val_accuracy: 0.6888 - val_auc: 0.7661\n",
      "Epoch 234/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5898 - accuracy: 0.6994 - auc: 0.7545 - val_loss: 0.5842 - val_accuracy: 0.6888 - val_auc: 0.7668\n",
      "Epoch 235/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5952 - accuracy: 0.6843 - auc: 0.7487 - val_loss: 0.5841 - val_accuracy: 0.6918 - val_auc: 0.7676\n",
      "Epoch 236/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5946 - accuracy: 0.6928 - auc: 0.7507 - val_loss: 0.5844 - val_accuracy: 0.6918 - val_auc: 0.7668\n",
      "Epoch 237/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5915 - accuracy: 0.6947 - auc: 0.7541 - val_loss: 0.5842 - val_accuracy: 0.6918 - val_auc: 0.7662\n",
      "Epoch 238/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5852 - accuracy: 0.7060 - auc: 0.7641 - val_loss: 0.5837 - val_accuracy: 0.7039 - val_auc: 0.7671\n",
      "Epoch 239/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5896 - accuracy: 0.7042 - auc: 0.7573 - val_loss: 0.5843 - val_accuracy: 0.7009 - val_auc: 0.7665\n",
      "Epoch 240/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5901 - accuracy: 0.6975 - auc: 0.7576 - val_loss: 0.5840 - val_accuracy: 0.6979 - val_auc: 0.7671\n",
      "Epoch 241/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5926 - accuracy: 0.7004 - auc: 0.7532 - val_loss: 0.5846 - val_accuracy: 0.6949 - val_auc: 0.7662\n",
      "Epoch 242/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5880 - accuracy: 0.6909 - auc: 0.7560 - val_loss: 0.5841 - val_accuracy: 0.6979 - val_auc: 0.7673\n",
      "Epoch 243/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5927 - accuracy: 0.6909 - auc: 0.7500 - val_loss: 0.5835 - val_accuracy: 0.6979 - val_auc: 0.7682\n",
      "Epoch 244/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5881 - accuracy: 0.7089 - auc: 0.7573 - val_loss: 0.5841 - val_accuracy: 0.6979 - val_auc: 0.7672\n",
      "Epoch 245/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5844 - accuracy: 0.7004 - auc: 0.7609 - val_loss: 0.5836 - val_accuracy: 0.6949 - val_auc: 0.7677\n",
      "Epoch 246/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5983 - accuracy: 0.6853 - auc: 0.7444 - val_loss: 0.5831 - val_accuracy: 0.6949 - val_auc: 0.7688\n",
      "Epoch 247/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5808 - accuracy: 0.7089 - auc: 0.7625 - val_loss: 0.5828 - val_accuracy: 0.6949 - val_auc: 0.7691\n",
      "Epoch 248/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5954 - accuracy: 0.7051 - auc: 0.7503 - val_loss: 0.5828 - val_accuracy: 0.6979 - val_auc: 0.7693\n",
      "Epoch 249/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5901 - accuracy: 0.7032 - auc: 0.7558 - val_loss: 0.5827 - val_accuracy: 0.7009 - val_auc: 0.7691\n",
      "Epoch 250/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5877 - accuracy: 0.6938 - auc: 0.7560 - val_loss: 0.5830 - val_accuracy: 0.6979 - val_auc: 0.7688\n",
      "Epoch 251/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5904 - accuracy: 0.6909 - auc: 0.7529 - val_loss: 0.5836 - val_accuracy: 0.6918 - val_auc: 0.7683\n",
      "Epoch 252/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5917 - accuracy: 0.6985 - auc: 0.7522 - val_loss: 0.5835 - val_accuracy: 0.6918 - val_auc: 0.7683\n",
      "Epoch 253/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5836 - accuracy: 0.7051 - auc: 0.7632 - val_loss: 0.5839 - val_accuracy: 0.6979 - val_auc: 0.7673\n",
      "Epoch 254/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5931 - accuracy: 0.7023 - auc: 0.7538 - val_loss: 0.5835 - val_accuracy: 0.6918 - val_auc: 0.7680\n",
      "Epoch 255/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5828 - accuracy: 0.7098 - auc: 0.7656 - val_loss: 0.5837 - val_accuracy: 0.6949 - val_auc: 0.7680\n",
      "Epoch 256/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5890 - accuracy: 0.6909 - auc: 0.7578 - val_loss: 0.5829 - val_accuracy: 0.6949 - val_auc: 0.7692\n",
      "Epoch 257/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5881 - accuracy: 0.7042 - auc: 0.7601 - val_loss: 0.5829 - val_accuracy: 0.6979 - val_auc: 0.7693\n",
      "Epoch 258/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5855 - accuracy: 0.6928 - auc: 0.7600 - val_loss: 0.5823 - val_accuracy: 0.7009 - val_auc: 0.7700\n",
      "Epoch 259/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5850 - accuracy: 0.6947 - auc: 0.7590 - val_loss: 0.5820 - val_accuracy: 0.7009 - val_auc: 0.7703\n",
      "Epoch 260/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5917 - accuracy: 0.7079 - auc: 0.7579 - val_loss: 0.5813 - val_accuracy: 0.7009 - val_auc: 0.7710\n",
      "Epoch 261/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5817 - accuracy: 0.7051 - auc: 0.7638 - val_loss: 0.5807 - val_accuracy: 0.7009 - val_auc: 0.7717\n",
      "Epoch 262/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5863 - accuracy: 0.6985 - auc: 0.7604 - val_loss: 0.5808 - val_accuracy: 0.7039 - val_auc: 0.7709\n",
      "Epoch 263/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5860 - accuracy: 0.6938 - auc: 0.7614 - val_loss: 0.5803 - val_accuracy: 0.7039 - val_auc: 0.7720\n",
      "Epoch 264/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5817 - accuracy: 0.7051 - auc: 0.7640 - val_loss: 0.5804 - val_accuracy: 0.7039 - val_auc: 0.7718\n",
      "Epoch 265/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5793 - accuracy: 0.7108 - auc: 0.7675 - val_loss: 0.5799 - val_accuracy: 0.7100 - val_auc: 0.7720\n",
      "Epoch 266/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5858 - accuracy: 0.7164 - auc: 0.7597 - val_loss: 0.5809 - val_accuracy: 0.7069 - val_auc: 0.7709\n",
      "Epoch 267/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5819 - accuracy: 0.6824 - auc: 0.7617 - val_loss: 0.5814 - val_accuracy: 0.7009 - val_auc: 0.7707\n",
      "Epoch 268/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5891 - accuracy: 0.6975 - auc: 0.7569 - val_loss: 0.5814 - val_accuracy: 0.7039 - val_auc: 0.7709\n",
      "Epoch 269/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5865 - accuracy: 0.7051 - auc: 0.7613 - val_loss: 0.5819 - val_accuracy: 0.7009 - val_auc: 0.7702\n",
      "Epoch 270/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5800 - accuracy: 0.7183 - auc: 0.7712 - val_loss: 0.5821 - val_accuracy: 0.7009 - val_auc: 0.7700\n",
      "Epoch 271/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5837 - accuracy: 0.7004 - auc: 0.7637 - val_loss: 0.5828 - val_accuracy: 0.7039 - val_auc: 0.7691\n",
      "Epoch 272/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5911 - accuracy: 0.6909 - auc: 0.7536 - val_loss: 0.5819 - val_accuracy: 0.7009 - val_auc: 0.7702\n",
      "Epoch 273/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5862 - accuracy: 0.7004 - auc: 0.7596 - val_loss: 0.5820 - val_accuracy: 0.6979 - val_auc: 0.7700\n",
      "Epoch 274/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5900 - accuracy: 0.6815 - auc: 0.7529 - val_loss: 0.5825 - val_accuracy: 0.6949 - val_auc: 0.7696\n",
      "Epoch 275/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5843 - accuracy: 0.7032 - auc: 0.7619 - val_loss: 0.5821 - val_accuracy: 0.7009 - val_auc: 0.7699\n",
      "Epoch 276/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5822 - accuracy: 0.7098 - auc: 0.7604 - val_loss: 0.5819 - val_accuracy: 0.7039 - val_auc: 0.7706\n",
      "Epoch 277/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5877 - accuracy: 0.6919 - auc: 0.7586 - val_loss: 0.5820 - val_accuracy: 0.7009 - val_auc: 0.7702\n",
      "Epoch 278/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5844 - accuracy: 0.6975 - auc: 0.7601 - val_loss: 0.5817 - val_accuracy: 0.6979 - val_auc: 0.7709\n",
      "Epoch 279/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5810 - accuracy: 0.7060 - auc: 0.7658 - val_loss: 0.5805 - val_accuracy: 0.7039 - val_auc: 0.7721\n",
      "Epoch 280/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5742 - accuracy: 0.7004 - auc: 0.7708 - val_loss: 0.5813 - val_accuracy: 0.7009 - val_auc: 0.7719\n",
      "Epoch 281/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5844 - accuracy: 0.7032 - auc: 0.7605 - val_loss: 0.5801 - val_accuracy: 0.7039 - val_auc: 0.7722\n",
      "Epoch 282/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5842 - accuracy: 0.6985 - auc: 0.7605 - val_loss: 0.5789 - val_accuracy: 0.7069 - val_auc: 0.7740\n",
      "Epoch 283/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5730 - accuracy: 0.7155 - auc: 0.7756 - val_loss: 0.5792 - val_accuracy: 0.7069 - val_auc: 0.7737\n",
      "Epoch 284/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5816 - accuracy: 0.7127 - auc: 0.7656 - val_loss: 0.5783 - val_accuracy: 0.7069 - val_auc: 0.7746\n",
      "Epoch 285/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5929 - accuracy: 0.6871 - auc: 0.7499 - val_loss: 0.5779 - val_accuracy: 0.7069 - val_auc: 0.7755\n",
      "Epoch 286/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5852 - accuracy: 0.7042 - auc: 0.7600 - val_loss: 0.5778 - val_accuracy: 0.7100 - val_auc: 0.7754\n",
      "Epoch 287/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5776 - accuracy: 0.7051 - auc: 0.7687 - val_loss: 0.5786 - val_accuracy: 0.7039 - val_auc: 0.7743\n",
      "Epoch 288/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5809 - accuracy: 0.6966 - auc: 0.7653 - val_loss: 0.5790 - val_accuracy: 0.7069 - val_auc: 0.7739\n",
      "Epoch 289/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5890 - accuracy: 0.7174 - auc: 0.7586 - val_loss: 0.5787 - val_accuracy: 0.7069 - val_auc: 0.7745\n",
      "Epoch 290/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5878 - accuracy: 0.7051 - auc: 0.7557 - val_loss: 0.5784 - val_accuracy: 0.7039 - val_auc: 0.7747\n",
      "Epoch 291/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5848 - accuracy: 0.7079 - auc: 0.7617 - val_loss: 0.5791 - val_accuracy: 0.7039 - val_auc: 0.7745\n",
      "Epoch 292/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5912 - accuracy: 0.7004 - auc: 0.7544 - val_loss: 0.5793 - val_accuracy: 0.7069 - val_auc: 0.7742\n",
      "Epoch 293/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5890 - accuracy: 0.7042 - auc: 0.7556 - val_loss: 0.5785 - val_accuracy: 0.7069 - val_auc: 0.7750\n",
      "Epoch 294/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5814 - accuracy: 0.7023 - auc: 0.7675 - val_loss: 0.5789 - val_accuracy: 0.7039 - val_auc: 0.7746\n",
      "Epoch 295/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5928 - accuracy: 0.6947 - auc: 0.7537 - val_loss: 0.5783 - val_accuracy: 0.7039 - val_auc: 0.7753\n",
      "Epoch 296/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5796 - accuracy: 0.7051 - auc: 0.7701 - val_loss: 0.5790 - val_accuracy: 0.6979 - val_auc: 0.7749\n",
      "Epoch 297/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5796 - accuracy: 0.7164 - auc: 0.7671 - val_loss: 0.5788 - val_accuracy: 0.6979 - val_auc: 0.7747\n",
      "Epoch 298/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5827 - accuracy: 0.7070 - auc: 0.7645 - val_loss: 0.5781 - val_accuracy: 0.6979 - val_auc: 0.7756\n",
      "Epoch 299/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5818 - accuracy: 0.7089 - auc: 0.7665 - val_loss: 0.5785 - val_accuracy: 0.7009 - val_auc: 0.7756\n",
      "Epoch 300/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5860 - accuracy: 0.7098 - auc: 0.7592 - val_loss: 0.5776 - val_accuracy: 0.7009 - val_auc: 0.7764\n",
      "Epoch 301/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5916 - accuracy: 0.6994 - auc: 0.7526 - val_loss: 0.5781 - val_accuracy: 0.7039 - val_auc: 0.7763\n",
      "Epoch 302/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5809 - accuracy: 0.6947 - auc: 0.7648 - val_loss: 0.5786 - val_accuracy: 0.7039 - val_auc: 0.7752\n",
      "Epoch 303/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5809 - accuracy: 0.7013 - auc: 0.7669 - val_loss: 0.5789 - val_accuracy: 0.7009 - val_auc: 0.7748\n",
      "Epoch 304/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5827 - accuracy: 0.7023 - auc: 0.7643 - val_loss: 0.5777 - val_accuracy: 0.7009 - val_auc: 0.7763\n",
      "Epoch 305/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5755 - accuracy: 0.7004 - auc: 0.7705 - val_loss: 0.5783 - val_accuracy: 0.7039 - val_auc: 0.7756\n",
      "Epoch 306/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5778 - accuracy: 0.7127 - auc: 0.7693 - val_loss: 0.5779 - val_accuracy: 0.7039 - val_auc: 0.7762\n",
      "Epoch 307/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5834 - accuracy: 0.7108 - auc: 0.7617 - val_loss: 0.5776 - val_accuracy: 0.7069 - val_auc: 0.7766\n",
      "Epoch 308/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5808 - accuracy: 0.7013 - auc: 0.7662 - val_loss: 0.5780 - val_accuracy: 0.7009 - val_auc: 0.7763\n",
      "Epoch 309/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5771 - accuracy: 0.7108 - auc: 0.7708 - val_loss: 0.5778 - val_accuracy: 0.7009 - val_auc: 0.7765\n",
      "Epoch 310/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5768 - accuracy: 0.7060 - auc: 0.7690 - val_loss: 0.5774 - val_accuracy: 0.7039 - val_auc: 0.7771\n",
      "Epoch 311/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5790 - accuracy: 0.7089 - auc: 0.7681 - val_loss: 0.5781 - val_accuracy: 0.7009 - val_auc: 0.7763\n",
      "Epoch 312/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5759 - accuracy: 0.7136 - auc: 0.7724 - val_loss: 0.5779 - val_accuracy: 0.7069 - val_auc: 0.7762\n",
      "Epoch 313/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5877 - accuracy: 0.7032 - auc: 0.7587 - val_loss: 0.5770 - val_accuracy: 0.7069 - val_auc: 0.7774\n",
      "Epoch 314/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5865 - accuracy: 0.7013 - auc: 0.7588 - val_loss: 0.5773 - val_accuracy: 0.7039 - val_auc: 0.7774\n",
      "Epoch 315/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5758 - accuracy: 0.7146 - auc: 0.7737 - val_loss: 0.5771 - val_accuracy: 0.7039 - val_auc: 0.7770\n",
      "Epoch 316/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5716 - accuracy: 0.7089 - auc: 0.7768 - val_loss: 0.5769 - val_accuracy: 0.7100 - val_auc: 0.7779\n",
      "Epoch 317/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5708 - accuracy: 0.7089 - auc: 0.7765 - val_loss: 0.5772 - val_accuracy: 0.7100 - val_auc: 0.7775\n",
      "Epoch 318/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5773 - accuracy: 0.7098 - auc: 0.7659 - val_loss: 0.5758 - val_accuracy: 0.7069 - val_auc: 0.7792\n",
      "Epoch 319/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5854 - accuracy: 0.7117 - auc: 0.7628 - val_loss: 0.5759 - val_accuracy: 0.7069 - val_auc: 0.7790\n",
      "Epoch 320/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5955 - accuracy: 0.6843 - auc: 0.7469 - val_loss: 0.5757 - val_accuracy: 0.7039 - val_auc: 0.7791\n",
      "Epoch 321/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5793 - accuracy: 0.7155 - auc: 0.7670 - val_loss: 0.5760 - val_accuracy: 0.7069 - val_auc: 0.7787\n",
      "Epoch 322/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5760 - accuracy: 0.7108 - auc: 0.7733 - val_loss: 0.5767 - val_accuracy: 0.7039 - val_auc: 0.7782\n",
      "Epoch 323/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5787 - accuracy: 0.6966 - auc: 0.7683 - val_loss: 0.5769 - val_accuracy: 0.7069 - val_auc: 0.7781\n",
      "Epoch 324/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5877 - accuracy: 0.7051 - auc: 0.7583 - val_loss: 0.5767 - val_accuracy: 0.7069 - val_auc: 0.7777\n",
      "Epoch 325/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5750 - accuracy: 0.7117 - auc: 0.7723 - val_loss: 0.5758 - val_accuracy: 0.7100 - val_auc: 0.7789\n",
      "Epoch 326/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5820 - accuracy: 0.6994 - auc: 0.7657 - val_loss: 0.5758 - val_accuracy: 0.7069 - val_auc: 0.7795\n",
      "Epoch 327/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5784 - accuracy: 0.7079 - auc: 0.7660 - val_loss: 0.5759 - val_accuracy: 0.7100 - val_auc: 0.7791\n",
      "Epoch 328/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5788 - accuracy: 0.7127 - auc: 0.7686 - val_loss: 0.5753 - val_accuracy: 0.7069 - val_auc: 0.7797\n",
      "Epoch 329/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5812 - accuracy: 0.7060 - auc: 0.7690 - val_loss: 0.5752 - val_accuracy: 0.7100 - val_auc: 0.7796\n",
      "Epoch 330/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5743 - accuracy: 0.7051 - auc: 0.7715 - val_loss: 0.5748 - val_accuracy: 0.7069 - val_auc: 0.7799\n",
      "Epoch 331/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5862 - accuracy: 0.6919 - auc: 0.7581 - val_loss: 0.5755 - val_accuracy: 0.7130 - val_auc: 0.7794\n",
      "Epoch 332/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5772 - accuracy: 0.7202 - auc: 0.7728 - val_loss: 0.5755 - val_accuracy: 0.7130 - val_auc: 0.7793\n",
      "Epoch 333/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5764 - accuracy: 0.6985 - auc: 0.7671 - val_loss: 0.5760 - val_accuracy: 0.7100 - val_auc: 0.7784\n",
      "Epoch 334/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5729 - accuracy: 0.7042 - auc: 0.7720 - val_loss: 0.5757 - val_accuracy: 0.7100 - val_auc: 0.7786\n",
      "Epoch 335/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5782 - accuracy: 0.7023 - auc: 0.7697 - val_loss: 0.5762 - val_accuracy: 0.7069 - val_auc: 0.7780\n",
      "Epoch 336/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5752 - accuracy: 0.7060 - auc: 0.7715 - val_loss: 0.5765 - val_accuracy: 0.7100 - val_auc: 0.7776\n",
      "Epoch 337/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5791 - accuracy: 0.7155 - auc: 0.7687 - val_loss: 0.5770 - val_accuracy: 0.7130 - val_auc: 0.7770\n",
      "Epoch 338/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5804 - accuracy: 0.7146 - auc: 0.7664 - val_loss: 0.5770 - val_accuracy: 0.7100 - val_auc: 0.7770\n",
      "Epoch 339/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5770 - accuracy: 0.7127 - auc: 0.7691 - val_loss: 0.5769 - val_accuracy: 0.7100 - val_auc: 0.7767\n",
      "Epoch 340/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5873 - accuracy: 0.7032 - auc: 0.7593 - val_loss: 0.5769 - val_accuracy: 0.7069 - val_auc: 0.7777\n",
      "Epoch 341/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5799 - accuracy: 0.6994 - auc: 0.7664 - val_loss: 0.5763 - val_accuracy: 0.7130 - val_auc: 0.7779\n",
      "Epoch 342/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5720 - accuracy: 0.7183 - auc: 0.7757 - val_loss: 0.5764 - val_accuracy: 0.7130 - val_auc: 0.7776\n",
      "Epoch 343/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5842 - accuracy: 0.6928 - auc: 0.7579 - val_loss: 0.5761 - val_accuracy: 0.7130 - val_auc: 0.7780\n",
      "Epoch 344/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5687 - accuracy: 0.7023 - auc: 0.7767 - val_loss: 0.5765 - val_accuracy: 0.7130 - val_auc: 0.7779\n",
      "Epoch 345/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5838 - accuracy: 0.6975 - auc: 0.7603 - val_loss: 0.5763 - val_accuracy: 0.7130 - val_auc: 0.7777\n",
      "Epoch 346/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5741 - accuracy: 0.7174 - auc: 0.7745 - val_loss: 0.5753 - val_accuracy: 0.7130 - val_auc: 0.7792\n",
      "Epoch 347/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5887 - accuracy: 0.6994 - auc: 0.7610 - val_loss: 0.5755 - val_accuracy: 0.7100 - val_auc: 0.7788\n",
      "Epoch 348/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5706 - accuracy: 0.7060 - auc: 0.7766 - val_loss: 0.5752 - val_accuracy: 0.7130 - val_auc: 0.7795\n",
      "Epoch 349/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5856 - accuracy: 0.6928 - auc: 0.7587 - val_loss: 0.5756 - val_accuracy: 0.7130 - val_auc: 0.7786\n",
      "Epoch 350/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5817 - accuracy: 0.6975 - auc: 0.7612 - val_loss: 0.5753 - val_accuracy: 0.7130 - val_auc: 0.7790\n",
      "Epoch 351/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5808 - accuracy: 0.6909 - auc: 0.7637 - val_loss: 0.5750 - val_accuracy: 0.7130 - val_auc: 0.7798\n",
      "Epoch 352/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5815 - accuracy: 0.7202 - auc: 0.7693 - val_loss: 0.5748 - val_accuracy: 0.7130 - val_auc: 0.7799\n",
      "Epoch 353/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5742 - accuracy: 0.7136 - auc: 0.7717 - val_loss: 0.5741 - val_accuracy: 0.7160 - val_auc: 0.7811\n",
      "Epoch 354/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5820 - accuracy: 0.6947 - auc: 0.7627 - val_loss: 0.5741 - val_accuracy: 0.7130 - val_auc: 0.7808\n",
      "Epoch 355/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5692 - accuracy: 0.7174 - auc: 0.7778 - val_loss: 0.5743 - val_accuracy: 0.7130 - val_auc: 0.7801\n",
      "Epoch 356/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5818 - accuracy: 0.7051 - auc: 0.7649 - val_loss: 0.5746 - val_accuracy: 0.7130 - val_auc: 0.7801\n",
      "Epoch 357/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5787 - accuracy: 0.7183 - auc: 0.7668 - val_loss: 0.5746 - val_accuracy: 0.7160 - val_auc: 0.7799\n",
      "Epoch 358/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5799 - accuracy: 0.7051 - auc: 0.7674 - val_loss: 0.5747 - val_accuracy: 0.7130 - val_auc: 0.7801\n",
      "Epoch 359/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5725 - accuracy: 0.7183 - auc: 0.7757 - val_loss: 0.5751 - val_accuracy: 0.7130 - val_auc: 0.7798\n",
      "Epoch 360/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5749 - accuracy: 0.7174 - auc: 0.7705 - val_loss: 0.5755 - val_accuracy: 0.7160 - val_auc: 0.7791\n",
      "Epoch 361/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5711 - accuracy: 0.7042 - auc: 0.7731 - val_loss: 0.5748 - val_accuracy: 0.7130 - val_auc: 0.7796\n",
      "Epoch 362/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5823 - accuracy: 0.7089 - auc: 0.7641 - val_loss: 0.5738 - val_accuracy: 0.7160 - val_auc: 0.7811\n",
      "Epoch 363/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5744 - accuracy: 0.7136 - auc: 0.7778 - val_loss: 0.5744 - val_accuracy: 0.7100 - val_auc: 0.7805\n",
      "Epoch 364/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5875 - accuracy: 0.7004 - auc: 0.7594 - val_loss: 0.5748 - val_accuracy: 0.7100 - val_auc: 0.7794\n",
      "Epoch 365/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5672 - accuracy: 0.7221 - auc: 0.7826 - val_loss: 0.5740 - val_accuracy: 0.7160 - val_auc: 0.7809\n",
      "Epoch 366/700\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.5903 - accuracy: 0.6890 - auc: 0.7529 - val_loss: 0.5735 - val_accuracy: 0.7160 - val_auc: 0.7812\n",
      "Epoch 367/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5792 - accuracy: 0.7098 - auc: 0.7674 - val_loss: 0.5738 - val_accuracy: 0.7130 - val_auc: 0.7808\n",
      "Epoch 368/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5767 - accuracy: 0.7136 - auc: 0.7720 - val_loss: 0.5741 - val_accuracy: 0.7160 - val_auc: 0.7808\n",
      "Epoch 369/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5873 - accuracy: 0.7098 - auc: 0.7597 - val_loss: 0.5738 - val_accuracy: 0.7190 - val_auc: 0.7814\n",
      "Epoch 370/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5746 - accuracy: 0.7155 - auc: 0.7756 - val_loss: 0.5744 - val_accuracy: 0.7160 - val_auc: 0.7808\n",
      "Epoch 371/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5602 - accuracy: 0.7164 - auc: 0.7847 - val_loss: 0.5740 - val_accuracy: 0.7160 - val_auc: 0.7819\n",
      "Epoch 372/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5746 - accuracy: 0.7136 - auc: 0.7707 - val_loss: 0.5743 - val_accuracy: 0.7130 - val_auc: 0.7816\n",
      "Epoch 373/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5784 - accuracy: 0.7136 - auc: 0.7710 - val_loss: 0.5738 - val_accuracy: 0.7130 - val_auc: 0.7822\n",
      "Epoch 374/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5654 - accuracy: 0.7250 - auc: 0.7810 - val_loss: 0.5740 - val_accuracy: 0.7160 - val_auc: 0.7811\n",
      "Epoch 375/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5754 - accuracy: 0.7004 - auc: 0.7708 - val_loss: 0.5734 - val_accuracy: 0.7160 - val_auc: 0.7820\n",
      "Epoch 376/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5681 - accuracy: 0.7127 - auc: 0.7787 - val_loss: 0.5743 - val_accuracy: 0.7160 - val_auc: 0.7807\n",
      "Epoch 377/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5829 - accuracy: 0.7042 - auc: 0.7624 - val_loss: 0.5741 - val_accuracy: 0.7130 - val_auc: 0.7809\n",
      "Epoch 378/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5856 - accuracy: 0.6938 - auc: 0.7598 - val_loss: 0.5753 - val_accuracy: 0.7160 - val_auc: 0.7791\n",
      "Epoch 379/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5790 - accuracy: 0.7013 - auc: 0.7664 - val_loss: 0.5748 - val_accuracy: 0.7100 - val_auc: 0.7798\n",
      "Epoch 380/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5760 - accuracy: 0.7013 - auc: 0.7678 - val_loss: 0.5737 - val_accuracy: 0.7160 - val_auc: 0.7812\n",
      "Epoch 381/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5715 - accuracy: 0.7042 - auc: 0.7779 - val_loss: 0.5744 - val_accuracy: 0.7160 - val_auc: 0.7806\n",
      "Epoch 382/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5861 - accuracy: 0.7032 - auc: 0.7620 - val_loss: 0.5743 - val_accuracy: 0.7190 - val_auc: 0.7809\n",
      "Epoch 383/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5761 - accuracy: 0.7108 - auc: 0.7695 - val_loss: 0.5746 - val_accuracy: 0.7160 - val_auc: 0.7805\n",
      "Epoch 384/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5752 - accuracy: 0.7202 - auc: 0.7721 - val_loss: 0.5746 - val_accuracy: 0.7190 - val_auc: 0.7805\n",
      "Epoch 385/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5867 - accuracy: 0.7004 - auc: 0.7587 - val_loss: 0.5745 - val_accuracy: 0.7190 - val_auc: 0.7806\n",
      "Epoch 386/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5717 - accuracy: 0.7051 - auc: 0.7736 - val_loss: 0.5739 - val_accuracy: 0.7190 - val_auc: 0.7809\n",
      "Epoch 387/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5780 - accuracy: 0.7051 - auc: 0.7646 - val_loss: 0.5744 - val_accuracy: 0.7160 - val_auc: 0.7809\n",
      "Epoch 388/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5862 - accuracy: 0.6928 - auc: 0.7575 - val_loss: 0.5740 - val_accuracy: 0.7160 - val_auc: 0.7814\n",
      "Epoch 389/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5743 - accuracy: 0.7079 - auc: 0.7742 - val_loss: 0.5734 - val_accuracy: 0.7190 - val_auc: 0.7822\n",
      "Epoch 390/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5764 - accuracy: 0.7164 - auc: 0.7713 - val_loss: 0.5736 - val_accuracy: 0.7190 - val_auc: 0.7820\n",
      "Epoch 391/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5802 - accuracy: 0.6947 - auc: 0.7649 - val_loss: 0.5734 - val_accuracy: 0.7190 - val_auc: 0.7812\n",
      "Epoch 392/700\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 0.5862 - accuracy: 0.7070 - auc: 0.7595 - val_loss: 0.5731 - val_accuracy: 0.7221 - val_auc: 0.7825\n",
      "Epoch 393/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5747 - accuracy: 0.7051 - auc: 0.7702 - val_loss: 0.5730 - val_accuracy: 0.7190 - val_auc: 0.7828\n",
      "Epoch 394/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5754 - accuracy: 0.7212 - auc: 0.7713 - val_loss: 0.5723 - val_accuracy: 0.7221 - val_auc: 0.7837\n",
      "Epoch 395/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5716 - accuracy: 0.7183 - auc: 0.7771 - val_loss: 0.5723 - val_accuracy: 0.7221 - val_auc: 0.7836\n",
      "Epoch 396/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5754 - accuracy: 0.7117 - auc: 0.7701 - val_loss: 0.5716 - val_accuracy: 0.7251 - val_auc: 0.7844\n",
      "Epoch 397/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5744 - accuracy: 0.7155 - auc: 0.7727 - val_loss: 0.5723 - val_accuracy: 0.7221 - val_auc: 0.7836\n",
      "Epoch 398/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5714 - accuracy: 0.7013 - auc: 0.7744 - val_loss: 0.5717 - val_accuracy: 0.7221 - val_auc: 0.7845\n",
      "Epoch 399/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5677 - accuracy: 0.7193 - auc: 0.7823 - val_loss: 0.5717 - val_accuracy: 0.7251 - val_auc: 0.7844\n",
      "Epoch 400/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5822 - accuracy: 0.7183 - auc: 0.7633 - val_loss: 0.5705 - val_accuracy: 0.7221 - val_auc: 0.7856\n",
      "Epoch 401/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5648 - accuracy: 0.7231 - auc: 0.7854 - val_loss: 0.5708 - val_accuracy: 0.7221 - val_auc: 0.7849\n",
      "Epoch 402/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5721 - accuracy: 0.7146 - auc: 0.7729 - val_loss: 0.5713 - val_accuracy: 0.7160 - val_auc: 0.7846\n",
      "Epoch 403/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5815 - accuracy: 0.7060 - auc: 0.7634 - val_loss: 0.5714 - val_accuracy: 0.7281 - val_auc: 0.7840\n",
      "Epoch 404/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5752 - accuracy: 0.7164 - auc: 0.7701 - val_loss: 0.5708 - val_accuracy: 0.7281 - val_auc: 0.7853\n",
      "Epoch 405/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5752 - accuracy: 0.7051 - auc: 0.7707 - val_loss: 0.5712 - val_accuracy: 0.7221 - val_auc: 0.7840\n",
      "Epoch 406/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5730 - accuracy: 0.7146 - auc: 0.7729 - val_loss: 0.5725 - val_accuracy: 0.7221 - val_auc: 0.7834\n",
      "Epoch 407/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5748 - accuracy: 0.7070 - auc: 0.7704 - val_loss: 0.5722 - val_accuracy: 0.7251 - val_auc: 0.7833\n",
      "Epoch 408/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5693 - accuracy: 0.7183 - auc: 0.7789 - val_loss: 0.5706 - val_accuracy: 0.7251 - val_auc: 0.7853\n",
      "Epoch 409/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5761 - accuracy: 0.7079 - auc: 0.7678 - val_loss: 0.5709 - val_accuracy: 0.7251 - val_auc: 0.7853\n",
      "Epoch 410/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5754 - accuracy: 0.7108 - auc: 0.7708 - val_loss: 0.5716 - val_accuracy: 0.7281 - val_auc: 0.7841\n",
      "Epoch 411/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5728 - accuracy: 0.7117 - auc: 0.7725 - val_loss: 0.5709 - val_accuracy: 0.7281 - val_auc: 0.7850\n",
      "Epoch 412/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5787 - accuracy: 0.7042 - auc: 0.7640 - val_loss: 0.5709 - val_accuracy: 0.7281 - val_auc: 0.7849\n",
      "Epoch 413/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5657 - accuracy: 0.7297 - auc: 0.7824 - val_loss: 0.5703 - val_accuracy: 0.7281 - val_auc: 0.7856\n",
      "Epoch 414/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5674 - accuracy: 0.7032 - auc: 0.7799 - val_loss: 0.5703 - val_accuracy: 0.7221 - val_auc: 0.7861\n",
      "Epoch 415/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5731 - accuracy: 0.7108 - auc: 0.7723 - val_loss: 0.5710 - val_accuracy: 0.7190 - val_auc: 0.7847\n",
      "Epoch 416/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5778 - accuracy: 0.7193 - auc: 0.7699 - val_loss: 0.5713 - val_accuracy: 0.7221 - val_auc: 0.7847\n",
      "Epoch 417/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5620 - accuracy: 0.7098 - auc: 0.7844 - val_loss: 0.5722 - val_accuracy: 0.7221 - val_auc: 0.7841\n",
      "Epoch 418/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5677 - accuracy: 0.7070 - auc: 0.7774 - val_loss: 0.5722 - val_accuracy: 0.7221 - val_auc: 0.7840\n",
      "Epoch 419/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5560 - accuracy: 0.7155 - auc: 0.7906 - val_loss: 0.5714 - val_accuracy: 0.7251 - val_auc: 0.7852\n",
      "Epoch 420/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5729 - accuracy: 0.7051 - auc: 0.7704 - val_loss: 0.5715 - val_accuracy: 0.7251 - val_auc: 0.7847\n",
      "Epoch 421/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5754 - accuracy: 0.7117 - auc: 0.7700 - val_loss: 0.5730 - val_accuracy: 0.7281 - val_auc: 0.7835\n",
      "Epoch 422/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5740 - accuracy: 0.7117 - auc: 0.7719 - val_loss: 0.5723 - val_accuracy: 0.7221 - val_auc: 0.7839\n",
      "Epoch 423/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5618 - accuracy: 0.7240 - auc: 0.7855 - val_loss: 0.5725 - val_accuracy: 0.7190 - val_auc: 0.7837\n",
      "Epoch 424/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5771 - accuracy: 0.7004 - auc: 0.7662 - val_loss: 0.5723 - val_accuracy: 0.7190 - val_auc: 0.7838\n",
      "Epoch 425/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5808 - accuracy: 0.6843 - auc: 0.7659 - val_loss: 0.5724 - val_accuracy: 0.7221 - val_auc: 0.7840\n",
      "Epoch 426/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5757 - accuracy: 0.7127 - auc: 0.7690 - val_loss: 0.5723 - val_accuracy: 0.7221 - val_auc: 0.7844\n",
      "Epoch 427/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5658 - accuracy: 0.7004 - auc: 0.7787 - val_loss: 0.5717 - val_accuracy: 0.7221 - val_auc: 0.7850\n",
      "Epoch 428/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5805 - accuracy: 0.6957 - auc: 0.7650 - val_loss: 0.5711 - val_accuracy: 0.7221 - val_auc: 0.7854\n",
      "Epoch 429/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5665 - accuracy: 0.7212 - auc: 0.7810 - val_loss: 0.5715 - val_accuracy: 0.7190 - val_auc: 0.7846\n",
      "Epoch 430/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5722 - accuracy: 0.7042 - auc: 0.7713 - val_loss: 0.5710 - val_accuracy: 0.7190 - val_auc: 0.7850\n",
      "Epoch 431/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5745 - accuracy: 0.7089 - auc: 0.7721 - val_loss: 0.5720 - val_accuracy: 0.7281 - val_auc: 0.7842\n",
      "Epoch 432/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5670 - accuracy: 0.7079 - auc: 0.7803 - val_loss: 0.5720 - val_accuracy: 0.7281 - val_auc: 0.7846\n",
      "Epoch 433/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5779 - accuracy: 0.7127 - auc: 0.7710 - val_loss: 0.5725 - val_accuracy: 0.7251 - val_auc: 0.7838\n",
      "Epoch 434/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5685 - accuracy: 0.7183 - auc: 0.7774 - val_loss: 0.5721 - val_accuracy: 0.7221 - val_auc: 0.7839\n",
      "Epoch 435/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5750 - accuracy: 0.7146 - auc: 0.7716 - val_loss: 0.5726 - val_accuracy: 0.7281 - val_auc: 0.7836\n",
      "Epoch 436/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5766 - accuracy: 0.7146 - auc: 0.7750 - val_loss: 0.5714 - val_accuracy: 0.7281 - val_auc: 0.7846\n",
      "Epoch 437/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5711 - accuracy: 0.7136 - auc: 0.7772 - val_loss: 0.5713 - val_accuracy: 0.7281 - val_auc: 0.7846\n",
      "Epoch 438/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5626 - accuracy: 0.7079 - auc: 0.7800 - val_loss: 0.5706 - val_accuracy: 0.7281 - val_auc: 0.7852\n",
      "Epoch 439/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5713 - accuracy: 0.7183 - auc: 0.7788 - val_loss: 0.5715 - val_accuracy: 0.7281 - val_auc: 0.7842\n",
      "Epoch 440/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5767 - accuracy: 0.6947 - auc: 0.7657 - val_loss: 0.5707 - val_accuracy: 0.7281 - val_auc: 0.7852\n",
      "Epoch 441/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5700 - accuracy: 0.7051 - auc: 0.7756 - val_loss: 0.5713 - val_accuracy: 0.7281 - val_auc: 0.7847\n",
      "Epoch 442/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5791 - accuracy: 0.6947 - auc: 0.7639 - val_loss: 0.5712 - val_accuracy: 0.7281 - val_auc: 0.7846\n",
      "Epoch 443/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5560 - accuracy: 0.7193 - auc: 0.7912 - val_loss: 0.5714 - val_accuracy: 0.7281 - val_auc: 0.7852\n",
      "Epoch 444/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5596 - accuracy: 0.7363 - auc: 0.7897 - val_loss: 0.5715 - val_accuracy: 0.7311 - val_auc: 0.7840\n",
      "Epoch 00444: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('fearfull_ravdess.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1523,
     "status": "ok",
     "timestamp": 1596124118652,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "551ac120-4b2e-496d-fb38-e145fffe2bf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5702730417251587\n",
      "accuracy :  0.7220543622970581\n",
      "auc :  0.7860735058784485\n",
      "\n",
      "(True Negatives):  154\n",
      "(False Positives):  61\n",
      "(False Negatives):  31\n",
      "(True Positives):  85\n",
      "Total emotions_happy:  116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.72      0.77       215\n",
      "           1       0.58      0.73      0.65       116\n",
      "\n",
      "    accuracy                           0.72       331\n",
      "   macro avg       0.71      0.72      0.71       331\n",
      "weighted avg       0.74      0.72      0.73       331\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('fearfull_ravdess.hdf5')\n",
    "test_predictions_baseline = model.predict(X_test)\n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1011,
     "status": "ok",
     "timestamp": 1596124151514,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "da257091-d208-448a-c35b-d3a0c302ae9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5380187034606934\n",
      "accuracy :  0.7433962225914001\n",
      "auc :  0.8182840943336487\n",
      "\n",
      "(True Negatives):  128\n",
      "(False Positives):  43\n",
      "(False Negatives):  25\n",
      "(True Positives):  69\n",
      "Total emotions_happy:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79       171\n",
      "           1       0.62      0.73      0.67        94\n",
      "\n",
      "    accuracy                           0.74       265\n",
      "   macro avg       0.73      0.74      0.73       265\n",
      "weighted avg       0.76      0.74      0.75       265\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val)\n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wu7Em55Kq0U"
   },
   "source": [
    "Classification sans oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xX8HiJbmLPO_"
   },
   "source": [
    "Features selction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzB76wjaKodw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3082,
     "status": "ok",
     "timestamp": 1596539728906,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "60lGmL8KLSQb",
    "outputId": "2dbff0ae-49ca-4ab5-933e-d64f6bd4b560"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration                                      X_removed\n",
       "0         1  [0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]\n",
       "1         2  [0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]\n",
       "2         3  [0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]\n",
       "3         4  [0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]\n",
       "4         5  [0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 18, 19, 21]    1000\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "   \n",
    "    \n",
    "    \n",
    "    X = np.asarray(X_scaler)\n",
    "    y = labels\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeNSqblGL4kL"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected_out = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected_out.append([ X[i][4], X[i][6], X[i][7], \n",
    "               X[i][11], X[i][12], \n",
    "                X[i][15], X[i][16], X[i][17], X[i][20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 494,
     "status": "ok",
     "timestamp": 1596540039537,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5W4yZY5vMZ7L",
    "outputId": "083161dd-2cff-47cd-a99f-42197424da54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796\n",
      "249\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train_out, X_test_out, y_train_out, y_test_out = train_test_split(\n",
    "    X_selected_out, labels, test_size=0.2, random_state=1)\n",
    "X_train_out, X_val_out, y_train_out, y_val_out = train_test_split(\n",
    "    X_train_out, y_train_out, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train_out))\n",
    "print(len(X_test_out))\n",
    "print(len(X_val_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L2dkeu1RNLwQ"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ey_QTFjGNNzk"
   },
   "outputs": [],
   "source": [
    "X_train_out = np.asarray(X_train_out)\n",
    "X_test_out = np.asarray(X_test_out)\n",
    "X_val_out = np.asarray(X_val_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1596540354104,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "IVoNJaQxNyFr",
    "outputId": "ce0091d1-6abe-46b7-e1f0-7a7c9d9bfd5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(796, 9, 1)\n",
      "(249, 9, 1)\n",
      "(200, 9, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train_out = np.reshape(X_train_out, (X_train_out.shape[0], X_train_out.shape[1], 1))\n",
    " X_test_out = np.reshape(X_test_out, (X_test_out.shape[0], X_test_out.shape[1], 1))\n",
    " X_val_out = np.reshape(X_val_out, (X_val_out.shape[0], X_val_out.shape[1], 1))\n",
    "\n",
    " print(X_train_out.shape)\n",
    " print(X_test_out.shape)\n",
    " print(X_val_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1596540451062,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "YUI2vS97OL5W",
    "outputId": "e9be3714-31e5-4830-e076-9b46ac0aa016"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(796, 2)\n",
      "(249, 2)\n",
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train_out = to_categorical(y_train_out)\n",
    "y_test_out = to_categorical(y_test_out)\n",
    "y_val_out = to_categorical(y_val_out)\n",
    "\n",
    "print(y_train_out.shape)\n",
    "print(y_test_out.shape)\n",
    "print(y_val_out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZkGmZ7W1Oi80"
   },
   "source": [
    "Model with out oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejbeQEpnOi8-"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (9,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1596540538733,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3bqJxl0QOi9Y",
    "outputId": "ff60bec7-778e-417c-b8de-54f8b5f8a40e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 9, 1)]            0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 9, 128)            768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 9, 128)            512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 9, 128)            82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2306      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 85,642\n",
      "Trainable params: 85,382\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## First LFLB (local feature learning block)\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train_out.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10851,
     "status": "ok",
     "timestamp": 1596540676345,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ekszgbwvOi91",
    "outputId": "8135a525-ca20-4845-d239-151ac92fbf2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.8246 - accuracy: 0.5616 - auc: 0.5269 - val_loss: 0.6896 - val_accuracy: 0.5382 - val_auc: 0.5590\n",
      "Epoch 2/700\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7630 - accuracy: 0.5628 - auc: 0.5732 - val_loss: 0.6795 - val_accuracy: 0.6024 - val_auc: 0.6499\n",
      "Epoch 3/700\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.7220 - accuracy: 0.5829 - auc: 0.5954 - val_loss: 0.6713 - val_accuracy: 0.6586 - val_auc: 0.7247\n",
      "Epoch 4/700\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.7390 - accuracy: 0.5590 - auc: 0.5728 - val_loss: 0.6648 - val_accuracy: 0.7349 - val_auc: 0.7690\n",
      "Epoch 5/700\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.7244 - accuracy: 0.5616 - auc: 0.5757 - val_loss: 0.6618 - val_accuracy: 0.7349 - val_auc: 0.7780\n",
      "Epoch 6/700\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7061 - accuracy: 0.5754 - auc: 0.5920 - val_loss: 0.6600 - val_accuracy: 0.7430 - val_auc: 0.7793\n",
      "Epoch 7/700\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7106 - accuracy: 0.5766 - auc: 0.5922 - val_loss: 0.6598 - val_accuracy: 0.7349 - val_auc: 0.7747\n",
      "Epoch 8/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.7015 - accuracy: 0.5754 - auc: 0.5916 - val_loss: 0.6609 - val_accuracy: 0.7189 - val_auc: 0.7629\n",
      "Epoch 9/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6952 - accuracy: 0.5917 - auc: 0.6004 - val_loss: 0.6620 - val_accuracy: 0.6988 - val_auc: 0.7496\n",
      "Epoch 10/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6960 - accuracy: 0.5842 - auc: 0.6074 - val_loss: 0.6623 - val_accuracy: 0.6948 - val_auc: 0.7447\n",
      "Epoch 11/700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6954 - accuracy: 0.5565 - auc: 0.5918 - val_loss: 0.6635 - val_accuracy: 0.6908 - val_auc: 0.7289\n",
      "Epoch 12/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6893 - accuracy: 0.5804 - auc: 0.5995 - val_loss: 0.6650 - val_accuracy: 0.6827 - val_auc: 0.7199\n",
      "Epoch 13/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6809 - accuracy: 0.6018 - auc: 0.6174 - val_loss: 0.6664 - val_accuracy: 0.6867 - val_auc: 0.7064\n",
      "Epoch 14/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6865 - accuracy: 0.5905 - auc: 0.6042 - val_loss: 0.6666 - val_accuracy: 0.6787 - val_auc: 0.6989\n",
      "Epoch 15/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6788 - accuracy: 0.5980 - auc: 0.6248 - val_loss: 0.6685 - val_accuracy: 0.6627 - val_auc: 0.6886\n",
      "Epoch 16/700\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5905 - auc: 0.6046 - val_loss: 0.6691 - val_accuracy: 0.6627 - val_auc: 0.6806\n",
      "Epoch 17/700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6854 - accuracy: 0.5917 - auc: 0.6078 - val_loss: 0.6702 - val_accuracy: 0.6586 - val_auc: 0.6692\n",
      "Epoch 18/700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6794 - accuracy: 0.6005 - auc: 0.6266 - val_loss: 0.6725 - val_accuracy: 0.6546 - val_auc: 0.6557\n",
      "Epoch 19/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6797 - accuracy: 0.5892 - auc: 0.6165 - val_loss: 0.6743 - val_accuracy: 0.6225 - val_auc: 0.6445\n",
      "Epoch 20/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6725 - accuracy: 0.6244 - auc: 0.6465 - val_loss: 0.6751 - val_accuracy: 0.6265 - val_auc: 0.6346\n",
      "Epoch 21/700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6782 - accuracy: 0.5980 - auc: 0.6187 - val_loss: 0.6762 - val_accuracy: 0.6104 - val_auc: 0.6302\n",
      "Epoch 22/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6708 - accuracy: 0.6206 - auc: 0.6393 - val_loss: 0.6769 - val_accuracy: 0.6104 - val_auc: 0.6226\n",
      "Epoch 23/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6794 - accuracy: 0.6043 - auc: 0.6183 - val_loss: 0.6770 - val_accuracy: 0.6104 - val_auc: 0.6210\n",
      "Epoch 24/700\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.6729 - accuracy: 0.5967 - auc: 0.6287 - val_loss: 0.6768 - val_accuracy: 0.6104 - val_auc: 0.6214\n",
      "Epoch 25/700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6693 - accuracy: 0.6068 - auc: 0.6354 - val_loss: 0.6775 - val_accuracy: 0.6064 - val_auc: 0.6187\n",
      "Epoch 26/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6700 - accuracy: 0.6080 - auc: 0.6340 - val_loss: 0.6768 - val_accuracy: 0.6104 - val_auc: 0.6193\n",
      "Epoch 27/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6741 - accuracy: 0.6193 - auc: 0.6370 - val_loss: 0.6758 - val_accuracy: 0.6104 - val_auc: 0.6217\n",
      "Epoch 28/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6755 - accuracy: 0.5879 - auc: 0.6240 - val_loss: 0.6760 - val_accuracy: 0.6024 - val_auc: 0.6196\n",
      "Epoch 29/700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6663 - accuracy: 0.5980 - auc: 0.6429 - val_loss: 0.6780 - val_accuracy: 0.5984 - val_auc: 0.6153\n",
      "Epoch 30/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6679 - accuracy: 0.6106 - auc: 0.6422 - val_loss: 0.6774 - val_accuracy: 0.6024 - val_auc: 0.6155\n",
      "Epoch 31/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6756 - accuracy: 0.6030 - auc: 0.6259 - val_loss: 0.6762 - val_accuracy: 0.6024 - val_auc: 0.6165\n",
      "Epoch 32/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6735 - accuracy: 0.6018 - auc: 0.6278 - val_loss: 0.6768 - val_accuracy: 0.6024 - val_auc: 0.6160\n",
      "Epoch 33/700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6682 - accuracy: 0.6080 - auc: 0.6439 - val_loss: 0.6766 - val_accuracy: 0.6064 - val_auc: 0.6173\n",
      "Epoch 34/700\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.6680 - accuracy: 0.6231 - auc: 0.6434 - val_loss: 0.6767 - val_accuracy: 0.5984 - val_auc: 0.6166\n",
      "Epoch 35/700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6653 - accuracy: 0.6206 - auc: 0.6471 - val_loss: 0.6753 - val_accuracy: 0.6145 - val_auc: 0.6216\n",
      "Epoch 36/700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6758 - accuracy: 0.5942 - auc: 0.6266 - val_loss: 0.6755 - val_accuracy: 0.6145 - val_auc: 0.6211\n",
      "Epoch 37/700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6711 - accuracy: 0.6319 - auc: 0.6410 - val_loss: 0.6749 - val_accuracy: 0.6145 - val_auc: 0.6234\n",
      "Epoch 00037: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('fearfull_outover_ravdess.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train_out, y_train_out, batch_size=64, epochs=700, validation_data=(X_test_out, y_test_out), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6Z9lA6COi9-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('fearfull_outover_ravdess.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1a0xGocOi-I"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_predictions_baseline = model.predict(X_test_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1xdr1b6Oi-Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1018,
     "status": "ok",
     "timestamp": 1596540875675,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "aAL5PdZrOi-b",
    "outputId": "6e5d0d89-1e33-4236-9183-0deb1508ff38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.6597882509231567\n",
      "accuracy :  0.7349397540092468\n",
      "auc :  0.7746971845626831\n",
      "\n",
      "(True Negatives):  171\n",
      "(False Positives):  40\n",
      "(False Negatives):  26\n",
      "(True Positives):  12\n",
      "Total emotions_happy:  38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84       211\n",
      "           1       0.23      0.32      0.27        38\n",
      "\n",
      "    accuracy                           0.73       249\n",
      "   macro avg       0.55      0.56      0.55       249\n",
      "weighted avg       0.77      0.73      0.75       249\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_test_out, y_test_out,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test_out, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7FecPpJsOi-j"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpZ2C4PdOi-l"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1596541071499,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "_Ds3lZcXOi-r",
    "outputId": "68efc15c-1e40-4f95-a23f-e94110a624a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.652274489402771\n",
      "accuracy :  0.7649999856948853\n",
      "auc :  0.8261125087738037\n",
      "\n",
      "(True Negatives):  143\n",
      "(False Positives):  29\n",
      "(False Negatives):  18\n",
      "(True Positives):  10\n",
      "Total emotions_happy:  28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       172\n",
      "           1       0.26      0.36      0.30        28\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.57      0.59      0.58       200\n",
      "weighted avg       0.80      0.77      0.78       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_val_out, y_val_out,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val_out, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNePI+N17EfxEUnNsxxkNFa",
   "collapsed_sections": [
    "h8U62d8rGqo9"
   ],
   "name": "deep_fearfull_RAVDESS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
