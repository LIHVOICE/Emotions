{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8505,
     "status": "ok",
     "timestamp": 1596177854340,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ymHSlukhKIF9",
    "outputId": "1279eea0-e6f2-4ca1-d750-b42a5a091cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.7.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (2.1.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.18.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.16.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (4.4.2)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.15.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.48.0)\n",
      "Collecting soundfile>=0.9.0\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (49.1.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.14.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)\n",
      "Building wheels for collected packages: librosa\n",
      "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for librosa: filename=librosa-0.7.2-cp36-none-any.whl size=1612885 sha256=4a6b61ffb70e8a09af4e17946262f7822c5cab77ded33643f40d0ff58171d3bd\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/6e/d7/bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
      "Successfully built librosa\n",
      "Installing collected packages: soundfile, librosa\n",
      "  Found existing installation: librosa 0.6.3\n",
      "    Uninstalling librosa-0.6.3:\n",
      "      Successfully uninstalled librosa-0.6.3\n",
      "Successfully installed librosa-0.7.2 soundfile-0.10.3.post1\n"
     ]
    }
   ],
   "source": [
    "pip install librosa==0.7.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10002,
     "status": "ok",
     "timestamp": 1596026935548,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "sXnDmXR7RDr2",
    "outputId": "3b9dff36-3699-413b-8a0a-75f3af305685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10711,
     "status": "ok",
     "timestamp": 1596026954464,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Y04m-jvKRDsJ",
    "outputId": "ce46bb70-bae2-4985-8f6b-ee3fece0cc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
      "CPU (s):\n",
      "2.876127255\n",
      "GPU (s):\n",
      "0.1083209219999901\n",
      "GPU speedup over CPU: 26x\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27325,
     "status": "ok",
     "timestamp": 1596178708220,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l9EbbgJpzQDD",
    "outputId": "ed8c680c-c9fc-4417-df9b-1e73b421120e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7139,
     "status": "ok",
     "timestamp": 1596178732897,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ltf4WKPCeyVR",
    "outputId": "b941455e-261e-416f-9b05-84c11dd04e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praat-parselmouth\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7b/9fa1172a63b6277603d27bb5613559b5a8888f58e68c1698017b87b0061d/praat_parselmouth-0.3.3-cp36-cp36m-manylinux1_x86_64.whl (9.0MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0MB 2.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from praat-parselmouth) (1.18.5)\n",
      "Installing collected packages: praat-parselmouth\n",
      "Successfully installed praat-parselmouth-0.3.3\n"
     ]
    }
   ],
   "source": [
    "pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7297,
     "status": "ok",
     "timestamp": 1596178778015,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PNwtWyMXe_Qb",
    "outputId": "6c9cc6ba-ffca-491e-c496-2e017c79ea97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting essentia\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/cf/3c776d02b63fed7b0958bef2ce57b900870e2ac3f1fd8ffbb63f22d0e69e/essentia-2.1b6.dev234-cp36-cp36m-manylinux1_x86_64.whl (11.7MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7MB 331kB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from essentia) (3.13)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from essentia) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from essentia) (1.15.0)\n",
      "Installing collected packages: essentia\n",
      "Successfully installed essentia-2.1b6.dev234\n"
     ]
    }
   ],
   "source": [
    "pip install essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3930,
     "status": "ok",
     "timestamp": 1596178785612,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "B9TmOS9AFg61",
    "outputId": "7ec8814f-257a-4c53-cc0a-1e9d9798d91a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "#Spafe for audio\n",
    "#import spafe\n",
    "import scipy.io.wavfile\n",
    "#import spafe.utils.vis as vis\n",
    "#from spafe.features.mfcc import mfcc, imfcc\n",
    "#from spafe.features.gfcc import gfcc\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1579,
     "status": "ok",
     "timestamp": 1596178898641,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "QAD42F-CgYli",
    "outputId": "c82c70b1-5c20-48eb-fd19-7aab5e992108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "cd drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3184,
     "status": "ok",
     "timestamp": 1596178954362,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "b820672a-c5e3-46e5-83c7-4c8bff85966e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy/03-01-03-02-01-01-09_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy/03-01-03-02-02-02-10_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust/03-01-07-02-01-01-12_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy/03-01-03-01-01-01-02_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry/03-01-05-01-01-02-16_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            audio label\n",
       "0    happy/03-01-03-02-01-01-09_norm_outNoise.wav     0\n",
       "1    happy/03-01-03-02-02-02-10_norm_outNoise.wav     0\n",
       "2  disgust/03-01-07-02-01-01-12_norm_outNoise.wav     0\n",
       "3    happy/03-01-03-01-01-01-02_norm_outNoise.wav     0\n",
       "4    angry/03-01-05-01-01-02-16_norm_outNoise.wav     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"audio_emotion\"\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i[7] == '8':\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) # here at df defined, with the columns we add the values:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1596178995074,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "42d73a78-34e6-43e7-a7cf-85fd2a7b5c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1053\n",
      "1     192\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1596179041928,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1596179169824,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "AjNAMwsfG2C8"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    fs, sig = scipy.io.wavfile.read(audio_path) \n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    spec =  fram_window(audio_path) \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)\n",
    "            \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "               \n",
    "    #gfccs = gfcc(sig= spec, fs=fs, num_ceps=13)    \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    #features.append(np.mean(gfccs))\n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3459322,
     "status": "ok",
     "timestamp": 1596182706479,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "folder ='audio_emotion'\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(folder+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1596182852071,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "8edd7351-e256-4333-db66-97fcd3de6134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1596182883507,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1298,
     "status": "ok",
     "timestamp": 1596182916731,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 679,
     "status": "ok",
     "timestamp": 1596182946519,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "4961fb16-9e0c-4ae0-ee36-bfbd9ba8f7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 606\n",
      "After OverSampling, counts of label '0': 1053\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \" [1, 2, 3, 12, 13, 14]   \" are deleted 494 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28957,
     "status": "ok",
     "timestamp": 1596183005212,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "1f161b18-f807-4f55-d335-be62ac4bac4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4, 12, 13, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3, 12, 13, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2, 3, 4, 12, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 3, 12, 13, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 2, 3, 12, 13, 14]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration                 X_removed\n",
       "0         1  [1, 2, 3, 4, 12, 13, 14]\n",
       "1         2     [1, 2, 3, 12, 13, 14]\n",
       "2         3      [1, 2, 3, 4, 12, 13]\n",
       "3         4     [1, 2, 3, 12, 13, 14]\n",
       "4         5     [1, 2, 3, 12, 13, 14]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 12, 13, 14]          494\n",
       "[1, 2, 3, 4, 12, 13, 14]       397\n",
       "[1, 2, 3, 4, 5, 12, 13, 14]     45\n",
       "[1, 2, 3, 5, 12, 13, 14]        30\n",
       "[1, 2, 3, 12, 13]               17\n",
       "[1, 2, 3, 4, 12, 13]            15\n",
       "[1, 2, 3, 5, 12, 13]             1\n",
       "[1, 2, 3, 4, 5, 12, 13]          1\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1596183123404,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6sTQj5wDWdev"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0], X[i][4],  X[i][5], X[i][6], X[i][7], X[i][8],  X[i][9], X[i][10],\n",
    "               X[i][11],  X[i][15], \n",
    "                X[i][16], X[i][17], X[i][18], X[i][19],  X[i][20], X[i][21]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1596183125305,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "80ad0881-2f17-4419-c0f7-bcbcdc5003d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061\n",
      "332\n",
      "266\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2428,
     "status": "ok",
     "timestamp": 1596183147291,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "TWis1PUVfK_4",
    "outputId": "ed5d4474-14dc-42d5-a9cc-2ebbf379e6d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Plot imports ###\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "### Warning ###\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1596183166256,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 736,
     "status": "ok",
     "timestamp": 1596183176062,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "7b830776-7d63-4b78-c826-29c08fabf33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1061, 16, 1)\n",
      "(332, 16, 1)\n",
      "(266, 16, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1596183201169,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "fe5231bf-b32c-4cd9-f1c7-afde9a79174c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1061, 2)\n",
      "(332, 2)\n",
      "(266, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1596183219643,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1596183222992,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "e6dbb1c7-7120-403f-d00b-890d5ae96a3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 1)]           0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 16, 128)           768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 16, 128)           512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 16, 128)           82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 87,434\n",
      "Trainable params: 87,174\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## First LFLB (local feature learning block)\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1596183227427,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 255195,
     "status": "ok",
     "timestamp": 1596183494088,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "ca284e87-e454-4c0d-9876-20f6bce0d304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "17/17 [==============================] - 1s 52ms/step - loss: 0.7746 - accuracy: 0.5589 - auc: 0.5656 - val_loss: 0.6759 - val_accuracy: 0.6235 - val_auc: 0.6914\n",
      "Epoch 2/700\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.6824 - accuracy: 0.6249 - auc: 0.6702 - val_loss: 0.6590 - val_accuracy: 0.6717 - val_auc: 0.7525\n",
      "Epoch 3/700\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.6437 - accuracy: 0.6598 - auc: 0.7164 - val_loss: 0.6468 - val_accuracy: 0.6747 - val_auc: 0.7671\n",
      "Epoch 4/700\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.6413 - accuracy: 0.6777 - auc: 0.7220 - val_loss: 0.6377 - val_accuracy: 0.6807 - val_auc: 0.7744\n",
      "Epoch 5/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.6292 - accuracy: 0.6824 - auc: 0.7337 - val_loss: 0.6311 - val_accuracy: 0.6988 - val_auc: 0.7793\n",
      "Epoch 6/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5879 - accuracy: 0.6909 - auc: 0.7602 - val_loss: 0.6274 - val_accuracy: 0.6958 - val_auc: 0.7858\n",
      "Epoch 7/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5933 - accuracy: 0.7088 - auc: 0.7613 - val_loss: 0.6232 - val_accuracy: 0.7108 - val_auc: 0.7888\n",
      "Epoch 8/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.6068 - accuracy: 0.6937 - auc: 0.7515 - val_loss: 0.6186 - val_accuracy: 0.7048 - val_auc: 0.7907\n",
      "Epoch 9/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5985 - accuracy: 0.6956 - auc: 0.7625 - val_loss: 0.6148 - val_accuracy: 0.7018 - val_auc: 0.7932\n",
      "Epoch 10/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5892 - accuracy: 0.7097 - auc: 0.7663 - val_loss: 0.6121 - val_accuracy: 0.7169 - val_auc: 0.7946\n",
      "Epoch 11/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5795 - accuracy: 0.7172 - auc: 0.7772 - val_loss: 0.6089 - val_accuracy: 0.7229 - val_auc: 0.7917\n",
      "Epoch 12/700\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.5854 - accuracy: 0.7078 - auc: 0.7669 - val_loss: 0.6053 - val_accuracy: 0.7319 - val_auc: 0.7918\n",
      "Epoch 13/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5644 - accuracy: 0.7248 - auc: 0.7852 - val_loss: 0.6015 - val_accuracy: 0.7289 - val_auc: 0.7885\n",
      "Epoch 14/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5694 - accuracy: 0.7276 - auc: 0.7825 - val_loss: 0.5977 - val_accuracy: 0.7380 - val_auc: 0.7900\n",
      "Epoch 15/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5704 - accuracy: 0.7116 - auc: 0.7787 - val_loss: 0.5944 - val_accuracy: 0.7410 - val_auc: 0.7897\n",
      "Epoch 16/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5804 - accuracy: 0.7116 - auc: 0.7718 - val_loss: 0.5903 - val_accuracy: 0.7500 - val_auc: 0.7889\n",
      "Epoch 17/700\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.5739 - accuracy: 0.7097 - auc: 0.7756 - val_loss: 0.5866 - val_accuracy: 0.7440 - val_auc: 0.7867\n",
      "Epoch 18/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5681 - accuracy: 0.7314 - auc: 0.7843 - val_loss: 0.5832 - val_accuracy: 0.7380 - val_auc: 0.7865\n",
      "Epoch 19/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5556 - accuracy: 0.7191 - auc: 0.7897 - val_loss: 0.5788 - val_accuracy: 0.7470 - val_auc: 0.7879\n",
      "Epoch 20/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5673 - accuracy: 0.7125 - auc: 0.7820 - val_loss: 0.5753 - val_accuracy: 0.7470 - val_auc: 0.7874\n",
      "Epoch 21/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5674 - accuracy: 0.7191 - auc: 0.7849 - val_loss: 0.5714 - val_accuracy: 0.7440 - val_auc: 0.7879\n",
      "Epoch 22/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5515 - accuracy: 0.7229 - auc: 0.7947 - val_loss: 0.5683 - val_accuracy: 0.7380 - val_auc: 0.7884\n",
      "Epoch 23/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5684 - accuracy: 0.7154 - auc: 0.7819 - val_loss: 0.5646 - val_accuracy: 0.7410 - val_auc: 0.7890\n",
      "Epoch 24/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5522 - accuracy: 0.7333 - auc: 0.7953 - val_loss: 0.5609 - val_accuracy: 0.7410 - val_auc: 0.7902\n",
      "Epoch 25/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5576 - accuracy: 0.7220 - auc: 0.7892 - val_loss: 0.5588 - val_accuracy: 0.7410 - val_auc: 0.7903\n",
      "Epoch 26/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5603 - accuracy: 0.7144 - auc: 0.7878 - val_loss: 0.5547 - val_accuracy: 0.7440 - val_auc: 0.7938\n",
      "Epoch 27/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5602 - accuracy: 0.7267 - auc: 0.7876 - val_loss: 0.5528 - val_accuracy: 0.7440 - val_auc: 0.7937\n",
      "Epoch 28/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5506 - accuracy: 0.7352 - auc: 0.7966 - val_loss: 0.5502 - val_accuracy: 0.7440 - val_auc: 0.7954\n",
      "Epoch 29/700\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.5524 - accuracy: 0.7304 - auc: 0.7930 - val_loss: 0.5472 - val_accuracy: 0.7500 - val_auc: 0.7982\n",
      "Epoch 30/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5519 - accuracy: 0.7352 - auc: 0.7961 - val_loss: 0.5451 - val_accuracy: 0.7500 - val_auc: 0.7986\n",
      "Epoch 31/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5471 - accuracy: 0.7408 - auc: 0.8007 - val_loss: 0.5437 - val_accuracy: 0.7500 - val_auc: 0.7992\n",
      "Epoch 32/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5514 - accuracy: 0.7276 - auc: 0.7981 - val_loss: 0.5425 - val_accuracy: 0.7530 - val_auc: 0.7991\n",
      "Epoch 33/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5558 - accuracy: 0.7229 - auc: 0.7901 - val_loss: 0.5422 - val_accuracy: 0.7440 - val_auc: 0.7983\n",
      "Epoch 34/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5526 - accuracy: 0.7229 - auc: 0.7936 - val_loss: 0.5407 - val_accuracy: 0.7440 - val_auc: 0.7993\n",
      "Epoch 35/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5529 - accuracy: 0.7248 - auc: 0.7954 - val_loss: 0.5375 - val_accuracy: 0.7500 - val_auc: 0.8023\n",
      "Epoch 36/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5443 - accuracy: 0.7304 - auc: 0.7992 - val_loss: 0.5385 - val_accuracy: 0.7440 - val_auc: 0.8006\n",
      "Epoch 37/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5463 - accuracy: 0.7267 - auc: 0.7991 - val_loss: 0.5365 - val_accuracy: 0.7440 - val_auc: 0.8022\n",
      "Epoch 38/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5459 - accuracy: 0.7201 - auc: 0.7990 - val_loss: 0.5350 - val_accuracy: 0.7470 - val_auc: 0.8036\n",
      "Epoch 39/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5451 - accuracy: 0.7361 - auc: 0.7994 - val_loss: 0.5361 - val_accuracy: 0.7470 - val_auc: 0.8023\n",
      "Epoch 40/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5387 - accuracy: 0.7446 - auc: 0.8036 - val_loss: 0.5343 - val_accuracy: 0.7440 - val_auc: 0.8039\n",
      "Epoch 41/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5552 - accuracy: 0.7248 - auc: 0.7914 - val_loss: 0.5343 - val_accuracy: 0.7410 - val_auc: 0.8040\n",
      "Epoch 42/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5349 - accuracy: 0.7408 - auc: 0.8076 - val_loss: 0.5335 - val_accuracy: 0.7410 - val_auc: 0.8045\n",
      "Epoch 43/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5302 - accuracy: 0.7465 - auc: 0.8115 - val_loss: 0.5319 - val_accuracy: 0.7470 - val_auc: 0.8061\n",
      "Epoch 44/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5335 - accuracy: 0.7418 - auc: 0.8094 - val_loss: 0.5312 - val_accuracy: 0.7470 - val_auc: 0.8066\n",
      "Epoch 45/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5369 - accuracy: 0.7370 - auc: 0.8082 - val_loss: 0.5320 - val_accuracy: 0.7470 - val_auc: 0.8053\n",
      "Epoch 46/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5379 - accuracy: 0.7352 - auc: 0.8067 - val_loss: 0.5314 - val_accuracy: 0.7440 - val_auc: 0.8056\n",
      "Epoch 47/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5382 - accuracy: 0.7446 - auc: 0.8066 - val_loss: 0.5301 - val_accuracy: 0.7440 - val_auc: 0.8072\n",
      "Epoch 48/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5411 - accuracy: 0.7323 - auc: 0.8023 - val_loss: 0.5293 - val_accuracy: 0.7470 - val_auc: 0.8080\n",
      "Epoch 49/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5454 - accuracy: 0.7304 - auc: 0.8001 - val_loss: 0.5300 - val_accuracy: 0.7470 - val_auc: 0.8072\n",
      "Epoch 50/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5282 - accuracy: 0.7606 - auc: 0.8143 - val_loss: 0.5292 - val_accuracy: 0.7470 - val_auc: 0.8087\n",
      "Epoch 51/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5395 - accuracy: 0.7323 - auc: 0.8054 - val_loss: 0.5300 - val_accuracy: 0.7470 - val_auc: 0.8068\n",
      "Epoch 52/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5378 - accuracy: 0.7286 - auc: 0.8061 - val_loss: 0.5303 - val_accuracy: 0.7470 - val_auc: 0.8072\n",
      "Epoch 53/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5382 - accuracy: 0.7418 - auc: 0.8084 - val_loss: 0.5305 - val_accuracy: 0.7440 - val_auc: 0.8067\n",
      "Epoch 54/700\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.5395 - accuracy: 0.7352 - auc: 0.8051 - val_loss: 0.5289 - val_accuracy: 0.7470 - val_auc: 0.8081\n",
      "Epoch 55/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5495 - accuracy: 0.7323 - auc: 0.7970 - val_loss: 0.5284 - val_accuracy: 0.7470 - val_auc: 0.8084\n",
      "Epoch 56/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5318 - accuracy: 0.7352 - auc: 0.8124 - val_loss: 0.5280 - val_accuracy: 0.7470 - val_auc: 0.8082\n",
      "Epoch 57/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5289 - accuracy: 0.7446 - auc: 0.8150 - val_loss: 0.5283 - val_accuracy: 0.7500 - val_auc: 0.8086\n",
      "Epoch 58/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5302 - accuracy: 0.7323 - auc: 0.8128 - val_loss: 0.5281 - val_accuracy: 0.7530 - val_auc: 0.8084\n",
      "Epoch 59/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5388 - accuracy: 0.7295 - auc: 0.8057 - val_loss: 0.5273 - val_accuracy: 0.7500 - val_auc: 0.8092\n",
      "Epoch 60/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5261 - accuracy: 0.7408 - auc: 0.8176 - val_loss: 0.5269 - val_accuracy: 0.7500 - val_auc: 0.8099\n",
      "Epoch 61/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5319 - accuracy: 0.7484 - auc: 0.8112 - val_loss: 0.5272 - val_accuracy: 0.7500 - val_auc: 0.8095\n",
      "Epoch 62/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5270 - accuracy: 0.7521 - auc: 0.8164 - val_loss: 0.5259 - val_accuracy: 0.7500 - val_auc: 0.8111\n",
      "Epoch 63/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5324 - accuracy: 0.7380 - auc: 0.8111 - val_loss: 0.5260 - val_accuracy: 0.7500 - val_auc: 0.8109\n",
      "Epoch 64/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5370 - accuracy: 0.7323 - auc: 0.8054 - val_loss: 0.5262 - val_accuracy: 0.7500 - val_auc: 0.8109\n",
      "Epoch 65/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5433 - accuracy: 0.7314 - auc: 0.8036 - val_loss: 0.5268 - val_accuracy: 0.7500 - val_auc: 0.8100\n",
      "Epoch 66/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5382 - accuracy: 0.7352 - auc: 0.8067 - val_loss: 0.5259 - val_accuracy: 0.7530 - val_auc: 0.8113\n",
      "Epoch 67/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5313 - accuracy: 0.7512 - auc: 0.8120 - val_loss: 0.5251 - val_accuracy: 0.7560 - val_auc: 0.8123\n",
      "Epoch 68/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5343 - accuracy: 0.7465 - auc: 0.8110 - val_loss: 0.5262 - val_accuracy: 0.7500 - val_auc: 0.8108\n",
      "Epoch 69/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5335 - accuracy: 0.7342 - auc: 0.8110 - val_loss: 0.5260 - val_accuracy: 0.7500 - val_auc: 0.8104\n",
      "Epoch 70/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5429 - accuracy: 0.7361 - auc: 0.8044 - val_loss: 0.5252 - val_accuracy: 0.7500 - val_auc: 0.8122\n",
      "Epoch 71/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5281 - accuracy: 0.7436 - auc: 0.8155 - val_loss: 0.5255 - val_accuracy: 0.7530 - val_auc: 0.8121\n",
      "Epoch 72/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5296 - accuracy: 0.7380 - auc: 0.8124 - val_loss: 0.5255 - val_accuracy: 0.7530 - val_auc: 0.8120\n",
      "Epoch 73/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5399 - accuracy: 0.7276 - auc: 0.8047 - val_loss: 0.5267 - val_accuracy: 0.7500 - val_auc: 0.8100\n",
      "Epoch 74/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5259 - accuracy: 0.7304 - auc: 0.8152 - val_loss: 0.5265 - val_accuracy: 0.7470 - val_auc: 0.8103\n",
      "Epoch 75/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5243 - accuracy: 0.7455 - auc: 0.8177 - val_loss: 0.5264 - val_accuracy: 0.7500 - val_auc: 0.8108\n",
      "Epoch 76/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5351 - accuracy: 0.7370 - auc: 0.8092 - val_loss: 0.5262 - val_accuracy: 0.7500 - val_auc: 0.8110\n",
      "Epoch 77/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5268 - accuracy: 0.7493 - auc: 0.8169 - val_loss: 0.5266 - val_accuracy: 0.7500 - val_auc: 0.8107\n",
      "Epoch 78/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5240 - accuracy: 0.7568 - auc: 0.8194 - val_loss: 0.5263 - val_accuracy: 0.7500 - val_auc: 0.8107\n",
      "Epoch 79/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5264 - accuracy: 0.7399 - auc: 0.8149 - val_loss: 0.5251 - val_accuracy: 0.7530 - val_auc: 0.8124\n",
      "Epoch 80/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5270 - accuracy: 0.7446 - auc: 0.8143 - val_loss: 0.5245 - val_accuracy: 0.7530 - val_auc: 0.8134\n",
      "Epoch 81/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5248 - accuracy: 0.7465 - auc: 0.8185 - val_loss: 0.5231 - val_accuracy: 0.7560 - val_auc: 0.8153\n",
      "Epoch 82/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5253 - accuracy: 0.7549 - auc: 0.8159 - val_loss: 0.5240 - val_accuracy: 0.7530 - val_auc: 0.8136\n",
      "Epoch 83/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5286 - accuracy: 0.7465 - auc: 0.8137 - val_loss: 0.5242 - val_accuracy: 0.7530 - val_auc: 0.8134\n",
      "Epoch 84/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5270 - accuracy: 0.7436 - auc: 0.8160 - val_loss: 0.5240 - val_accuracy: 0.7560 - val_auc: 0.8129\n",
      "Epoch 85/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5226 - accuracy: 0.7474 - auc: 0.8196 - val_loss: 0.5242 - val_accuracy: 0.7500 - val_auc: 0.8129\n",
      "Epoch 86/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5290 - accuracy: 0.7399 - auc: 0.8142 - val_loss: 0.5243 - val_accuracy: 0.7500 - val_auc: 0.8127\n",
      "Epoch 87/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5253 - accuracy: 0.7493 - auc: 0.8170 - val_loss: 0.5234 - val_accuracy: 0.7560 - val_auc: 0.8145\n",
      "Epoch 88/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5249 - accuracy: 0.7408 - auc: 0.8186 - val_loss: 0.5239 - val_accuracy: 0.7560 - val_auc: 0.8139\n",
      "Epoch 89/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5265 - accuracy: 0.7512 - auc: 0.8163 - val_loss: 0.5235 - val_accuracy: 0.7560 - val_auc: 0.8148\n",
      "Epoch 90/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5277 - accuracy: 0.7427 - auc: 0.8150 - val_loss: 0.5237 - val_accuracy: 0.7560 - val_auc: 0.8134\n",
      "Epoch 91/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5274 - accuracy: 0.7446 - auc: 0.8155 - val_loss: 0.5236 - val_accuracy: 0.7530 - val_auc: 0.8138\n",
      "Epoch 92/700\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.5215 - accuracy: 0.7521 - auc: 0.8192 - val_loss: 0.5229 - val_accuracy: 0.7530 - val_auc: 0.8147\n",
      "Epoch 93/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5253 - accuracy: 0.7521 - auc: 0.8161 - val_loss: 0.5227 - val_accuracy: 0.7590 - val_auc: 0.8151\n",
      "Epoch 94/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5296 - accuracy: 0.7408 - auc: 0.8144 - val_loss: 0.5224 - val_accuracy: 0.7590 - val_auc: 0.8151\n",
      "Epoch 95/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5207 - accuracy: 0.7521 - auc: 0.8216 - val_loss: 0.5233 - val_accuracy: 0.7560 - val_auc: 0.8135\n",
      "Epoch 96/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5315 - accuracy: 0.7455 - auc: 0.8152 - val_loss: 0.5225 - val_accuracy: 0.7530 - val_auc: 0.8148\n",
      "Epoch 97/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5226 - accuracy: 0.7578 - auc: 0.8194 - val_loss: 0.5227 - val_accuracy: 0.7530 - val_auc: 0.8146\n",
      "Epoch 98/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5378 - accuracy: 0.7399 - auc: 0.8081 - val_loss: 0.5214 - val_accuracy: 0.7560 - val_auc: 0.8166\n",
      "Epoch 99/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5170 - accuracy: 0.7512 - auc: 0.8231 - val_loss: 0.5223 - val_accuracy: 0.7530 - val_auc: 0.8153\n",
      "Epoch 100/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5264 - accuracy: 0.7370 - auc: 0.8158 - val_loss: 0.5215 - val_accuracy: 0.7560 - val_auc: 0.8160\n",
      "Epoch 101/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5192 - accuracy: 0.7578 - auc: 0.8239 - val_loss: 0.5211 - val_accuracy: 0.7590 - val_auc: 0.8163\n",
      "Epoch 102/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5224 - accuracy: 0.7389 - auc: 0.8188 - val_loss: 0.5209 - val_accuracy: 0.7590 - val_auc: 0.8168\n",
      "Epoch 103/700\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.5246 - accuracy: 0.7502 - auc: 0.8188 - val_loss: 0.5200 - val_accuracy: 0.7620 - val_auc: 0.8178\n",
      "Epoch 104/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5220 - accuracy: 0.7465 - auc: 0.8203 - val_loss: 0.5204 - val_accuracy: 0.7620 - val_auc: 0.8181\n",
      "Epoch 105/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5190 - accuracy: 0.7521 - auc: 0.8220 - val_loss: 0.5207 - val_accuracy: 0.7590 - val_auc: 0.8172\n",
      "Epoch 106/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5163 - accuracy: 0.7549 - auc: 0.8246 - val_loss: 0.5213 - val_accuracy: 0.7590 - val_auc: 0.8171\n",
      "Epoch 107/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5301 - accuracy: 0.7304 - auc: 0.8117 - val_loss: 0.5213 - val_accuracy: 0.7590 - val_auc: 0.8171\n",
      "Epoch 108/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5201 - accuracy: 0.7502 - auc: 0.8208 - val_loss: 0.5210 - val_accuracy: 0.7590 - val_auc: 0.8171\n",
      "Epoch 109/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5188 - accuracy: 0.7474 - auc: 0.8222 - val_loss: 0.5211 - val_accuracy: 0.7590 - val_auc: 0.8168\n",
      "Epoch 110/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5184 - accuracy: 0.7502 - auc: 0.8225 - val_loss: 0.5217 - val_accuracy: 0.7590 - val_auc: 0.8163\n",
      "Epoch 111/700\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.5232 - accuracy: 0.7455 - auc: 0.8166 - val_loss: 0.5202 - val_accuracy: 0.7651 - val_auc: 0.8179\n",
      "Epoch 112/700\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.5153 - accuracy: 0.7484 - auc: 0.8249 - val_loss: 0.5200 - val_accuracy: 0.7681 - val_auc: 0.8184\n",
      "Epoch 113/700\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5232 - accuracy: 0.7502 - auc: 0.8190 - val_loss: 0.5196 - val_accuracy: 0.7651 - val_auc: 0.8187\n",
      "Epoch 114/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5102 - accuracy: 0.7597 - auc: 0.8302 - val_loss: 0.5207 - val_accuracy: 0.7620 - val_auc: 0.8179\n",
      "Epoch 115/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5159 - accuracy: 0.7502 - auc: 0.8236 - val_loss: 0.5213 - val_accuracy: 0.7620 - val_auc: 0.8169\n",
      "Epoch 116/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5195 - accuracy: 0.7484 - auc: 0.8231 - val_loss: 0.5214 - val_accuracy: 0.7590 - val_auc: 0.8168\n",
      "Epoch 117/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5258 - accuracy: 0.7502 - auc: 0.8189 - val_loss: 0.5208 - val_accuracy: 0.7620 - val_auc: 0.8177\n",
      "Epoch 118/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5223 - accuracy: 0.7549 - auc: 0.8204 - val_loss: 0.5215 - val_accuracy: 0.7590 - val_auc: 0.8164\n",
      "Epoch 119/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5076 - accuracy: 0.7625 - auc: 0.8321 - val_loss: 0.5217 - val_accuracy: 0.7620 - val_auc: 0.8166\n",
      "Epoch 120/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5142 - accuracy: 0.7540 - auc: 0.8285 - val_loss: 0.5209 - val_accuracy: 0.7620 - val_auc: 0.8174\n",
      "Epoch 121/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5177 - accuracy: 0.7502 - auc: 0.8241 - val_loss: 0.5212 - val_accuracy: 0.7620 - val_auc: 0.8174\n",
      "Epoch 122/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5181 - accuracy: 0.7540 - auc: 0.8243 - val_loss: 0.5204 - val_accuracy: 0.7620 - val_auc: 0.8180\n",
      "Epoch 123/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5134 - accuracy: 0.7540 - auc: 0.8264 - val_loss: 0.5209 - val_accuracy: 0.7620 - val_auc: 0.8177\n",
      "Epoch 124/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5122 - accuracy: 0.7446 - auc: 0.8269 - val_loss: 0.5218 - val_accuracy: 0.7620 - val_auc: 0.8171\n",
      "Epoch 125/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5185 - accuracy: 0.7408 - auc: 0.8216 - val_loss: 0.5214 - val_accuracy: 0.7651 - val_auc: 0.8170\n",
      "Epoch 126/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5137 - accuracy: 0.7455 - auc: 0.8278 - val_loss: 0.5218 - val_accuracy: 0.7620 - val_auc: 0.8172\n",
      "Epoch 127/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5137 - accuracy: 0.7512 - auc: 0.8247 - val_loss: 0.5212 - val_accuracy: 0.7651 - val_auc: 0.8176\n",
      "Epoch 128/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5155 - accuracy: 0.7549 - auc: 0.8277 - val_loss: 0.5204 - val_accuracy: 0.7651 - val_auc: 0.8184\n",
      "Epoch 129/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5146 - accuracy: 0.7436 - auc: 0.8251 - val_loss: 0.5203 - val_accuracy: 0.7681 - val_auc: 0.8182\n",
      "Epoch 130/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5139 - accuracy: 0.7625 - auc: 0.8291 - val_loss: 0.5192 - val_accuracy: 0.7681 - val_auc: 0.8191\n",
      "Epoch 131/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5223 - accuracy: 0.7559 - auc: 0.8206 - val_loss: 0.5193 - val_accuracy: 0.7620 - val_auc: 0.8190\n",
      "Epoch 132/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5144 - accuracy: 0.7484 - auc: 0.8247 - val_loss: 0.5198 - val_accuracy: 0.7620 - val_auc: 0.8186\n",
      "Epoch 133/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5180 - accuracy: 0.7484 - auc: 0.8223 - val_loss: 0.5186 - val_accuracy: 0.7651 - val_auc: 0.8195\n",
      "Epoch 134/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5226 - accuracy: 0.7465 - auc: 0.8197 - val_loss: 0.5191 - val_accuracy: 0.7651 - val_auc: 0.8192\n",
      "Epoch 135/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5150 - accuracy: 0.7531 - auc: 0.8247 - val_loss: 0.5203 - val_accuracy: 0.7651 - val_auc: 0.8187\n",
      "Epoch 136/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5137 - accuracy: 0.7540 - auc: 0.8253 - val_loss: 0.5204 - val_accuracy: 0.7651 - val_auc: 0.8183\n",
      "Epoch 137/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5214 - accuracy: 0.7568 - auc: 0.8204 - val_loss: 0.5213 - val_accuracy: 0.7620 - val_auc: 0.8174\n",
      "Epoch 138/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5146 - accuracy: 0.7502 - auc: 0.8255 - val_loss: 0.5211 - val_accuracy: 0.7590 - val_auc: 0.8175\n",
      "Epoch 139/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5111 - accuracy: 0.7672 - auc: 0.8295 - val_loss: 0.5200 - val_accuracy: 0.7651 - val_auc: 0.8184\n",
      "Epoch 140/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5180 - accuracy: 0.7502 - auc: 0.8240 - val_loss: 0.5199 - val_accuracy: 0.7620 - val_auc: 0.8187\n",
      "Epoch 141/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5091 - accuracy: 0.7606 - auc: 0.8319 - val_loss: 0.5205 - val_accuracy: 0.7620 - val_auc: 0.8173\n",
      "Epoch 142/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5207 - accuracy: 0.7540 - auc: 0.8206 - val_loss: 0.5203 - val_accuracy: 0.7620 - val_auc: 0.8176\n",
      "Epoch 143/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5228 - accuracy: 0.7597 - auc: 0.8206 - val_loss: 0.5208 - val_accuracy: 0.7620 - val_auc: 0.8176\n",
      "Epoch 144/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5182 - accuracy: 0.7625 - auc: 0.8251 - val_loss: 0.5210 - val_accuracy: 0.7681 - val_auc: 0.8174\n",
      "Epoch 145/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5043 - accuracy: 0.7549 - auc: 0.8328 - val_loss: 0.5204 - val_accuracy: 0.7651 - val_auc: 0.8180\n",
      "Epoch 146/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5128 - accuracy: 0.7502 - auc: 0.8260 - val_loss: 0.5207 - val_accuracy: 0.7620 - val_auc: 0.8174\n",
      "Epoch 147/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5174 - accuracy: 0.7549 - auc: 0.8243 - val_loss: 0.5206 - val_accuracy: 0.7620 - val_auc: 0.8178\n",
      "Epoch 148/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5054 - accuracy: 0.7615 - auc: 0.8314 - val_loss: 0.5211 - val_accuracy: 0.7620 - val_auc: 0.8170\n",
      "Epoch 149/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5108 - accuracy: 0.7446 - auc: 0.8289 - val_loss: 0.5206 - val_accuracy: 0.7620 - val_auc: 0.8174\n",
      "Epoch 150/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5191 - accuracy: 0.7455 - auc: 0.8225 - val_loss: 0.5209 - val_accuracy: 0.7590 - val_auc: 0.8169\n",
      "Epoch 151/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5146 - accuracy: 0.7521 - auc: 0.8264 - val_loss: 0.5199 - val_accuracy: 0.7681 - val_auc: 0.8181\n",
      "Epoch 152/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5179 - accuracy: 0.7389 - auc: 0.8217 - val_loss: 0.5201 - val_accuracy: 0.7651 - val_auc: 0.8181\n",
      "Epoch 153/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5138 - accuracy: 0.7606 - auc: 0.8281 - val_loss: 0.5198 - val_accuracy: 0.7620 - val_auc: 0.8184\n",
      "Epoch 154/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5165 - accuracy: 0.7521 - auc: 0.8244 - val_loss: 0.5192 - val_accuracy: 0.7681 - val_auc: 0.8189\n",
      "Epoch 155/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5081 - accuracy: 0.7653 - auc: 0.8309 - val_loss: 0.5195 - val_accuracy: 0.7651 - val_auc: 0.8186\n",
      "Epoch 156/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5134 - accuracy: 0.7559 - auc: 0.8284 - val_loss: 0.5186 - val_accuracy: 0.7681 - val_auc: 0.8196\n",
      "Epoch 157/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5151 - accuracy: 0.7549 - auc: 0.8253 - val_loss: 0.5188 - val_accuracy: 0.7681 - val_auc: 0.8195\n",
      "Epoch 158/700\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.5118 - accuracy: 0.7578 - auc: 0.8284 - val_loss: 0.5184 - val_accuracy: 0.7681 - val_auc: 0.8198\n",
      "Epoch 159/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5117 - accuracy: 0.7521 - auc: 0.8296 - val_loss: 0.5190 - val_accuracy: 0.7681 - val_auc: 0.8187\n",
      "Epoch 160/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5123 - accuracy: 0.7578 - auc: 0.8264 - val_loss: 0.5187 - val_accuracy: 0.7681 - val_auc: 0.8189\n",
      "Epoch 161/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5051 - accuracy: 0.7672 - auc: 0.8350 - val_loss: 0.5179 - val_accuracy: 0.7681 - val_auc: 0.8206\n",
      "Epoch 162/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5175 - accuracy: 0.7625 - auc: 0.8238 - val_loss: 0.5187 - val_accuracy: 0.7651 - val_auc: 0.8194\n",
      "Epoch 163/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5058 - accuracy: 0.7644 - auc: 0.8322 - val_loss: 0.5187 - val_accuracy: 0.7711 - val_auc: 0.8192\n",
      "Epoch 164/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5087 - accuracy: 0.7540 - auc: 0.8308 - val_loss: 0.5182 - val_accuracy: 0.7681 - val_auc: 0.8203\n",
      "Epoch 165/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5110 - accuracy: 0.7634 - auc: 0.8311 - val_loss: 0.5184 - val_accuracy: 0.7681 - val_auc: 0.8201\n",
      "Epoch 166/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5078 - accuracy: 0.7493 - auc: 0.8311 - val_loss: 0.5185 - val_accuracy: 0.7681 - val_auc: 0.8201\n",
      "Epoch 167/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5028 - accuracy: 0.7578 - auc: 0.8366 - val_loss: 0.5173 - val_accuracy: 0.7681 - val_auc: 0.8209\n",
      "Epoch 168/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5136 - accuracy: 0.7597 - auc: 0.8267 - val_loss: 0.5177 - val_accuracy: 0.7681 - val_auc: 0.8210\n",
      "Epoch 169/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5039 - accuracy: 0.7653 - auc: 0.8359 - val_loss: 0.5171 - val_accuracy: 0.7651 - val_auc: 0.8211\n",
      "Epoch 170/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5181 - accuracy: 0.7568 - auc: 0.8237 - val_loss: 0.5168 - val_accuracy: 0.7651 - val_auc: 0.8213\n",
      "Epoch 171/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5110 - accuracy: 0.7587 - auc: 0.8284 - val_loss: 0.5178 - val_accuracy: 0.7651 - val_auc: 0.8205\n",
      "Epoch 172/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5145 - accuracy: 0.7587 - auc: 0.8262 - val_loss: 0.5183 - val_accuracy: 0.7651 - val_auc: 0.8202\n",
      "Epoch 173/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5058 - accuracy: 0.7578 - auc: 0.8337 - val_loss: 0.5174 - val_accuracy: 0.7651 - val_auc: 0.8205\n",
      "Epoch 174/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5150 - accuracy: 0.7587 - auc: 0.8272 - val_loss: 0.5174 - val_accuracy: 0.7651 - val_auc: 0.8206\n",
      "Epoch 175/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5131 - accuracy: 0.7700 - auc: 0.8277 - val_loss: 0.5174 - val_accuracy: 0.7681 - val_auc: 0.8205\n",
      "Epoch 176/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5111 - accuracy: 0.7512 - auc: 0.8289 - val_loss: 0.5179 - val_accuracy: 0.7681 - val_auc: 0.8200\n",
      "Epoch 177/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5146 - accuracy: 0.7644 - auc: 0.8271 - val_loss: 0.5181 - val_accuracy: 0.7681 - val_auc: 0.8199\n",
      "Epoch 178/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5116 - accuracy: 0.7540 - auc: 0.8285 - val_loss: 0.5184 - val_accuracy: 0.7681 - val_auc: 0.8195\n",
      "Epoch 179/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5082 - accuracy: 0.7540 - auc: 0.8304 - val_loss: 0.5179 - val_accuracy: 0.7681 - val_auc: 0.8206\n",
      "Epoch 180/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5061 - accuracy: 0.7644 - auc: 0.8343 - val_loss: 0.5171 - val_accuracy: 0.7681 - val_auc: 0.8208\n",
      "Epoch 181/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5038 - accuracy: 0.7606 - auc: 0.8338 - val_loss: 0.5173 - val_accuracy: 0.7651 - val_auc: 0.8206\n",
      "Epoch 182/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5095 - accuracy: 0.7625 - auc: 0.8309 - val_loss: 0.5189 - val_accuracy: 0.7620 - val_auc: 0.8193\n",
      "Epoch 183/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5090 - accuracy: 0.7540 - auc: 0.8293 - val_loss: 0.5186 - val_accuracy: 0.7651 - val_auc: 0.8198\n",
      "Epoch 184/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5074 - accuracy: 0.7493 - auc: 0.8320 - val_loss: 0.5183 - val_accuracy: 0.7681 - val_auc: 0.8200\n",
      "Epoch 185/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5184 - accuracy: 0.7625 - auc: 0.8250 - val_loss: 0.5179 - val_accuracy: 0.7681 - val_auc: 0.8197\n",
      "Epoch 186/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5072 - accuracy: 0.7681 - auc: 0.8324 - val_loss: 0.5171 - val_accuracy: 0.7651 - val_auc: 0.8208\n",
      "Epoch 187/700\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.5070 - accuracy: 0.7568 - auc: 0.8325 - val_loss: 0.5165 - val_accuracy: 0.7620 - val_auc: 0.8221\n",
      "Epoch 188/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5015 - accuracy: 0.7653 - auc: 0.8362 - val_loss: 0.5167 - val_accuracy: 0.7590 - val_auc: 0.8219\n",
      "Epoch 189/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5071 - accuracy: 0.7568 - auc: 0.8316 - val_loss: 0.5174 - val_accuracy: 0.7651 - val_auc: 0.8210\n",
      "Epoch 190/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5034 - accuracy: 0.7625 - auc: 0.8334 - val_loss: 0.5177 - val_accuracy: 0.7651 - val_auc: 0.8205\n",
      "Epoch 191/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5133 - accuracy: 0.7531 - auc: 0.8264 - val_loss: 0.5173 - val_accuracy: 0.7620 - val_auc: 0.8214\n",
      "Epoch 192/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5123 - accuracy: 0.7634 - auc: 0.8291 - val_loss: 0.5175 - val_accuracy: 0.7681 - val_auc: 0.8204\n",
      "Epoch 193/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5028 - accuracy: 0.7606 - auc: 0.8354 - val_loss: 0.5171 - val_accuracy: 0.7651 - val_auc: 0.8213\n",
      "Epoch 194/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5099 - accuracy: 0.7615 - auc: 0.8320 - val_loss: 0.5168 - val_accuracy: 0.7651 - val_auc: 0.8215\n",
      "Epoch 195/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5140 - accuracy: 0.7738 - auc: 0.8285 - val_loss: 0.5165 - val_accuracy: 0.7651 - val_auc: 0.8213\n",
      "Epoch 196/700\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.5052 - accuracy: 0.7653 - auc: 0.8344 - val_loss: 0.5161 - val_accuracy: 0.7651 - val_auc: 0.8219\n",
      "Epoch 197/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5079 - accuracy: 0.7615 - auc: 0.8310 - val_loss: 0.5164 - val_accuracy: 0.7681 - val_auc: 0.8216\n",
      "Epoch 198/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5083 - accuracy: 0.7587 - auc: 0.8337 - val_loss: 0.5155 - val_accuracy: 0.7651 - val_auc: 0.8225\n",
      "Epoch 199/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5112 - accuracy: 0.7663 - auc: 0.8297 - val_loss: 0.5165 - val_accuracy: 0.7590 - val_auc: 0.8217\n",
      "Epoch 200/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5077 - accuracy: 0.7681 - auc: 0.8311 - val_loss: 0.5165 - val_accuracy: 0.7651 - val_auc: 0.8218\n",
      "Epoch 201/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5079 - accuracy: 0.7549 - auc: 0.8312 - val_loss: 0.5166 - val_accuracy: 0.7620 - val_auc: 0.8210\n",
      "Epoch 202/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5113 - accuracy: 0.7653 - auc: 0.8299 - val_loss: 0.5154 - val_accuracy: 0.7681 - val_auc: 0.8226\n",
      "Epoch 203/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5136 - accuracy: 0.7549 - auc: 0.8283 - val_loss: 0.5139 - val_accuracy: 0.7651 - val_auc: 0.8241\n",
      "Epoch 204/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5116 - accuracy: 0.7484 - auc: 0.8281 - val_loss: 0.5138 - val_accuracy: 0.7651 - val_auc: 0.8241\n",
      "Epoch 205/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5059 - accuracy: 0.7644 - auc: 0.8343 - val_loss: 0.5136 - val_accuracy: 0.7681 - val_auc: 0.8239\n",
      "Epoch 206/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5033 - accuracy: 0.7663 - auc: 0.8351 - val_loss: 0.5135 - val_accuracy: 0.7681 - val_auc: 0.8237\n",
      "Epoch 207/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5194 - accuracy: 0.7691 - auc: 0.8270 - val_loss: 0.5147 - val_accuracy: 0.7681 - val_auc: 0.8226\n",
      "Epoch 208/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4979 - accuracy: 0.7681 - auc: 0.8389 - val_loss: 0.5154 - val_accuracy: 0.7681 - val_auc: 0.8216\n",
      "Epoch 209/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5064 - accuracy: 0.7493 - auc: 0.8319 - val_loss: 0.5149 - val_accuracy: 0.7681 - val_auc: 0.8225\n",
      "Epoch 210/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5022 - accuracy: 0.7719 - auc: 0.8371 - val_loss: 0.5153 - val_accuracy: 0.7681 - val_auc: 0.8218\n",
      "Epoch 211/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5056 - accuracy: 0.7606 - auc: 0.8333 - val_loss: 0.5161 - val_accuracy: 0.7681 - val_auc: 0.8210\n",
      "Epoch 212/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5086 - accuracy: 0.7540 - auc: 0.8315 - val_loss: 0.5157 - val_accuracy: 0.7681 - val_auc: 0.8211\n",
      "Epoch 213/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5023 - accuracy: 0.7653 - auc: 0.8362 - val_loss: 0.5151 - val_accuracy: 0.7681 - val_auc: 0.8219\n",
      "Epoch 214/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5007 - accuracy: 0.7597 - auc: 0.8374 - val_loss: 0.5151 - val_accuracy: 0.7681 - val_auc: 0.8220\n",
      "Epoch 215/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5027 - accuracy: 0.7615 - auc: 0.8356 - val_loss: 0.5146 - val_accuracy: 0.7681 - val_auc: 0.8226\n",
      "Epoch 216/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5066 - accuracy: 0.7615 - auc: 0.8333 - val_loss: 0.5140 - val_accuracy: 0.7651 - val_auc: 0.8233\n",
      "Epoch 217/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4991 - accuracy: 0.7587 - auc: 0.8380 - val_loss: 0.5136 - val_accuracy: 0.7681 - val_auc: 0.8235\n",
      "Epoch 218/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5064 - accuracy: 0.7644 - auc: 0.8342 - val_loss: 0.5149 - val_accuracy: 0.7681 - val_auc: 0.8222\n",
      "Epoch 219/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5023 - accuracy: 0.7587 - auc: 0.8352 - val_loss: 0.5151 - val_accuracy: 0.7620 - val_auc: 0.8222\n",
      "Epoch 220/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5061 - accuracy: 0.7540 - auc: 0.8322 - val_loss: 0.5135 - val_accuracy: 0.7651 - val_auc: 0.8235\n",
      "Epoch 221/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5023 - accuracy: 0.7672 - auc: 0.8363 - val_loss: 0.5148 - val_accuracy: 0.7681 - val_auc: 0.8221\n",
      "Epoch 222/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5003 - accuracy: 0.7738 - auc: 0.8371 - val_loss: 0.5155 - val_accuracy: 0.7651 - val_auc: 0.8215\n",
      "Epoch 223/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5037 - accuracy: 0.7672 - auc: 0.8346 - val_loss: 0.5161 - val_accuracy: 0.7651 - val_auc: 0.8215\n",
      "Epoch 224/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5020 - accuracy: 0.7578 - auc: 0.8358 - val_loss: 0.5168 - val_accuracy: 0.7620 - val_auc: 0.8205\n",
      "Epoch 225/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5044 - accuracy: 0.7512 - auc: 0.8353 - val_loss: 0.5165 - val_accuracy: 0.7620 - val_auc: 0.8210\n",
      "Epoch 226/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5038 - accuracy: 0.7587 - auc: 0.8344 - val_loss: 0.5153 - val_accuracy: 0.7590 - val_auc: 0.8219\n",
      "Epoch 227/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5095 - accuracy: 0.7549 - auc: 0.8308 - val_loss: 0.5155 - val_accuracy: 0.7651 - val_auc: 0.8218\n",
      "Epoch 228/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5095 - accuracy: 0.7710 - auc: 0.8308 - val_loss: 0.5159 - val_accuracy: 0.7651 - val_auc: 0.8216\n",
      "Epoch 229/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5050 - accuracy: 0.7597 - auc: 0.8336 - val_loss: 0.5159 - val_accuracy: 0.7651 - val_auc: 0.8214\n",
      "Epoch 230/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5006 - accuracy: 0.7691 - auc: 0.8372 - val_loss: 0.5152 - val_accuracy: 0.7651 - val_auc: 0.8217\n",
      "Epoch 231/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5091 - accuracy: 0.7540 - auc: 0.8307 - val_loss: 0.5153 - val_accuracy: 0.7651 - val_auc: 0.8218\n",
      "Epoch 232/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5044 - accuracy: 0.7653 - auc: 0.8357 - val_loss: 0.5152 - val_accuracy: 0.7651 - val_auc: 0.8218\n",
      "Epoch 233/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5040 - accuracy: 0.7521 - auc: 0.8332 - val_loss: 0.5156 - val_accuracy: 0.7620 - val_auc: 0.8218\n",
      "Epoch 234/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4956 - accuracy: 0.7568 - auc: 0.8390 - val_loss: 0.5139 - val_accuracy: 0.7620 - val_auc: 0.8232\n",
      "Epoch 235/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4952 - accuracy: 0.7813 - auc: 0.8429 - val_loss: 0.5141 - val_accuracy: 0.7620 - val_auc: 0.8229\n",
      "Epoch 236/700\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.5026 - accuracy: 0.7559 - auc: 0.8362 - val_loss: 0.5133 - val_accuracy: 0.7651 - val_auc: 0.8236\n",
      "Epoch 237/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5029 - accuracy: 0.7738 - auc: 0.8355 - val_loss: 0.5134 - val_accuracy: 0.7620 - val_auc: 0.8239\n",
      "Epoch 238/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4966 - accuracy: 0.7634 - auc: 0.8389 - val_loss: 0.5139 - val_accuracy: 0.7651 - val_auc: 0.8225\n",
      "Epoch 239/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5047 - accuracy: 0.7700 - auc: 0.8356 - val_loss: 0.5135 - val_accuracy: 0.7681 - val_auc: 0.8229\n",
      "Epoch 240/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5016 - accuracy: 0.7795 - auc: 0.8376 - val_loss: 0.5135 - val_accuracy: 0.7651 - val_auc: 0.8230\n",
      "Epoch 241/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5101 - accuracy: 0.7568 - auc: 0.8309 - val_loss: 0.5134 - val_accuracy: 0.7651 - val_auc: 0.8235\n",
      "Epoch 242/700\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.4965 - accuracy: 0.7672 - auc: 0.8396 - val_loss: 0.5131 - val_accuracy: 0.7651 - val_auc: 0.8234\n",
      "Epoch 243/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5048 - accuracy: 0.7615 - auc: 0.8333 - val_loss: 0.5133 - val_accuracy: 0.7651 - val_auc: 0.8235\n",
      "Epoch 244/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5009 - accuracy: 0.7606 - auc: 0.8372 - val_loss: 0.5135 - val_accuracy: 0.7651 - val_auc: 0.8233\n",
      "Epoch 245/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5110 - accuracy: 0.7634 - auc: 0.8304 - val_loss: 0.5142 - val_accuracy: 0.7620 - val_auc: 0.8224\n",
      "Epoch 246/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5074 - accuracy: 0.7606 - auc: 0.8308 - val_loss: 0.5134 - val_accuracy: 0.7681 - val_auc: 0.8233\n",
      "Epoch 247/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5062 - accuracy: 0.7681 - auc: 0.8339 - val_loss: 0.5126 - val_accuracy: 0.7681 - val_auc: 0.8243\n",
      "Epoch 248/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5084 - accuracy: 0.7597 - auc: 0.8322 - val_loss: 0.5118 - val_accuracy: 0.7681 - val_auc: 0.8252\n",
      "Epoch 249/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4994 - accuracy: 0.7625 - auc: 0.8377 - val_loss: 0.5120 - val_accuracy: 0.7681 - val_auc: 0.8245\n",
      "Epoch 250/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5035 - accuracy: 0.7587 - auc: 0.8342 - val_loss: 0.5123 - val_accuracy: 0.7711 - val_auc: 0.8243\n",
      "Epoch 251/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4951 - accuracy: 0.7719 - auc: 0.8422 - val_loss: 0.5121 - val_accuracy: 0.7681 - val_auc: 0.8247\n",
      "Epoch 252/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4945 - accuracy: 0.7663 - auc: 0.8410 - val_loss: 0.5130 - val_accuracy: 0.7620 - val_auc: 0.8240\n",
      "Epoch 253/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5051 - accuracy: 0.7719 - auc: 0.8361 - val_loss: 0.5136 - val_accuracy: 0.7590 - val_auc: 0.8236\n",
      "Epoch 254/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5095 - accuracy: 0.7559 - auc: 0.8282 - val_loss: 0.5137 - val_accuracy: 0.7590 - val_auc: 0.8233\n",
      "Epoch 255/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4981 - accuracy: 0.7663 - auc: 0.8387 - val_loss: 0.5156 - val_accuracy: 0.7620 - val_auc: 0.8215\n",
      "Epoch 256/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5060 - accuracy: 0.7653 - auc: 0.8345 - val_loss: 0.5148 - val_accuracy: 0.7651 - val_auc: 0.8222\n",
      "Epoch 257/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5066 - accuracy: 0.7549 - auc: 0.8322 - val_loss: 0.5143 - val_accuracy: 0.7651 - val_auc: 0.8222\n",
      "Epoch 258/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4967 - accuracy: 0.7644 - auc: 0.8398 - val_loss: 0.5128 - val_accuracy: 0.7651 - val_auc: 0.8241\n",
      "Epoch 259/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5030 - accuracy: 0.7644 - auc: 0.8355 - val_loss: 0.5129 - val_accuracy: 0.7620 - val_auc: 0.8241\n",
      "Epoch 260/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4977 - accuracy: 0.7681 - auc: 0.8382 - val_loss: 0.5126 - val_accuracy: 0.7620 - val_auc: 0.8245\n",
      "Epoch 261/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5102 - accuracy: 0.7606 - auc: 0.8315 - val_loss: 0.5127 - val_accuracy: 0.7620 - val_auc: 0.8243\n",
      "Epoch 262/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5066 - accuracy: 0.7625 - auc: 0.8320 - val_loss: 0.5122 - val_accuracy: 0.7651 - val_auc: 0.8244\n",
      "Epoch 263/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4906 - accuracy: 0.7710 - auc: 0.8437 - val_loss: 0.5130 - val_accuracy: 0.7651 - val_auc: 0.8241\n",
      "Epoch 264/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5029 - accuracy: 0.7606 - auc: 0.8356 - val_loss: 0.5128 - val_accuracy: 0.7620 - val_auc: 0.8247\n",
      "Epoch 265/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4995 - accuracy: 0.7710 - auc: 0.8394 - val_loss: 0.5126 - val_accuracy: 0.7590 - val_auc: 0.8246\n",
      "Epoch 266/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5063 - accuracy: 0.7729 - auc: 0.8343 - val_loss: 0.5118 - val_accuracy: 0.7651 - val_auc: 0.8255\n",
      "Epoch 267/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4992 - accuracy: 0.7710 - auc: 0.8400 - val_loss: 0.5115 - val_accuracy: 0.7620 - val_auc: 0.8256\n",
      "Epoch 268/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4989 - accuracy: 0.7615 - auc: 0.8384 - val_loss: 0.5113 - val_accuracy: 0.7620 - val_auc: 0.8256\n",
      "Epoch 269/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4980 - accuracy: 0.7663 - auc: 0.8405 - val_loss: 0.5115 - val_accuracy: 0.7620 - val_auc: 0.8252\n",
      "Epoch 270/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4980 - accuracy: 0.7578 - auc: 0.8379 - val_loss: 0.5117 - val_accuracy: 0.7651 - val_auc: 0.8249\n",
      "Epoch 271/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5036 - accuracy: 0.7663 - auc: 0.8357 - val_loss: 0.5118 - val_accuracy: 0.7681 - val_auc: 0.8249\n",
      "Epoch 272/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4981 - accuracy: 0.7615 - auc: 0.8388 - val_loss: 0.5109 - val_accuracy: 0.7681 - val_auc: 0.8258\n",
      "Epoch 273/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4934 - accuracy: 0.7785 - auc: 0.8419 - val_loss: 0.5115 - val_accuracy: 0.7681 - val_auc: 0.8253\n",
      "Epoch 274/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4952 - accuracy: 0.7757 - auc: 0.8416 - val_loss: 0.5113 - val_accuracy: 0.7681 - val_auc: 0.8252\n",
      "Epoch 275/700\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.5105 - accuracy: 0.7559 - auc: 0.8300 - val_loss: 0.5105 - val_accuracy: 0.7681 - val_auc: 0.8260\n",
      "Epoch 276/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4974 - accuracy: 0.7719 - auc: 0.8405 - val_loss: 0.5108 - val_accuracy: 0.7681 - val_auc: 0.8259\n",
      "Epoch 277/700\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.4893 - accuracy: 0.7719 - auc: 0.8474 - val_loss: 0.5104 - val_accuracy: 0.7681 - val_auc: 0.8261\n",
      "Epoch 278/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5045 - accuracy: 0.7549 - auc: 0.8335 - val_loss: 0.5112 - val_accuracy: 0.7651 - val_auc: 0.8254\n",
      "Epoch 279/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5008 - accuracy: 0.7681 - auc: 0.8380 - val_loss: 0.5115 - val_accuracy: 0.7681 - val_auc: 0.8249\n",
      "Epoch 280/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4935 - accuracy: 0.7653 - auc: 0.8416 - val_loss: 0.5112 - val_accuracy: 0.7681 - val_auc: 0.8255\n",
      "Epoch 281/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5040 - accuracy: 0.7615 - auc: 0.8338 - val_loss: 0.5114 - val_accuracy: 0.7651 - val_auc: 0.8249\n",
      "Epoch 282/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4962 - accuracy: 0.7634 - auc: 0.8402 - val_loss: 0.5121 - val_accuracy: 0.7651 - val_auc: 0.8248\n",
      "Epoch 283/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4984 - accuracy: 0.7653 - auc: 0.8396 - val_loss: 0.5123 - val_accuracy: 0.7620 - val_auc: 0.8244\n",
      "Epoch 284/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4891 - accuracy: 0.7625 - auc: 0.8472 - val_loss: 0.5123 - val_accuracy: 0.7651 - val_auc: 0.8246\n",
      "Epoch 285/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5003 - accuracy: 0.7700 - auc: 0.8389 - val_loss: 0.5129 - val_accuracy: 0.7620 - val_auc: 0.8241\n",
      "Epoch 286/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4942 - accuracy: 0.7719 - auc: 0.8426 - val_loss: 0.5120 - val_accuracy: 0.7620 - val_auc: 0.8248\n",
      "Epoch 287/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4974 - accuracy: 0.7738 - auc: 0.8397 - val_loss: 0.5110 - val_accuracy: 0.7651 - val_auc: 0.8258\n",
      "Epoch 288/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4988 - accuracy: 0.7644 - auc: 0.8372 - val_loss: 0.5106 - val_accuracy: 0.7651 - val_auc: 0.8263\n",
      "Epoch 289/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5000 - accuracy: 0.7672 - auc: 0.8390 - val_loss: 0.5103 - val_accuracy: 0.7651 - val_auc: 0.8264\n",
      "Epoch 290/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4950 - accuracy: 0.7634 - auc: 0.8409 - val_loss: 0.5096 - val_accuracy: 0.7681 - val_auc: 0.8278\n",
      "Epoch 291/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5040 - accuracy: 0.7747 - auc: 0.8353 - val_loss: 0.5100 - val_accuracy: 0.7681 - val_auc: 0.8272\n",
      "Epoch 292/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4937 - accuracy: 0.7719 - auc: 0.8433 - val_loss: 0.5096 - val_accuracy: 0.7681 - val_auc: 0.8271\n",
      "Epoch 293/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4950 - accuracy: 0.7776 - auc: 0.8407 - val_loss: 0.5098 - val_accuracy: 0.7681 - val_auc: 0.8266\n",
      "Epoch 294/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5030 - accuracy: 0.7738 - auc: 0.8370 - val_loss: 0.5103 - val_accuracy: 0.7681 - val_auc: 0.8268\n",
      "Epoch 295/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4904 - accuracy: 0.7804 - auc: 0.8453 - val_loss: 0.5098 - val_accuracy: 0.7681 - val_auc: 0.8270\n",
      "Epoch 296/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4968 - accuracy: 0.7776 - auc: 0.8410 - val_loss: 0.5106 - val_accuracy: 0.7681 - val_auc: 0.8256\n",
      "Epoch 297/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4893 - accuracy: 0.7719 - auc: 0.8464 - val_loss: 0.5101 - val_accuracy: 0.7651 - val_auc: 0.8265\n",
      "Epoch 298/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4964 - accuracy: 0.7691 - auc: 0.8400 - val_loss: 0.5095 - val_accuracy: 0.7681 - val_auc: 0.8271\n",
      "Epoch 299/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5057 - accuracy: 0.7597 - auc: 0.8334 - val_loss: 0.5100 - val_accuracy: 0.7681 - val_auc: 0.8266\n",
      "Epoch 300/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4945 - accuracy: 0.7795 - auc: 0.8401 - val_loss: 0.5097 - val_accuracy: 0.7651 - val_auc: 0.8268\n",
      "Epoch 301/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4842 - accuracy: 0.7795 - auc: 0.8498 - val_loss: 0.5096 - val_accuracy: 0.7651 - val_auc: 0.8270\n",
      "Epoch 302/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4871 - accuracy: 0.7644 - auc: 0.8474 - val_loss: 0.5090 - val_accuracy: 0.7651 - val_auc: 0.8276\n",
      "Epoch 303/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4886 - accuracy: 0.7747 - auc: 0.8473 - val_loss: 0.5093 - val_accuracy: 0.7681 - val_auc: 0.8272\n",
      "Epoch 304/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5036 - accuracy: 0.7634 - auc: 0.8353 - val_loss: 0.5097 - val_accuracy: 0.7681 - val_auc: 0.8267\n",
      "Epoch 305/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4915 - accuracy: 0.7795 - auc: 0.8442 - val_loss: 0.5097 - val_accuracy: 0.7681 - val_auc: 0.8268\n",
      "Epoch 306/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4866 - accuracy: 0.7823 - auc: 0.8488 - val_loss: 0.5090 - val_accuracy: 0.7681 - val_auc: 0.8273\n",
      "Epoch 307/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4964 - accuracy: 0.7681 - auc: 0.8419 - val_loss: 0.5090 - val_accuracy: 0.7681 - val_auc: 0.8273\n",
      "Epoch 308/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4914 - accuracy: 0.7672 - auc: 0.8447 - val_loss: 0.5098 - val_accuracy: 0.7681 - val_auc: 0.8263\n",
      "Epoch 309/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5047 - accuracy: 0.7634 - auc: 0.8335 - val_loss: 0.5094 - val_accuracy: 0.7681 - val_auc: 0.8266\n",
      "Epoch 310/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4920 - accuracy: 0.7795 - auc: 0.8438 - val_loss: 0.5107 - val_accuracy: 0.7651 - val_auc: 0.8255\n",
      "Epoch 311/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4981 - accuracy: 0.7531 - auc: 0.8381 - val_loss: 0.5107 - val_accuracy: 0.7651 - val_auc: 0.8255\n",
      "Epoch 312/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4967 - accuracy: 0.7691 - auc: 0.8395 - val_loss: 0.5099 - val_accuracy: 0.7681 - val_auc: 0.8262\n",
      "Epoch 313/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4866 - accuracy: 0.7625 - auc: 0.8477 - val_loss: 0.5086 - val_accuracy: 0.7681 - val_auc: 0.8274\n",
      "Epoch 314/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4906 - accuracy: 0.7672 - auc: 0.8437 - val_loss: 0.5092 - val_accuracy: 0.7681 - val_auc: 0.8267\n",
      "Epoch 315/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4992 - accuracy: 0.7729 - auc: 0.8393 - val_loss: 0.5092 - val_accuracy: 0.7681 - val_auc: 0.8266\n",
      "Epoch 316/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5038 - accuracy: 0.7578 - auc: 0.8339 - val_loss: 0.5085 - val_accuracy: 0.7681 - val_auc: 0.8280\n",
      "Epoch 317/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4957 - accuracy: 0.7804 - auc: 0.8425 - val_loss: 0.5084 - val_accuracy: 0.7681 - val_auc: 0.8274\n",
      "Epoch 318/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4894 - accuracy: 0.7710 - auc: 0.8471 - val_loss: 0.5087 - val_accuracy: 0.7681 - val_auc: 0.8271\n",
      "Epoch 319/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5000 - accuracy: 0.7663 - auc: 0.8377 - val_loss: 0.5090 - val_accuracy: 0.7681 - val_auc: 0.8267\n",
      "Epoch 320/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4941 - accuracy: 0.7700 - auc: 0.8410 - val_loss: 0.5084 - val_accuracy: 0.7681 - val_auc: 0.8276\n",
      "Epoch 321/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4893 - accuracy: 0.7757 - auc: 0.8475 - val_loss: 0.5076 - val_accuracy: 0.7711 - val_auc: 0.8283\n",
      "Epoch 322/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5071 - accuracy: 0.7568 - auc: 0.8305 - val_loss: 0.5077 - val_accuracy: 0.7711 - val_auc: 0.8284\n",
      "Epoch 323/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4979 - accuracy: 0.7634 - auc: 0.8388 - val_loss: 0.5082 - val_accuracy: 0.7651 - val_auc: 0.8277\n",
      "Epoch 324/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4920 - accuracy: 0.7710 - auc: 0.8427 - val_loss: 0.5081 - val_accuracy: 0.7681 - val_auc: 0.8278\n",
      "Epoch 325/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4981 - accuracy: 0.7747 - auc: 0.8401 - val_loss: 0.5073 - val_accuracy: 0.7711 - val_auc: 0.8285\n",
      "Epoch 326/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4888 - accuracy: 0.7747 - auc: 0.8472 - val_loss: 0.5082 - val_accuracy: 0.7681 - val_auc: 0.8278\n",
      "Epoch 327/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5010 - accuracy: 0.7776 - auc: 0.8382 - val_loss: 0.5076 - val_accuracy: 0.7711 - val_auc: 0.8285\n",
      "Epoch 328/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4915 - accuracy: 0.7738 - auc: 0.8458 - val_loss: 0.5073 - val_accuracy: 0.7711 - val_auc: 0.8288\n",
      "Epoch 329/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4862 - accuracy: 0.7823 - auc: 0.8491 - val_loss: 0.5077 - val_accuracy: 0.7681 - val_auc: 0.8281\n",
      "Epoch 330/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4876 - accuracy: 0.7634 - auc: 0.8472 - val_loss: 0.5078 - val_accuracy: 0.7711 - val_auc: 0.8282\n",
      "Epoch 331/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4932 - accuracy: 0.7644 - auc: 0.8430 - val_loss: 0.5074 - val_accuracy: 0.7711 - val_auc: 0.8285\n",
      "Epoch 332/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4852 - accuracy: 0.7766 - auc: 0.8484 - val_loss: 0.5078 - val_accuracy: 0.7681 - val_auc: 0.8279\n",
      "Epoch 333/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5020 - accuracy: 0.7738 - auc: 0.8367 - val_loss: 0.5074 - val_accuracy: 0.7711 - val_auc: 0.8287\n",
      "Epoch 334/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4976 - accuracy: 0.7719 - auc: 0.8400 - val_loss: 0.5074 - val_accuracy: 0.7681 - val_auc: 0.8285\n",
      "Epoch 335/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4983 - accuracy: 0.7710 - auc: 0.8393 - val_loss: 0.5071 - val_accuracy: 0.7681 - val_auc: 0.8293\n",
      "Epoch 336/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4851 - accuracy: 0.7766 - auc: 0.8497 - val_loss: 0.5063 - val_accuracy: 0.7711 - val_auc: 0.8302\n",
      "Epoch 337/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4985 - accuracy: 0.7606 - auc: 0.8371 - val_loss: 0.5068 - val_accuracy: 0.7711 - val_auc: 0.8293\n",
      "Epoch 338/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4892 - accuracy: 0.7663 - auc: 0.8475 - val_loss: 0.5079 - val_accuracy: 0.7711 - val_auc: 0.8284\n",
      "Epoch 339/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4924 - accuracy: 0.7823 - auc: 0.8450 - val_loss: 0.5076 - val_accuracy: 0.7681 - val_auc: 0.8284\n",
      "Epoch 340/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4846 - accuracy: 0.7766 - auc: 0.8501 - val_loss: 0.5077 - val_accuracy: 0.7681 - val_auc: 0.8281\n",
      "Epoch 341/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4968 - accuracy: 0.7663 - auc: 0.8392 - val_loss: 0.5067 - val_accuracy: 0.7711 - val_auc: 0.8292\n",
      "Epoch 342/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4944 - accuracy: 0.7757 - auc: 0.8428 - val_loss: 0.5072 - val_accuracy: 0.7681 - val_auc: 0.8283\n",
      "Epoch 343/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4957 - accuracy: 0.7776 - auc: 0.8427 - val_loss: 0.5075 - val_accuracy: 0.7681 - val_auc: 0.8281\n",
      "Epoch 344/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4880 - accuracy: 0.7719 - auc: 0.8474 - val_loss: 0.5072 - val_accuracy: 0.7711 - val_auc: 0.8290\n",
      "Epoch 345/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4874 - accuracy: 0.7776 - auc: 0.8494 - val_loss: 0.5072 - val_accuracy: 0.7711 - val_auc: 0.8292\n",
      "Epoch 346/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4940 - accuracy: 0.7653 - auc: 0.8416 - val_loss: 0.5069 - val_accuracy: 0.7711 - val_auc: 0.8291\n",
      "Epoch 347/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4947 - accuracy: 0.7738 - auc: 0.8430 - val_loss: 0.5069 - val_accuracy: 0.7681 - val_auc: 0.8292\n",
      "Epoch 348/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4960 - accuracy: 0.7710 - auc: 0.8402 - val_loss: 0.5067 - val_accuracy: 0.7681 - val_auc: 0.8291\n",
      "Epoch 349/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4937 - accuracy: 0.7738 - auc: 0.8438 - val_loss: 0.5068 - val_accuracy: 0.7681 - val_auc: 0.8284\n",
      "Epoch 350/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4903 - accuracy: 0.7710 - auc: 0.8451 - val_loss: 0.5067 - val_accuracy: 0.7681 - val_auc: 0.8287\n",
      "Epoch 351/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4978 - accuracy: 0.7719 - auc: 0.8389 - val_loss: 0.5063 - val_accuracy: 0.7711 - val_auc: 0.8296\n",
      "Epoch 352/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4846 - accuracy: 0.7710 - auc: 0.8490 - val_loss: 0.5062 - val_accuracy: 0.7681 - val_auc: 0.8297\n",
      "Epoch 353/700\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.5043 - accuracy: 0.7587 - auc: 0.8340 - val_loss: 0.5065 - val_accuracy: 0.7681 - val_auc: 0.8291\n",
      "Epoch 354/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4895 - accuracy: 0.7719 - auc: 0.8451 - val_loss: 0.5064 - val_accuracy: 0.7681 - val_auc: 0.8297\n",
      "Epoch 355/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4968 - accuracy: 0.7615 - auc: 0.8391 - val_loss: 0.5070 - val_accuracy: 0.7681 - val_auc: 0.8289\n",
      "Epoch 356/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4879 - accuracy: 0.7795 - auc: 0.8474 - val_loss: 0.5066 - val_accuracy: 0.7681 - val_auc: 0.8293\n",
      "Epoch 357/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4922 - accuracy: 0.7578 - auc: 0.8425 - val_loss: 0.5067 - val_accuracy: 0.7711 - val_auc: 0.8290\n",
      "Epoch 358/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4916 - accuracy: 0.7729 - auc: 0.8441 - val_loss: 0.5073 - val_accuracy: 0.7651 - val_auc: 0.8281\n",
      "Epoch 359/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4841 - accuracy: 0.7832 - auc: 0.8491 - val_loss: 0.5068 - val_accuracy: 0.7681 - val_auc: 0.8290\n",
      "Epoch 360/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4899 - accuracy: 0.7738 - auc: 0.8462 - val_loss: 0.5054 - val_accuracy: 0.7711 - val_auc: 0.8303\n",
      "Epoch 361/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4915 - accuracy: 0.7729 - auc: 0.8454 - val_loss: 0.5059 - val_accuracy: 0.7711 - val_auc: 0.8296\n",
      "Epoch 362/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4795 - accuracy: 0.7870 - auc: 0.8531 - val_loss: 0.5059 - val_accuracy: 0.7651 - val_auc: 0.8301\n",
      "Epoch 363/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4923 - accuracy: 0.7691 - auc: 0.8438 - val_loss: 0.5062 - val_accuracy: 0.7651 - val_auc: 0.8300\n",
      "Epoch 364/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4923 - accuracy: 0.7644 - auc: 0.8436 - val_loss: 0.5068 - val_accuracy: 0.7681 - val_auc: 0.8294\n",
      "Epoch 365/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4912 - accuracy: 0.7823 - auc: 0.8447 - val_loss: 0.5069 - val_accuracy: 0.7681 - val_auc: 0.8284\n",
      "Epoch 366/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4855 - accuracy: 0.7681 - auc: 0.8488 - val_loss: 0.5073 - val_accuracy: 0.7620 - val_auc: 0.8278\n",
      "Epoch 367/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4894 - accuracy: 0.7785 - auc: 0.8468 - val_loss: 0.5071 - val_accuracy: 0.7681 - val_auc: 0.8283\n",
      "Epoch 368/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4868 - accuracy: 0.7795 - auc: 0.8486 - val_loss: 0.5068 - val_accuracy: 0.7681 - val_auc: 0.8290\n",
      "Epoch 369/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4891 - accuracy: 0.7757 - auc: 0.8449 - val_loss: 0.5073 - val_accuracy: 0.7681 - val_auc: 0.8281\n",
      "Epoch 370/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4858 - accuracy: 0.7842 - auc: 0.8498 - val_loss: 0.5078 - val_accuracy: 0.7651 - val_auc: 0.8278\n",
      "Epoch 371/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4988 - accuracy: 0.7568 - auc: 0.8390 - val_loss: 0.5065 - val_accuracy: 0.7681 - val_auc: 0.8291\n",
      "Epoch 372/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4915 - accuracy: 0.7776 - auc: 0.8442 - val_loss: 0.5064 - val_accuracy: 0.7651 - val_auc: 0.8289\n",
      "Epoch 373/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4927 - accuracy: 0.7597 - auc: 0.8423 - val_loss: 0.5062 - val_accuracy: 0.7711 - val_auc: 0.8294\n",
      "Epoch 374/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4929 - accuracy: 0.7776 - auc: 0.8428 - val_loss: 0.5055 - val_accuracy: 0.7741 - val_auc: 0.8303\n",
      "Epoch 375/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4959 - accuracy: 0.7681 - auc: 0.8406 - val_loss: 0.5055 - val_accuracy: 0.7741 - val_auc: 0.8299\n",
      "Epoch 376/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4885 - accuracy: 0.7691 - auc: 0.8454 - val_loss: 0.5060 - val_accuracy: 0.7681 - val_auc: 0.8295\n",
      "Epoch 377/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4872 - accuracy: 0.7795 - auc: 0.8469 - val_loss: 0.5061 - val_accuracy: 0.7651 - val_auc: 0.8285\n",
      "Epoch 378/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4909 - accuracy: 0.7747 - auc: 0.8448 - val_loss: 0.5058 - val_accuracy: 0.7681 - val_auc: 0.8287\n",
      "Epoch 379/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4912 - accuracy: 0.7691 - auc: 0.8435 - val_loss: 0.5058 - val_accuracy: 0.7620 - val_auc: 0.8294\n",
      "Epoch 380/700\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 0.4898 - accuracy: 0.7700 - auc: 0.8475 - val_loss: 0.5050 - val_accuracy: 0.7620 - val_auc: 0.8297\n",
      "Epoch 381/700\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.4980 - accuracy: 0.7615 - auc: 0.8380 - val_loss: 0.5045 - val_accuracy: 0.7620 - val_auc: 0.8299\n",
      "Epoch 382/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4889 - accuracy: 0.7738 - auc: 0.8453 - val_loss: 0.5046 - val_accuracy: 0.7651 - val_auc: 0.8298\n",
      "Epoch 383/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4944 - accuracy: 0.7729 - auc: 0.8418 - val_loss: 0.5046 - val_accuracy: 0.7651 - val_auc: 0.8299\n",
      "Epoch 384/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4808 - accuracy: 0.7757 - auc: 0.8513 - val_loss: 0.5051 - val_accuracy: 0.7651 - val_auc: 0.8295\n",
      "Epoch 385/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4843 - accuracy: 0.7719 - auc: 0.8478 - val_loss: 0.5056 - val_accuracy: 0.7651 - val_auc: 0.8294\n",
      "Epoch 386/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4885 - accuracy: 0.7672 - auc: 0.8452 - val_loss: 0.5049 - val_accuracy: 0.7651 - val_auc: 0.8298\n",
      "Epoch 387/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4909 - accuracy: 0.7719 - auc: 0.8440 - val_loss: 0.5049 - val_accuracy: 0.7651 - val_auc: 0.8299\n",
      "Epoch 388/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4901 - accuracy: 0.7672 - auc: 0.8448 - val_loss: 0.5060 - val_accuracy: 0.7651 - val_auc: 0.8287\n",
      "Epoch 389/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4969 - accuracy: 0.7747 - auc: 0.8405 - val_loss: 0.5055 - val_accuracy: 0.7620 - val_auc: 0.8290\n",
      "Epoch 390/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4953 - accuracy: 0.7804 - auc: 0.8416 - val_loss: 0.5057 - val_accuracy: 0.7651 - val_auc: 0.8288\n",
      "Epoch 391/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4793 - accuracy: 0.7804 - auc: 0.8531 - val_loss: 0.5052 - val_accuracy: 0.7620 - val_auc: 0.8295\n",
      "Epoch 392/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4910 - accuracy: 0.7729 - auc: 0.8437 - val_loss: 0.5055 - val_accuracy: 0.7620 - val_auc: 0.8295\n",
      "Epoch 393/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4880 - accuracy: 0.7738 - auc: 0.8464 - val_loss: 0.5058 - val_accuracy: 0.7651 - val_auc: 0.8292\n",
      "Epoch 394/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4866 - accuracy: 0.7757 - auc: 0.8492 - val_loss: 0.5049 - val_accuracy: 0.7620 - val_auc: 0.8303\n",
      "Epoch 395/700\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.4948 - accuracy: 0.7823 - auc: 0.8430 - val_loss: 0.5039 - val_accuracy: 0.7651 - val_auc: 0.8311\n",
      "Epoch 396/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4947 - accuracy: 0.7691 - auc: 0.8417 - val_loss: 0.5044 - val_accuracy: 0.7620 - val_auc: 0.8306\n",
      "Epoch 397/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4784 - accuracy: 0.7851 - auc: 0.8541 - val_loss: 0.5042 - val_accuracy: 0.7651 - val_auc: 0.8303\n",
      "Epoch 398/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4761 - accuracy: 0.7804 - auc: 0.8571 - val_loss: 0.5039 - val_accuracy: 0.7620 - val_auc: 0.8306\n",
      "Epoch 399/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4827 - accuracy: 0.7813 - auc: 0.8519 - val_loss: 0.5035 - val_accuracy: 0.7681 - val_auc: 0.8313\n",
      "Epoch 400/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4818 - accuracy: 0.7795 - auc: 0.8504 - val_loss: 0.5027 - val_accuracy: 0.7711 - val_auc: 0.8323\n",
      "Epoch 401/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4736 - accuracy: 0.7832 - auc: 0.8584 - val_loss: 0.5025 - val_accuracy: 0.7681 - val_auc: 0.8322\n",
      "Epoch 402/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4935 - accuracy: 0.7672 - auc: 0.8421 - val_loss: 0.5031 - val_accuracy: 0.7681 - val_auc: 0.8315\n",
      "Epoch 403/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4919 - accuracy: 0.7672 - auc: 0.8451 - val_loss: 0.5031 - val_accuracy: 0.7620 - val_auc: 0.8314\n",
      "Epoch 404/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4905 - accuracy: 0.7738 - auc: 0.8438 - val_loss: 0.5034 - val_accuracy: 0.7651 - val_auc: 0.8312\n",
      "Epoch 405/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4786 - accuracy: 0.7823 - auc: 0.8525 - val_loss: 0.5029 - val_accuracy: 0.7681 - val_auc: 0.8328\n",
      "Epoch 406/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4922 - accuracy: 0.7719 - auc: 0.8433 - val_loss: 0.5033 - val_accuracy: 0.7681 - val_auc: 0.8320\n",
      "Epoch 407/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4820 - accuracy: 0.7870 - auc: 0.8516 - val_loss: 0.5030 - val_accuracy: 0.7681 - val_auc: 0.8325\n",
      "Epoch 408/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4881 - accuracy: 0.7738 - auc: 0.8453 - val_loss: 0.5035 - val_accuracy: 0.7681 - val_auc: 0.8321\n",
      "Epoch 409/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4945 - accuracy: 0.7597 - auc: 0.8417 - val_loss: 0.5036 - val_accuracy: 0.7651 - val_auc: 0.8317\n",
      "Epoch 410/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4884 - accuracy: 0.7634 - auc: 0.8460 - val_loss: 0.5036 - val_accuracy: 0.7681 - val_auc: 0.8317\n",
      "Epoch 411/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4976 - accuracy: 0.7625 - auc: 0.8383 - val_loss: 0.5033 - val_accuracy: 0.7681 - val_auc: 0.8316\n",
      "Epoch 412/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4864 - accuracy: 0.7672 - auc: 0.8478 - val_loss: 0.5040 - val_accuracy: 0.7681 - val_auc: 0.8318\n",
      "Epoch 413/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4878 - accuracy: 0.7738 - auc: 0.8465 - val_loss: 0.5038 - val_accuracy: 0.7681 - val_auc: 0.8314\n",
      "Epoch 414/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4939 - accuracy: 0.7738 - auc: 0.8417 - val_loss: 0.5039 - val_accuracy: 0.7651 - val_auc: 0.8306\n",
      "Epoch 415/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4852 - accuracy: 0.7691 - auc: 0.8482 - val_loss: 0.5025 - val_accuracy: 0.7741 - val_auc: 0.8325\n",
      "Epoch 416/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4901 - accuracy: 0.7747 - auc: 0.8465 - val_loss: 0.5031 - val_accuracy: 0.7711 - val_auc: 0.8316\n",
      "Epoch 417/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4839 - accuracy: 0.7917 - auc: 0.8500 - val_loss: 0.5030 - val_accuracy: 0.7711 - val_auc: 0.8318\n",
      "Epoch 418/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4976 - accuracy: 0.7681 - auc: 0.8392 - val_loss: 0.5029 - val_accuracy: 0.7711 - val_auc: 0.8318\n",
      "Epoch 419/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4868 - accuracy: 0.7691 - auc: 0.8465 - val_loss: 0.5026 - val_accuracy: 0.7711 - val_auc: 0.8320\n",
      "Epoch 420/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4981 - accuracy: 0.7710 - auc: 0.8388 - val_loss: 0.5025 - val_accuracy: 0.7711 - val_auc: 0.8326\n",
      "Epoch 421/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4982 - accuracy: 0.7644 - auc: 0.8390 - val_loss: 0.5014 - val_accuracy: 0.7771 - val_auc: 0.8334\n",
      "Epoch 422/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4886 - accuracy: 0.7663 - auc: 0.8462 - val_loss: 0.5017 - val_accuracy: 0.7741 - val_auc: 0.8327\n",
      "Epoch 423/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4852 - accuracy: 0.7691 - auc: 0.8467 - val_loss: 0.5009 - val_accuracy: 0.7741 - val_auc: 0.8340\n",
      "Epoch 424/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4910 - accuracy: 0.7681 - auc: 0.8438 - val_loss: 0.5011 - val_accuracy: 0.7741 - val_auc: 0.8339\n",
      "Epoch 425/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4819 - accuracy: 0.7700 - auc: 0.8502 - val_loss: 0.5008 - val_accuracy: 0.7741 - val_auc: 0.8342\n",
      "Epoch 426/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4872 - accuracy: 0.7700 - auc: 0.8456 - val_loss: 0.5005 - val_accuracy: 0.7711 - val_auc: 0.8340\n",
      "Epoch 427/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.5010 - accuracy: 0.7559 - auc: 0.8365 - val_loss: 0.5005 - val_accuracy: 0.7741 - val_auc: 0.8344\n",
      "Epoch 428/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4846 - accuracy: 0.7766 - auc: 0.8486 - val_loss: 0.5016 - val_accuracy: 0.7711 - val_auc: 0.8326\n",
      "Epoch 429/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4835 - accuracy: 0.7776 - auc: 0.8490 - val_loss: 0.5022 - val_accuracy: 0.7681 - val_auc: 0.8324\n",
      "Epoch 430/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4826 - accuracy: 0.7719 - auc: 0.8504 - val_loss: 0.5014 - val_accuracy: 0.7711 - val_auc: 0.8332\n",
      "Epoch 431/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4843 - accuracy: 0.7870 - auc: 0.8497 - val_loss: 0.5015 - val_accuracy: 0.7681 - val_auc: 0.8329\n",
      "Epoch 432/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4849 - accuracy: 0.7766 - auc: 0.8504 - val_loss: 0.5020 - val_accuracy: 0.7681 - val_auc: 0.8327\n",
      "Epoch 433/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4931 - accuracy: 0.7691 - auc: 0.8427 - val_loss: 0.5029 - val_accuracy: 0.7620 - val_auc: 0.8312\n",
      "Epoch 434/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4854 - accuracy: 0.7795 - auc: 0.8490 - val_loss: 0.5022 - val_accuracy: 0.7681 - val_auc: 0.8326\n",
      "Epoch 435/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4905 - accuracy: 0.7823 - auc: 0.8471 - val_loss: 0.5034 - val_accuracy: 0.7651 - val_auc: 0.8308\n",
      "Epoch 436/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4834 - accuracy: 0.7832 - auc: 0.8496 - val_loss: 0.5026 - val_accuracy: 0.7711 - val_auc: 0.8318\n",
      "Epoch 437/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4902 - accuracy: 0.7785 - auc: 0.8459 - val_loss: 0.5021 - val_accuracy: 0.7681 - val_auc: 0.8318\n",
      "Epoch 438/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4772 - accuracy: 0.7926 - auc: 0.8552 - val_loss: 0.5025 - val_accuracy: 0.7651 - val_auc: 0.8313\n",
      "Epoch 439/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4873 - accuracy: 0.7832 - auc: 0.8460 - val_loss: 0.5021 - val_accuracy: 0.7651 - val_auc: 0.8319\n",
      "Epoch 440/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4790 - accuracy: 0.7804 - auc: 0.8532 - val_loss: 0.5019 - val_accuracy: 0.7651 - val_auc: 0.8321\n",
      "Epoch 441/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4835 - accuracy: 0.7795 - auc: 0.8503 - val_loss: 0.5014 - val_accuracy: 0.7681 - val_auc: 0.8329\n",
      "Epoch 442/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4808 - accuracy: 0.7691 - auc: 0.8529 - val_loss: 0.5019 - val_accuracy: 0.7681 - val_auc: 0.8320\n",
      "Epoch 443/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4841 - accuracy: 0.7606 - auc: 0.8481 - val_loss: 0.5017 - val_accuracy: 0.7681 - val_auc: 0.8325\n",
      "Epoch 444/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4901 - accuracy: 0.7710 - auc: 0.8440 - val_loss: 0.5007 - val_accuracy: 0.7711 - val_auc: 0.8336\n",
      "Epoch 445/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4899 - accuracy: 0.7653 - auc: 0.8446 - val_loss: 0.5015 - val_accuracy: 0.7711 - val_auc: 0.8334\n",
      "Epoch 446/700\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 0.4873 - accuracy: 0.7766 - auc: 0.8459 - val_loss: 0.5005 - val_accuracy: 0.7711 - val_auc: 0.8345\n",
      "Epoch 447/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4788 - accuracy: 0.7766 - auc: 0.8534 - val_loss: 0.5001 - val_accuracy: 0.7681 - val_auc: 0.8348\n",
      "Epoch 448/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4900 - accuracy: 0.7700 - auc: 0.8463 - val_loss: 0.5003 - val_accuracy: 0.7681 - val_auc: 0.8350\n",
      "Epoch 449/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4831 - accuracy: 0.7700 - auc: 0.8501 - val_loss: 0.5001 - val_accuracy: 0.7681 - val_auc: 0.8348\n",
      "Epoch 450/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4830 - accuracy: 0.7738 - auc: 0.8494 - val_loss: 0.5007 - val_accuracy: 0.7681 - val_auc: 0.8339\n",
      "Epoch 451/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4836 - accuracy: 0.7700 - auc: 0.8479 - val_loss: 0.5004 - val_accuracy: 0.7711 - val_auc: 0.8344\n",
      "Epoch 452/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4884 - accuracy: 0.7719 - auc: 0.8460 - val_loss: 0.5016 - val_accuracy: 0.7681 - val_auc: 0.8327\n",
      "Epoch 453/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4820 - accuracy: 0.7785 - auc: 0.8511 - val_loss: 0.5006 - val_accuracy: 0.7681 - val_auc: 0.8336\n",
      "Epoch 454/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4924 - accuracy: 0.7823 - auc: 0.8465 - val_loss: 0.5002 - val_accuracy: 0.7681 - val_auc: 0.8342\n",
      "Epoch 455/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4842 - accuracy: 0.7700 - auc: 0.8470 - val_loss: 0.5002 - val_accuracy: 0.7681 - val_auc: 0.8347\n",
      "Epoch 456/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4810 - accuracy: 0.7663 - auc: 0.8508 - val_loss: 0.5001 - val_accuracy: 0.7681 - val_auc: 0.8347\n",
      "Epoch 457/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4785 - accuracy: 0.7785 - auc: 0.8528 - val_loss: 0.4989 - val_accuracy: 0.7681 - val_auc: 0.8358\n",
      "Epoch 458/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4931 - accuracy: 0.7842 - auc: 0.8437 - val_loss: 0.4986 - val_accuracy: 0.7741 - val_auc: 0.8360\n",
      "Epoch 459/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4762 - accuracy: 0.7842 - auc: 0.8548 - val_loss: 0.4985 - val_accuracy: 0.7711 - val_auc: 0.8362\n",
      "Epoch 460/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4827 - accuracy: 0.7813 - auc: 0.8509 - val_loss: 0.4989 - val_accuracy: 0.7711 - val_auc: 0.8352\n",
      "Epoch 461/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4764 - accuracy: 0.7917 - auc: 0.8546 - val_loss: 0.4994 - val_accuracy: 0.7711 - val_auc: 0.8347\n",
      "Epoch 462/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4842 - accuracy: 0.7766 - auc: 0.8492 - val_loss: 0.5002 - val_accuracy: 0.7741 - val_auc: 0.8335\n",
      "Epoch 463/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4848 - accuracy: 0.7738 - auc: 0.8495 - val_loss: 0.5006 - val_accuracy: 0.7711 - val_auc: 0.8334\n",
      "Epoch 464/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4890 - accuracy: 0.7747 - auc: 0.8456 - val_loss: 0.5007 - val_accuracy: 0.7681 - val_auc: 0.8329\n",
      "Epoch 465/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4876 - accuracy: 0.7700 - auc: 0.8472 - val_loss: 0.5003 - val_accuracy: 0.7741 - val_auc: 0.8342\n",
      "Epoch 466/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4796 - accuracy: 0.7823 - auc: 0.8521 - val_loss: 0.4993 - val_accuracy: 0.7801 - val_auc: 0.8347\n",
      "Epoch 467/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4864 - accuracy: 0.7776 - auc: 0.8492 - val_loss: 0.5004 - val_accuracy: 0.7771 - val_auc: 0.8335\n",
      "Epoch 468/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4770 - accuracy: 0.7776 - auc: 0.8545 - val_loss: 0.4994 - val_accuracy: 0.7771 - val_auc: 0.8345\n",
      "Epoch 469/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4753 - accuracy: 0.7926 - auc: 0.8569 - val_loss: 0.5006 - val_accuracy: 0.7741 - val_auc: 0.8331\n",
      "Epoch 470/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4854 - accuracy: 0.7738 - auc: 0.8487 - val_loss: 0.4999 - val_accuracy: 0.7681 - val_auc: 0.8337\n",
      "Epoch 471/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4885 - accuracy: 0.7738 - auc: 0.8460 - val_loss: 0.5003 - val_accuracy: 0.7771 - val_auc: 0.8340\n",
      "Epoch 472/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4785 - accuracy: 0.7926 - auc: 0.8558 - val_loss: 0.4998 - val_accuracy: 0.7711 - val_auc: 0.8346\n",
      "Epoch 473/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4853 - accuracy: 0.7832 - auc: 0.8469 - val_loss: 0.4995 - val_accuracy: 0.7711 - val_auc: 0.8347\n",
      "Epoch 474/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4881 - accuracy: 0.7842 - auc: 0.8469 - val_loss: 0.4998 - val_accuracy: 0.7651 - val_auc: 0.8340\n",
      "Epoch 475/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4895 - accuracy: 0.7785 - auc: 0.8470 - val_loss: 0.4999 - val_accuracy: 0.7741 - val_auc: 0.8343\n",
      "Epoch 476/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4714 - accuracy: 0.7851 - auc: 0.8586 - val_loss: 0.5002 - val_accuracy: 0.7681 - val_auc: 0.8336\n",
      "Epoch 477/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4778 - accuracy: 0.7842 - auc: 0.8543 - val_loss: 0.4998 - val_accuracy: 0.7711 - val_auc: 0.8340\n",
      "Epoch 478/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4830 - accuracy: 0.7776 - auc: 0.8500 - val_loss: 0.4992 - val_accuracy: 0.7711 - val_auc: 0.8350\n",
      "Epoch 479/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4837 - accuracy: 0.7776 - auc: 0.8486 - val_loss: 0.4993 - val_accuracy: 0.7711 - val_auc: 0.8348\n",
      "Epoch 480/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4723 - accuracy: 0.7870 - auc: 0.8588 - val_loss: 0.4997 - val_accuracy: 0.7711 - val_auc: 0.8342\n",
      "Epoch 481/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4799 - accuracy: 0.7776 - auc: 0.8526 - val_loss: 0.4989 - val_accuracy: 0.7741 - val_auc: 0.8356\n",
      "Epoch 482/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4892 - accuracy: 0.7766 - auc: 0.8459 - val_loss: 0.4988 - val_accuracy: 0.7711 - val_auc: 0.8362\n",
      "Epoch 483/700\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.4782 - accuracy: 0.7842 - auc: 0.8532 - val_loss: 0.4984 - val_accuracy: 0.7711 - val_auc: 0.8366\n",
      "Epoch 484/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4783 - accuracy: 0.7804 - auc: 0.8544 - val_loss: 0.4978 - val_accuracy: 0.7741 - val_auc: 0.8363\n",
      "Epoch 485/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4866 - accuracy: 0.7691 - auc: 0.8460 - val_loss: 0.4972 - val_accuracy: 0.7711 - val_auc: 0.8369\n",
      "Epoch 486/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.4932 - accuracy: 0.7625 - auc: 0.8431 - val_loss: 0.4972 - val_accuracy: 0.7711 - val_auc: 0.8372\n",
      "Epoch 487/700\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4699 - accuracy: 0.7879 - auc: 0.8596 - val_loss: 0.4968 - val_accuracy: 0.7711 - val_auc: 0.8375\n",
      "Epoch 488/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4844 - accuracy: 0.7804 - auc: 0.8493 - val_loss: 0.4972 - val_accuracy: 0.7741 - val_auc: 0.8372\n",
      "Epoch 489/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4874 - accuracy: 0.7842 - auc: 0.8502 - val_loss: 0.4978 - val_accuracy: 0.7771 - val_auc: 0.8360\n",
      "Epoch 490/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4805 - accuracy: 0.7719 - auc: 0.8515 - val_loss: 0.4978 - val_accuracy: 0.7771 - val_auc: 0.8357\n",
      "Epoch 491/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4802 - accuracy: 0.7738 - auc: 0.8512 - val_loss: 0.4988 - val_accuracy: 0.7771 - val_auc: 0.8352\n",
      "Epoch 492/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4877 - accuracy: 0.7719 - auc: 0.8484 - val_loss: 0.4989 - val_accuracy: 0.7771 - val_auc: 0.8350\n",
      "Epoch 493/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4735 - accuracy: 0.7832 - auc: 0.8565 - val_loss: 0.5002 - val_accuracy: 0.7711 - val_auc: 0.8333\n",
      "Epoch 494/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4813 - accuracy: 0.7813 - auc: 0.8535 - val_loss: 0.4997 - val_accuracy: 0.7711 - val_auc: 0.8342\n",
      "Epoch 495/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4754 - accuracy: 0.7898 - auc: 0.8551 - val_loss: 0.4998 - val_accuracy: 0.7711 - val_auc: 0.8343\n",
      "Epoch 496/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4823 - accuracy: 0.7738 - auc: 0.8504 - val_loss: 0.4992 - val_accuracy: 0.7741 - val_auc: 0.8350\n",
      "Epoch 497/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4828 - accuracy: 0.7681 - auc: 0.8505 - val_loss: 0.4994 - val_accuracy: 0.7741 - val_auc: 0.8347\n",
      "Epoch 498/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4814 - accuracy: 0.7776 - auc: 0.8496 - val_loss: 0.4986 - val_accuracy: 0.7741 - val_auc: 0.8355\n",
      "Epoch 499/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4800 - accuracy: 0.7861 - auc: 0.8546 - val_loss: 0.4981 - val_accuracy: 0.7711 - val_auc: 0.8356\n",
      "Epoch 500/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.4826 - accuracy: 0.7747 - auc: 0.8512 - val_loss: 0.4988 - val_accuracy: 0.7711 - val_auc: 0.8350\n",
      "Epoch 501/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4673 - accuracy: 0.7889 - auc: 0.8615 - val_loss: 0.4980 - val_accuracy: 0.7741 - val_auc: 0.8357\n",
      "Epoch 502/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4731 - accuracy: 0.7889 - auc: 0.8581 - val_loss: 0.4970 - val_accuracy: 0.7741 - val_auc: 0.8369\n",
      "Epoch 503/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4782 - accuracy: 0.7757 - auc: 0.8533 - val_loss: 0.4975 - val_accuracy: 0.7711 - val_auc: 0.8361\n",
      "Epoch 504/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4783 - accuracy: 0.7889 - auc: 0.8548 - val_loss: 0.4969 - val_accuracy: 0.7711 - val_auc: 0.8369\n",
      "Epoch 505/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4762 - accuracy: 0.7832 - auc: 0.8549 - val_loss: 0.4976 - val_accuracy: 0.7741 - val_auc: 0.8363\n",
      "Epoch 506/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4731 - accuracy: 0.7842 - auc: 0.8570 - val_loss: 0.4983 - val_accuracy: 0.7741 - val_auc: 0.8357\n",
      "Epoch 507/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4822 - accuracy: 0.7719 - auc: 0.8500 - val_loss: 0.4990 - val_accuracy: 0.7711 - val_auc: 0.8350\n",
      "Epoch 508/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4697 - accuracy: 0.7813 - auc: 0.8578 - val_loss: 0.4986 - val_accuracy: 0.7711 - val_auc: 0.8350\n",
      "Epoch 509/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4790 - accuracy: 0.7804 - auc: 0.8543 - val_loss: 0.4993 - val_accuracy: 0.7711 - val_auc: 0.8342\n",
      "Epoch 510/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4772 - accuracy: 0.7936 - auc: 0.8556 - val_loss: 0.4980 - val_accuracy: 0.7741 - val_auc: 0.8356\n",
      "Epoch 511/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4809 - accuracy: 0.7804 - auc: 0.8514 - val_loss: 0.4981 - val_accuracy: 0.7711 - val_auc: 0.8357\n",
      "Epoch 512/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4796 - accuracy: 0.7842 - auc: 0.8532 - val_loss: 0.4975 - val_accuracy: 0.7711 - val_auc: 0.8359\n",
      "Epoch 513/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4724 - accuracy: 0.7738 - auc: 0.8562 - val_loss: 0.4985 - val_accuracy: 0.7771 - val_auc: 0.8353\n",
      "Epoch 514/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4679 - accuracy: 0.7823 - auc: 0.8601 - val_loss: 0.4984 - val_accuracy: 0.7711 - val_auc: 0.8354\n",
      "Epoch 515/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4878 - accuracy: 0.7851 - auc: 0.8463 - val_loss: 0.4998 - val_accuracy: 0.7711 - val_auc: 0.8340\n",
      "Epoch 516/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4770 - accuracy: 0.7898 - auc: 0.8541 - val_loss: 0.4986 - val_accuracy: 0.7741 - val_auc: 0.8351\n",
      "Epoch 517/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.4788 - accuracy: 0.7691 - auc: 0.8536 - val_loss: 0.4988 - val_accuracy: 0.7741 - val_auc: 0.8350\n",
      "Epoch 00517: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('surprised_ravdess.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1596183548466,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ddcJYxjpRmou"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('surprised_ravdess.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 789,
     "status": "ok",
     "timestamp": 1596183550649,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "w4snlhBmRqz8"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_predictions_baseline = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 973,
     "status": "ok",
     "timestamp": 1596183553386,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1507,
     "status": "ok",
     "timestamp": 1596183557169,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "f2d3c043-687a-45f6-b443-246579aca126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.4967958331108093\n",
      "accuracy :  0.7710843086242676\n",
      "auc :  0.8374627828598022\n",
      "\n",
      "(True Negatives):  147\n",
      "(False Positives):  59\n",
      "(False Negatives):  17\n",
      "(True Positives):  109\n",
      "Total emotions_happy:  126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.79       206\n",
      "           1       0.65      0.87      0.74       126\n",
      "\n",
      "    accuracy                           0.77       332\n",
      "   macro avg       0.77      0.79      0.77       332\n",
      "weighted avg       0.80      0.77      0.77       332\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1596183572832,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "GJk2L3O8ImIn"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1596183576129,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "42d83cb1-92a8-47f7-df05-789a0787218a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.4520934820175171\n",
      "accuracy :  0.7706766724586487\n",
      "auc :  0.8695516586303711\n",
      "\n",
      "(True Negatives):  117\n",
      "(False Positives):  50\n",
      "(False Negatives):  11\n",
      "(True Positives):  88\n",
      "Total emotions_happy:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.70      0.79       167\n",
      "           1       0.64      0.89      0.74        99\n",
      "\n",
      "    accuracy                           0.77       266\n",
      "   macro avg       0.78      0.79      0.77       266\n",
      "weighted avg       0.81      0.77      0.77       266\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNtBm7hN1GoiMAg/zVfMG3Z",
   "name": "deep_surprised_RAVDESS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
