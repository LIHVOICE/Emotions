{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7138,
     "status": "ok",
     "timestamp": 1596107986133,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ymHSlukhKIF9",
    "outputId": "d79791df-0254-40b7-f549-55158862b6ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.7.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 3.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (2.1.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.18.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.16.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (4.4.2)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.15.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.48.0)\n",
      "Collecting soundfile>=0.9.0\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (49.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.14.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)\n",
      "Building wheels for collected packages: librosa\n",
      "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for librosa: filename=librosa-0.7.2-cp36-none-any.whl size=1612885 sha256=c64b85ba115c40e2f87553dd9e2a1abcb281a83f5b08bddfe370e009cb7b1c57\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/6e/d7/bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
      "Successfully built librosa\n",
      "Installing collected packages: soundfile, librosa\n",
      "  Found existing installation: librosa 0.6.3\n",
      "    Uninstalling librosa-0.6.3:\n",
      "      Successfully uninstalled librosa-0.6.3\n",
      "Successfully installed librosa-0.7.2 soundfile-0.10.3.post1\n"
     ]
    }
   ],
   "source": [
    "pip install librosa==0.7.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10002,
     "status": "ok",
     "timestamp": 1596026935548,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "sXnDmXR7RDr2",
    "outputId": "3b9dff36-3699-413b-8a0a-75f3af305685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10711,
     "status": "ok",
     "timestamp": 1596026954464,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Y04m-jvKRDsJ",
    "outputId": "ce46bb70-bae2-4985-8f6b-ee3fece0cc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
      "CPU (s):\n",
      "2.876127255\n",
      "GPU (s):\n",
      "0.1083209219999901\n",
      "GPU speedup over CPU: 26x\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 51131,
     "status": "ok",
     "timestamp": 1596108084977,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l9EbbgJpzQDD",
    "outputId": "1811b2f0-8ce2-4c7b-8958-88c3122a4238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5214,
     "status": "ok",
     "timestamp": 1596108111606,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ltf4WKPCeyVR",
    "outputId": "21e318d6-aa8d-4d42-da84-1bd24b172265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praat-parselmouth\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7b/9fa1172a63b6277603d27bb5613559b5a8888f58e68c1698017b87b0061d/praat_parselmouth-0.3.3-cp36-cp36m-manylinux1_x86_64.whl (9.0MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0MB 2.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from praat-parselmouth) (1.18.5)\n",
      "Installing collected packages: praat-parselmouth\n",
      "Successfully installed praat-parselmouth-0.3.3\n"
     ]
    }
   ],
   "source": [
    "pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5882,
     "status": "ok",
     "timestamp": 1596108126759,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PNwtWyMXe_Qb",
    "outputId": "18743601-76f3-4a5e-bb3d-c6dfbd0c4d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting essentia\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/cf/3c776d02b63fed7b0958bef2ce57b900870e2ac3f1fd8ffbb63f22d0e69e/essentia-2.1b6.dev234-cp36-cp36m-manylinux1_x86_64.whl (11.7MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7MB 3.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from essentia) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from essentia) (3.13)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from essentia) (1.18.5)\n",
      "Installing collected packages: essentia\n",
      "Successfully installed essentia-2.1b6.dev234\n"
     ]
    }
   ],
   "source": [
    "pip install essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5969,
     "status": "ok",
     "timestamp": 1596108141733,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "B9TmOS9AFg61",
    "outputId": "4ab952f7-795c-45ca-a03e-d007976dd973"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "#Spafe for audio\n",
    "#import spafe\n",
    "import scipy.io.wavfile\n",
    "#import spafe.utils.vis as vis\n",
    "#from spafe.features.mfcc import mfcc, imfcc\n",
    "#from spafe.features.gfcc import gfcc\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1596108189089,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "QAD42F-CgYli",
    "outputId": "e8742626-793e-4585-d308-996e0acb5b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "cd drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8185,
     "status": "ok",
     "timestamp": 1596108200104,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "94ecf03b-7460-488d-d4c4-1a2c0c2c6536"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disgust/03-01-07-02-01-02-10_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy/03-01-03-02-01-01-06_norm_outNoise.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral/03-01-01-01-01-01-05_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad/03-01-04-01-01-02-14_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust/03-01-07-02-02-02-17_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            audio label\n",
       "0  disgust/03-01-07-02-01-02-10_norm_outNoise.wav     0\n",
       "1    happy/03-01-03-02-01-01-06_norm_outNoise.wav     1\n",
       "2  neutral/03-01-01-01-01-01-05_norm_outNoise.wav     0\n",
       "3      sad/03-01-04-01-01-02-14_norm_outNoise.wav     0\n",
       "4  disgust/03-01-07-02-02-02-17_norm_outNoise.wav     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"audio_emotion\"\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i[7] == '3':\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) # here at df defined, with the columns we add the values:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1596108310277,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "c4d3873f-bfc6-426b-ff58-e13d44afafc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1053\n",
      "1     192\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1596108472332,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1596108474572,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "AjNAMwsfG2C8"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    fs, sig = scipy.io.wavfile.read(audio_path) \n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    spec =  fram_window(audio_path) \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)\n",
    "            \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "               \n",
    "    #gfccs = gfcc(sig= spec, fs=fs, num_ceps=13)    \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    #features.append(np.mean(gfccs))\n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2679376,
     "status": "ok",
     "timestamp": 1596111158295,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "folder ='audio_emotion'\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(folder+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1596111205529,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "255a8d63-1879-41ed-aa9a-5043ab91232d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1596111347332,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1596111366508,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1596111384582,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "d3f37dab-2a57-48ea-fa78-c3741711ccce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 660\n",
      "After OverSampling, counts of label '0': 1053\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \"[1, 2, 3, 4, 9, 10, 12, 14, 18, 19, 20, 21]  \" are deleted 597 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27555,
     "status": "ok",
     "timestamp": 1596111437107,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "68f67e86-51a7-46a9-d985-70888b25981e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4, 9, 10, 12, 14, 18, 19, 20, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3, 4, 9, 10, 12, 14, 18, 19, 20, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2, 3, 4, 9, 10, 12, 14, 18, 19, 20, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 3, 4, 5, 9, 10, 12, 14, 18, 19, 20, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 2, 3, 4, 9, 10, 12, 14, 18, 19, 20, 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration                                       X_removed\n",
       "0         1     [1, 2, 3, 4, 9, 10, 12, 14, 18, 19, 20, 21]\n",
       "1         2     [1, 2, 3, 4, 9, 10, 12, 14, 18, 19, 20, 21]\n",
       "2         3     [1, 2, 3, 4, 9, 10, 12, 14, 18, 19, 20, 21]\n",
       "3         4  [1, 2, 3, 4, 5, 9, 10, 12, 14, 18, 19, 20, 21]\n",
       "4         5     [1, 2, 3, 4, 9, 10, 12, 14, 18, 19, 20, 21]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 9, 10, 12, 14, 18, 19, 20, 21]       597\n",
       "[1, 2, 3, 4, 5, 9, 10, 12, 14, 18, 19, 20, 21]    401\n",
       "[1, 2, 3, 4, 9, 10, 12, 18, 19, 20, 21]             2\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1596111741546,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "rCHkL6UXWBi5"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0], X[i][5],  X[i][6], X[i][7], X[i][8],\n",
    "               X[i][11],  X[i][13], X[i][15],  X[i][16], X[i][17]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1596111760946,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "35b9082d-84bb-4245-b1f4-aca8dc82e34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096\n",
      "343\n",
      "274\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2268,
     "status": "ok",
     "timestamp": 1596111782376,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "TWis1PUVfK_4",
    "outputId": "5036811b-f2ce-4f25-a3ee-aa0685d9f0fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Plot imports ###\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "### Warning ###\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1596111804936,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1596111814858,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "d797ba62-3b12-40f3-c69b-8003de8b699e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 10, 1)\n",
      "(343, 10, 1)\n",
      "(274, 10, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1596111834828,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "8055b953-9008-406c-ed46-21e6012e8c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 2)\n",
      "(343, 2)\n",
      "(274, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1132,
     "status": "ok",
     "timestamp": 1596111884711,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "2af1ff63-1075-4990-dc22-a13c8cb3926d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 10, 1)]           0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 10, 128)           768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 10, 128)           512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 10, 128)           82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2562      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 85,898\n",
      "Trainable params: 85,638\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## First LFLB (local feature learning block)\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1596111897450,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 203807,
     "status": "ok",
     "timestamp": 1596112119754,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "40d4315e-1682-43ca-f5b2-91c7dc76389e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.8910 - accuracy: 0.5255 - auc: 0.5305 - val_loss: 0.6994 - val_accuracy: 0.5160 - val_auc: 0.5061\n",
      "Epoch 2/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.8198 - accuracy: 0.5566 - auc: 0.5729 - val_loss: 0.6950 - val_accuracy: 0.5277 - val_auc: 0.5306\n",
      "Epoch 3/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.7906 - accuracy: 0.5584 - auc: 0.5756 - val_loss: 0.6934 - val_accuracy: 0.5394 - val_auc: 0.5393\n",
      "Epoch 4/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.7517 - accuracy: 0.5630 - auc: 0.5941 - val_loss: 0.6898 - val_accuracy: 0.5510 - val_auc: 0.5556\n",
      "Epoch 5/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.7405 - accuracy: 0.5776 - auc: 0.6089 - val_loss: 0.6859 - val_accuracy: 0.5539 - val_auc: 0.5738\n",
      "Epoch 6/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.7151 - accuracy: 0.5803 - auc: 0.6187 - val_loss: 0.6866 - val_accuracy: 0.5569 - val_auc: 0.5705\n",
      "Epoch 7/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.7088 - accuracy: 0.5839 - auc: 0.6164 - val_loss: 0.6863 - val_accuracy: 0.5656 - val_auc: 0.5729\n",
      "Epoch 8/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6893 - accuracy: 0.6068 - auc: 0.6380 - val_loss: 0.6868 - val_accuracy: 0.5656 - val_auc: 0.5719\n",
      "Epoch 9/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6723 - accuracy: 0.6095 - auc: 0.6557 - val_loss: 0.6859 - val_accuracy: 0.5569 - val_auc: 0.5742\n",
      "Epoch 10/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6900 - accuracy: 0.5985 - auc: 0.6348 - val_loss: 0.6870 - val_accuracy: 0.5598 - val_auc: 0.5727\n",
      "Epoch 11/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6792 - accuracy: 0.6013 - auc: 0.6469 - val_loss: 0.6876 - val_accuracy: 0.5627 - val_auc: 0.5713\n",
      "Epoch 12/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6755 - accuracy: 0.6040 - auc: 0.6451 - val_loss: 0.6854 - val_accuracy: 0.5598 - val_auc: 0.5785\n",
      "Epoch 13/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6818 - accuracy: 0.5894 - auc: 0.6322 - val_loss: 0.6872 - val_accuracy: 0.5481 - val_auc: 0.5772\n",
      "Epoch 14/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6626 - accuracy: 0.6049 - auc: 0.6559 - val_loss: 0.6864 - val_accuracy: 0.5452 - val_auc: 0.5802\n",
      "Epoch 15/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6598 - accuracy: 0.6259 - auc: 0.6636 - val_loss: 0.6841 - val_accuracy: 0.5510 - val_auc: 0.5876\n",
      "Epoch 16/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6394 - accuracy: 0.6378 - auc: 0.6898 - val_loss: 0.6804 - val_accuracy: 0.5598 - val_auc: 0.5982\n",
      "Epoch 17/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6444 - accuracy: 0.6223 - auc: 0.6777 - val_loss: 0.6774 - val_accuracy: 0.5569 - val_auc: 0.6057\n",
      "Epoch 18/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6622 - accuracy: 0.6186 - auc: 0.6582 - val_loss: 0.6772 - val_accuracy: 0.5860 - val_auc: 0.6107\n",
      "Epoch 19/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6590 - accuracy: 0.6031 - auc: 0.6619 - val_loss: 0.6731 - val_accuracy: 0.5918 - val_auc: 0.6182\n",
      "Epoch 20/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6429 - accuracy: 0.6350 - auc: 0.6827 - val_loss: 0.6699 - val_accuracy: 0.5977 - val_auc: 0.6255\n",
      "Epoch 21/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6495 - accuracy: 0.6369 - auc: 0.6793 - val_loss: 0.6679 - val_accuracy: 0.5977 - val_auc: 0.6308\n",
      "Epoch 22/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.6483 - accuracy: 0.6268 - auc: 0.6788 - val_loss: 0.6640 - val_accuracy: 0.6093 - val_auc: 0.6386\n",
      "Epoch 23/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.6348 - accuracy: 0.6496 - auc: 0.6978 - val_loss: 0.6606 - val_accuracy: 0.6122 - val_auc: 0.6457\n",
      "Epoch 24/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6353 - accuracy: 0.6414 - auc: 0.6955 - val_loss: 0.6572 - val_accuracy: 0.6152 - val_auc: 0.6526\n",
      "Epoch 25/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6241 - accuracy: 0.6524 - auc: 0.7100 - val_loss: 0.6520 - val_accuracy: 0.6239 - val_auc: 0.6629\n",
      "Epoch 26/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6415 - accuracy: 0.6150 - auc: 0.6780 - val_loss: 0.6511 - val_accuracy: 0.6268 - val_auc: 0.6639\n",
      "Epoch 27/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6267 - accuracy: 0.6323 - auc: 0.6993 - val_loss: 0.6513 - val_accuracy: 0.6239 - val_auc: 0.6646\n",
      "Epoch 28/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6244 - accuracy: 0.6423 - auc: 0.7097 - val_loss: 0.6489 - val_accuracy: 0.6327 - val_auc: 0.6693\n",
      "Epoch 29/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6356 - accuracy: 0.6369 - auc: 0.6936 - val_loss: 0.6457 - val_accuracy: 0.6356 - val_auc: 0.6746\n",
      "Epoch 30/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6361 - accuracy: 0.6405 - auc: 0.6919 - val_loss: 0.6408 - val_accuracy: 0.6472 - val_auc: 0.6808\n",
      "Epoch 31/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6189 - accuracy: 0.6487 - auc: 0.7074 - val_loss: 0.6365 - val_accuracy: 0.6501 - val_auc: 0.6889\n",
      "Epoch 32/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6227 - accuracy: 0.6432 - auc: 0.7052 - val_loss: 0.6377 - val_accuracy: 0.6443 - val_auc: 0.6870\n",
      "Epoch 33/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6207 - accuracy: 0.6332 - auc: 0.7068 - val_loss: 0.6359 - val_accuracy: 0.6472 - val_auc: 0.6909\n",
      "Epoch 34/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6303 - accuracy: 0.6451 - auc: 0.6991 - val_loss: 0.6375 - val_accuracy: 0.6443 - val_auc: 0.6885\n",
      "Epoch 35/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6340 - accuracy: 0.6286 - auc: 0.6916 - val_loss: 0.6354 - val_accuracy: 0.6472 - val_auc: 0.6922\n",
      "Epoch 36/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6270 - accuracy: 0.6369 - auc: 0.7009 - val_loss: 0.6303 - val_accuracy: 0.6618 - val_auc: 0.6987\n",
      "Epoch 37/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6235 - accuracy: 0.6469 - auc: 0.7101 - val_loss: 0.6261 - val_accuracy: 0.6618 - val_auc: 0.7046\n",
      "Epoch 38/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6119 - accuracy: 0.6487 - auc: 0.7230 - val_loss: 0.6280 - val_accuracy: 0.6560 - val_auc: 0.7022\n",
      "Epoch 39/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6186 - accuracy: 0.6405 - auc: 0.7087 - val_loss: 0.6276 - val_accuracy: 0.6618 - val_auc: 0.7028\n",
      "Epoch 40/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6096 - accuracy: 0.6524 - auc: 0.7213 - val_loss: 0.6265 - val_accuracy: 0.6589 - val_auc: 0.7045\n",
      "Epoch 41/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.6224 - accuracy: 0.6588 - auc: 0.7087 - val_loss: 0.6258 - val_accuracy: 0.6647 - val_auc: 0.7048\n",
      "Epoch 42/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6211 - accuracy: 0.6259 - auc: 0.7026 - val_loss: 0.6258 - val_accuracy: 0.6560 - val_auc: 0.7053\n",
      "Epoch 43/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6143 - accuracy: 0.6478 - auc: 0.7145 - val_loss: 0.6222 - val_accuracy: 0.6560 - val_auc: 0.7106\n",
      "Epoch 44/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6154 - accuracy: 0.6414 - auc: 0.7134 - val_loss: 0.6218 - val_accuracy: 0.6560 - val_auc: 0.7109\n",
      "Epoch 45/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.6107 - accuracy: 0.6578 - auc: 0.7208 - val_loss: 0.6201 - val_accuracy: 0.6531 - val_auc: 0.7129\n",
      "Epoch 46/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6235 - accuracy: 0.6423 - auc: 0.7036 - val_loss: 0.6193 - val_accuracy: 0.6531 - val_auc: 0.7142\n",
      "Epoch 47/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6017 - accuracy: 0.6569 - auc: 0.7307 - val_loss: 0.6215 - val_accuracy: 0.6589 - val_auc: 0.7112\n",
      "Epoch 48/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6216 - accuracy: 0.6378 - auc: 0.7049 - val_loss: 0.6218 - val_accuracy: 0.6531 - val_auc: 0.7108\n",
      "Epoch 49/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6018 - accuracy: 0.6578 - auc: 0.7325 - val_loss: 0.6228 - val_accuracy: 0.6560 - val_auc: 0.7092\n",
      "Epoch 50/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6096 - accuracy: 0.6633 - auc: 0.7206 - val_loss: 0.6213 - val_accuracy: 0.6501 - val_auc: 0.7111\n",
      "Epoch 51/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6234 - accuracy: 0.6505 - auc: 0.7061 - val_loss: 0.6188 - val_accuracy: 0.6618 - val_auc: 0.7144\n",
      "Epoch 52/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6062 - accuracy: 0.6551 - auc: 0.7231 - val_loss: 0.6198 - val_accuracy: 0.6560 - val_auc: 0.7135\n",
      "Epoch 53/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.6094 - accuracy: 0.6688 - auc: 0.7241 - val_loss: 0.6177 - val_accuracy: 0.6589 - val_auc: 0.7166\n",
      "Epoch 54/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6161 - accuracy: 0.6432 - auc: 0.7118 - val_loss: 0.6193 - val_accuracy: 0.6560 - val_auc: 0.7146\n",
      "Epoch 55/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6050 - accuracy: 0.6588 - auc: 0.7245 - val_loss: 0.6176 - val_accuracy: 0.6560 - val_auc: 0.7165\n",
      "Epoch 56/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6121 - accuracy: 0.6451 - auc: 0.7169 - val_loss: 0.6184 - val_accuracy: 0.6560 - val_auc: 0.7150\n",
      "Epoch 57/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6052 - accuracy: 0.6578 - auc: 0.7257 - val_loss: 0.6181 - val_accuracy: 0.6589 - val_auc: 0.7154\n",
      "Epoch 58/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.6074 - accuracy: 0.6478 - auc: 0.7229 - val_loss: 0.6162 - val_accuracy: 0.6676 - val_auc: 0.7179\n",
      "Epoch 59/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6064 - accuracy: 0.6597 - auc: 0.7262 - val_loss: 0.6165 - val_accuracy: 0.6647 - val_auc: 0.7169\n",
      "Epoch 60/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6105 - accuracy: 0.6396 - auc: 0.7165 - val_loss: 0.6157 - val_accuracy: 0.6676 - val_auc: 0.7185\n",
      "Epoch 61/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6072 - accuracy: 0.6505 - auc: 0.7231 - val_loss: 0.6160 - val_accuracy: 0.6706 - val_auc: 0.7179\n",
      "Epoch 62/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6128 - accuracy: 0.6588 - auc: 0.7174 - val_loss: 0.6146 - val_accuracy: 0.6706 - val_auc: 0.7196\n",
      "Epoch 63/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6084 - accuracy: 0.6469 - auc: 0.7166 - val_loss: 0.6153 - val_accuracy: 0.6676 - val_auc: 0.7190\n",
      "Epoch 64/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6049 - accuracy: 0.6679 - auc: 0.7296 - val_loss: 0.6168 - val_accuracy: 0.6589 - val_auc: 0.7169\n",
      "Epoch 65/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6040 - accuracy: 0.6505 - auc: 0.7241 - val_loss: 0.6164 - val_accuracy: 0.6647 - val_auc: 0.7184\n",
      "Epoch 66/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5965 - accuracy: 0.6588 - auc: 0.7342 - val_loss: 0.6176 - val_accuracy: 0.6531 - val_auc: 0.7160\n",
      "Epoch 67/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6061 - accuracy: 0.6496 - auc: 0.7214 - val_loss: 0.6153 - val_accuracy: 0.6501 - val_auc: 0.7186\n",
      "Epoch 68/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5965 - accuracy: 0.6688 - auc: 0.7376 - val_loss: 0.6167 - val_accuracy: 0.6531 - val_auc: 0.7178\n",
      "Epoch 69/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6129 - accuracy: 0.6542 - auc: 0.7184 - val_loss: 0.6141 - val_accuracy: 0.6618 - val_auc: 0.7200\n",
      "Epoch 70/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5974 - accuracy: 0.6624 - auc: 0.7332 - val_loss: 0.6130 - val_accuracy: 0.6647 - val_auc: 0.7212\n",
      "Epoch 71/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6051 - accuracy: 0.6442 - auc: 0.7213 - val_loss: 0.6134 - val_accuracy: 0.6647 - val_auc: 0.7212\n",
      "Epoch 72/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6047 - accuracy: 0.6542 - auc: 0.7242 - val_loss: 0.6141 - val_accuracy: 0.6589 - val_auc: 0.7208\n",
      "Epoch 73/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6082 - accuracy: 0.6496 - auc: 0.7202 - val_loss: 0.6151 - val_accuracy: 0.6560 - val_auc: 0.7196\n",
      "Epoch 74/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6039 - accuracy: 0.6460 - auc: 0.7233 - val_loss: 0.6142 - val_accuracy: 0.6618 - val_auc: 0.7208\n",
      "Epoch 75/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5928 - accuracy: 0.6752 - auc: 0.7432 - val_loss: 0.6141 - val_accuracy: 0.6618 - val_auc: 0.7207\n",
      "Epoch 76/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6128 - accuracy: 0.6460 - auc: 0.7157 - val_loss: 0.6140 - val_accuracy: 0.6647 - val_auc: 0.7210\n",
      "Epoch 77/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6066 - accuracy: 0.6578 - auc: 0.7238 - val_loss: 0.6146 - val_accuracy: 0.6618 - val_auc: 0.7201\n",
      "Epoch 78/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6108 - accuracy: 0.6597 - auc: 0.7210 - val_loss: 0.6153 - val_accuracy: 0.6589 - val_auc: 0.7196\n",
      "Epoch 79/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5987 - accuracy: 0.6788 - auc: 0.7365 - val_loss: 0.6163 - val_accuracy: 0.6560 - val_auc: 0.7182\n",
      "Epoch 80/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5949 - accuracy: 0.6588 - auc: 0.7372 - val_loss: 0.6154 - val_accuracy: 0.6560 - val_auc: 0.7191\n",
      "Epoch 81/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6018 - accuracy: 0.6633 - auc: 0.7280 - val_loss: 0.6127 - val_accuracy: 0.6706 - val_auc: 0.7229\n",
      "Epoch 82/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5988 - accuracy: 0.6688 - auc: 0.7346 - val_loss: 0.6125 - val_accuracy: 0.6735 - val_auc: 0.7230\n",
      "Epoch 83/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5877 - accuracy: 0.6706 - auc: 0.7454 - val_loss: 0.6107 - val_accuracy: 0.6735 - val_auc: 0.7253\n",
      "Epoch 84/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6007 - accuracy: 0.6624 - auc: 0.7305 - val_loss: 0.6122 - val_accuracy: 0.6676 - val_auc: 0.7239\n",
      "Epoch 85/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5974 - accuracy: 0.6816 - auc: 0.7383 - val_loss: 0.6103 - val_accuracy: 0.6706 - val_auc: 0.7262\n",
      "Epoch 86/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5948 - accuracy: 0.6724 - auc: 0.7383 - val_loss: 0.6120 - val_accuracy: 0.6706 - val_auc: 0.7239\n",
      "Epoch 87/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5999 - accuracy: 0.6578 - auc: 0.7325 - val_loss: 0.6136 - val_accuracy: 0.6647 - val_auc: 0.7223\n",
      "Epoch 88/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6000 - accuracy: 0.6642 - auc: 0.7320 - val_loss: 0.6130 - val_accuracy: 0.6676 - val_auc: 0.7232\n",
      "Epoch 89/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6010 - accuracy: 0.6588 - auc: 0.7312 - val_loss: 0.6116 - val_accuracy: 0.6706 - val_auc: 0.7250\n",
      "Epoch 90/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5955 - accuracy: 0.6670 - auc: 0.7367 - val_loss: 0.6116 - val_accuracy: 0.6735 - val_auc: 0.7250\n",
      "Epoch 91/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5972 - accuracy: 0.6661 - auc: 0.7334 - val_loss: 0.6116 - val_accuracy: 0.6706 - val_auc: 0.7250\n",
      "Epoch 92/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5967 - accuracy: 0.6551 - auc: 0.7364 - val_loss: 0.6116 - val_accuracy: 0.6706 - val_auc: 0.7243\n",
      "Epoch 93/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5942 - accuracy: 0.6651 - auc: 0.7359 - val_loss: 0.6125 - val_accuracy: 0.6706 - val_auc: 0.7240\n",
      "Epoch 94/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5958 - accuracy: 0.6606 - auc: 0.7356 - val_loss: 0.6102 - val_accuracy: 0.6676 - val_auc: 0.7272\n",
      "Epoch 95/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5928 - accuracy: 0.6651 - auc: 0.7404 - val_loss: 0.6103 - val_accuracy: 0.6764 - val_auc: 0.7260\n",
      "Epoch 96/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5971 - accuracy: 0.6578 - auc: 0.7324 - val_loss: 0.6117 - val_accuracy: 0.6793 - val_auc: 0.7247\n",
      "Epoch 97/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5955 - accuracy: 0.6661 - auc: 0.7381 - val_loss: 0.6123 - val_accuracy: 0.6735 - val_auc: 0.7242\n",
      "Epoch 98/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5907 - accuracy: 0.6679 - auc: 0.7421 - val_loss: 0.6111 - val_accuracy: 0.6676 - val_auc: 0.7250\n",
      "Epoch 99/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5973 - accuracy: 0.6697 - auc: 0.7357 - val_loss: 0.6141 - val_accuracy: 0.6676 - val_auc: 0.7216\n",
      "Epoch 100/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5917 - accuracy: 0.6560 - auc: 0.7423 - val_loss: 0.6126 - val_accuracy: 0.6735 - val_auc: 0.7235\n",
      "Epoch 101/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6029 - accuracy: 0.6752 - auc: 0.7292 - val_loss: 0.6121 - val_accuracy: 0.6706 - val_auc: 0.7240\n",
      "Epoch 102/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5860 - accuracy: 0.6797 - auc: 0.7487 - val_loss: 0.6107 - val_accuracy: 0.6735 - val_auc: 0.7257\n",
      "Epoch 103/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.6009 - accuracy: 0.6615 - auc: 0.7327 - val_loss: 0.6113 - val_accuracy: 0.6764 - val_auc: 0.7251\n",
      "Epoch 104/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5901 - accuracy: 0.6661 - auc: 0.7445 - val_loss: 0.6112 - val_accuracy: 0.6735 - val_auc: 0.7249\n",
      "Epoch 105/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5922 - accuracy: 0.6633 - auc: 0.7407 - val_loss: 0.6083 - val_accuracy: 0.6822 - val_auc: 0.7283\n",
      "Epoch 106/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5987 - accuracy: 0.6542 - auc: 0.7321 - val_loss: 0.6082 - val_accuracy: 0.6793 - val_auc: 0.7288\n",
      "Epoch 107/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.6005 - accuracy: 0.6588 - auc: 0.7288 - val_loss: 0.6075 - val_accuracy: 0.6764 - val_auc: 0.7294\n",
      "Epoch 108/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5967 - accuracy: 0.6670 - auc: 0.7391 - val_loss: 0.6074 - val_accuracy: 0.6822 - val_auc: 0.7295\n",
      "Epoch 109/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5962 - accuracy: 0.6487 - auc: 0.7320 - val_loss: 0.6093 - val_accuracy: 0.6764 - val_auc: 0.7266\n",
      "Epoch 110/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5918 - accuracy: 0.6642 - auc: 0.7399 - val_loss: 0.6079 - val_accuracy: 0.6793 - val_auc: 0.7288\n",
      "Epoch 111/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5897 - accuracy: 0.6743 - auc: 0.7448 - val_loss: 0.6064 - val_accuracy: 0.6793 - val_auc: 0.7304\n",
      "Epoch 112/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5983 - accuracy: 0.6560 - auc: 0.7296 - val_loss: 0.6068 - val_accuracy: 0.6793 - val_auc: 0.7302\n",
      "Epoch 113/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5890 - accuracy: 0.6706 - auc: 0.7430 - val_loss: 0.6097 - val_accuracy: 0.6735 - val_auc: 0.7270\n",
      "Epoch 114/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6085 - accuracy: 0.6505 - auc: 0.7209 - val_loss: 0.6099 - val_accuracy: 0.6793 - val_auc: 0.7266\n",
      "Epoch 115/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5928 - accuracy: 0.6661 - auc: 0.7399 - val_loss: 0.6064 - val_accuracy: 0.6822 - val_auc: 0.7310\n",
      "Epoch 116/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5936 - accuracy: 0.6606 - auc: 0.7385 - val_loss: 0.6042 - val_accuracy: 0.6764 - val_auc: 0.7326\n",
      "Epoch 117/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5869 - accuracy: 0.6734 - auc: 0.7441 - val_loss: 0.6029 - val_accuracy: 0.6793 - val_auc: 0.7343\n",
      "Epoch 118/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5883 - accuracy: 0.6715 - auc: 0.7469 - val_loss: 0.6037 - val_accuracy: 0.6793 - val_auc: 0.7341\n",
      "Epoch 119/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5898 - accuracy: 0.6606 - auc: 0.7419 - val_loss: 0.6038 - val_accuracy: 0.6822 - val_auc: 0.7336\n",
      "Epoch 120/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5876 - accuracy: 0.6661 - auc: 0.7478 - val_loss: 0.6048 - val_accuracy: 0.6764 - val_auc: 0.7327\n",
      "Epoch 121/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5968 - accuracy: 0.6661 - auc: 0.7342 - val_loss: 0.6058 - val_accuracy: 0.6764 - val_auc: 0.7319\n",
      "Epoch 122/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5952 - accuracy: 0.6679 - auc: 0.7395 - val_loss: 0.6046 - val_accuracy: 0.6793 - val_auc: 0.7332\n",
      "Epoch 123/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5793 - accuracy: 0.6852 - auc: 0.7538 - val_loss: 0.6052 - val_accuracy: 0.6706 - val_auc: 0.7329\n",
      "Epoch 124/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5903 - accuracy: 0.6688 - auc: 0.7449 - val_loss: 0.6043 - val_accuracy: 0.6822 - val_auc: 0.7338\n",
      "Epoch 125/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5796 - accuracy: 0.6779 - auc: 0.7584 - val_loss: 0.6040 - val_accuracy: 0.6822 - val_auc: 0.7341\n",
      "Epoch 126/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5823 - accuracy: 0.6770 - auc: 0.7536 - val_loss: 0.6052 - val_accuracy: 0.6793 - val_auc: 0.7334\n",
      "Epoch 127/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5869 - accuracy: 0.6569 - auc: 0.7449 - val_loss: 0.6054 - val_accuracy: 0.6793 - val_auc: 0.7326\n",
      "Epoch 128/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5850 - accuracy: 0.6779 - auc: 0.7487 - val_loss: 0.6054 - val_accuracy: 0.6735 - val_auc: 0.7331\n",
      "Epoch 129/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5968 - accuracy: 0.6515 - auc: 0.7340 - val_loss: 0.6045 - val_accuracy: 0.6764 - val_auc: 0.7336\n",
      "Epoch 130/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5896 - accuracy: 0.6633 - auc: 0.7440 - val_loss: 0.6054 - val_accuracy: 0.6764 - val_auc: 0.7327\n",
      "Epoch 131/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5956 - accuracy: 0.6642 - auc: 0.7363 - val_loss: 0.6057 - val_accuracy: 0.6735 - val_auc: 0.7321\n",
      "Epoch 132/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5855 - accuracy: 0.6834 - auc: 0.7487 - val_loss: 0.6061 - val_accuracy: 0.6735 - val_auc: 0.7319\n",
      "Epoch 133/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5953 - accuracy: 0.6706 - auc: 0.7392 - val_loss: 0.6042 - val_accuracy: 0.6822 - val_auc: 0.7346\n",
      "Epoch 134/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5980 - accuracy: 0.6496 - auc: 0.7312 - val_loss: 0.6036 - val_accuracy: 0.6822 - val_auc: 0.7349\n",
      "Epoch 135/700\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.5849 - accuracy: 0.6706 - auc: 0.7510 - val_loss: 0.6027 - val_accuracy: 0.6735 - val_auc: 0.7358\n",
      "Epoch 136/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5775 - accuracy: 0.6807 - auc: 0.7599 - val_loss: 0.6022 - val_accuracy: 0.6735 - val_auc: 0.7361\n",
      "Epoch 137/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5901 - accuracy: 0.6670 - auc: 0.7430 - val_loss: 0.6031 - val_accuracy: 0.6735 - val_auc: 0.7353\n",
      "Epoch 138/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5938 - accuracy: 0.6797 - auc: 0.7410 - val_loss: 0.6008 - val_accuracy: 0.6793 - val_auc: 0.7373\n",
      "Epoch 139/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5907 - accuracy: 0.6797 - auc: 0.7448 - val_loss: 0.6017 - val_accuracy: 0.6764 - val_auc: 0.7367\n",
      "Epoch 140/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5923 - accuracy: 0.6551 - auc: 0.7390 - val_loss: 0.6009 - val_accuracy: 0.6793 - val_auc: 0.7368\n",
      "Epoch 141/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5907 - accuracy: 0.6724 - auc: 0.7446 - val_loss: 0.6020 - val_accuracy: 0.6706 - val_auc: 0.7365\n",
      "Epoch 142/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5950 - accuracy: 0.6542 - auc: 0.7365 - val_loss: 0.6017 - val_accuracy: 0.6764 - val_auc: 0.7370\n",
      "Epoch 143/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5893 - accuracy: 0.6743 - auc: 0.7453 - val_loss: 0.6024 - val_accuracy: 0.6764 - val_auc: 0.7361\n",
      "Epoch 144/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5901 - accuracy: 0.6779 - auc: 0.7466 - val_loss: 0.6041 - val_accuracy: 0.6735 - val_auc: 0.7344\n",
      "Epoch 145/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5892 - accuracy: 0.6670 - auc: 0.7441 - val_loss: 0.6047 - val_accuracy: 0.6735 - val_auc: 0.7334\n",
      "Epoch 146/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5927 - accuracy: 0.6588 - auc: 0.7398 - val_loss: 0.6033 - val_accuracy: 0.6735 - val_auc: 0.7349\n",
      "Epoch 147/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5824 - accuracy: 0.6807 - auc: 0.7527 - val_loss: 0.6029 - val_accuracy: 0.6706 - val_auc: 0.7355\n",
      "Epoch 148/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5927 - accuracy: 0.6734 - auc: 0.7420 - val_loss: 0.6029 - val_accuracy: 0.6706 - val_auc: 0.7356\n",
      "Epoch 149/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5813 - accuracy: 0.6770 - auc: 0.7529 - val_loss: 0.6024 - val_accuracy: 0.6735 - val_auc: 0.7362\n",
      "Epoch 150/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5802 - accuracy: 0.6807 - auc: 0.7565 - val_loss: 0.6014 - val_accuracy: 0.6764 - val_auc: 0.7378\n",
      "Epoch 151/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5761 - accuracy: 0.6880 - auc: 0.7626 - val_loss: 0.6010 - val_accuracy: 0.6793 - val_auc: 0.7378\n",
      "Epoch 152/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5777 - accuracy: 0.6770 - auc: 0.7579 - val_loss: 0.6005 - val_accuracy: 0.6764 - val_auc: 0.7390\n",
      "Epoch 153/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5821 - accuracy: 0.6807 - auc: 0.7540 - val_loss: 0.5998 - val_accuracy: 0.6735 - val_auc: 0.7396\n",
      "Epoch 154/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5915 - accuracy: 0.6715 - auc: 0.7416 - val_loss: 0.6001 - val_accuracy: 0.6793 - val_auc: 0.7388\n",
      "Epoch 155/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5889 - accuracy: 0.6743 - auc: 0.7454 - val_loss: 0.6000 - val_accuracy: 0.6764 - val_auc: 0.7390\n",
      "Epoch 156/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5888 - accuracy: 0.6651 - auc: 0.7440 - val_loss: 0.5984 - val_accuracy: 0.6793 - val_auc: 0.7405\n",
      "Epoch 157/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5796 - accuracy: 0.6807 - auc: 0.7583 - val_loss: 0.5983 - val_accuracy: 0.6822 - val_auc: 0.7408\n",
      "Epoch 158/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5792 - accuracy: 0.6779 - auc: 0.7588 - val_loss: 0.5976 - val_accuracy: 0.6793 - val_auc: 0.7416\n",
      "Epoch 159/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5797 - accuracy: 0.6797 - auc: 0.7572 - val_loss: 0.5980 - val_accuracy: 0.6793 - val_auc: 0.7412\n",
      "Epoch 160/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5826 - accuracy: 0.6825 - auc: 0.7528 - val_loss: 0.5983 - val_accuracy: 0.6764 - val_auc: 0.7409\n",
      "Epoch 161/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5875 - accuracy: 0.6770 - auc: 0.7481 - val_loss: 0.5985 - val_accuracy: 0.6764 - val_auc: 0.7412\n",
      "Epoch 162/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5866 - accuracy: 0.6834 - auc: 0.7515 - val_loss: 0.5977 - val_accuracy: 0.6793 - val_auc: 0.7411\n",
      "Epoch 163/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5900 - accuracy: 0.6807 - auc: 0.7421 - val_loss: 0.5991 - val_accuracy: 0.6764 - val_auc: 0.7404\n",
      "Epoch 164/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5887 - accuracy: 0.6834 - auc: 0.7477 - val_loss: 0.5996 - val_accuracy: 0.6764 - val_auc: 0.7404\n",
      "Epoch 165/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5837 - accuracy: 0.6734 - auc: 0.7489 - val_loss: 0.6002 - val_accuracy: 0.6793 - val_auc: 0.7394\n",
      "Epoch 166/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5819 - accuracy: 0.6788 - auc: 0.7547 - val_loss: 0.5993 - val_accuracy: 0.6822 - val_auc: 0.7402\n",
      "Epoch 167/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5798 - accuracy: 0.6724 - auc: 0.7541 - val_loss: 0.5970 - val_accuracy: 0.6793 - val_auc: 0.7432\n",
      "Epoch 168/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5888 - accuracy: 0.6642 - auc: 0.7452 - val_loss: 0.5957 - val_accuracy: 0.6822 - val_auc: 0.7445\n",
      "Epoch 169/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5754 - accuracy: 0.6807 - auc: 0.7608 - val_loss: 0.5952 - val_accuracy: 0.6822 - val_auc: 0.7449\n",
      "Epoch 170/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5774 - accuracy: 0.6916 - auc: 0.7577 - val_loss: 0.5955 - val_accuracy: 0.6822 - val_auc: 0.7440\n",
      "Epoch 171/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5778 - accuracy: 0.6807 - auc: 0.7589 - val_loss: 0.5961 - val_accuracy: 0.6851 - val_auc: 0.7435\n",
      "Epoch 172/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5863 - accuracy: 0.6734 - auc: 0.7462 - val_loss: 0.5992 - val_accuracy: 0.6851 - val_auc: 0.7402\n",
      "Epoch 173/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5839 - accuracy: 0.6816 - auc: 0.7524 - val_loss: 0.5982 - val_accuracy: 0.6880 - val_auc: 0.7410\n",
      "Epoch 174/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5799 - accuracy: 0.6907 - auc: 0.7582 - val_loss: 0.5977 - val_accuracy: 0.6851 - val_auc: 0.7418\n",
      "Epoch 175/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5783 - accuracy: 0.6734 - auc: 0.7567 - val_loss: 0.5995 - val_accuracy: 0.6822 - val_auc: 0.7397\n",
      "Epoch 176/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5700 - accuracy: 0.6843 - auc: 0.7681 - val_loss: 0.5988 - val_accuracy: 0.6880 - val_auc: 0.7401\n",
      "Epoch 177/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5834 - accuracy: 0.6880 - auc: 0.7519 - val_loss: 0.5993 - val_accuracy: 0.6880 - val_auc: 0.7406\n",
      "Epoch 178/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5794 - accuracy: 0.6770 - auc: 0.7561 - val_loss: 0.5984 - val_accuracy: 0.6793 - val_auc: 0.7415\n",
      "Epoch 179/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5941 - accuracy: 0.6615 - auc: 0.7350 - val_loss: 0.5989 - val_accuracy: 0.6880 - val_auc: 0.7405\n",
      "Epoch 180/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5843 - accuracy: 0.6560 - auc: 0.7457 - val_loss: 0.5977 - val_accuracy: 0.6822 - val_auc: 0.7418\n",
      "Epoch 181/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5820 - accuracy: 0.6761 - auc: 0.7519 - val_loss: 0.5969 - val_accuracy: 0.6822 - val_auc: 0.7428\n",
      "Epoch 182/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5755 - accuracy: 0.6807 - auc: 0.7621 - val_loss: 0.5995 - val_accuracy: 0.6793 - val_auc: 0.7406\n",
      "Epoch 183/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5884 - accuracy: 0.6788 - auc: 0.7483 - val_loss: 0.6009 - val_accuracy: 0.6822 - val_auc: 0.7388\n",
      "Epoch 184/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5842 - accuracy: 0.6843 - auc: 0.7522 - val_loss: 0.5996 - val_accuracy: 0.6793 - val_auc: 0.7404\n",
      "Epoch 185/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5793 - accuracy: 0.6679 - auc: 0.7537 - val_loss: 0.5991 - val_accuracy: 0.6851 - val_auc: 0.7406\n",
      "Epoch 186/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5706 - accuracy: 0.6843 - auc: 0.7659 - val_loss: 0.5987 - val_accuracy: 0.6880 - val_auc: 0.7401\n",
      "Epoch 187/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5704 - accuracy: 0.6843 - auc: 0.7666 - val_loss: 0.5969 - val_accuracy: 0.6880 - val_auc: 0.7424\n",
      "Epoch 188/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5777 - accuracy: 0.6880 - auc: 0.7589 - val_loss: 0.5962 - val_accuracy: 0.6880 - val_auc: 0.7434\n",
      "Epoch 189/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5784 - accuracy: 0.6816 - auc: 0.7571 - val_loss: 0.5967 - val_accuracy: 0.6851 - val_auc: 0.7430\n",
      "Epoch 190/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5717 - accuracy: 0.6807 - auc: 0.7642 - val_loss: 0.5959 - val_accuracy: 0.6851 - val_auc: 0.7439\n",
      "Epoch 191/700\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.5768 - accuracy: 0.6816 - auc: 0.7602 - val_loss: 0.5936 - val_accuracy: 0.6880 - val_auc: 0.7463\n",
      "Epoch 192/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5813 - accuracy: 0.6779 - auc: 0.7517 - val_loss: 0.5940 - val_accuracy: 0.6880 - val_auc: 0.7459\n",
      "Epoch 193/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5804 - accuracy: 0.6788 - auc: 0.7544 - val_loss: 0.5958 - val_accuracy: 0.6880 - val_auc: 0.7439\n",
      "Epoch 194/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5758 - accuracy: 0.6834 - auc: 0.7581 - val_loss: 0.5973 - val_accuracy: 0.6851 - val_auc: 0.7429\n",
      "Epoch 195/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5771 - accuracy: 0.6807 - auc: 0.7578 - val_loss: 0.5960 - val_accuracy: 0.6851 - val_auc: 0.7441\n",
      "Epoch 196/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5744 - accuracy: 0.6843 - auc: 0.7630 - val_loss: 0.5962 - val_accuracy: 0.6851 - val_auc: 0.7443\n",
      "Epoch 197/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5789 - accuracy: 0.6752 - auc: 0.7556 - val_loss: 0.5956 - val_accuracy: 0.6851 - val_auc: 0.7446\n",
      "Epoch 198/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5795 - accuracy: 0.6788 - auc: 0.7553 - val_loss: 0.5960 - val_accuracy: 0.6880 - val_auc: 0.7443\n",
      "Epoch 199/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5707 - accuracy: 0.6980 - auc: 0.7667 - val_loss: 0.5968 - val_accuracy: 0.6851 - val_auc: 0.7431\n",
      "Epoch 200/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5752 - accuracy: 0.6816 - auc: 0.7591 - val_loss: 0.5983 - val_accuracy: 0.6822 - val_auc: 0.7414\n",
      "Epoch 201/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5746 - accuracy: 0.6788 - auc: 0.7612 - val_loss: 0.5968 - val_accuracy: 0.6880 - val_auc: 0.7433\n",
      "Epoch 202/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5742 - accuracy: 0.6797 - auc: 0.7603 - val_loss: 0.5959 - val_accuracy: 0.6910 - val_auc: 0.7440\n",
      "Epoch 203/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5667 - accuracy: 0.6816 - auc: 0.7712 - val_loss: 0.5942 - val_accuracy: 0.6910 - val_auc: 0.7458\n",
      "Epoch 204/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5792 - accuracy: 0.6807 - auc: 0.7563 - val_loss: 0.5955 - val_accuracy: 0.6880 - val_auc: 0.7445\n",
      "Epoch 205/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5853 - accuracy: 0.6797 - auc: 0.7497 - val_loss: 0.5939 - val_accuracy: 0.6793 - val_auc: 0.7467\n",
      "Epoch 206/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5849 - accuracy: 0.6807 - auc: 0.7516 - val_loss: 0.5932 - val_accuracy: 0.6851 - val_auc: 0.7471\n",
      "Epoch 207/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5818 - accuracy: 0.6843 - auc: 0.7537 - val_loss: 0.5924 - val_accuracy: 0.6880 - val_auc: 0.7475\n",
      "Epoch 208/700\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5769 - accuracy: 0.6697 - auc: 0.7582 - val_loss: 0.5917 - val_accuracy: 0.6851 - val_auc: 0.7488\n",
      "Epoch 209/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5754 - accuracy: 0.6852 - auc: 0.7581 - val_loss: 0.5925 - val_accuracy: 0.6822 - val_auc: 0.7477\n",
      "Epoch 210/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5790 - accuracy: 0.6870 - auc: 0.7598 - val_loss: 0.5930 - val_accuracy: 0.6822 - val_auc: 0.7474\n",
      "Epoch 211/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5807 - accuracy: 0.6816 - auc: 0.7575 - val_loss: 0.5942 - val_accuracy: 0.6822 - val_auc: 0.7454\n",
      "Epoch 212/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5774 - accuracy: 0.6861 - auc: 0.7591 - val_loss: 0.5938 - val_accuracy: 0.6793 - val_auc: 0.7466\n",
      "Epoch 213/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5775 - accuracy: 0.6770 - auc: 0.7579 - val_loss: 0.5943 - val_accuracy: 0.6851 - val_auc: 0.7459\n",
      "Epoch 214/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5801 - accuracy: 0.6843 - auc: 0.7568 - val_loss: 0.5944 - val_accuracy: 0.6880 - val_auc: 0.7457\n",
      "Epoch 215/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5701 - accuracy: 0.6889 - auc: 0.7655 - val_loss: 0.5966 - val_accuracy: 0.6851 - val_auc: 0.7428\n",
      "Epoch 216/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5769 - accuracy: 0.6734 - auc: 0.7566 - val_loss: 0.5950 - val_accuracy: 0.6822 - val_auc: 0.7453\n",
      "Epoch 217/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5768 - accuracy: 0.6797 - auc: 0.7569 - val_loss: 0.5972 - val_accuracy: 0.6851 - val_auc: 0.7423\n",
      "Epoch 218/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5683 - accuracy: 0.6870 - auc: 0.7694 - val_loss: 0.5952 - val_accuracy: 0.6880 - val_auc: 0.7446\n",
      "Epoch 219/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5800 - accuracy: 0.6807 - auc: 0.7521 - val_loss: 0.5948 - val_accuracy: 0.6822 - val_auc: 0.7459\n",
      "Epoch 220/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5766 - accuracy: 0.6825 - auc: 0.7595 - val_loss: 0.5941 - val_accuracy: 0.6880 - val_auc: 0.7466\n",
      "Epoch 221/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5716 - accuracy: 0.6843 - auc: 0.7663 - val_loss: 0.5932 - val_accuracy: 0.6851 - val_auc: 0.7473\n",
      "Epoch 222/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5696 - accuracy: 0.6880 - auc: 0.7709 - val_loss: 0.5925 - val_accuracy: 0.6822 - val_auc: 0.7481\n",
      "Epoch 223/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5752 - accuracy: 0.6807 - auc: 0.7615 - val_loss: 0.5913 - val_accuracy: 0.6822 - val_auc: 0.7501\n",
      "Epoch 224/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5725 - accuracy: 0.6779 - auc: 0.7629 - val_loss: 0.5922 - val_accuracy: 0.6851 - val_auc: 0.7490\n",
      "Epoch 225/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5762 - accuracy: 0.6752 - auc: 0.7616 - val_loss: 0.5911 - val_accuracy: 0.6822 - val_auc: 0.7506\n",
      "Epoch 226/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5746 - accuracy: 0.6816 - auc: 0.7617 - val_loss: 0.5908 - val_accuracy: 0.6851 - val_auc: 0.7505\n",
      "Epoch 227/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5742 - accuracy: 0.6916 - auc: 0.7631 - val_loss: 0.5919 - val_accuracy: 0.6822 - val_auc: 0.7501\n",
      "Epoch 228/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5720 - accuracy: 0.6916 - auc: 0.7629 - val_loss: 0.5914 - val_accuracy: 0.6822 - val_auc: 0.7504\n",
      "Epoch 229/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5694 - accuracy: 0.6852 - auc: 0.7666 - val_loss: 0.5918 - val_accuracy: 0.6880 - val_auc: 0.7495\n",
      "Epoch 230/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5731 - accuracy: 0.6861 - auc: 0.7634 - val_loss: 0.5916 - val_accuracy: 0.6880 - val_auc: 0.7496\n",
      "Epoch 231/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5799 - accuracy: 0.6834 - auc: 0.7560 - val_loss: 0.5901 - val_accuracy: 0.6880 - val_auc: 0.7513\n",
      "Epoch 232/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5645 - accuracy: 0.6953 - auc: 0.7729 - val_loss: 0.5908 - val_accuracy: 0.6793 - val_auc: 0.7508\n",
      "Epoch 233/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5676 - accuracy: 0.6925 - auc: 0.7695 - val_loss: 0.5911 - val_accuracy: 0.6851 - val_auc: 0.7500\n",
      "Epoch 234/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5803 - accuracy: 0.6870 - auc: 0.7551 - val_loss: 0.5902 - val_accuracy: 0.6910 - val_auc: 0.7503\n",
      "Epoch 235/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5777 - accuracy: 0.6880 - auc: 0.7587 - val_loss: 0.5902 - val_accuracy: 0.6880 - val_auc: 0.7510\n",
      "Epoch 236/700\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5791 - accuracy: 0.6807 - auc: 0.7545 - val_loss: 0.5894 - val_accuracy: 0.6880 - val_auc: 0.7517\n",
      "Epoch 237/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5774 - accuracy: 0.6825 - auc: 0.7602 - val_loss: 0.5914 - val_accuracy: 0.6851 - val_auc: 0.7496\n",
      "Epoch 238/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5794 - accuracy: 0.6834 - auc: 0.7555 - val_loss: 0.5911 - val_accuracy: 0.6851 - val_auc: 0.7505\n",
      "Epoch 239/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5713 - accuracy: 0.6825 - auc: 0.7644 - val_loss: 0.5915 - val_accuracy: 0.6910 - val_auc: 0.7498\n",
      "Epoch 240/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5689 - accuracy: 0.6934 - auc: 0.7688 - val_loss: 0.5903 - val_accuracy: 0.6880 - val_auc: 0.7514\n",
      "Epoch 241/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5720 - accuracy: 0.6861 - auc: 0.7655 - val_loss: 0.5885 - val_accuracy: 0.6880 - val_auc: 0.7529\n",
      "Epoch 242/700\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.5744 - accuracy: 0.6852 - auc: 0.7641 - val_loss: 0.5883 - val_accuracy: 0.6880 - val_auc: 0.7530\n",
      "Epoch 243/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5647 - accuracy: 0.7007 - auc: 0.7733 - val_loss: 0.5895 - val_accuracy: 0.6880 - val_auc: 0.7516\n",
      "Epoch 244/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5701 - accuracy: 0.6861 - auc: 0.7685 - val_loss: 0.5898 - val_accuracy: 0.6880 - val_auc: 0.7515\n",
      "Epoch 245/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5804 - accuracy: 0.6770 - auc: 0.7561 - val_loss: 0.5900 - val_accuracy: 0.6851 - val_auc: 0.7506\n",
      "Epoch 246/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5651 - accuracy: 0.6870 - auc: 0.7712 - val_loss: 0.5886 - val_accuracy: 0.6910 - val_auc: 0.7526\n",
      "Epoch 247/700\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.5625 - accuracy: 0.6943 - auc: 0.7745 - val_loss: 0.5877 - val_accuracy: 0.6822 - val_auc: 0.7537\n",
      "Epoch 248/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5679 - accuracy: 0.6797 - auc: 0.7709 - val_loss: 0.5896 - val_accuracy: 0.6851 - val_auc: 0.7513\n",
      "Epoch 249/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5680 - accuracy: 0.6962 - auc: 0.7701 - val_loss: 0.5894 - val_accuracy: 0.6793 - val_auc: 0.7519\n",
      "Epoch 250/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5723 - accuracy: 0.6916 - auc: 0.7650 - val_loss: 0.5882 - val_accuracy: 0.6822 - val_auc: 0.7534\n",
      "Epoch 251/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5660 - accuracy: 0.6898 - auc: 0.7712 - val_loss: 0.5895 - val_accuracy: 0.6764 - val_auc: 0.7519\n",
      "Epoch 252/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5661 - accuracy: 0.6834 - auc: 0.7717 - val_loss: 0.5885 - val_accuracy: 0.6793 - val_auc: 0.7529\n",
      "Epoch 253/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5653 - accuracy: 0.6980 - auc: 0.7737 - val_loss: 0.5876 - val_accuracy: 0.6822 - val_auc: 0.7539\n",
      "Epoch 254/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5831 - accuracy: 0.6788 - auc: 0.7536 - val_loss: 0.5901 - val_accuracy: 0.6822 - val_auc: 0.7514\n",
      "Epoch 255/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5694 - accuracy: 0.6953 - auc: 0.7661 - val_loss: 0.5880 - val_accuracy: 0.6793 - val_auc: 0.7534\n",
      "Epoch 256/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5594 - accuracy: 0.6898 - auc: 0.7773 - val_loss: 0.5882 - val_accuracy: 0.6822 - val_auc: 0.7535\n",
      "Epoch 257/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5638 - accuracy: 0.7016 - auc: 0.7753 - val_loss: 0.5896 - val_accuracy: 0.6793 - val_auc: 0.7521\n",
      "Epoch 258/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5716 - accuracy: 0.6870 - auc: 0.7639 - val_loss: 0.5893 - val_accuracy: 0.6793 - val_auc: 0.7529\n",
      "Epoch 259/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5712 - accuracy: 0.6797 - auc: 0.7619 - val_loss: 0.5892 - val_accuracy: 0.6822 - val_auc: 0.7526\n",
      "Epoch 260/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5765 - accuracy: 0.6880 - auc: 0.7597 - val_loss: 0.5890 - val_accuracy: 0.6822 - val_auc: 0.7525\n",
      "Epoch 261/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5765 - accuracy: 0.6953 - auc: 0.7608 - val_loss: 0.5898 - val_accuracy: 0.6793 - val_auc: 0.7518\n",
      "Epoch 262/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5750 - accuracy: 0.6797 - auc: 0.7609 - val_loss: 0.5891 - val_accuracy: 0.6793 - val_auc: 0.7524\n",
      "Epoch 263/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5746 - accuracy: 0.6898 - auc: 0.7614 - val_loss: 0.5899 - val_accuracy: 0.6851 - val_auc: 0.7516\n",
      "Epoch 264/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5706 - accuracy: 0.6962 - auc: 0.7688 - val_loss: 0.5902 - val_accuracy: 0.6851 - val_auc: 0.7512\n",
      "Epoch 265/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5614 - accuracy: 0.6980 - auc: 0.7751 - val_loss: 0.5886 - val_accuracy: 0.6793 - val_auc: 0.7524\n",
      "Epoch 266/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5770 - accuracy: 0.6870 - auc: 0.7600 - val_loss: 0.5898 - val_accuracy: 0.6851 - val_auc: 0.7522\n",
      "Epoch 267/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5644 - accuracy: 0.6962 - auc: 0.7747 - val_loss: 0.5891 - val_accuracy: 0.6910 - val_auc: 0.7522\n",
      "Epoch 268/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5645 - accuracy: 0.6943 - auc: 0.7729 - val_loss: 0.5899 - val_accuracy: 0.6910 - val_auc: 0.7513\n",
      "Epoch 269/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5657 - accuracy: 0.6870 - auc: 0.7700 - val_loss: 0.5884 - val_accuracy: 0.6910 - val_auc: 0.7535\n",
      "Epoch 270/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5772 - accuracy: 0.6752 - auc: 0.7596 - val_loss: 0.5857 - val_accuracy: 0.6910 - val_auc: 0.7559\n",
      "Epoch 271/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5833 - accuracy: 0.6880 - auc: 0.7547 - val_loss: 0.5858 - val_accuracy: 0.6910 - val_auc: 0.7557\n",
      "Epoch 272/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5731 - accuracy: 0.6962 - auc: 0.7615 - val_loss: 0.5876 - val_accuracy: 0.6910 - val_auc: 0.7535\n",
      "Epoch 273/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5659 - accuracy: 0.6916 - auc: 0.7710 - val_loss: 0.5867 - val_accuracy: 0.6880 - val_auc: 0.7549\n",
      "Epoch 274/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5682 - accuracy: 0.6834 - auc: 0.7681 - val_loss: 0.5866 - val_accuracy: 0.6793 - val_auc: 0.7553\n",
      "Epoch 275/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5777 - accuracy: 0.6761 - auc: 0.7534 - val_loss: 0.5877 - val_accuracy: 0.6822 - val_auc: 0.7544\n",
      "Epoch 276/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5671 - accuracy: 0.7016 - auc: 0.7710 - val_loss: 0.5875 - val_accuracy: 0.6851 - val_auc: 0.7542\n",
      "Epoch 277/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5695 - accuracy: 0.6898 - auc: 0.7651 - val_loss: 0.5881 - val_accuracy: 0.6764 - val_auc: 0.7541\n",
      "Epoch 278/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5696 - accuracy: 0.7026 - auc: 0.7709 - val_loss: 0.5880 - val_accuracy: 0.6764 - val_auc: 0.7542\n",
      "Epoch 279/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5736 - accuracy: 0.6861 - auc: 0.7633 - val_loss: 0.5883 - val_accuracy: 0.6851 - val_auc: 0.7539\n",
      "Epoch 280/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5790 - accuracy: 0.6788 - auc: 0.7547 - val_loss: 0.5863 - val_accuracy: 0.6793 - val_auc: 0.7557\n",
      "Epoch 281/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5572 - accuracy: 0.7135 - auc: 0.7828 - val_loss: 0.5870 - val_accuracy: 0.6793 - val_auc: 0.7551\n",
      "Epoch 282/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5752 - accuracy: 0.6843 - auc: 0.7628 - val_loss: 0.5852 - val_accuracy: 0.6822 - val_auc: 0.7567\n",
      "Epoch 283/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5629 - accuracy: 0.6943 - auc: 0.7733 - val_loss: 0.5865 - val_accuracy: 0.6735 - val_auc: 0.7553\n",
      "Epoch 284/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5723 - accuracy: 0.6880 - auc: 0.7637 - val_loss: 0.5872 - val_accuracy: 0.6764 - val_auc: 0.7547\n",
      "Epoch 285/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5655 - accuracy: 0.6816 - auc: 0.7696 - val_loss: 0.5883 - val_accuracy: 0.6880 - val_auc: 0.7537\n",
      "Epoch 286/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5591 - accuracy: 0.6943 - auc: 0.7798 - val_loss: 0.5880 - val_accuracy: 0.6910 - val_auc: 0.7539\n",
      "Epoch 287/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5585 - accuracy: 0.7144 - auc: 0.7804 - val_loss: 0.5866 - val_accuracy: 0.6822 - val_auc: 0.7554\n",
      "Epoch 288/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5701 - accuracy: 0.6934 - auc: 0.7674 - val_loss: 0.5872 - val_accuracy: 0.6939 - val_auc: 0.7548\n",
      "Epoch 289/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5632 - accuracy: 0.6916 - auc: 0.7746 - val_loss: 0.5878 - val_accuracy: 0.6910 - val_auc: 0.7550\n",
      "Epoch 290/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5684 - accuracy: 0.6907 - auc: 0.7677 - val_loss: 0.5873 - val_accuracy: 0.6880 - val_auc: 0.7549\n",
      "Epoch 291/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5714 - accuracy: 0.6907 - auc: 0.7665 - val_loss: 0.5876 - val_accuracy: 0.6880 - val_auc: 0.7542\n",
      "Epoch 292/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5631 - accuracy: 0.7071 - auc: 0.7760 - val_loss: 0.5875 - val_accuracy: 0.6851 - val_auc: 0.7544\n",
      "Epoch 293/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5629 - accuracy: 0.6834 - auc: 0.7717 - val_loss: 0.5887 - val_accuracy: 0.6793 - val_auc: 0.7540\n",
      "Epoch 294/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5709 - accuracy: 0.6898 - auc: 0.7689 - val_loss: 0.5898 - val_accuracy: 0.6910 - val_auc: 0.7525\n",
      "Epoch 295/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5685 - accuracy: 0.6971 - auc: 0.7692 - val_loss: 0.5893 - val_accuracy: 0.6880 - val_auc: 0.7535\n",
      "Epoch 296/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5686 - accuracy: 0.6916 - auc: 0.7696 - val_loss: 0.5886 - val_accuracy: 0.6880 - val_auc: 0.7538\n",
      "Epoch 297/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5646 - accuracy: 0.6916 - auc: 0.7718 - val_loss: 0.5878 - val_accuracy: 0.6880 - val_auc: 0.7549\n",
      "Epoch 298/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5624 - accuracy: 0.6898 - auc: 0.7738 - val_loss: 0.5864 - val_accuracy: 0.6880 - val_auc: 0.7562\n",
      "Epoch 299/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5614 - accuracy: 0.7035 - auc: 0.7767 - val_loss: 0.5852 - val_accuracy: 0.6822 - val_auc: 0.7573\n",
      "Epoch 300/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5677 - accuracy: 0.6861 - auc: 0.7678 - val_loss: 0.5853 - val_accuracy: 0.6851 - val_auc: 0.7577\n",
      "Epoch 301/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5619 - accuracy: 0.7071 - auc: 0.7763 - val_loss: 0.5858 - val_accuracy: 0.6939 - val_auc: 0.7565\n",
      "Epoch 302/700\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.5716 - accuracy: 0.6971 - auc: 0.7692 - val_loss: 0.5843 - val_accuracy: 0.6939 - val_auc: 0.7577\n",
      "Epoch 303/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5692 - accuracy: 0.6925 - auc: 0.7696 - val_loss: 0.5823 - val_accuracy: 0.6851 - val_auc: 0.7597\n",
      "Epoch 304/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5644 - accuracy: 0.6889 - auc: 0.7722 - val_loss: 0.5825 - val_accuracy: 0.6851 - val_auc: 0.7598\n",
      "Epoch 305/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5814 - accuracy: 0.6807 - auc: 0.7553 - val_loss: 0.5830 - val_accuracy: 0.6910 - val_auc: 0.7588\n",
      "Epoch 306/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5607 - accuracy: 0.7053 - auc: 0.7784 - val_loss: 0.5836 - val_accuracy: 0.6910 - val_auc: 0.7591\n",
      "Epoch 307/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5590 - accuracy: 0.6980 - auc: 0.7797 - val_loss: 0.5818 - val_accuracy: 0.6880 - val_auc: 0.7600\n",
      "Epoch 308/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5727 - accuracy: 0.6934 - auc: 0.7647 - val_loss: 0.5826 - val_accuracy: 0.6939 - val_auc: 0.7596\n",
      "Epoch 309/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5564 - accuracy: 0.6989 - auc: 0.7812 - val_loss: 0.5813 - val_accuracy: 0.6851 - val_auc: 0.7610\n",
      "Epoch 310/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5692 - accuracy: 0.6916 - auc: 0.7684 - val_loss: 0.5818 - val_accuracy: 0.6880 - val_auc: 0.7605\n",
      "Epoch 311/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5704 - accuracy: 0.6825 - auc: 0.7643 - val_loss: 0.5824 - val_accuracy: 0.6939 - val_auc: 0.7599\n",
      "Epoch 312/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5675 - accuracy: 0.6980 - auc: 0.7721 - val_loss: 0.5813 - val_accuracy: 0.6939 - val_auc: 0.7608\n",
      "Epoch 313/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5608 - accuracy: 0.7035 - auc: 0.7758 - val_loss: 0.5829 - val_accuracy: 0.6997 - val_auc: 0.7593\n",
      "Epoch 314/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5553 - accuracy: 0.7053 - auc: 0.7837 - val_loss: 0.5827 - val_accuracy: 0.6939 - val_auc: 0.7598\n",
      "Epoch 315/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5639 - accuracy: 0.6971 - auc: 0.7741 - val_loss: 0.5850 - val_accuracy: 0.6968 - val_auc: 0.7572\n",
      "Epoch 316/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5637 - accuracy: 0.6943 - auc: 0.7724 - val_loss: 0.5842 - val_accuracy: 0.6968 - val_auc: 0.7583\n",
      "Epoch 317/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5657 - accuracy: 0.6934 - auc: 0.7747 - val_loss: 0.5833 - val_accuracy: 0.7026 - val_auc: 0.7589\n",
      "Epoch 318/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5715 - accuracy: 0.6889 - auc: 0.7647 - val_loss: 0.5845 - val_accuracy: 0.6939 - val_auc: 0.7577\n",
      "Epoch 319/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5630 - accuracy: 0.6825 - auc: 0.7717 - val_loss: 0.5834 - val_accuracy: 0.6939 - val_auc: 0.7591\n",
      "Epoch 320/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5753 - accuracy: 0.6852 - auc: 0.7614 - val_loss: 0.5826 - val_accuracy: 0.6939 - val_auc: 0.7600\n",
      "Epoch 321/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5712 - accuracy: 0.6925 - auc: 0.7675 - val_loss: 0.5820 - val_accuracy: 0.6880 - val_auc: 0.7601\n",
      "Epoch 322/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5598 - accuracy: 0.6889 - auc: 0.7785 - val_loss: 0.5822 - val_accuracy: 0.6968 - val_auc: 0.7601\n",
      "Epoch 323/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5565 - accuracy: 0.7044 - auc: 0.7828 - val_loss: 0.5819 - val_accuracy: 0.6968 - val_auc: 0.7604\n",
      "Epoch 324/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5637 - accuracy: 0.6898 - auc: 0.7730 - val_loss: 0.5805 - val_accuracy: 0.6880 - val_auc: 0.7616\n",
      "Epoch 325/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5689 - accuracy: 0.6889 - auc: 0.7705 - val_loss: 0.5835 - val_accuracy: 0.6939 - val_auc: 0.7585\n",
      "Epoch 326/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5634 - accuracy: 0.6980 - auc: 0.7726 - val_loss: 0.5808 - val_accuracy: 0.6939 - val_auc: 0.7613\n",
      "Epoch 327/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5657 - accuracy: 0.6843 - auc: 0.7696 - val_loss: 0.5787 - val_accuracy: 0.6968 - val_auc: 0.7640\n",
      "Epoch 328/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5703 - accuracy: 0.6907 - auc: 0.7655 - val_loss: 0.5782 - val_accuracy: 0.6968 - val_auc: 0.7643\n",
      "Epoch 329/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5632 - accuracy: 0.6898 - auc: 0.7734 - val_loss: 0.5787 - val_accuracy: 0.6968 - val_auc: 0.7637\n",
      "Epoch 330/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5645 - accuracy: 0.6962 - auc: 0.7744 - val_loss: 0.5793 - val_accuracy: 0.6968 - val_auc: 0.7634\n",
      "Epoch 331/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5619 - accuracy: 0.7144 - auc: 0.7781 - val_loss: 0.5788 - val_accuracy: 0.6939 - val_auc: 0.7642\n",
      "Epoch 332/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5564 - accuracy: 0.7144 - auc: 0.7824 - val_loss: 0.5801 - val_accuracy: 0.6880 - val_auc: 0.7620\n",
      "Epoch 333/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5613 - accuracy: 0.6971 - auc: 0.7773 - val_loss: 0.5803 - val_accuracy: 0.6910 - val_auc: 0.7618\n",
      "Epoch 334/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5658 - accuracy: 0.7071 - auc: 0.7739 - val_loss: 0.5809 - val_accuracy: 0.6910 - val_auc: 0.7617\n",
      "Epoch 335/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5562 - accuracy: 0.7126 - auc: 0.7839 - val_loss: 0.5820 - val_accuracy: 0.6910 - val_auc: 0.7606\n",
      "Epoch 336/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5710 - accuracy: 0.6943 - auc: 0.7692 - val_loss: 0.5801 - val_accuracy: 0.6910 - val_auc: 0.7624\n",
      "Epoch 337/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5579 - accuracy: 0.6916 - auc: 0.7772 - val_loss: 0.5803 - val_accuracy: 0.6910 - val_auc: 0.7624\n",
      "Epoch 338/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5588 - accuracy: 0.6925 - auc: 0.7764 - val_loss: 0.5797 - val_accuracy: 0.6968 - val_auc: 0.7624\n",
      "Epoch 339/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5539 - accuracy: 0.7108 - auc: 0.7837 - val_loss: 0.5799 - val_accuracy: 0.6939 - val_auc: 0.7627\n",
      "Epoch 340/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5594 - accuracy: 0.6998 - auc: 0.7789 - val_loss: 0.5798 - val_accuracy: 0.6939 - val_auc: 0.7630\n",
      "Epoch 341/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5669 - accuracy: 0.6907 - auc: 0.7696 - val_loss: 0.5807 - val_accuracy: 0.6880 - val_auc: 0.7625\n",
      "Epoch 342/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5670 - accuracy: 0.6962 - auc: 0.7730 - val_loss: 0.5821 - val_accuracy: 0.6968 - val_auc: 0.7606\n",
      "Epoch 343/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5594 - accuracy: 0.6880 - auc: 0.7759 - val_loss: 0.5825 - val_accuracy: 0.6910 - val_auc: 0.7608\n",
      "Epoch 344/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5631 - accuracy: 0.7062 - auc: 0.7758 - val_loss: 0.5811 - val_accuracy: 0.6939 - val_auc: 0.7619\n",
      "Epoch 345/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5634 - accuracy: 0.7099 - auc: 0.7796 - val_loss: 0.5804 - val_accuracy: 0.6968 - val_auc: 0.7624\n",
      "Epoch 346/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5651 - accuracy: 0.6962 - auc: 0.7692 - val_loss: 0.5800 - val_accuracy: 0.6939 - val_auc: 0.7629\n",
      "Epoch 347/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5607 - accuracy: 0.7026 - auc: 0.7796 - val_loss: 0.5806 - val_accuracy: 0.6968 - val_auc: 0.7628\n",
      "Epoch 348/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5595 - accuracy: 0.7026 - auc: 0.7792 - val_loss: 0.5815 - val_accuracy: 0.6939 - val_auc: 0.7622\n",
      "Epoch 349/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5709 - accuracy: 0.6779 - auc: 0.7664 - val_loss: 0.5805 - val_accuracy: 0.6968 - val_auc: 0.7631\n",
      "Epoch 350/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5641 - accuracy: 0.7035 - auc: 0.7754 - val_loss: 0.5806 - val_accuracy: 0.6968 - val_auc: 0.7624\n",
      "Epoch 351/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5642 - accuracy: 0.6907 - auc: 0.7747 - val_loss: 0.5805 - val_accuracy: 0.6939 - val_auc: 0.7624\n",
      "Epoch 352/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5602 - accuracy: 0.7016 - auc: 0.7756 - val_loss: 0.5805 - val_accuracy: 0.6880 - val_auc: 0.7626\n",
      "Epoch 353/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5555 - accuracy: 0.7035 - auc: 0.7840 - val_loss: 0.5799 - val_accuracy: 0.6851 - val_auc: 0.7638\n",
      "Epoch 354/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5603 - accuracy: 0.7007 - auc: 0.7769 - val_loss: 0.5802 - val_accuracy: 0.6793 - val_auc: 0.7624\n",
      "Epoch 355/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5617 - accuracy: 0.6898 - auc: 0.7733 - val_loss: 0.5800 - val_accuracy: 0.6880 - val_auc: 0.7623\n",
      "Epoch 356/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5531 - accuracy: 0.7044 - auc: 0.7866 - val_loss: 0.5788 - val_accuracy: 0.6880 - val_auc: 0.7638\n",
      "Epoch 357/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5546 - accuracy: 0.7016 - auc: 0.7847 - val_loss: 0.5795 - val_accuracy: 0.6939 - val_auc: 0.7630\n",
      "Epoch 358/700\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.5635 - accuracy: 0.7007 - auc: 0.7753 - val_loss: 0.5777 - val_accuracy: 0.6939 - val_auc: 0.7652\n",
      "Epoch 359/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5629 - accuracy: 0.6980 - auc: 0.7773 - val_loss: 0.5786 - val_accuracy: 0.6968 - val_auc: 0.7644\n",
      "Epoch 360/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5662 - accuracy: 0.6971 - auc: 0.7738 - val_loss: 0.5805 - val_accuracy: 0.6939 - val_auc: 0.7615\n",
      "Epoch 361/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5643 - accuracy: 0.7080 - auc: 0.7738 - val_loss: 0.5799 - val_accuracy: 0.6939 - val_auc: 0.7623\n",
      "Epoch 362/700\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.5594 - accuracy: 0.6980 - auc: 0.7793 - val_loss: 0.5802 - val_accuracy: 0.6910 - val_auc: 0.7627\n",
      "Epoch 363/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5565 - accuracy: 0.6971 - auc: 0.7812 - val_loss: 0.5795 - val_accuracy: 0.6939 - val_auc: 0.7631\n",
      "Epoch 364/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5562 - accuracy: 0.6889 - auc: 0.7794 - val_loss: 0.5805 - val_accuracy: 0.6910 - val_auc: 0.7627\n",
      "Epoch 365/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5595 - accuracy: 0.6971 - auc: 0.7792 - val_loss: 0.5809 - val_accuracy: 0.6910 - val_auc: 0.7617\n",
      "Epoch 366/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5507 - accuracy: 0.7080 - auc: 0.7886 - val_loss: 0.5798 - val_accuracy: 0.6997 - val_auc: 0.7629\n",
      "Epoch 367/700\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5608 - accuracy: 0.6916 - auc: 0.7754 - val_loss: 0.5817 - val_accuracy: 0.6939 - val_auc: 0.7615\n",
      "Epoch 368/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5673 - accuracy: 0.6889 - auc: 0.7665 - val_loss: 0.5819 - val_accuracy: 0.6910 - val_auc: 0.7611\n",
      "Epoch 369/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5651 - accuracy: 0.6843 - auc: 0.7744 - val_loss: 0.5824 - val_accuracy: 0.6939 - val_auc: 0.7606\n",
      "Epoch 370/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5630 - accuracy: 0.6962 - auc: 0.7723 - val_loss: 0.5831 - val_accuracy: 0.6939 - val_auc: 0.7595\n",
      "Epoch 371/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5679 - accuracy: 0.6916 - auc: 0.7688 - val_loss: 0.5821 - val_accuracy: 0.6939 - val_auc: 0.7609\n",
      "Epoch 372/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5646 - accuracy: 0.6971 - auc: 0.7702 - val_loss: 0.5814 - val_accuracy: 0.6910 - val_auc: 0.7615\n",
      "Epoch 373/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5613 - accuracy: 0.7026 - auc: 0.7799 - val_loss: 0.5810 - val_accuracy: 0.6851 - val_auc: 0.7618\n",
      "Epoch 374/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5623 - accuracy: 0.6925 - auc: 0.7733 - val_loss: 0.5803 - val_accuracy: 0.6939 - val_auc: 0.7621\n",
      "Epoch 375/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5506 - accuracy: 0.7062 - auc: 0.7872 - val_loss: 0.5805 - val_accuracy: 0.6910 - val_auc: 0.7622\n",
      "Epoch 376/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5521 - accuracy: 0.7089 - auc: 0.7875 - val_loss: 0.5815 - val_accuracy: 0.6939 - val_auc: 0.7609\n",
      "Epoch 377/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5530 - accuracy: 0.7126 - auc: 0.7900 - val_loss: 0.5785 - val_accuracy: 0.6880 - val_auc: 0.7643\n",
      "Epoch 378/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5589 - accuracy: 0.6889 - auc: 0.7759 - val_loss: 0.5777 - val_accuracy: 0.6910 - val_auc: 0.7655\n",
      "Epoch 379/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5541 - accuracy: 0.7089 - auc: 0.7862 - val_loss: 0.5790 - val_accuracy: 0.6880 - val_auc: 0.7640\n",
      "Epoch 380/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5567 - accuracy: 0.6934 - auc: 0.7803 - val_loss: 0.5786 - val_accuracy: 0.6910 - val_auc: 0.7643\n",
      "Epoch 381/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5577 - accuracy: 0.7099 - auc: 0.7826 - val_loss: 0.5789 - val_accuracy: 0.6910 - val_auc: 0.7637\n",
      "Epoch 382/700\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.5572 - accuracy: 0.7099 - auc: 0.7802 - val_loss: 0.5772 - val_accuracy: 0.6939 - val_auc: 0.7656\n",
      "Epoch 383/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5558 - accuracy: 0.7135 - auc: 0.7858 - val_loss: 0.5773 - val_accuracy: 0.6997 - val_auc: 0.7660\n",
      "Epoch 384/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5616 - accuracy: 0.7062 - auc: 0.7766 - val_loss: 0.5783 - val_accuracy: 0.6997 - val_auc: 0.7647\n",
      "Epoch 385/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5626 - accuracy: 0.6889 - auc: 0.7760 - val_loss: 0.5769 - val_accuracy: 0.6939 - val_auc: 0.7665\n",
      "Epoch 386/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5543 - accuracy: 0.7053 - auc: 0.7851 - val_loss: 0.5771 - val_accuracy: 0.6997 - val_auc: 0.7661\n",
      "Epoch 387/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5616 - accuracy: 0.7117 - auc: 0.7800 - val_loss: 0.5785 - val_accuracy: 0.6997 - val_auc: 0.7644\n",
      "Epoch 388/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5546 - accuracy: 0.7053 - auc: 0.7829 - val_loss: 0.5782 - val_accuracy: 0.7026 - val_auc: 0.7648\n",
      "Epoch 389/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5561 - accuracy: 0.6989 - auc: 0.7816 - val_loss: 0.5777 - val_accuracy: 0.7026 - val_auc: 0.7655\n",
      "Epoch 390/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5613 - accuracy: 0.6852 - auc: 0.7752 - val_loss: 0.5766 - val_accuracy: 0.6968 - val_auc: 0.7670\n",
      "Epoch 391/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5539 - accuracy: 0.7080 - auc: 0.7867 - val_loss: 0.5747 - val_accuracy: 0.7026 - val_auc: 0.7686\n",
      "Epoch 392/700\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5585 - accuracy: 0.7035 - auc: 0.7811 - val_loss: 0.5741 - val_accuracy: 0.7026 - val_auc: 0.7699\n",
      "Epoch 393/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5551 - accuracy: 0.6998 - auc: 0.7824 - val_loss: 0.5760 - val_accuracy: 0.7055 - val_auc: 0.7671\n",
      "Epoch 394/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5585 - accuracy: 0.6980 - auc: 0.7786 - val_loss: 0.5774 - val_accuracy: 0.6997 - val_auc: 0.7661\n",
      "Epoch 395/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5612 - accuracy: 0.7089 - auc: 0.7789 - val_loss: 0.5777 - val_accuracy: 0.6997 - val_auc: 0.7653\n",
      "Epoch 396/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5588 - accuracy: 0.7016 - auc: 0.7826 - val_loss: 0.5780 - val_accuracy: 0.6997 - val_auc: 0.7650\n",
      "Epoch 397/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5538 - accuracy: 0.7144 - auc: 0.7862 - val_loss: 0.5768 - val_accuracy: 0.7026 - val_auc: 0.7665\n",
      "Epoch 398/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5510 - accuracy: 0.7199 - auc: 0.7882 - val_loss: 0.5769 - val_accuracy: 0.6968 - val_auc: 0.7668\n",
      "Epoch 399/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5565 - accuracy: 0.7007 - auc: 0.7800 - val_loss: 0.5778 - val_accuracy: 0.7026 - val_auc: 0.7662\n",
      "Epoch 400/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5517 - accuracy: 0.7181 - auc: 0.7881 - val_loss: 0.5767 - val_accuracy: 0.6939 - val_auc: 0.7666\n",
      "Epoch 401/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5545 - accuracy: 0.7089 - auc: 0.7837 - val_loss: 0.5761 - val_accuracy: 0.6968 - val_auc: 0.7676\n",
      "Epoch 402/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5434 - accuracy: 0.7026 - auc: 0.7944 - val_loss: 0.5757 - val_accuracy: 0.6910 - val_auc: 0.7674\n",
      "Epoch 403/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5489 - accuracy: 0.7208 - auc: 0.7929 - val_loss: 0.5737 - val_accuracy: 0.6939 - val_auc: 0.7699\n",
      "Epoch 404/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5518 - accuracy: 0.7035 - auc: 0.7851 - val_loss: 0.5744 - val_accuracy: 0.6968 - val_auc: 0.7697\n",
      "Epoch 405/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5589 - accuracy: 0.7044 - auc: 0.7778 - val_loss: 0.5737 - val_accuracy: 0.6910 - val_auc: 0.7704\n",
      "Epoch 406/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5598 - accuracy: 0.6962 - auc: 0.7770 - val_loss: 0.5742 - val_accuracy: 0.6939 - val_auc: 0.7701\n",
      "Epoch 407/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5518 - accuracy: 0.6925 - auc: 0.7876 - val_loss: 0.5749 - val_accuracy: 0.6910 - val_auc: 0.7691\n",
      "Epoch 408/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5596 - accuracy: 0.7062 - auc: 0.7821 - val_loss: 0.5765 - val_accuracy: 0.6968 - val_auc: 0.7670\n",
      "Epoch 409/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5602 - accuracy: 0.6998 - auc: 0.7765 - val_loss: 0.5772 - val_accuracy: 0.6997 - val_auc: 0.7665\n",
      "Epoch 410/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5587 - accuracy: 0.7126 - auc: 0.7784 - val_loss: 0.5782 - val_accuracy: 0.7026 - val_auc: 0.7657\n",
      "Epoch 411/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5603 - accuracy: 0.6998 - auc: 0.7782 - val_loss: 0.5782 - val_accuracy: 0.7055 - val_auc: 0.7658\n",
      "Epoch 412/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5528 - accuracy: 0.6870 - auc: 0.7837 - val_loss: 0.5791 - val_accuracy: 0.6968 - val_auc: 0.7648\n",
      "Epoch 413/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5588 - accuracy: 0.6989 - auc: 0.7804 - val_loss: 0.5792 - val_accuracy: 0.6939 - val_auc: 0.7647\n",
      "Epoch 414/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5630 - accuracy: 0.6980 - auc: 0.7768 - val_loss: 0.5786 - val_accuracy: 0.6939 - val_auc: 0.7653\n",
      "Epoch 415/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5535 - accuracy: 0.6971 - auc: 0.7856 - val_loss: 0.5775 - val_accuracy: 0.6968 - val_auc: 0.7660\n",
      "Epoch 416/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5674 - accuracy: 0.6934 - auc: 0.7728 - val_loss: 0.5786 - val_accuracy: 0.6997 - val_auc: 0.7652\n",
      "Epoch 417/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5533 - accuracy: 0.7016 - auc: 0.7829 - val_loss: 0.5782 - val_accuracy: 0.7026 - val_auc: 0.7657\n",
      "Epoch 418/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5497 - accuracy: 0.7117 - auc: 0.7892 - val_loss: 0.5772 - val_accuracy: 0.6997 - val_auc: 0.7667\n",
      "Epoch 419/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5523 - accuracy: 0.7080 - auc: 0.7876 - val_loss: 0.5765 - val_accuracy: 0.6997 - val_auc: 0.7671\n",
      "Epoch 420/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5554 - accuracy: 0.7071 - auc: 0.7817 - val_loss: 0.5770 - val_accuracy: 0.7026 - val_auc: 0.7669\n",
      "Epoch 421/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5599 - accuracy: 0.7062 - auc: 0.7793 - val_loss: 0.5764 - val_accuracy: 0.6997 - val_auc: 0.7678\n",
      "Epoch 422/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5705 - accuracy: 0.6797 - auc: 0.7680 - val_loss: 0.5755 - val_accuracy: 0.6997 - val_auc: 0.7682\n",
      "Epoch 423/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5559 - accuracy: 0.7117 - auc: 0.7819 - val_loss: 0.5744 - val_accuracy: 0.6910 - val_auc: 0.7693\n",
      "Epoch 424/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5542 - accuracy: 0.7062 - auc: 0.7855 - val_loss: 0.5740 - val_accuracy: 0.6939 - val_auc: 0.7700\n",
      "Epoch 425/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5591 - accuracy: 0.6934 - auc: 0.7791 - val_loss: 0.5742 - val_accuracy: 0.6939 - val_auc: 0.7701\n",
      "Epoch 426/700\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5620 - accuracy: 0.6989 - auc: 0.7770 - val_loss: 0.5768 - val_accuracy: 0.6997 - val_auc: 0.7669\n",
      "Epoch 427/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5549 - accuracy: 0.7062 - auc: 0.7849 - val_loss: 0.5762 - val_accuracy: 0.6968 - val_auc: 0.7679\n",
      "Epoch 428/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5496 - accuracy: 0.7162 - auc: 0.7878 - val_loss: 0.5769 - val_accuracy: 0.6968 - val_auc: 0.7670\n",
      "Epoch 429/700\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.5567 - accuracy: 0.7071 - auc: 0.7803 - val_loss: 0.5731 - val_accuracy: 0.6939 - val_auc: 0.7710\n",
      "Epoch 430/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5575 - accuracy: 0.7016 - auc: 0.7793 - val_loss: 0.5734 - val_accuracy: 0.6939 - val_auc: 0.7707\n",
      "Epoch 431/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5533 - accuracy: 0.6980 - auc: 0.7840 - val_loss: 0.5730 - val_accuracy: 0.6968 - val_auc: 0.7710\n",
      "Epoch 432/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5486 - accuracy: 0.7153 - auc: 0.7932 - val_loss: 0.5729 - val_accuracy: 0.6968 - val_auc: 0.7710\n",
      "Epoch 433/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5590 - accuracy: 0.6971 - auc: 0.7783 - val_loss: 0.5738 - val_accuracy: 0.6939 - val_auc: 0.7699\n",
      "Epoch 434/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5532 - accuracy: 0.7089 - auc: 0.7831 - val_loss: 0.5746 - val_accuracy: 0.6910 - val_auc: 0.7692\n",
      "Epoch 435/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5490 - accuracy: 0.7217 - auc: 0.7899 - val_loss: 0.5746 - val_accuracy: 0.6997 - val_auc: 0.7695\n",
      "Epoch 436/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5577 - accuracy: 0.7108 - auc: 0.7825 - val_loss: 0.5736 - val_accuracy: 0.6968 - val_auc: 0.7701\n",
      "Epoch 437/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5533 - accuracy: 0.7044 - auc: 0.7881 - val_loss: 0.5728 - val_accuracy: 0.6939 - val_auc: 0.7710\n",
      "Epoch 438/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5538 - accuracy: 0.7172 - auc: 0.7846 - val_loss: 0.5734 - val_accuracy: 0.7026 - val_auc: 0.7700\n",
      "Epoch 439/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5555 - accuracy: 0.7117 - auc: 0.7868 - val_loss: 0.5733 - val_accuracy: 0.7055 - val_auc: 0.7707\n",
      "Epoch 440/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5592 - accuracy: 0.6998 - auc: 0.7785 - val_loss: 0.5736 - val_accuracy: 0.7055 - val_auc: 0.7704\n",
      "Epoch 441/700\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5528 - accuracy: 0.7089 - auc: 0.7872 - val_loss: 0.5724 - val_accuracy: 0.6997 - val_auc: 0.7717\n",
      "Epoch 442/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5543 - accuracy: 0.7080 - auc: 0.7847 - val_loss: 0.5729 - val_accuracy: 0.6997 - val_auc: 0.7710\n",
      "Epoch 443/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5582 - accuracy: 0.7044 - auc: 0.7784 - val_loss: 0.5715 - val_accuracy: 0.6910 - val_auc: 0.7722\n",
      "Epoch 444/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5511 - accuracy: 0.7035 - auc: 0.7874 - val_loss: 0.5725 - val_accuracy: 0.7026 - val_auc: 0.7715\n",
      "Epoch 445/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5566 - accuracy: 0.6971 - auc: 0.7812 - val_loss: 0.5728 - val_accuracy: 0.6997 - val_auc: 0.7716\n",
      "Epoch 446/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5624 - accuracy: 0.6916 - auc: 0.7732 - val_loss: 0.5727 - val_accuracy: 0.7055 - val_auc: 0.7713\n",
      "Epoch 447/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5586 - accuracy: 0.7035 - auc: 0.7803 - val_loss: 0.5723 - val_accuracy: 0.7055 - val_auc: 0.7715\n",
      "Epoch 448/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5551 - accuracy: 0.7035 - auc: 0.7849 - val_loss: 0.5735 - val_accuracy: 0.7085 - val_auc: 0.7704\n",
      "Epoch 449/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5579 - accuracy: 0.7026 - auc: 0.7817 - val_loss: 0.5744 - val_accuracy: 0.7026 - val_auc: 0.7697\n",
      "Epoch 450/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5568 - accuracy: 0.7016 - auc: 0.7808 - val_loss: 0.5757 - val_accuracy: 0.7026 - val_auc: 0.7680\n",
      "Epoch 451/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5507 - accuracy: 0.7035 - auc: 0.7862 - val_loss: 0.5745 - val_accuracy: 0.6968 - val_auc: 0.7695\n",
      "Epoch 452/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5534 - accuracy: 0.7263 - auc: 0.7893 - val_loss: 0.5732 - val_accuracy: 0.6997 - val_auc: 0.7707\n",
      "Epoch 453/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5535 - accuracy: 0.6934 - auc: 0.7836 - val_loss: 0.5732 - val_accuracy: 0.6997 - val_auc: 0.7710\n",
      "Epoch 454/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5617 - accuracy: 0.7053 - auc: 0.7785 - val_loss: 0.5735 - val_accuracy: 0.7055 - val_auc: 0.7704\n",
      "Epoch 455/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5478 - accuracy: 0.7135 - auc: 0.7929 - val_loss: 0.5723 - val_accuracy: 0.7026 - val_auc: 0.7726\n",
      "Epoch 456/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5550 - accuracy: 0.7007 - auc: 0.7813 - val_loss: 0.5742 - val_accuracy: 0.7055 - val_auc: 0.7706\n",
      "Epoch 457/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5562 - accuracy: 0.7007 - auc: 0.7821 - val_loss: 0.5742 - val_accuracy: 0.7055 - val_auc: 0.7706\n",
      "Epoch 458/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5500 - accuracy: 0.7153 - auc: 0.7906 - val_loss: 0.5726 - val_accuracy: 0.6997 - val_auc: 0.7715\n",
      "Epoch 459/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5565 - accuracy: 0.7053 - auc: 0.7818 - val_loss: 0.5731 - val_accuracy: 0.6968 - val_auc: 0.7710\n",
      "Epoch 460/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5474 - accuracy: 0.7144 - auc: 0.7899 - val_loss: 0.5726 - val_accuracy: 0.6997 - val_auc: 0.7721\n",
      "Epoch 461/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5487 - accuracy: 0.7226 - auc: 0.7937 - val_loss: 0.5725 - val_accuracy: 0.6997 - val_auc: 0.7716\n",
      "Epoch 462/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5487 - accuracy: 0.7062 - auc: 0.7884 - val_loss: 0.5725 - val_accuracy: 0.6997 - val_auc: 0.7717\n",
      "Epoch 463/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5503 - accuracy: 0.7172 - auc: 0.7890 - val_loss: 0.5726 - val_accuracy: 0.6997 - val_auc: 0.7720\n",
      "Epoch 464/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5558 - accuracy: 0.6889 - auc: 0.7819 - val_loss: 0.5730 - val_accuracy: 0.6997 - val_auc: 0.7712\n",
      "Epoch 465/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5481 - accuracy: 0.7126 - auc: 0.7892 - val_loss: 0.5714 - val_accuracy: 0.7026 - val_auc: 0.7729\n",
      "Epoch 466/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5453 - accuracy: 0.7190 - auc: 0.7939 - val_loss: 0.5718 - val_accuracy: 0.6968 - val_auc: 0.7729\n",
      "Epoch 467/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5437 - accuracy: 0.7281 - auc: 0.7943 - val_loss: 0.5712 - val_accuracy: 0.7026 - val_auc: 0.7736\n",
      "Epoch 468/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5525 - accuracy: 0.7044 - auc: 0.7880 - val_loss: 0.5721 - val_accuracy: 0.7026 - val_auc: 0.7727\n",
      "Epoch 469/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5504 - accuracy: 0.7062 - auc: 0.7873 - val_loss: 0.5723 - val_accuracy: 0.7026 - val_auc: 0.7724\n",
      "Epoch 470/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5517 - accuracy: 0.6989 - auc: 0.7849 - val_loss: 0.5715 - val_accuracy: 0.6997 - val_auc: 0.7733\n",
      "Epoch 471/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5488 - accuracy: 0.7062 - auc: 0.7919 - val_loss: 0.5726 - val_accuracy: 0.6997 - val_auc: 0.7717\n",
      "Epoch 472/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5484 - accuracy: 0.7035 - auc: 0.7888 - val_loss: 0.5725 - val_accuracy: 0.6997 - val_auc: 0.7719\n",
      "Epoch 473/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5583 - accuracy: 0.6998 - auc: 0.7787 - val_loss: 0.5729 - val_accuracy: 0.7026 - val_auc: 0.7712\n",
      "Epoch 474/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5556 - accuracy: 0.7190 - auc: 0.7846 - val_loss: 0.5722 - val_accuracy: 0.7055 - val_auc: 0.7722\n",
      "Epoch 475/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5516 - accuracy: 0.7089 - auc: 0.7850 - val_loss: 0.5713 - val_accuracy: 0.7026 - val_auc: 0.7730\n",
      "Epoch 476/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5558 - accuracy: 0.7035 - auc: 0.7842 - val_loss: 0.5709 - val_accuracy: 0.6997 - val_auc: 0.7740\n",
      "Epoch 477/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5497 - accuracy: 0.7108 - auc: 0.7896 - val_loss: 0.5699 - val_accuracy: 0.7026 - val_auc: 0.7740\n",
      "Epoch 478/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5434 - accuracy: 0.7108 - auc: 0.7943 - val_loss: 0.5700 - val_accuracy: 0.7055 - val_auc: 0.7735\n",
      "Epoch 479/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5468 - accuracy: 0.7089 - auc: 0.7915 - val_loss: 0.5703 - val_accuracy: 0.7055 - val_auc: 0.7739\n",
      "Epoch 480/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5522 - accuracy: 0.6962 - auc: 0.7846 - val_loss: 0.5715 - val_accuracy: 0.7026 - val_auc: 0.7730\n",
      "Epoch 481/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5471 - accuracy: 0.7080 - auc: 0.7910 - val_loss: 0.5713 - val_accuracy: 0.6939 - val_auc: 0.7729\n",
      "Epoch 482/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5532 - accuracy: 0.7117 - auc: 0.7865 - val_loss: 0.5718 - val_accuracy: 0.6997 - val_auc: 0.7728\n",
      "Epoch 483/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5540 - accuracy: 0.6971 - auc: 0.7832 - val_loss: 0.5723 - val_accuracy: 0.6968 - val_auc: 0.7720\n",
      "Epoch 484/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5482 - accuracy: 0.7172 - auc: 0.7882 - val_loss: 0.5730 - val_accuracy: 0.6968 - val_auc: 0.7713\n",
      "Epoch 485/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5540 - accuracy: 0.6989 - auc: 0.7855 - val_loss: 0.5731 - val_accuracy: 0.7026 - val_auc: 0.7718\n",
      "Epoch 486/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5445 - accuracy: 0.7190 - auc: 0.7938 - val_loss: 0.5718 - val_accuracy: 0.6997 - val_auc: 0.7723\n",
      "Epoch 487/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5606 - accuracy: 0.6980 - auc: 0.7765 - val_loss: 0.5714 - val_accuracy: 0.7026 - val_auc: 0.7728\n",
      "Epoch 488/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5520 - accuracy: 0.7135 - auc: 0.7886 - val_loss: 0.5717 - val_accuracy: 0.7026 - val_auc: 0.7727\n",
      "Epoch 489/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5544 - accuracy: 0.7099 - auc: 0.7854 - val_loss: 0.5720 - val_accuracy: 0.7026 - val_auc: 0.7724\n",
      "Epoch 490/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5538 - accuracy: 0.7153 - auc: 0.7843 - val_loss: 0.5712 - val_accuracy: 0.7026 - val_auc: 0.7733\n",
      "Epoch 491/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5427 - accuracy: 0.7345 - auc: 0.7982 - val_loss: 0.5714 - val_accuracy: 0.6997 - val_auc: 0.7730\n",
      "Epoch 492/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5445 - accuracy: 0.7089 - auc: 0.7940 - val_loss: 0.5721 - val_accuracy: 0.6997 - val_auc: 0.7725\n",
      "Epoch 493/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5553 - accuracy: 0.6971 - auc: 0.7827 - val_loss: 0.5708 - val_accuracy: 0.6997 - val_auc: 0.7741\n",
      "Epoch 494/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5495 - accuracy: 0.7053 - auc: 0.7899 - val_loss: 0.5709 - val_accuracy: 0.6997 - val_auc: 0.7734\n",
      "Epoch 495/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5487 - accuracy: 0.6907 - auc: 0.7874 - val_loss: 0.5693 - val_accuracy: 0.7026 - val_auc: 0.7753\n",
      "Epoch 496/700\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.5567 - accuracy: 0.6989 - auc: 0.7797 - val_loss: 0.5678 - val_accuracy: 0.7026 - val_auc: 0.7763\n",
      "Epoch 497/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5540 - accuracy: 0.7035 - auc: 0.7846 - val_loss: 0.5667 - val_accuracy: 0.6997 - val_auc: 0.7776\n",
      "Epoch 498/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5390 - accuracy: 0.7199 - auc: 0.8015 - val_loss: 0.5663 - val_accuracy: 0.6968 - val_auc: 0.7783\n",
      "Epoch 499/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5575 - accuracy: 0.7153 - auc: 0.7831 - val_loss: 0.5680 - val_accuracy: 0.6997 - val_auc: 0.7768\n",
      "Epoch 500/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5467 - accuracy: 0.7026 - auc: 0.7903 - val_loss: 0.5687 - val_accuracy: 0.6910 - val_auc: 0.7757\n",
      "Epoch 501/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5490 - accuracy: 0.7053 - auc: 0.7875 - val_loss: 0.5699 - val_accuracy: 0.6939 - val_auc: 0.7746\n",
      "Epoch 502/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5585 - accuracy: 0.7080 - auc: 0.7795 - val_loss: 0.5702 - val_accuracy: 0.6997 - val_auc: 0.7741\n",
      "Epoch 503/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5434 - accuracy: 0.7144 - auc: 0.7953 - val_loss: 0.5697 - val_accuracy: 0.6997 - val_auc: 0.7747\n",
      "Epoch 504/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5552 - accuracy: 0.7062 - auc: 0.7818 - val_loss: 0.5699 - val_accuracy: 0.7026 - val_auc: 0.7746\n",
      "Epoch 505/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5599 - accuracy: 0.6907 - auc: 0.7780 - val_loss: 0.5719 - val_accuracy: 0.7085 - val_auc: 0.7726\n",
      "Epoch 506/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5441 - accuracy: 0.7071 - auc: 0.7930 - val_loss: 0.5725 - val_accuracy: 0.7026 - val_auc: 0.7724\n",
      "Epoch 507/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5438 - accuracy: 0.7181 - auc: 0.7952 - val_loss: 0.5722 - val_accuracy: 0.6997 - val_auc: 0.7730\n",
      "Epoch 508/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5552 - accuracy: 0.7071 - auc: 0.7839 - val_loss: 0.5724 - val_accuracy: 0.7026 - val_auc: 0.7727\n",
      "Epoch 509/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5458 - accuracy: 0.7007 - auc: 0.7916 - val_loss: 0.5697 - val_accuracy: 0.6997 - val_auc: 0.7748\n",
      "Epoch 510/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5522 - accuracy: 0.7035 - auc: 0.7864 - val_loss: 0.5704 - val_accuracy: 0.6968 - val_auc: 0.7744\n",
      "Epoch 511/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5550 - accuracy: 0.7071 - auc: 0.7827 - val_loss: 0.5721 - val_accuracy: 0.7055 - val_auc: 0.7730\n",
      "Epoch 512/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5557 - accuracy: 0.7062 - auc: 0.7819 - val_loss: 0.5725 - val_accuracy: 0.7026 - val_auc: 0.7727\n",
      "Epoch 513/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5382 - accuracy: 0.7172 - auc: 0.8017 - val_loss: 0.5716 - val_accuracy: 0.7055 - val_auc: 0.7734\n",
      "Epoch 514/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5527 - accuracy: 0.6962 - auc: 0.7870 - val_loss: 0.5709 - val_accuracy: 0.7026 - val_auc: 0.7741\n",
      "Epoch 515/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5416 - accuracy: 0.7016 - auc: 0.7951 - val_loss: 0.5697 - val_accuracy: 0.7055 - val_auc: 0.7751\n",
      "Epoch 516/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5528 - accuracy: 0.6943 - auc: 0.7827 - val_loss: 0.5696 - val_accuracy: 0.6997 - val_auc: 0.7756\n",
      "Epoch 517/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5512 - accuracy: 0.6980 - auc: 0.7853 - val_loss: 0.5698 - val_accuracy: 0.7026 - val_auc: 0.7751\n",
      "Epoch 518/700\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.5462 - accuracy: 0.7126 - auc: 0.7916 - val_loss: 0.5686 - val_accuracy: 0.6997 - val_auc: 0.7760\n",
      "Epoch 519/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5490 - accuracy: 0.7099 - auc: 0.7883 - val_loss: 0.5712 - val_accuracy: 0.7026 - val_auc: 0.7736\n",
      "Epoch 520/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5475 - accuracy: 0.7126 - auc: 0.7898 - val_loss: 0.5700 - val_accuracy: 0.7026 - val_auc: 0.7746\n",
      "Epoch 521/700\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5525 - accuracy: 0.7135 - auc: 0.7897 - val_loss: 0.5697 - val_accuracy: 0.6968 - val_auc: 0.7751\n",
      "Epoch 522/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5561 - accuracy: 0.7044 - auc: 0.7844 - val_loss: 0.5697 - val_accuracy: 0.6997 - val_auc: 0.7749\n",
      "Epoch 523/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5537 - accuracy: 0.7089 - auc: 0.7872 - val_loss: 0.5707 - val_accuracy: 0.6968 - val_auc: 0.7740\n",
      "Epoch 524/700\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.5479 - accuracy: 0.7144 - auc: 0.7927 - val_loss: 0.5705 - val_accuracy: 0.6968 - val_auc: 0.7746\n",
      "Epoch 525/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5466 - accuracy: 0.7117 - auc: 0.7902 - val_loss: 0.5709 - val_accuracy: 0.7026 - val_auc: 0.7742\n",
      "Epoch 526/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5388 - accuracy: 0.7108 - auc: 0.8016 - val_loss: 0.5704 - val_accuracy: 0.6997 - val_auc: 0.7745\n",
      "Epoch 527/700\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.5520 - accuracy: 0.7053 - auc: 0.7885 - val_loss: 0.5703 - val_accuracy: 0.7026 - val_auc: 0.7746\n",
      "Epoch 528/700\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5431 - accuracy: 0.7226 - auc: 0.7967 - val_loss: 0.5712 - val_accuracy: 0.7026 - val_auc: 0.7739\n",
      "Epoch 00528: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('happy_ravdess.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1596112127942,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ddcJYxjpRmou"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('happy_ravdess.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1596112137847,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "w4snlhBmRqz8"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_predictions_baseline = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1596112148253,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1024,
     "status": "ok",
     "timestamp": 1596112180857,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "a18ca646-8b73-435e-f366-ccf26cbed507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5662789344787598\n",
      "accuracy :  0.6967930197715759\n",
      "auc :  0.7782514095306396\n",
      "\n",
      "(True Negatives):  143\n",
      "(False Positives):  72\n",
      "(False Negatives):  32\n",
      "(True Positives):  96\n",
      "Total emotions_happy:  128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.73       215\n",
      "           1       0.57      0.75      0.65       128\n",
      "\n",
      "    accuracy                           0.70       343\n",
      "   macro avg       0.69      0.71      0.69       343\n",
      "weighted avg       0.73      0.70      0.70       343\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1596112292258,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "GJk2L3O8ImIn"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1596112305377,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "5c079e2e-f1ce-42da-aca6-89f70c4bc646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5499629974365234\n",
      "accuracy :  0.6788321137428284\n",
      "auc :  0.7899861335754395\n",
      "\n",
      "(True Negatives):  112\n",
      "(False Positives):  64\n",
      "(False Negatives):  24\n",
      "(True Positives):  74\n",
      "Total emotions_happy:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72       176\n",
      "           1       0.54      0.76      0.63        98\n",
      "\n",
      "    accuracy                           0.68       274\n",
      "   macro avg       0.68      0.70      0.67       274\n",
      "weighted avg       0.72      0.68      0.69       274\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOYhLQTcUIQKysadcKVCKUb",
   "name": "deep_happy_RAVDESS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
