{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7266,
     "status": "ok",
     "timestamp": 1596113189677,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ymHSlukhKIF9",
    "outputId": "3c507808-19aa-4560-e097-a8f6b4e3f0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.7.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 3.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (2.1.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.18.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.16.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (4.4.2)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.15.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.48.0)\n",
      "Collecting soundfile>=0.9.0\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (49.1.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.14.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)\n",
      "Building wheels for collected packages: librosa\n",
      "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for librosa: filename=librosa-0.7.2-cp36-none-any.whl size=1612885 sha256=d53221d17c79209f41c1c40b80ea98e025c2c9b9c07ba49ae2c3bdf64b4a15a5\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/6e/d7/bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
      "Successfully built librosa\n",
      "Installing collected packages: soundfile, librosa\n",
      "  Found existing installation: librosa 0.6.3\n",
      "    Uninstalling librosa-0.6.3:\n",
      "      Successfully uninstalled librosa-0.6.3\n",
      "Successfully installed librosa-0.7.2 soundfile-0.10.3.post1\n"
     ]
    }
   ],
   "source": [
    "pip install librosa==0.7.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10002,
     "status": "ok",
     "timestamp": 1596026935548,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "sXnDmXR7RDr2",
    "outputId": "3b9dff36-3699-413b-8a0a-75f3af305685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10711,
     "status": "ok",
     "timestamp": 1596026954464,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Y04m-jvKRDsJ",
    "outputId": "ce46bb70-bae2-4985-8f6b-ee3fece0cc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
      "CPU (s):\n",
      "2.876127255\n",
      "GPU (s):\n",
      "0.1083209219999901\n",
      "GPU speedup over CPU: 26x\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 51159,
     "status": "ok",
     "timestamp": 1596113292803,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l9EbbgJpzQDD",
    "outputId": "3108603a-a713-433f-8253-11c1b867f66d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5051,
     "status": "ok",
     "timestamp": 1596113316545,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ltf4WKPCeyVR",
    "outputId": "cec6a25d-5cfd-4e53-b68e-517c5502589d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praat-parselmouth\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7b/9fa1172a63b6277603d27bb5613559b5a8888f58e68c1698017b87b0061d/praat_parselmouth-0.3.3-cp36-cp36m-manylinux1_x86_64.whl (9.0MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0MB 3.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from praat-parselmouth) (1.18.5)\n",
      "Installing collected packages: praat-parselmouth\n",
      "Successfully installed praat-parselmouth-0.3.3\n"
     ]
    }
   ],
   "source": [
    "pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5468,
     "status": "ok",
     "timestamp": 1596113333949,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PNwtWyMXe_Qb",
    "outputId": "0fa51deb-8f8b-40e4-f589-8c62f235f9a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting essentia\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/cf/3c776d02b63fed7b0958bef2ce57b900870e2ac3f1fd8ffbb63f22d0e69e/essentia-2.1b6.dev234-cp36-cp36m-manylinux1_x86_64.whl (11.7MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7MB 3.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from essentia) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from essentia) (3.13)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from essentia) (1.15.0)\n",
      "Installing collected packages: essentia\n",
      "Successfully installed essentia-2.1b6.dev234\n"
     ]
    }
   ],
   "source": [
    "pip install essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5957,
     "status": "ok",
     "timestamp": 1596113358645,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "B9TmOS9AFg61",
    "outputId": "bc17996d-59d8-4c38-ab6b-c4e892bddecc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "#Spafe for audio\n",
    "#import spafe\n",
    "import scipy.io.wavfile\n",
    "#import spafe.utils.vis as vis\n",
    "#from spafe.features.mfcc import mfcc, imfcc\n",
    "#from spafe.features.gfcc import gfcc\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1596113385574,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "QAD42F-CgYli",
    "outputId": "a5bb4814-12e9-4232-d269-5a9972366f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "cd drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9043,
     "status": "ok",
     "timestamp": 1596113416556,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "5018098b-5530-404f-979b-63f5d495ac08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disgust/03-01-07-01-01-01-23_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral/03-01-01-01-02-02-19_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry/03-01-05-02-02-02-11_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy/03-01-03-02-02-02-19_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust/03-01-07-02-02-01-13_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            audio label\n",
       "0  disgust/03-01-07-01-01-01-23_norm_outNoise.wav     0\n",
       "1  neutral/03-01-01-01-02-02-19_norm_outNoise.wav     0\n",
       "2    angry/03-01-05-02-02-02-11_norm_outNoise.wav     0\n",
       "3    happy/03-01-03-02-02-02-19_norm_outNoise.wav     0\n",
       "4  disgust/03-01-07-02-02-01-13_norm_outNoise.wav     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"audio_emotion\"\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i[7] == '4':\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) # here at df defined, with the columns we add the values:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1596113539304,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "f64086df-4e4c-4cf8-ef1a-2425342462fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1056\n",
      "1     189\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1596113589935,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1596113635669,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "AjNAMwsfG2C8"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    fs, sig = scipy.io.wavfile.read(audio_path) \n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    spec =  fram_window(audio_path) \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)\n",
    "            \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "               \n",
    "    #gfccs = gfcc(sig= spec, fs=fs, num_ceps=13)    \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    #features.append(np.mean(gfccs))\n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2661413,
     "status": "ok",
     "timestamp": 1596116342347,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "folder ='audio_emotion'\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(folder+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1596116584862,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "5f3d23f9-3e8f-4693-902a-82ab0051d6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1596116606269,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1596116626256,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1596116649396,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "6b2af874-27a6-4b11-9a69-6d23eca733ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 632\n",
      "After OverSampling, counts of label '0': 1056\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \" [1, 2, 3, 4, 7, 8, 13, 15, 16, 17]   \" are deleted 838 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25619,
     "status": "ok",
     "timestamp": 1596116737394,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "8e82262f-66b1-4dfc-9730-4cf799323c91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4, 7, 8, 13, 15, 16, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3, 4, 7, 8, 13, 15, 16, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2, 3, 4, 7, 13, 15, 16, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 3, 4, 7, 8, 13, 15, 16, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 2, 3, 4, 7, 8, 13, 15, 16, 17]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration                           X_removed\n",
       "0         1  [1, 2, 3, 4, 7, 8, 13, 15, 16, 17]\n",
       "1         2  [1, 2, 3, 4, 7, 8, 13, 15, 16, 17]\n",
       "2         3     [1, 2, 3, 4, 7, 13, 15, 16, 17]\n",
       "3         4  [1, 2, 3, 4, 7, 8, 13, 15, 16, 17]\n",
       "4         5  [1, 2, 3, 4, 7, 8, 13, 15, 16, 17]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 7, 8, 13, 15, 16, 17]    838\n",
       "[1, 2, 3, 4, 7, 13, 15, 16, 17]       161\n",
       "[1, 2, 3, 4, 7, 8, 13, 16]              1\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1596116856001,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6sTQj5wDWdev"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0],  X[i][5], X[i][6], X[i][9], X[i][10],\n",
    "               X[i][11], X[i][12], X[i][14], \n",
    "                X[i][18], X[i][19], X[i][20], X[i][21]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1596117020903,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "9542403d-648c-4681-9e48-43b0bfa09cea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "338\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2238,
     "status": "ok",
     "timestamp": 1596117046313,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "TWis1PUVfK_4",
    "outputId": "0803f94b-14e0-45c5-c8eb-61173cc9a334"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Plot imports ###\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "### Warning ###\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1596117438143,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1596117448516,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "314d74de-225d-4dff-d6cd-7ecbbc2283dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 12, 1)\n",
      "(338, 12, 1)\n",
      "(270, 12, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1596117469644,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "bf9b506c-4ee3-4207-f109-3e444ff5618b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 2)\n",
      "(338, 2)\n",
      "(270, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 442,
     "status": "ok",
     "timestamp": 1596117669879,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (12,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "ok",
     "timestamp": 1596117682381,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "36432c70-b72a-4ee8-93a4-60a2e9cc53fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 12, 1)]           0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 12, 128)           768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 12, 128)           512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 12, 128)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 12, 128)           0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 12, 128)           82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 3074      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 86,410\n",
      "Trainable params: 86,150\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## First LFLB (local feature learning block)\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1596117693860,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 221586,
     "status": "ok",
     "timestamp": 1596117943530,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "4d956e4b-6945-47f8-e41d-ee555bec7af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.7809 - accuracy: 0.5667 - auc: 0.6065 - val_loss: 0.6664 - val_accuracy: 0.5828 - val_auc: 0.6328\n",
      "Epoch 2/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.7450 - accuracy: 0.5787 - auc: 0.6305 - val_loss: 0.6558 - val_accuracy: 0.6065 - val_auc: 0.6660\n",
      "Epoch 3/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.7492 - accuracy: 0.5759 - auc: 0.6292 - val_loss: 0.6484 - val_accuracy: 0.6361 - val_auc: 0.6857\n",
      "Epoch 4/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6994 - accuracy: 0.6074 - auc: 0.6622 - val_loss: 0.6428 - val_accuracy: 0.6450 - val_auc: 0.7006\n",
      "Epoch 5/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6789 - accuracy: 0.6241 - auc: 0.6711 - val_loss: 0.6378 - val_accuracy: 0.6479 - val_auc: 0.7133\n",
      "Epoch 6/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6732 - accuracy: 0.6083 - auc: 0.6694 - val_loss: 0.6340 - val_accuracy: 0.6509 - val_auc: 0.7214\n",
      "Epoch 7/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6548 - accuracy: 0.6315 - auc: 0.6868 - val_loss: 0.6314 - val_accuracy: 0.6627 - val_auc: 0.7237\n",
      "Epoch 8/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6593 - accuracy: 0.6157 - auc: 0.6764 - val_loss: 0.6295 - val_accuracy: 0.6716 - val_auc: 0.7265\n",
      "Epoch 9/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.6428 - accuracy: 0.6324 - auc: 0.6909 - val_loss: 0.6265 - val_accuracy: 0.6657 - val_auc: 0.7296\n",
      "Epoch 10/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6442 - accuracy: 0.6352 - auc: 0.6877 - val_loss: 0.6253 - val_accuracy: 0.6598 - val_auc: 0.7301\n",
      "Epoch 11/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6370 - accuracy: 0.6370 - auc: 0.6941 - val_loss: 0.6240 - val_accuracy: 0.6657 - val_auc: 0.7304\n",
      "Epoch 12/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6176 - accuracy: 0.6537 - auc: 0.7159 - val_loss: 0.6216 - val_accuracy: 0.6598 - val_auc: 0.7326\n",
      "Epoch 13/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6238 - accuracy: 0.6704 - auc: 0.7145 - val_loss: 0.6198 - val_accuracy: 0.6657 - val_auc: 0.7331\n",
      "Epoch 14/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6338 - accuracy: 0.6407 - auc: 0.6979 - val_loss: 0.6187 - val_accuracy: 0.6657 - val_auc: 0.7316\n",
      "Epoch 15/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6307 - accuracy: 0.6380 - auc: 0.7022 - val_loss: 0.6174 - val_accuracy: 0.6775 - val_auc: 0.7300\n",
      "Epoch 16/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6282 - accuracy: 0.6556 - auc: 0.7054 - val_loss: 0.6158 - val_accuracy: 0.6716 - val_auc: 0.7306\n",
      "Epoch 17/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6324 - accuracy: 0.6481 - auc: 0.7085 - val_loss: 0.6152 - val_accuracy: 0.6686 - val_auc: 0.7288\n",
      "Epoch 18/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6240 - accuracy: 0.6491 - auc: 0.7106 - val_loss: 0.6148 - val_accuracy: 0.6657 - val_auc: 0.7275\n",
      "Epoch 19/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6096 - accuracy: 0.6694 - auc: 0.7276 - val_loss: 0.6138 - val_accuracy: 0.6627 - val_auc: 0.7267\n",
      "Epoch 20/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6221 - accuracy: 0.6593 - auc: 0.7162 - val_loss: 0.6133 - val_accuracy: 0.6568 - val_auc: 0.7261\n",
      "Epoch 21/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.6274 - accuracy: 0.6583 - auc: 0.7092 - val_loss: 0.6128 - val_accuracy: 0.6538 - val_auc: 0.7251\n",
      "Epoch 22/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6211 - accuracy: 0.6630 - auc: 0.7170 - val_loss: 0.6115 - val_accuracy: 0.6568 - val_auc: 0.7250\n",
      "Epoch 23/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6191 - accuracy: 0.6583 - auc: 0.7195 - val_loss: 0.6114 - val_accuracy: 0.6509 - val_auc: 0.7250\n",
      "Epoch 24/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6056 - accuracy: 0.6824 - auc: 0.7369 - val_loss: 0.6106 - val_accuracy: 0.6627 - val_auc: 0.7264\n",
      "Epoch 25/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6273 - accuracy: 0.6463 - auc: 0.7059 - val_loss: 0.6108 - val_accuracy: 0.6686 - val_auc: 0.7247\n",
      "Epoch 26/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6100 - accuracy: 0.6759 - auc: 0.7295 - val_loss: 0.6107 - val_accuracy: 0.6686 - val_auc: 0.7240\n",
      "Epoch 27/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6212 - accuracy: 0.6546 - auc: 0.7132 - val_loss: 0.6105 - val_accuracy: 0.6598 - val_auc: 0.7237\n",
      "Epoch 28/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6195 - accuracy: 0.6491 - auc: 0.7191 - val_loss: 0.6107 - val_accuracy: 0.6568 - val_auc: 0.7232\n",
      "Epoch 29/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6157 - accuracy: 0.6667 - auc: 0.7222 - val_loss: 0.6103 - val_accuracy: 0.6479 - val_auc: 0.7226\n",
      "Epoch 30/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6173 - accuracy: 0.6593 - auc: 0.7194 - val_loss: 0.6106 - val_accuracy: 0.6450 - val_auc: 0.7222\n",
      "Epoch 31/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6169 - accuracy: 0.6694 - auc: 0.7240 - val_loss: 0.6106 - val_accuracy: 0.6450 - val_auc: 0.7221\n",
      "Epoch 32/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6110 - accuracy: 0.6620 - auc: 0.7287 - val_loss: 0.6101 - val_accuracy: 0.6479 - val_auc: 0.7222\n",
      "Epoch 33/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.6203 - accuracy: 0.6537 - auc: 0.7145 - val_loss: 0.6100 - val_accuracy: 0.6420 - val_auc: 0.7231\n",
      "Epoch 34/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6114 - accuracy: 0.6685 - auc: 0.7296 - val_loss: 0.6094 - val_accuracy: 0.6450 - val_auc: 0.7231\n",
      "Epoch 35/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6139 - accuracy: 0.6667 - auc: 0.7229 - val_loss: 0.6096 - val_accuracy: 0.6450 - val_auc: 0.7228\n",
      "Epoch 36/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6127 - accuracy: 0.6593 - auc: 0.7264 - val_loss: 0.6092 - val_accuracy: 0.6509 - val_auc: 0.7246\n",
      "Epoch 37/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6215 - accuracy: 0.6593 - auc: 0.7145 - val_loss: 0.6091 - val_accuracy: 0.6509 - val_auc: 0.7248\n",
      "Epoch 38/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6146 - accuracy: 0.6639 - auc: 0.7253 - val_loss: 0.6092 - val_accuracy: 0.6479 - val_auc: 0.7249\n",
      "Epoch 39/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6059 - accuracy: 0.6750 - auc: 0.7355 - val_loss: 0.6093 - val_accuracy: 0.6479 - val_auc: 0.7256\n",
      "Epoch 40/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6139 - accuracy: 0.6667 - auc: 0.7264 - val_loss: 0.6090 - val_accuracy: 0.6479 - val_auc: 0.7257\n",
      "Epoch 41/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6036 - accuracy: 0.6648 - auc: 0.7381 - val_loss: 0.6091 - val_accuracy: 0.6479 - val_auc: 0.7257\n",
      "Epoch 42/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6102 - accuracy: 0.6676 - auc: 0.7259 - val_loss: 0.6088 - val_accuracy: 0.6479 - val_auc: 0.7259\n",
      "Epoch 43/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6077 - accuracy: 0.6759 - auc: 0.7338 - val_loss: 0.6095 - val_accuracy: 0.6538 - val_auc: 0.7265\n",
      "Epoch 44/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6066 - accuracy: 0.6750 - auc: 0.7323 - val_loss: 0.6093 - val_accuracy: 0.6568 - val_auc: 0.7264\n",
      "Epoch 45/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6116 - accuracy: 0.6583 - auc: 0.7260 - val_loss: 0.6084 - val_accuracy: 0.6479 - val_auc: 0.7271\n",
      "Epoch 46/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6026 - accuracy: 0.6685 - auc: 0.7387 - val_loss: 0.6079 - val_accuracy: 0.6509 - val_auc: 0.7273\n",
      "Epoch 47/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6038 - accuracy: 0.6796 - auc: 0.7382 - val_loss: 0.6078 - val_accuracy: 0.6479 - val_auc: 0.7272\n",
      "Epoch 48/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6148 - accuracy: 0.6722 - auc: 0.7286 - val_loss: 0.6077 - val_accuracy: 0.6479 - val_auc: 0.7277\n",
      "Epoch 49/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6116 - accuracy: 0.6870 - auc: 0.7302 - val_loss: 0.6070 - val_accuracy: 0.6509 - val_auc: 0.7280\n",
      "Epoch 50/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6046 - accuracy: 0.6667 - auc: 0.7359 - val_loss: 0.6069 - val_accuracy: 0.6509 - val_auc: 0.7282\n",
      "Epoch 51/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6100 - accuracy: 0.6806 - auc: 0.7341 - val_loss: 0.6068 - val_accuracy: 0.6509 - val_auc: 0.7283\n",
      "Epoch 52/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6098 - accuracy: 0.6843 - auc: 0.7337 - val_loss: 0.6066 - val_accuracy: 0.6538 - val_auc: 0.7284\n",
      "Epoch 53/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6011 - accuracy: 0.6713 - auc: 0.7420 - val_loss: 0.6068 - val_accuracy: 0.6538 - val_auc: 0.7282\n",
      "Epoch 54/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6042 - accuracy: 0.6796 - auc: 0.7345 - val_loss: 0.6067 - val_accuracy: 0.6538 - val_auc: 0.7277\n",
      "Epoch 55/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6049 - accuracy: 0.6722 - auc: 0.7384 - val_loss: 0.6068 - val_accuracy: 0.6598 - val_auc: 0.7281\n",
      "Epoch 56/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5992 - accuracy: 0.6685 - auc: 0.7409 - val_loss: 0.6061 - val_accuracy: 0.6568 - val_auc: 0.7291\n",
      "Epoch 57/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6043 - accuracy: 0.6870 - auc: 0.7359 - val_loss: 0.6062 - val_accuracy: 0.6598 - val_auc: 0.7287\n",
      "Epoch 58/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6183 - accuracy: 0.6713 - auc: 0.7186 - val_loss: 0.6057 - val_accuracy: 0.6568 - val_auc: 0.7298\n",
      "Epoch 59/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6058 - accuracy: 0.6713 - auc: 0.7314 - val_loss: 0.6057 - val_accuracy: 0.6568 - val_auc: 0.7300\n",
      "Epoch 60/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6074 - accuracy: 0.6769 - auc: 0.7357 - val_loss: 0.6060 - val_accuracy: 0.6538 - val_auc: 0.7287\n",
      "Epoch 61/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6044 - accuracy: 0.6898 - auc: 0.7403 - val_loss: 0.6057 - val_accuracy: 0.6627 - val_auc: 0.7293\n",
      "Epoch 62/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6049 - accuracy: 0.6907 - auc: 0.7401 - val_loss: 0.6050 - val_accuracy: 0.6627 - val_auc: 0.7303\n",
      "Epoch 63/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6096 - accuracy: 0.6657 - auc: 0.7308 - val_loss: 0.6053 - val_accuracy: 0.6627 - val_auc: 0.7305\n",
      "Epoch 64/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6065 - accuracy: 0.6769 - auc: 0.7339 - val_loss: 0.6048 - val_accuracy: 0.6627 - val_auc: 0.7308\n",
      "Epoch 65/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6016 - accuracy: 0.6843 - auc: 0.7388 - val_loss: 0.6046 - val_accuracy: 0.6627 - val_auc: 0.7310\n",
      "Epoch 66/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6064 - accuracy: 0.6694 - auc: 0.7328 - val_loss: 0.6043 - val_accuracy: 0.6627 - val_auc: 0.7311\n",
      "Epoch 67/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6072 - accuracy: 0.6731 - auc: 0.7346 - val_loss: 0.6047 - val_accuracy: 0.6627 - val_auc: 0.7313\n",
      "Epoch 68/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6087 - accuracy: 0.6667 - auc: 0.7292 - val_loss: 0.6048 - val_accuracy: 0.6627 - val_auc: 0.7310\n",
      "Epoch 69/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6071 - accuracy: 0.6704 - auc: 0.7314 - val_loss: 0.6046 - val_accuracy: 0.6657 - val_auc: 0.7313\n",
      "Epoch 70/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6125 - accuracy: 0.6750 - auc: 0.7287 - val_loss: 0.6038 - val_accuracy: 0.6598 - val_auc: 0.7320\n",
      "Epoch 71/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6001 - accuracy: 0.6722 - auc: 0.7415 - val_loss: 0.6035 - val_accuracy: 0.6627 - val_auc: 0.7319\n",
      "Epoch 72/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5991 - accuracy: 0.6741 - auc: 0.7429 - val_loss: 0.6037 - val_accuracy: 0.6598 - val_auc: 0.7324\n",
      "Epoch 73/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6077 - accuracy: 0.6806 - auc: 0.7292 - val_loss: 0.6037 - val_accuracy: 0.6598 - val_auc: 0.7326\n",
      "Epoch 74/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5993 - accuracy: 0.6963 - auc: 0.7472 - val_loss: 0.6037 - val_accuracy: 0.6627 - val_auc: 0.7323\n",
      "Epoch 75/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6025 - accuracy: 0.6759 - auc: 0.7377 - val_loss: 0.6031 - val_accuracy: 0.6627 - val_auc: 0.7330\n",
      "Epoch 76/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6035 - accuracy: 0.6750 - auc: 0.7388 - val_loss: 0.6027 - val_accuracy: 0.6627 - val_auc: 0.7336\n",
      "Epoch 77/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6007 - accuracy: 0.6722 - auc: 0.7404 - val_loss: 0.6024 - val_accuracy: 0.6598 - val_auc: 0.7340\n",
      "Epoch 78/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5992 - accuracy: 0.6713 - auc: 0.7414 - val_loss: 0.6021 - val_accuracy: 0.6627 - val_auc: 0.7342\n",
      "Epoch 79/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.6033 - accuracy: 0.6935 - auc: 0.7400 - val_loss: 0.6018 - val_accuracy: 0.6627 - val_auc: 0.7347\n",
      "Epoch 80/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5987 - accuracy: 0.6815 - auc: 0.7449 - val_loss: 0.6019 - val_accuracy: 0.6627 - val_auc: 0.7349\n",
      "Epoch 81/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6020 - accuracy: 0.6815 - auc: 0.7386 - val_loss: 0.6016 - val_accuracy: 0.6598 - val_auc: 0.7349\n",
      "Epoch 82/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5992 - accuracy: 0.6852 - auc: 0.7441 - val_loss: 0.6012 - val_accuracy: 0.6598 - val_auc: 0.7353\n",
      "Epoch 83/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6018 - accuracy: 0.6861 - auc: 0.7417 - val_loss: 0.6006 - val_accuracy: 0.6598 - val_auc: 0.7360\n",
      "Epoch 84/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5967 - accuracy: 0.6769 - auc: 0.7436 - val_loss: 0.6010 - val_accuracy: 0.6598 - val_auc: 0.7353\n",
      "Epoch 85/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5939 - accuracy: 0.6769 - auc: 0.7508 - val_loss: 0.6009 - val_accuracy: 0.6598 - val_auc: 0.7354\n",
      "Epoch 86/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5936 - accuracy: 0.6907 - auc: 0.7474 - val_loss: 0.6009 - val_accuracy: 0.6598 - val_auc: 0.7358\n",
      "Epoch 87/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5993 - accuracy: 0.6861 - auc: 0.7462 - val_loss: 0.6009 - val_accuracy: 0.6598 - val_auc: 0.7355\n",
      "Epoch 88/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5950 - accuracy: 0.6870 - auc: 0.7496 - val_loss: 0.6008 - val_accuracy: 0.6627 - val_auc: 0.7358\n",
      "Epoch 89/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5874 - accuracy: 0.6981 - auc: 0.7564 - val_loss: 0.6010 - val_accuracy: 0.6627 - val_auc: 0.7363\n",
      "Epoch 90/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5990 - accuracy: 0.6852 - auc: 0.7412 - val_loss: 0.6005 - val_accuracy: 0.6627 - val_auc: 0.7368\n",
      "Epoch 91/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5935 - accuracy: 0.6926 - auc: 0.7497 - val_loss: 0.6001 - val_accuracy: 0.6598 - val_auc: 0.7366\n",
      "Epoch 92/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5986 - accuracy: 0.6731 - auc: 0.7431 - val_loss: 0.5998 - val_accuracy: 0.6627 - val_auc: 0.7371\n",
      "Epoch 93/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6008 - accuracy: 0.6806 - auc: 0.7447 - val_loss: 0.5995 - val_accuracy: 0.6627 - val_auc: 0.7371\n",
      "Epoch 94/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6028 - accuracy: 0.6787 - auc: 0.7380 - val_loss: 0.5996 - val_accuracy: 0.6627 - val_auc: 0.7361\n",
      "Epoch 95/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6001 - accuracy: 0.6731 - auc: 0.7417 - val_loss: 0.5997 - val_accuracy: 0.6627 - val_auc: 0.7363\n",
      "Epoch 96/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5995 - accuracy: 0.6889 - auc: 0.7433 - val_loss: 0.5997 - val_accuracy: 0.6627 - val_auc: 0.7364\n",
      "Epoch 97/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5967 - accuracy: 0.6676 - auc: 0.7447 - val_loss: 0.6000 - val_accuracy: 0.6627 - val_auc: 0.7359\n",
      "Epoch 98/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5951 - accuracy: 0.6759 - auc: 0.7438 - val_loss: 0.5998 - val_accuracy: 0.6627 - val_auc: 0.7362\n",
      "Epoch 99/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5992 - accuracy: 0.6741 - auc: 0.7449 - val_loss: 0.5995 - val_accuracy: 0.6598 - val_auc: 0.7361\n",
      "Epoch 100/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5914 - accuracy: 0.6935 - auc: 0.7521 - val_loss: 0.5988 - val_accuracy: 0.6627 - val_auc: 0.7376\n",
      "Epoch 101/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5930 - accuracy: 0.6907 - auc: 0.7490 - val_loss: 0.5987 - val_accuracy: 0.6627 - val_auc: 0.7380\n",
      "Epoch 102/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.6044 - accuracy: 0.6833 - auc: 0.7370 - val_loss: 0.5984 - val_accuracy: 0.6657 - val_auc: 0.7383\n",
      "Epoch 103/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5980 - accuracy: 0.6769 - auc: 0.7444 - val_loss: 0.5980 - val_accuracy: 0.6657 - val_auc: 0.7386\n",
      "Epoch 104/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5913 - accuracy: 0.6981 - auc: 0.7532 - val_loss: 0.5979 - val_accuracy: 0.6657 - val_auc: 0.7381\n",
      "Epoch 105/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5982 - accuracy: 0.6880 - auc: 0.7455 - val_loss: 0.5972 - val_accuracy: 0.6657 - val_auc: 0.7390\n",
      "Epoch 106/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5994 - accuracy: 0.6824 - auc: 0.7420 - val_loss: 0.5969 - val_accuracy: 0.6657 - val_auc: 0.7391\n",
      "Epoch 107/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5929 - accuracy: 0.6880 - auc: 0.7492 - val_loss: 0.5965 - val_accuracy: 0.6657 - val_auc: 0.7400\n",
      "Epoch 108/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5939 - accuracy: 0.6843 - auc: 0.7484 - val_loss: 0.5971 - val_accuracy: 0.6657 - val_auc: 0.7392\n",
      "Epoch 109/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5964 - accuracy: 0.6843 - auc: 0.7488 - val_loss: 0.5970 - val_accuracy: 0.6657 - val_auc: 0.7392\n",
      "Epoch 110/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5979 - accuracy: 0.7019 - auc: 0.7474 - val_loss: 0.5971 - val_accuracy: 0.6657 - val_auc: 0.7393\n",
      "Epoch 111/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5965 - accuracy: 0.6880 - auc: 0.7485 - val_loss: 0.5970 - val_accuracy: 0.6657 - val_auc: 0.7393\n",
      "Epoch 112/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5873 - accuracy: 0.7000 - auc: 0.7562 - val_loss: 0.5970 - val_accuracy: 0.6657 - val_auc: 0.7394\n",
      "Epoch 113/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5991 - accuracy: 0.6870 - auc: 0.7441 - val_loss: 0.5970 - val_accuracy: 0.6657 - val_auc: 0.7395\n",
      "Epoch 114/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5931 - accuracy: 0.6824 - auc: 0.7492 - val_loss: 0.5971 - val_accuracy: 0.6657 - val_auc: 0.7394\n",
      "Epoch 115/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5906 - accuracy: 0.6861 - auc: 0.7528 - val_loss: 0.5965 - val_accuracy: 0.6657 - val_auc: 0.7395\n",
      "Epoch 116/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5826 - accuracy: 0.7000 - auc: 0.7620 - val_loss: 0.5964 - val_accuracy: 0.6657 - val_auc: 0.7401\n",
      "Epoch 117/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5917 - accuracy: 0.6852 - auc: 0.7528 - val_loss: 0.5960 - val_accuracy: 0.6657 - val_auc: 0.7404\n",
      "Epoch 118/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5990 - accuracy: 0.6787 - auc: 0.7427 - val_loss: 0.5961 - val_accuracy: 0.6657 - val_auc: 0.7402\n",
      "Epoch 119/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5886 - accuracy: 0.6870 - auc: 0.7536 - val_loss: 0.5962 - val_accuracy: 0.6657 - val_auc: 0.7400\n",
      "Epoch 120/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.6009 - accuracy: 0.6769 - auc: 0.7412 - val_loss: 0.5962 - val_accuracy: 0.6657 - val_auc: 0.7401\n",
      "Epoch 121/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5930 - accuracy: 0.6806 - auc: 0.7482 - val_loss: 0.5956 - val_accuracy: 0.6657 - val_auc: 0.7409\n",
      "Epoch 122/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5872 - accuracy: 0.6898 - auc: 0.7573 - val_loss: 0.5949 - val_accuracy: 0.6686 - val_auc: 0.7418\n",
      "Epoch 123/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5962 - accuracy: 0.6843 - auc: 0.7490 - val_loss: 0.5948 - val_accuracy: 0.6657 - val_auc: 0.7417\n",
      "Epoch 124/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5903 - accuracy: 0.6861 - auc: 0.7550 - val_loss: 0.5944 - val_accuracy: 0.6686 - val_auc: 0.7420\n",
      "Epoch 125/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5881 - accuracy: 0.6954 - auc: 0.7581 - val_loss: 0.5944 - val_accuracy: 0.6716 - val_auc: 0.7422\n",
      "Epoch 126/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5948 - accuracy: 0.6917 - auc: 0.7502 - val_loss: 0.5942 - val_accuracy: 0.6657 - val_auc: 0.7425\n",
      "Epoch 127/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5935 - accuracy: 0.6907 - auc: 0.7506 - val_loss: 0.5939 - val_accuracy: 0.6686 - val_auc: 0.7430\n",
      "Epoch 128/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5979 - accuracy: 0.6806 - auc: 0.7463 - val_loss: 0.5939 - val_accuracy: 0.6686 - val_auc: 0.7428\n",
      "Epoch 129/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5921 - accuracy: 0.6880 - auc: 0.7518 - val_loss: 0.5938 - val_accuracy: 0.6657 - val_auc: 0.7425\n",
      "Epoch 130/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5939 - accuracy: 0.6861 - auc: 0.7496 - val_loss: 0.5935 - val_accuracy: 0.6657 - val_auc: 0.7429\n",
      "Epoch 131/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5918 - accuracy: 0.6824 - auc: 0.7510 - val_loss: 0.5932 - val_accuracy: 0.6686 - val_auc: 0.7432\n",
      "Epoch 132/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5983 - accuracy: 0.6806 - auc: 0.7423 - val_loss: 0.5934 - val_accuracy: 0.6686 - val_auc: 0.7429\n",
      "Epoch 133/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5931 - accuracy: 0.6815 - auc: 0.7492 - val_loss: 0.5936 - val_accuracy: 0.6657 - val_auc: 0.7428\n",
      "Epoch 134/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5861 - accuracy: 0.6981 - auc: 0.7556 - val_loss: 0.5941 - val_accuracy: 0.6657 - val_auc: 0.7428\n",
      "Epoch 135/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5991 - accuracy: 0.6722 - auc: 0.7434 - val_loss: 0.5941 - val_accuracy: 0.6686 - val_auc: 0.7425\n",
      "Epoch 136/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5883 - accuracy: 0.6870 - auc: 0.7555 - val_loss: 0.5937 - val_accuracy: 0.6686 - val_auc: 0.7426\n",
      "Epoch 137/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5922 - accuracy: 0.6935 - auc: 0.7492 - val_loss: 0.5935 - val_accuracy: 0.6716 - val_auc: 0.7429\n",
      "Epoch 138/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5968 - accuracy: 0.6907 - auc: 0.7461 - val_loss: 0.5942 - val_accuracy: 0.6716 - val_auc: 0.7423\n",
      "Epoch 139/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5853 - accuracy: 0.6898 - auc: 0.7587 - val_loss: 0.5938 - val_accuracy: 0.6746 - val_auc: 0.7423\n",
      "Epoch 140/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5922 - accuracy: 0.6861 - auc: 0.7528 - val_loss: 0.5936 - val_accuracy: 0.6716 - val_auc: 0.7428\n",
      "Epoch 141/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.6001 - accuracy: 0.6694 - auc: 0.7414 - val_loss: 0.5931 - val_accuracy: 0.6716 - val_auc: 0.7436\n",
      "Epoch 142/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5836 - accuracy: 0.6907 - auc: 0.7567 - val_loss: 0.5928 - val_accuracy: 0.6716 - val_auc: 0.7439\n",
      "Epoch 143/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5868 - accuracy: 0.6870 - auc: 0.7561 - val_loss: 0.5925 - val_accuracy: 0.6746 - val_auc: 0.7445\n",
      "Epoch 144/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5894 - accuracy: 0.6852 - auc: 0.7518 - val_loss: 0.5924 - val_accuracy: 0.6746 - val_auc: 0.7443\n",
      "Epoch 145/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5888 - accuracy: 0.6972 - auc: 0.7556 - val_loss: 0.5920 - val_accuracy: 0.6716 - val_auc: 0.7450\n",
      "Epoch 146/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5881 - accuracy: 0.6815 - auc: 0.7537 - val_loss: 0.5916 - val_accuracy: 0.6716 - val_auc: 0.7456\n",
      "Epoch 147/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5868 - accuracy: 0.6944 - auc: 0.7571 - val_loss: 0.5920 - val_accuracy: 0.6716 - val_auc: 0.7451\n",
      "Epoch 148/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5824 - accuracy: 0.6963 - auc: 0.7624 - val_loss: 0.5921 - val_accuracy: 0.6746 - val_auc: 0.7453\n",
      "Epoch 149/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5834 - accuracy: 0.7019 - auc: 0.7602 - val_loss: 0.5921 - val_accuracy: 0.6805 - val_auc: 0.7453\n",
      "Epoch 150/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5834 - accuracy: 0.6926 - auc: 0.7588 - val_loss: 0.5920 - val_accuracy: 0.6775 - val_auc: 0.7452\n",
      "Epoch 151/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.6008 - accuracy: 0.6870 - auc: 0.7424 - val_loss: 0.5917 - val_accuracy: 0.6775 - val_auc: 0.7456\n",
      "Epoch 152/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5830 - accuracy: 0.6852 - auc: 0.7588 - val_loss: 0.5907 - val_accuracy: 0.6746 - val_auc: 0.7460\n",
      "Epoch 153/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5873 - accuracy: 0.6880 - auc: 0.7551 - val_loss: 0.5909 - val_accuracy: 0.6746 - val_auc: 0.7455\n",
      "Epoch 154/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5838 - accuracy: 0.6843 - auc: 0.7582 - val_loss: 0.5910 - val_accuracy: 0.6746 - val_auc: 0.7457\n",
      "Epoch 155/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5834 - accuracy: 0.6963 - auc: 0.7602 - val_loss: 0.5908 - val_accuracy: 0.6775 - val_auc: 0.7459\n",
      "Epoch 156/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5903 - accuracy: 0.6954 - auc: 0.7543 - val_loss: 0.5907 - val_accuracy: 0.6716 - val_auc: 0.7467\n",
      "Epoch 157/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5860 - accuracy: 0.6991 - auc: 0.7597 - val_loss: 0.5908 - val_accuracy: 0.6716 - val_auc: 0.7464\n",
      "Epoch 158/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5835 - accuracy: 0.7000 - auc: 0.7615 - val_loss: 0.5908 - val_accuracy: 0.6746 - val_auc: 0.7462\n",
      "Epoch 159/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5885 - accuracy: 0.6861 - auc: 0.7538 - val_loss: 0.5902 - val_accuracy: 0.6775 - val_auc: 0.7469\n",
      "Epoch 160/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5912 - accuracy: 0.6870 - auc: 0.7520 - val_loss: 0.5907 - val_accuracy: 0.6775 - val_auc: 0.7462\n",
      "Epoch 161/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5837 - accuracy: 0.6972 - auc: 0.7619 - val_loss: 0.5900 - val_accuracy: 0.6716 - val_auc: 0.7468\n",
      "Epoch 162/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5859 - accuracy: 0.6972 - auc: 0.7567 - val_loss: 0.5904 - val_accuracy: 0.6775 - val_auc: 0.7463\n",
      "Epoch 163/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5878 - accuracy: 0.6972 - auc: 0.7565 - val_loss: 0.5902 - val_accuracy: 0.6746 - val_auc: 0.7470\n",
      "Epoch 164/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5911 - accuracy: 0.6796 - auc: 0.7501 - val_loss: 0.5899 - val_accuracy: 0.6775 - val_auc: 0.7464\n",
      "Epoch 165/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5904 - accuracy: 0.6843 - auc: 0.7534 - val_loss: 0.5897 - val_accuracy: 0.6746 - val_auc: 0.7465\n",
      "Epoch 166/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5904 - accuracy: 0.6861 - auc: 0.7545 - val_loss: 0.5896 - val_accuracy: 0.6716 - val_auc: 0.7468\n",
      "Epoch 167/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5800 - accuracy: 0.7000 - auc: 0.7643 - val_loss: 0.5894 - val_accuracy: 0.6775 - val_auc: 0.7475\n",
      "Epoch 168/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5836 - accuracy: 0.6750 - auc: 0.7595 - val_loss: 0.5896 - val_accuracy: 0.6716 - val_auc: 0.7467\n",
      "Epoch 169/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5817 - accuracy: 0.6944 - auc: 0.7621 - val_loss: 0.5895 - val_accuracy: 0.6746 - val_auc: 0.7472\n",
      "Epoch 170/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5908 - accuracy: 0.6870 - auc: 0.7565 - val_loss: 0.5892 - val_accuracy: 0.6775 - val_auc: 0.7476\n",
      "Epoch 171/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5809 - accuracy: 0.6861 - auc: 0.7634 - val_loss: 0.5891 - val_accuracy: 0.6716 - val_auc: 0.7479\n",
      "Epoch 172/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5827 - accuracy: 0.6963 - auc: 0.7609 - val_loss: 0.5886 - val_accuracy: 0.6716 - val_auc: 0.7484\n",
      "Epoch 173/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5850 - accuracy: 0.6833 - auc: 0.7560 - val_loss: 0.5884 - val_accuracy: 0.6686 - val_auc: 0.7480\n",
      "Epoch 174/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5921 - accuracy: 0.6935 - auc: 0.7519 - val_loss: 0.5885 - val_accuracy: 0.6746 - val_auc: 0.7483\n",
      "Epoch 175/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5782 - accuracy: 0.6972 - auc: 0.7678 - val_loss: 0.5881 - val_accuracy: 0.6716 - val_auc: 0.7492\n",
      "Epoch 176/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5898 - accuracy: 0.6963 - auc: 0.7541 - val_loss: 0.5883 - val_accuracy: 0.6716 - val_auc: 0.7489\n",
      "Epoch 177/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5832 - accuracy: 0.6898 - auc: 0.7577 - val_loss: 0.5878 - val_accuracy: 0.6716 - val_auc: 0.7492\n",
      "Epoch 178/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5818 - accuracy: 0.7074 - auc: 0.7643 - val_loss: 0.5872 - val_accuracy: 0.6746 - val_auc: 0.7501\n",
      "Epoch 179/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5777 - accuracy: 0.7148 - auc: 0.7680 - val_loss: 0.5873 - val_accuracy: 0.6686 - val_auc: 0.7502\n",
      "Epoch 180/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5893 - accuracy: 0.6815 - auc: 0.7513 - val_loss: 0.5868 - val_accuracy: 0.6686 - val_auc: 0.7504\n",
      "Epoch 181/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5791 - accuracy: 0.6935 - auc: 0.7648 - val_loss: 0.5867 - val_accuracy: 0.6716 - val_auc: 0.7502\n",
      "Epoch 182/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5902 - accuracy: 0.6889 - auc: 0.7563 - val_loss: 0.5865 - val_accuracy: 0.6716 - val_auc: 0.7508\n",
      "Epoch 183/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5887 - accuracy: 0.6944 - auc: 0.7522 - val_loss: 0.5869 - val_accuracy: 0.6746 - val_auc: 0.7501\n",
      "Epoch 184/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5878 - accuracy: 0.6870 - auc: 0.7561 - val_loss: 0.5871 - val_accuracy: 0.6746 - val_auc: 0.7497\n",
      "Epoch 185/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5791 - accuracy: 0.7037 - auc: 0.7650 - val_loss: 0.5869 - val_accuracy: 0.6716 - val_auc: 0.7502\n",
      "Epoch 186/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5882 - accuracy: 0.6861 - auc: 0.7560 - val_loss: 0.5869 - val_accuracy: 0.6805 - val_auc: 0.7498\n",
      "Epoch 187/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5803 - accuracy: 0.6880 - auc: 0.7617 - val_loss: 0.5867 - val_accuracy: 0.6716 - val_auc: 0.7505\n",
      "Epoch 188/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5826 - accuracy: 0.6926 - auc: 0.7607 - val_loss: 0.5867 - val_accuracy: 0.6746 - val_auc: 0.7505\n",
      "Epoch 189/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5850 - accuracy: 0.6991 - auc: 0.7595 - val_loss: 0.5863 - val_accuracy: 0.6716 - val_auc: 0.7509\n",
      "Epoch 190/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5854 - accuracy: 0.6898 - auc: 0.7582 - val_loss: 0.5855 - val_accuracy: 0.6775 - val_auc: 0.7516\n",
      "Epoch 191/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5804 - accuracy: 0.7000 - auc: 0.7663 - val_loss: 0.5856 - val_accuracy: 0.6746 - val_auc: 0.7520\n",
      "Epoch 192/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5911 - accuracy: 0.6806 - auc: 0.7476 - val_loss: 0.5857 - val_accuracy: 0.6805 - val_auc: 0.7514\n",
      "Epoch 193/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5873 - accuracy: 0.6889 - auc: 0.7547 - val_loss: 0.5852 - val_accuracy: 0.6805 - val_auc: 0.7524\n",
      "Epoch 194/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5800 - accuracy: 0.6954 - auc: 0.7620 - val_loss: 0.5854 - val_accuracy: 0.6746 - val_auc: 0.7522\n",
      "Epoch 195/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5789 - accuracy: 0.6981 - auc: 0.7666 - val_loss: 0.5851 - val_accuracy: 0.6746 - val_auc: 0.7523\n",
      "Epoch 196/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5769 - accuracy: 0.7056 - auc: 0.7684 - val_loss: 0.5843 - val_accuracy: 0.6805 - val_auc: 0.7535\n",
      "Epoch 197/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5798 - accuracy: 0.7019 - auc: 0.7650 - val_loss: 0.5844 - val_accuracy: 0.6746 - val_auc: 0.7539\n",
      "Epoch 198/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5793 - accuracy: 0.7009 - auc: 0.7653 - val_loss: 0.5849 - val_accuracy: 0.6775 - val_auc: 0.7529\n",
      "Epoch 199/700\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5887 - accuracy: 0.6907 - auc: 0.7541 - val_loss: 0.5852 - val_accuracy: 0.6775 - val_auc: 0.7522\n",
      "Epoch 200/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5886 - accuracy: 0.6889 - auc: 0.7543 - val_loss: 0.5849 - val_accuracy: 0.6775 - val_auc: 0.7522\n",
      "Epoch 201/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5836 - accuracy: 0.6907 - auc: 0.7593 - val_loss: 0.5848 - val_accuracy: 0.6746 - val_auc: 0.7527\n",
      "Epoch 202/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5766 - accuracy: 0.7009 - auc: 0.7663 - val_loss: 0.5844 - val_accuracy: 0.6746 - val_auc: 0.7529\n",
      "Epoch 203/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5789 - accuracy: 0.7019 - auc: 0.7641 - val_loss: 0.5845 - val_accuracy: 0.6775 - val_auc: 0.7532\n",
      "Epoch 204/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5795 - accuracy: 0.6880 - auc: 0.7655 - val_loss: 0.5841 - val_accuracy: 0.6716 - val_auc: 0.7536\n",
      "Epoch 205/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5867 - accuracy: 0.6991 - auc: 0.7588 - val_loss: 0.5839 - val_accuracy: 0.6716 - val_auc: 0.7537\n",
      "Epoch 206/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5782 - accuracy: 0.6926 - auc: 0.7646 - val_loss: 0.5840 - val_accuracy: 0.6746 - val_auc: 0.7538\n",
      "Epoch 207/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5831 - accuracy: 0.6935 - auc: 0.7625 - val_loss: 0.5838 - val_accuracy: 0.6716 - val_auc: 0.7537\n",
      "Epoch 208/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5903 - accuracy: 0.6917 - auc: 0.7524 - val_loss: 0.5838 - val_accuracy: 0.6746 - val_auc: 0.7536\n",
      "Epoch 209/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5873 - accuracy: 0.6917 - auc: 0.7532 - val_loss: 0.5844 - val_accuracy: 0.6746 - val_auc: 0.7533\n",
      "Epoch 210/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5796 - accuracy: 0.6991 - auc: 0.7636 - val_loss: 0.5843 - val_accuracy: 0.6657 - val_auc: 0.7535\n",
      "Epoch 211/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5788 - accuracy: 0.7102 - auc: 0.7684 - val_loss: 0.5841 - val_accuracy: 0.6686 - val_auc: 0.7538\n",
      "Epoch 212/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5757 - accuracy: 0.6917 - auc: 0.7688 - val_loss: 0.5843 - val_accuracy: 0.6686 - val_auc: 0.7535\n",
      "Epoch 213/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5867 - accuracy: 0.6991 - auc: 0.7585 - val_loss: 0.5847 - val_accuracy: 0.6686 - val_auc: 0.7534\n",
      "Epoch 214/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5915 - accuracy: 0.7046 - auc: 0.7556 - val_loss: 0.5841 - val_accuracy: 0.6686 - val_auc: 0.7539\n",
      "Epoch 215/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5895 - accuracy: 0.6907 - auc: 0.7558 - val_loss: 0.5839 - val_accuracy: 0.6686 - val_auc: 0.7540\n",
      "Epoch 216/700\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.5801 - accuracy: 0.6991 - auc: 0.7629 - val_loss: 0.5835 - val_accuracy: 0.6746 - val_auc: 0.7544\n",
      "Epoch 217/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5771 - accuracy: 0.6954 - auc: 0.7701 - val_loss: 0.5834 - val_accuracy: 0.6716 - val_auc: 0.7549\n",
      "Epoch 218/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5869 - accuracy: 0.6944 - auc: 0.7545 - val_loss: 0.5830 - val_accuracy: 0.6686 - val_auc: 0.7553\n",
      "Epoch 219/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5700 - accuracy: 0.7130 - auc: 0.7758 - val_loss: 0.5832 - val_accuracy: 0.6686 - val_auc: 0.7545\n",
      "Epoch 220/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5775 - accuracy: 0.7028 - auc: 0.7660 - val_loss: 0.5829 - val_accuracy: 0.6686 - val_auc: 0.7551\n",
      "Epoch 221/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5785 - accuracy: 0.6935 - auc: 0.7651 - val_loss: 0.5827 - val_accuracy: 0.6686 - val_auc: 0.7556\n",
      "Epoch 222/700\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5848 - accuracy: 0.6991 - auc: 0.7583 - val_loss: 0.5824 - val_accuracy: 0.6686 - val_auc: 0.7559\n",
      "Epoch 223/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5757 - accuracy: 0.6981 - auc: 0.7673 - val_loss: 0.5822 - val_accuracy: 0.6686 - val_auc: 0.7560\n",
      "Epoch 224/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5807 - accuracy: 0.6898 - auc: 0.7614 - val_loss: 0.5825 - val_accuracy: 0.6716 - val_auc: 0.7556\n",
      "Epoch 225/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5780 - accuracy: 0.6963 - auc: 0.7664 - val_loss: 0.5824 - val_accuracy: 0.6716 - val_auc: 0.7559\n",
      "Epoch 226/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5694 - accuracy: 0.7037 - auc: 0.7735 - val_loss: 0.5826 - val_accuracy: 0.6746 - val_auc: 0.7556\n",
      "Epoch 227/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5847 - accuracy: 0.6907 - auc: 0.7583 - val_loss: 0.5823 - val_accuracy: 0.6746 - val_auc: 0.7558\n",
      "Epoch 228/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5786 - accuracy: 0.6935 - auc: 0.7658 - val_loss: 0.5815 - val_accuracy: 0.6746 - val_auc: 0.7566\n",
      "Epoch 229/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5878 - accuracy: 0.6852 - auc: 0.7544 - val_loss: 0.5812 - val_accuracy: 0.6746 - val_auc: 0.7574\n",
      "Epoch 230/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5763 - accuracy: 0.7065 - auc: 0.7695 - val_loss: 0.5811 - val_accuracy: 0.6686 - val_auc: 0.7575\n",
      "Epoch 231/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5710 - accuracy: 0.7102 - auc: 0.7721 - val_loss: 0.5809 - val_accuracy: 0.6686 - val_auc: 0.7578\n",
      "Epoch 232/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5755 - accuracy: 0.7074 - auc: 0.7687 - val_loss: 0.5807 - val_accuracy: 0.6716 - val_auc: 0.7585\n",
      "Epoch 233/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5740 - accuracy: 0.7093 - auc: 0.7696 - val_loss: 0.5805 - val_accuracy: 0.6686 - val_auc: 0.7584\n",
      "Epoch 234/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5886 - accuracy: 0.6944 - auc: 0.7574 - val_loss: 0.5812 - val_accuracy: 0.6716 - val_auc: 0.7577\n",
      "Epoch 235/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5834 - accuracy: 0.6926 - auc: 0.7585 - val_loss: 0.5806 - val_accuracy: 0.6686 - val_auc: 0.7584\n",
      "Epoch 236/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5705 - accuracy: 0.7102 - auc: 0.7740 - val_loss: 0.5808 - val_accuracy: 0.6716 - val_auc: 0.7589\n",
      "Epoch 237/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5869 - accuracy: 0.6972 - auc: 0.7581 - val_loss: 0.5807 - val_accuracy: 0.6716 - val_auc: 0.7582\n",
      "Epoch 238/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5846 - accuracy: 0.6981 - auc: 0.7579 - val_loss: 0.5811 - val_accuracy: 0.6686 - val_auc: 0.7578\n",
      "Epoch 239/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5775 - accuracy: 0.7083 - auc: 0.7663 - val_loss: 0.5809 - val_accuracy: 0.6686 - val_auc: 0.7579\n",
      "Epoch 240/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5776 - accuracy: 0.7056 - auc: 0.7666 - val_loss: 0.5809 - val_accuracy: 0.6716 - val_auc: 0.7576\n",
      "Epoch 241/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5716 - accuracy: 0.7065 - auc: 0.7743 - val_loss: 0.5807 - val_accuracy: 0.6716 - val_auc: 0.7577\n",
      "Epoch 242/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5768 - accuracy: 0.6972 - auc: 0.7661 - val_loss: 0.5813 - val_accuracy: 0.6716 - val_auc: 0.7571\n",
      "Epoch 243/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5828 - accuracy: 0.6981 - auc: 0.7574 - val_loss: 0.5803 - val_accuracy: 0.6716 - val_auc: 0.7580\n",
      "Epoch 244/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5761 - accuracy: 0.6963 - auc: 0.7681 - val_loss: 0.5801 - val_accuracy: 0.6686 - val_auc: 0.7590\n",
      "Epoch 245/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5757 - accuracy: 0.7074 - auc: 0.7683 - val_loss: 0.5797 - val_accuracy: 0.6686 - val_auc: 0.7595\n",
      "Epoch 246/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5806 - accuracy: 0.6907 - auc: 0.7626 - val_loss: 0.5790 - val_accuracy: 0.6716 - val_auc: 0.7597\n",
      "Epoch 247/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5709 - accuracy: 0.7019 - auc: 0.7730 - val_loss: 0.5796 - val_accuracy: 0.6686 - val_auc: 0.7593\n",
      "Epoch 248/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5718 - accuracy: 0.7028 - auc: 0.7704 - val_loss: 0.5793 - val_accuracy: 0.6686 - val_auc: 0.7595\n",
      "Epoch 249/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5815 - accuracy: 0.7009 - auc: 0.7620 - val_loss: 0.5788 - val_accuracy: 0.6686 - val_auc: 0.7599\n",
      "Epoch 250/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5791 - accuracy: 0.6963 - auc: 0.7620 - val_loss: 0.5783 - val_accuracy: 0.6686 - val_auc: 0.7605\n",
      "Epoch 251/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5703 - accuracy: 0.7167 - auc: 0.7763 - val_loss: 0.5780 - val_accuracy: 0.6746 - val_auc: 0.7608\n",
      "Epoch 252/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5689 - accuracy: 0.7176 - auc: 0.7755 - val_loss: 0.5781 - val_accuracy: 0.6746 - val_auc: 0.7605\n",
      "Epoch 253/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5701 - accuracy: 0.7074 - auc: 0.7760 - val_loss: 0.5777 - val_accuracy: 0.6746 - val_auc: 0.7608\n",
      "Epoch 254/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5803 - accuracy: 0.7065 - auc: 0.7634 - val_loss: 0.5780 - val_accuracy: 0.6746 - val_auc: 0.7606\n",
      "Epoch 255/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5792 - accuracy: 0.6843 - auc: 0.7630 - val_loss: 0.5781 - val_accuracy: 0.6716 - val_auc: 0.7609\n",
      "Epoch 256/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5815 - accuracy: 0.7037 - auc: 0.7616 - val_loss: 0.5779 - val_accuracy: 0.6686 - val_auc: 0.7608\n",
      "Epoch 257/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5748 - accuracy: 0.6898 - auc: 0.7674 - val_loss: 0.5766 - val_accuracy: 0.6686 - val_auc: 0.7619\n",
      "Epoch 258/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5684 - accuracy: 0.7009 - auc: 0.7754 - val_loss: 0.5759 - val_accuracy: 0.6686 - val_auc: 0.7630\n",
      "Epoch 259/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5680 - accuracy: 0.7065 - auc: 0.7764 - val_loss: 0.5758 - val_accuracy: 0.6686 - val_auc: 0.7627\n",
      "Epoch 260/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5712 - accuracy: 0.7083 - auc: 0.7755 - val_loss: 0.5759 - val_accuracy: 0.6716 - val_auc: 0.7632\n",
      "Epoch 261/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5756 - accuracy: 0.7019 - auc: 0.7659 - val_loss: 0.5760 - val_accuracy: 0.6746 - val_auc: 0.7627\n",
      "Epoch 262/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5773 - accuracy: 0.6972 - auc: 0.7675 - val_loss: 0.5762 - val_accuracy: 0.6746 - val_auc: 0.7627\n",
      "Epoch 263/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5767 - accuracy: 0.6954 - auc: 0.7682 - val_loss: 0.5761 - val_accuracy: 0.6746 - val_auc: 0.7626\n",
      "Epoch 264/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5858 - accuracy: 0.6981 - auc: 0.7577 - val_loss: 0.5770 - val_accuracy: 0.6775 - val_auc: 0.7619\n",
      "Epoch 265/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5758 - accuracy: 0.7009 - auc: 0.7705 - val_loss: 0.5774 - val_accuracy: 0.6686 - val_auc: 0.7612\n",
      "Epoch 266/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5752 - accuracy: 0.6963 - auc: 0.7708 - val_loss: 0.5771 - val_accuracy: 0.6746 - val_auc: 0.7621\n",
      "Epoch 267/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5733 - accuracy: 0.7102 - auc: 0.7717 - val_loss: 0.5765 - val_accuracy: 0.6834 - val_auc: 0.7625\n",
      "Epoch 268/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5661 - accuracy: 0.7130 - auc: 0.7787 - val_loss: 0.5764 - val_accuracy: 0.6834 - val_auc: 0.7623\n",
      "Epoch 269/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5744 - accuracy: 0.7046 - auc: 0.7699 - val_loss: 0.5761 - val_accuracy: 0.6746 - val_auc: 0.7625\n",
      "Epoch 270/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5772 - accuracy: 0.7194 - auc: 0.7724 - val_loss: 0.5756 - val_accuracy: 0.6775 - val_auc: 0.7631\n",
      "Epoch 271/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5710 - accuracy: 0.7046 - auc: 0.7767 - val_loss: 0.5754 - val_accuracy: 0.6746 - val_auc: 0.7634\n",
      "Epoch 272/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5663 - accuracy: 0.6981 - auc: 0.7755 - val_loss: 0.5748 - val_accuracy: 0.6746 - val_auc: 0.7637\n",
      "Epoch 273/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5698 - accuracy: 0.6954 - auc: 0.7748 - val_loss: 0.5747 - val_accuracy: 0.6746 - val_auc: 0.7643\n",
      "Epoch 274/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5732 - accuracy: 0.7065 - auc: 0.7695 - val_loss: 0.5751 - val_accuracy: 0.6805 - val_auc: 0.7635\n",
      "Epoch 275/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5682 - accuracy: 0.7046 - auc: 0.7767 - val_loss: 0.5753 - val_accuracy: 0.6805 - val_auc: 0.7637\n",
      "Epoch 276/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5715 - accuracy: 0.6954 - auc: 0.7680 - val_loss: 0.5749 - val_accuracy: 0.6775 - val_auc: 0.7638\n",
      "Epoch 277/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5859 - accuracy: 0.6880 - auc: 0.7549 - val_loss: 0.5746 - val_accuracy: 0.6746 - val_auc: 0.7645\n",
      "Epoch 278/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5698 - accuracy: 0.7074 - auc: 0.7748 - val_loss: 0.5748 - val_accuracy: 0.6864 - val_auc: 0.7647\n",
      "Epoch 279/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5738 - accuracy: 0.7111 - auc: 0.7691 - val_loss: 0.5747 - val_accuracy: 0.6834 - val_auc: 0.7643\n",
      "Epoch 280/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5752 - accuracy: 0.7046 - auc: 0.7672 - val_loss: 0.5751 - val_accuracy: 0.6805 - val_auc: 0.7644\n",
      "Epoch 281/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5783 - accuracy: 0.6954 - auc: 0.7686 - val_loss: 0.5752 - val_accuracy: 0.6805 - val_auc: 0.7641\n",
      "Epoch 282/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5784 - accuracy: 0.7074 - auc: 0.7677 - val_loss: 0.5756 - val_accuracy: 0.6805 - val_auc: 0.7635\n",
      "Epoch 283/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5710 - accuracy: 0.6917 - auc: 0.7719 - val_loss: 0.5751 - val_accuracy: 0.6805 - val_auc: 0.7639\n",
      "Epoch 284/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5745 - accuracy: 0.7009 - auc: 0.7692 - val_loss: 0.5752 - val_accuracy: 0.6805 - val_auc: 0.7642\n",
      "Epoch 285/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5805 - accuracy: 0.7000 - auc: 0.7623 - val_loss: 0.5752 - val_accuracy: 0.6775 - val_auc: 0.7636\n",
      "Epoch 286/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5669 - accuracy: 0.7167 - auc: 0.7801 - val_loss: 0.5749 - val_accuracy: 0.6805 - val_auc: 0.7640\n",
      "Epoch 287/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5747 - accuracy: 0.6991 - auc: 0.7689 - val_loss: 0.5746 - val_accuracy: 0.6834 - val_auc: 0.7649\n",
      "Epoch 288/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5811 - accuracy: 0.6935 - auc: 0.7605 - val_loss: 0.5742 - val_accuracy: 0.6834 - val_auc: 0.7648\n",
      "Epoch 289/700\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5734 - accuracy: 0.7083 - auc: 0.7691 - val_loss: 0.5747 - val_accuracy: 0.6864 - val_auc: 0.7651\n",
      "Epoch 290/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5748 - accuracy: 0.7111 - auc: 0.7683 - val_loss: 0.5748 - val_accuracy: 0.6864 - val_auc: 0.7647\n",
      "Epoch 291/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5748 - accuracy: 0.6907 - auc: 0.7683 - val_loss: 0.5751 - val_accuracy: 0.6834 - val_auc: 0.7648\n",
      "Epoch 292/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5636 - accuracy: 0.7028 - auc: 0.7798 - val_loss: 0.5753 - val_accuracy: 0.6834 - val_auc: 0.7643\n",
      "Epoch 293/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5692 - accuracy: 0.7046 - auc: 0.7730 - val_loss: 0.5755 - val_accuracy: 0.6864 - val_auc: 0.7641\n",
      "Epoch 294/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5771 - accuracy: 0.7148 - auc: 0.7682 - val_loss: 0.5751 - val_accuracy: 0.6864 - val_auc: 0.7643\n",
      "Epoch 295/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5738 - accuracy: 0.7046 - auc: 0.7707 - val_loss: 0.5743 - val_accuracy: 0.6834 - val_auc: 0.7653\n",
      "Epoch 296/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5792 - accuracy: 0.7111 - auc: 0.7611 - val_loss: 0.5743 - val_accuracy: 0.6864 - val_auc: 0.7654\n",
      "Epoch 297/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5751 - accuracy: 0.6963 - auc: 0.7668 - val_loss: 0.5736 - val_accuracy: 0.6834 - val_auc: 0.7654\n",
      "Epoch 298/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5834 - accuracy: 0.6954 - auc: 0.7564 - val_loss: 0.5736 - val_accuracy: 0.6864 - val_auc: 0.7656\n",
      "Epoch 299/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5660 - accuracy: 0.7028 - auc: 0.7779 - val_loss: 0.5740 - val_accuracy: 0.6864 - val_auc: 0.7654\n",
      "Epoch 300/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5737 - accuracy: 0.6926 - auc: 0.7681 - val_loss: 0.5735 - val_accuracy: 0.6864 - val_auc: 0.7660\n",
      "Epoch 301/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5754 - accuracy: 0.6889 - auc: 0.7682 - val_loss: 0.5732 - val_accuracy: 0.6893 - val_auc: 0.7661\n",
      "Epoch 302/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5692 - accuracy: 0.7019 - auc: 0.7746 - val_loss: 0.5732 - val_accuracy: 0.6893 - val_auc: 0.7663\n",
      "Epoch 303/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5679 - accuracy: 0.7120 - auc: 0.7749 - val_loss: 0.5737 - val_accuracy: 0.6864 - val_auc: 0.7661\n",
      "Epoch 304/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5803 - accuracy: 0.7019 - auc: 0.7638 - val_loss: 0.5735 - val_accuracy: 0.6834 - val_auc: 0.7658\n",
      "Epoch 305/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5696 - accuracy: 0.7111 - auc: 0.7734 - val_loss: 0.5734 - val_accuracy: 0.6834 - val_auc: 0.7656\n",
      "Epoch 306/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5714 - accuracy: 0.7019 - auc: 0.7698 - val_loss: 0.5734 - val_accuracy: 0.6805 - val_auc: 0.7656\n",
      "Epoch 307/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5608 - accuracy: 0.7167 - auc: 0.7829 - val_loss: 0.5732 - val_accuracy: 0.6864 - val_auc: 0.7661\n",
      "Epoch 308/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5763 - accuracy: 0.7028 - auc: 0.7683 - val_loss: 0.5736 - val_accuracy: 0.6775 - val_auc: 0.7655\n",
      "Epoch 309/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5674 - accuracy: 0.7148 - auc: 0.7762 - val_loss: 0.5736 - val_accuracy: 0.6775 - val_auc: 0.7653\n",
      "Epoch 310/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5772 - accuracy: 0.7037 - auc: 0.7643 - val_loss: 0.5740 - val_accuracy: 0.6746 - val_auc: 0.7650\n",
      "Epoch 311/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5720 - accuracy: 0.7000 - auc: 0.7722 - val_loss: 0.5733 - val_accuracy: 0.6805 - val_auc: 0.7659\n",
      "Epoch 312/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5732 - accuracy: 0.7074 - auc: 0.7707 - val_loss: 0.5731 - val_accuracy: 0.6805 - val_auc: 0.7664\n",
      "Epoch 313/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5713 - accuracy: 0.7148 - auc: 0.7782 - val_loss: 0.5736 - val_accuracy: 0.6805 - val_auc: 0.7652\n",
      "Epoch 314/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5747 - accuracy: 0.7000 - auc: 0.7674 - val_loss: 0.5735 - val_accuracy: 0.6805 - val_auc: 0.7663\n",
      "Epoch 315/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5722 - accuracy: 0.7093 - auc: 0.7716 - val_loss: 0.5735 - val_accuracy: 0.6805 - val_auc: 0.7659\n",
      "Epoch 316/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5695 - accuracy: 0.6972 - auc: 0.7738 - val_loss: 0.5728 - val_accuracy: 0.6834 - val_auc: 0.7667\n",
      "Epoch 317/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5671 - accuracy: 0.7176 - auc: 0.7783 - val_loss: 0.5733 - val_accuracy: 0.6834 - val_auc: 0.7660\n",
      "Epoch 318/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5659 - accuracy: 0.7130 - auc: 0.7778 - val_loss: 0.5731 - val_accuracy: 0.6864 - val_auc: 0.7664\n",
      "Epoch 319/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5729 - accuracy: 0.7083 - auc: 0.7685 - val_loss: 0.5728 - val_accuracy: 0.6864 - val_auc: 0.7661\n",
      "Epoch 320/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5634 - accuracy: 0.7185 - auc: 0.7793 - val_loss: 0.5722 - val_accuracy: 0.6834 - val_auc: 0.7672\n",
      "Epoch 321/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5649 - accuracy: 0.7176 - auc: 0.7765 - val_loss: 0.5727 - val_accuracy: 0.6805 - val_auc: 0.7669\n",
      "Epoch 322/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5644 - accuracy: 0.7056 - auc: 0.7766 - val_loss: 0.5729 - val_accuracy: 0.6834 - val_auc: 0.7665\n",
      "Epoch 323/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5622 - accuracy: 0.7019 - auc: 0.7809 - val_loss: 0.5722 - val_accuracy: 0.6805 - val_auc: 0.7672\n",
      "Epoch 324/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5632 - accuracy: 0.7046 - auc: 0.7804 - val_loss: 0.5712 - val_accuracy: 0.6834 - val_auc: 0.7684\n",
      "Epoch 325/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5644 - accuracy: 0.7111 - auc: 0.7781 - val_loss: 0.5711 - val_accuracy: 0.6775 - val_auc: 0.7681\n",
      "Epoch 326/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5655 - accuracy: 0.7019 - auc: 0.7778 - val_loss: 0.5704 - val_accuracy: 0.6834 - val_auc: 0.7690\n",
      "Epoch 327/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5696 - accuracy: 0.7046 - auc: 0.7746 - val_loss: 0.5699 - val_accuracy: 0.6834 - val_auc: 0.7696\n",
      "Epoch 328/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5696 - accuracy: 0.6981 - auc: 0.7717 - val_loss: 0.5698 - val_accuracy: 0.6893 - val_auc: 0.7696\n",
      "Epoch 329/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5687 - accuracy: 0.7102 - auc: 0.7776 - val_loss: 0.5700 - val_accuracy: 0.6834 - val_auc: 0.7694\n",
      "Epoch 330/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5680 - accuracy: 0.7074 - auc: 0.7751 - val_loss: 0.5701 - val_accuracy: 0.6834 - val_auc: 0.7692\n",
      "Epoch 331/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5655 - accuracy: 0.7037 - auc: 0.7784 - val_loss: 0.5701 - val_accuracy: 0.6864 - val_auc: 0.7698\n",
      "Epoch 332/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5705 - accuracy: 0.7083 - auc: 0.7732 - val_loss: 0.5696 - val_accuracy: 0.6864 - val_auc: 0.7701\n",
      "Epoch 333/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5737 - accuracy: 0.7000 - auc: 0.7690 - val_loss: 0.5691 - val_accuracy: 0.6864 - val_auc: 0.7707\n",
      "Epoch 334/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5628 - accuracy: 0.7093 - auc: 0.7811 - val_loss: 0.5684 - val_accuracy: 0.6864 - val_auc: 0.7718\n",
      "Epoch 335/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5673 - accuracy: 0.7046 - auc: 0.7750 - val_loss: 0.5685 - val_accuracy: 0.6864 - val_auc: 0.7710\n",
      "Epoch 336/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5785 - accuracy: 0.7009 - auc: 0.7648 - val_loss: 0.5690 - val_accuracy: 0.6864 - val_auc: 0.7705\n",
      "Epoch 337/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5634 - accuracy: 0.7185 - auc: 0.7831 - val_loss: 0.5689 - val_accuracy: 0.6864 - val_auc: 0.7709\n",
      "Epoch 338/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5677 - accuracy: 0.7102 - auc: 0.7766 - val_loss: 0.5688 - val_accuracy: 0.6834 - val_auc: 0.7708\n",
      "Epoch 339/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5714 - accuracy: 0.7028 - auc: 0.7738 - val_loss: 0.5694 - val_accuracy: 0.6864 - val_auc: 0.7699\n",
      "Epoch 340/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5600 - accuracy: 0.7056 - auc: 0.7839 - val_loss: 0.5691 - val_accuracy: 0.6864 - val_auc: 0.7707\n",
      "Epoch 341/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5645 - accuracy: 0.7028 - auc: 0.7764 - val_loss: 0.5697 - val_accuracy: 0.6864 - val_auc: 0.7703\n",
      "Epoch 342/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5621 - accuracy: 0.7259 - auc: 0.7815 - val_loss: 0.5696 - val_accuracy: 0.6893 - val_auc: 0.7701\n",
      "Epoch 343/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5694 - accuracy: 0.6954 - auc: 0.7713 - val_loss: 0.5696 - val_accuracy: 0.6864 - val_auc: 0.7702\n",
      "Epoch 344/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5609 - accuracy: 0.7019 - auc: 0.7804 - val_loss: 0.5692 - val_accuracy: 0.6893 - val_auc: 0.7702\n",
      "Epoch 345/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5656 - accuracy: 0.7074 - auc: 0.7759 - val_loss: 0.5682 - val_accuracy: 0.6834 - val_auc: 0.7712\n",
      "Epoch 346/700\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5755 - accuracy: 0.6954 - auc: 0.7672 - val_loss: 0.5684 - val_accuracy: 0.6834 - val_auc: 0.7713\n",
      "Epoch 347/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5660 - accuracy: 0.7009 - auc: 0.7773 - val_loss: 0.5686 - val_accuracy: 0.6834 - val_auc: 0.7709\n",
      "Epoch 348/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5595 - accuracy: 0.7102 - auc: 0.7851 - val_loss: 0.5684 - val_accuracy: 0.6864 - val_auc: 0.7710\n",
      "Epoch 349/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5701 - accuracy: 0.7083 - auc: 0.7731 - val_loss: 0.5683 - val_accuracy: 0.6864 - val_auc: 0.7717\n",
      "Epoch 350/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5588 - accuracy: 0.7157 - auc: 0.7870 - val_loss: 0.5684 - val_accuracy: 0.6834 - val_auc: 0.7714\n",
      "Epoch 351/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5761 - accuracy: 0.7000 - auc: 0.7681 - val_loss: 0.5683 - val_accuracy: 0.6805 - val_auc: 0.7714\n",
      "Epoch 352/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5662 - accuracy: 0.7065 - auc: 0.7762 - val_loss: 0.5683 - val_accuracy: 0.6834 - val_auc: 0.7711\n",
      "Epoch 353/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5796 - accuracy: 0.6907 - auc: 0.7624 - val_loss: 0.5681 - val_accuracy: 0.6834 - val_auc: 0.7711\n",
      "Epoch 354/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5681 - accuracy: 0.7000 - auc: 0.7747 - val_loss: 0.5677 - val_accuracy: 0.6834 - val_auc: 0.7716\n",
      "Epoch 355/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5697 - accuracy: 0.7046 - auc: 0.7727 - val_loss: 0.5688 - val_accuracy: 0.6864 - val_auc: 0.7706\n",
      "Epoch 356/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5710 - accuracy: 0.6944 - auc: 0.7691 - val_loss: 0.5685 - val_accuracy: 0.6834 - val_auc: 0.7710\n",
      "Epoch 357/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5631 - accuracy: 0.7213 - auc: 0.7818 - val_loss: 0.5679 - val_accuracy: 0.6834 - val_auc: 0.7718\n",
      "Epoch 358/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5639 - accuracy: 0.7185 - auc: 0.7811 - val_loss: 0.5672 - val_accuracy: 0.6834 - val_auc: 0.7725\n",
      "Epoch 359/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5625 - accuracy: 0.7074 - auc: 0.7778 - val_loss: 0.5672 - val_accuracy: 0.6834 - val_auc: 0.7723\n",
      "Epoch 360/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5629 - accuracy: 0.7083 - auc: 0.7832 - val_loss: 0.5679 - val_accuracy: 0.6834 - val_auc: 0.7716\n",
      "Epoch 361/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5696 - accuracy: 0.7176 - auc: 0.7742 - val_loss: 0.5681 - val_accuracy: 0.6834 - val_auc: 0.7714\n",
      "Epoch 362/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5670 - accuracy: 0.7065 - auc: 0.7760 - val_loss: 0.5673 - val_accuracy: 0.6834 - val_auc: 0.7719\n",
      "Epoch 363/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5682 - accuracy: 0.6981 - auc: 0.7733 - val_loss: 0.5681 - val_accuracy: 0.6834 - val_auc: 0.7714\n",
      "Epoch 364/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5674 - accuracy: 0.7028 - auc: 0.7762 - val_loss: 0.5685 - val_accuracy: 0.6834 - val_auc: 0.7707\n",
      "Epoch 365/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5647 - accuracy: 0.7083 - auc: 0.7766 - val_loss: 0.5682 - val_accuracy: 0.6834 - val_auc: 0.7710\n",
      "Epoch 366/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5677 - accuracy: 0.7074 - auc: 0.7778 - val_loss: 0.5677 - val_accuracy: 0.6805 - val_auc: 0.7717\n",
      "Epoch 367/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5647 - accuracy: 0.7056 - auc: 0.7808 - val_loss: 0.5677 - val_accuracy: 0.6834 - val_auc: 0.7719\n",
      "Epoch 368/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5733 - accuracy: 0.7009 - auc: 0.7691 - val_loss: 0.5679 - val_accuracy: 0.6834 - val_auc: 0.7713\n",
      "Epoch 369/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5617 - accuracy: 0.7222 - auc: 0.7851 - val_loss: 0.5685 - val_accuracy: 0.6864 - val_auc: 0.7711\n",
      "Epoch 370/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5635 - accuracy: 0.7037 - auc: 0.7802 - val_loss: 0.5684 - val_accuracy: 0.6834 - val_auc: 0.7708\n",
      "Epoch 371/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5634 - accuracy: 0.7028 - auc: 0.7795 - val_loss: 0.5680 - val_accuracy: 0.6893 - val_auc: 0.7718\n",
      "Epoch 372/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5679 - accuracy: 0.7102 - auc: 0.7751 - val_loss: 0.5677 - val_accuracy: 0.6893 - val_auc: 0.7718\n",
      "Epoch 373/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5653 - accuracy: 0.7019 - auc: 0.7767 - val_loss: 0.5677 - val_accuracy: 0.6864 - val_auc: 0.7717\n",
      "Epoch 374/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5687 - accuracy: 0.6972 - auc: 0.7719 - val_loss: 0.5678 - val_accuracy: 0.6834 - val_auc: 0.7718\n",
      "Epoch 375/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5681 - accuracy: 0.7019 - auc: 0.7744 - val_loss: 0.5679 - val_accuracy: 0.6805 - val_auc: 0.7715\n",
      "Epoch 376/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5707 - accuracy: 0.7037 - auc: 0.7752 - val_loss: 0.5682 - val_accuracy: 0.6864 - val_auc: 0.7711\n",
      "Epoch 377/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5665 - accuracy: 0.7056 - auc: 0.7758 - val_loss: 0.5682 - val_accuracy: 0.6864 - val_auc: 0.7709\n",
      "Epoch 378/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5703 - accuracy: 0.7120 - auc: 0.7738 - val_loss: 0.5685 - val_accuracy: 0.6864 - val_auc: 0.7708\n",
      "Epoch 379/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5606 - accuracy: 0.6963 - auc: 0.7797 - val_loss: 0.5680 - val_accuracy: 0.6923 - val_auc: 0.7719\n",
      "Epoch 380/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5553 - accuracy: 0.7093 - auc: 0.7886 - val_loss: 0.5673 - val_accuracy: 0.6893 - val_auc: 0.7725\n",
      "Epoch 381/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5618 - accuracy: 0.7185 - auc: 0.7834 - val_loss: 0.5672 - val_accuracy: 0.6893 - val_auc: 0.7721\n",
      "Epoch 382/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5636 - accuracy: 0.6972 - auc: 0.7805 - val_loss: 0.5671 - val_accuracy: 0.6893 - val_auc: 0.7724\n",
      "Epoch 383/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5648 - accuracy: 0.7139 - auc: 0.7789 - val_loss: 0.5668 - val_accuracy: 0.6893 - val_auc: 0.7725\n",
      "Epoch 384/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5576 - accuracy: 0.7046 - auc: 0.7843 - val_loss: 0.5665 - val_accuracy: 0.6893 - val_auc: 0.7732\n",
      "Epoch 385/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5628 - accuracy: 0.7157 - auc: 0.7802 - val_loss: 0.5668 - val_accuracy: 0.6893 - val_auc: 0.7724\n",
      "Epoch 386/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5630 - accuracy: 0.7000 - auc: 0.7787 - val_loss: 0.5667 - val_accuracy: 0.6864 - val_auc: 0.7726\n",
      "Epoch 387/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5589 - accuracy: 0.7185 - auc: 0.7848 - val_loss: 0.5667 - val_accuracy: 0.6893 - val_auc: 0.7729\n",
      "Epoch 388/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5604 - accuracy: 0.7157 - auc: 0.7837 - val_loss: 0.5665 - val_accuracy: 0.6864 - val_auc: 0.7731\n",
      "Epoch 389/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5664 - accuracy: 0.7102 - auc: 0.7794 - val_loss: 0.5669 - val_accuracy: 0.6864 - val_auc: 0.7726\n",
      "Epoch 390/700\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.5582 - accuracy: 0.7185 - auc: 0.7878 - val_loss: 0.5668 - val_accuracy: 0.6864 - val_auc: 0.7722\n",
      "Epoch 391/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5602 - accuracy: 0.7111 - auc: 0.7812 - val_loss: 0.5671 - val_accuracy: 0.6893 - val_auc: 0.7726\n",
      "Epoch 392/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5564 - accuracy: 0.7083 - auc: 0.7853 - val_loss: 0.5669 - val_accuracy: 0.6834 - val_auc: 0.7725\n",
      "Epoch 393/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5698 - accuracy: 0.6944 - auc: 0.7704 - val_loss: 0.5665 - val_accuracy: 0.6864 - val_auc: 0.7729\n",
      "Epoch 394/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5631 - accuracy: 0.7185 - auc: 0.7804 - val_loss: 0.5666 - val_accuracy: 0.6834 - val_auc: 0.7728\n",
      "Epoch 395/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5667 - accuracy: 0.7139 - auc: 0.7774 - val_loss: 0.5663 - val_accuracy: 0.6864 - val_auc: 0.7731\n",
      "Epoch 396/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5563 - accuracy: 0.7130 - auc: 0.7857 - val_loss: 0.5664 - val_accuracy: 0.6834 - val_auc: 0.7731\n",
      "Epoch 397/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5648 - accuracy: 0.6991 - auc: 0.7753 - val_loss: 0.5669 - val_accuracy: 0.6834 - val_auc: 0.7725\n",
      "Epoch 398/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5596 - accuracy: 0.7083 - auc: 0.7836 - val_loss: 0.5667 - val_accuracy: 0.6834 - val_auc: 0.7725\n",
      "Epoch 399/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5633 - accuracy: 0.7074 - auc: 0.7813 - val_loss: 0.5663 - val_accuracy: 0.6864 - val_auc: 0.7728\n",
      "Epoch 400/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5622 - accuracy: 0.7046 - auc: 0.7794 - val_loss: 0.5661 - val_accuracy: 0.6864 - val_auc: 0.7730\n",
      "Epoch 401/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5628 - accuracy: 0.7074 - auc: 0.7787 - val_loss: 0.5659 - val_accuracy: 0.6864 - val_auc: 0.7737\n",
      "Epoch 402/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5619 - accuracy: 0.7111 - auc: 0.7799 - val_loss: 0.5655 - val_accuracy: 0.6864 - val_auc: 0.7735\n",
      "Epoch 403/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5609 - accuracy: 0.7056 - auc: 0.7799 - val_loss: 0.5651 - val_accuracy: 0.6834 - val_auc: 0.7743\n",
      "Epoch 404/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5694 - accuracy: 0.7028 - auc: 0.7733 - val_loss: 0.5649 - val_accuracy: 0.6834 - val_auc: 0.7747\n",
      "Epoch 405/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5621 - accuracy: 0.7120 - auc: 0.7811 - val_loss: 0.5650 - val_accuracy: 0.6834 - val_auc: 0.7747\n",
      "Epoch 406/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5677 - accuracy: 0.7083 - auc: 0.7742 - val_loss: 0.5654 - val_accuracy: 0.6864 - val_auc: 0.7741\n",
      "Epoch 407/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5683 - accuracy: 0.7028 - auc: 0.7741 - val_loss: 0.5659 - val_accuracy: 0.6893 - val_auc: 0.7738\n",
      "Epoch 408/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5573 - accuracy: 0.7204 - auc: 0.7861 - val_loss: 0.5660 - val_accuracy: 0.6834 - val_auc: 0.7735\n",
      "Epoch 409/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5566 - accuracy: 0.7139 - auc: 0.7905 - val_loss: 0.5665 - val_accuracy: 0.6893 - val_auc: 0.7732\n",
      "Epoch 410/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5608 - accuracy: 0.7130 - auc: 0.7827 - val_loss: 0.5661 - val_accuracy: 0.6893 - val_auc: 0.7734\n",
      "Epoch 411/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5620 - accuracy: 0.7111 - auc: 0.7804 - val_loss: 0.5659 - val_accuracy: 0.6923 - val_auc: 0.7740\n",
      "Epoch 412/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5523 - accuracy: 0.7259 - auc: 0.7933 - val_loss: 0.5655 - val_accuracy: 0.6923 - val_auc: 0.7741\n",
      "Epoch 413/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5673 - accuracy: 0.6991 - auc: 0.7734 - val_loss: 0.5653 - val_accuracy: 0.6893 - val_auc: 0.7746\n",
      "Epoch 414/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5631 - accuracy: 0.7111 - auc: 0.7812 - val_loss: 0.5653 - val_accuracy: 0.6893 - val_auc: 0.7744\n",
      "Epoch 415/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5688 - accuracy: 0.7065 - auc: 0.7746 - val_loss: 0.5652 - val_accuracy: 0.6893 - val_auc: 0.7744\n",
      "Epoch 416/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5622 - accuracy: 0.7009 - auc: 0.7799 - val_loss: 0.5658 - val_accuracy: 0.6893 - val_auc: 0.7736\n",
      "Epoch 417/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5619 - accuracy: 0.7028 - auc: 0.7803 - val_loss: 0.5652 - val_accuracy: 0.6893 - val_auc: 0.7739\n",
      "Epoch 418/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5588 - accuracy: 0.7157 - auc: 0.7838 - val_loss: 0.5650 - val_accuracy: 0.6923 - val_auc: 0.7748\n",
      "Epoch 419/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5624 - accuracy: 0.7111 - auc: 0.7800 - val_loss: 0.5651 - val_accuracy: 0.6923 - val_auc: 0.7742\n",
      "Epoch 420/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5539 - accuracy: 0.7130 - auc: 0.7900 - val_loss: 0.5648 - val_accuracy: 0.6893 - val_auc: 0.7750\n",
      "Epoch 421/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5597 - accuracy: 0.7093 - auc: 0.7829 - val_loss: 0.5659 - val_accuracy: 0.6923 - val_auc: 0.7739\n",
      "Epoch 422/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5600 - accuracy: 0.7130 - auc: 0.7833 - val_loss: 0.5655 - val_accuracy: 0.6893 - val_auc: 0.7746\n",
      "Epoch 423/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5555 - accuracy: 0.7065 - auc: 0.7860 - val_loss: 0.5659 - val_accuracy: 0.6864 - val_auc: 0.7741\n",
      "Epoch 424/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5605 - accuracy: 0.6954 - auc: 0.7821 - val_loss: 0.5654 - val_accuracy: 0.6864 - val_auc: 0.7746\n",
      "Epoch 425/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5629 - accuracy: 0.7046 - auc: 0.7795 - val_loss: 0.5653 - val_accuracy: 0.6864 - val_auc: 0.7745\n",
      "Epoch 426/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5618 - accuracy: 0.7019 - auc: 0.7795 - val_loss: 0.5645 - val_accuracy: 0.6923 - val_auc: 0.7751\n",
      "Epoch 427/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5554 - accuracy: 0.7278 - auc: 0.7900 - val_loss: 0.5644 - val_accuracy: 0.6893 - val_auc: 0.7751\n",
      "Epoch 428/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5583 - accuracy: 0.7065 - auc: 0.7825 - val_loss: 0.5639 - val_accuracy: 0.6864 - val_auc: 0.7754\n",
      "Epoch 429/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5606 - accuracy: 0.7028 - auc: 0.7833 - val_loss: 0.5643 - val_accuracy: 0.6864 - val_auc: 0.7747\n",
      "Epoch 430/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5534 - accuracy: 0.7130 - auc: 0.7883 - val_loss: 0.5640 - val_accuracy: 0.6834 - val_auc: 0.7754\n",
      "Epoch 431/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5706 - accuracy: 0.7074 - auc: 0.7718 - val_loss: 0.5644 - val_accuracy: 0.6834 - val_auc: 0.7746\n",
      "Epoch 432/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5578 - accuracy: 0.6935 - auc: 0.7824 - val_loss: 0.5634 - val_accuracy: 0.6864 - val_auc: 0.7758\n",
      "Epoch 433/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5596 - accuracy: 0.7046 - auc: 0.7827 - val_loss: 0.5633 - val_accuracy: 0.6864 - val_auc: 0.7756\n",
      "Epoch 434/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5615 - accuracy: 0.6991 - auc: 0.7799 - val_loss: 0.5634 - val_accuracy: 0.6805 - val_auc: 0.7754\n",
      "Epoch 435/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5613 - accuracy: 0.7074 - auc: 0.7828 - val_loss: 0.5631 - val_accuracy: 0.6893 - val_auc: 0.7759\n",
      "Epoch 436/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5559 - accuracy: 0.7176 - auc: 0.7870 - val_loss: 0.5630 - val_accuracy: 0.6893 - val_auc: 0.7760\n",
      "Epoch 437/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5627 - accuracy: 0.7046 - auc: 0.7783 - val_loss: 0.5632 - val_accuracy: 0.6923 - val_auc: 0.7758\n",
      "Epoch 438/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5646 - accuracy: 0.7093 - auc: 0.7766 - val_loss: 0.5631 - val_accuracy: 0.6893 - val_auc: 0.7758\n",
      "Epoch 439/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5623 - accuracy: 0.7019 - auc: 0.7793 - val_loss: 0.5634 - val_accuracy: 0.6923 - val_auc: 0.7758\n",
      "Epoch 440/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5688 - accuracy: 0.6954 - auc: 0.7695 - val_loss: 0.5635 - val_accuracy: 0.6953 - val_auc: 0.7758\n",
      "Epoch 441/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5517 - accuracy: 0.7194 - auc: 0.7907 - val_loss: 0.5629 - val_accuracy: 0.6982 - val_auc: 0.7764\n",
      "Epoch 442/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5587 - accuracy: 0.7065 - auc: 0.7829 - val_loss: 0.5627 - val_accuracy: 0.6923 - val_auc: 0.7774\n",
      "Epoch 443/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5680 - accuracy: 0.6991 - auc: 0.7716 - val_loss: 0.5626 - val_accuracy: 0.6923 - val_auc: 0.7769\n",
      "Epoch 444/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5593 - accuracy: 0.7046 - auc: 0.7812 - val_loss: 0.5625 - val_accuracy: 0.6923 - val_auc: 0.7772\n",
      "Epoch 445/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5660 - accuracy: 0.7028 - auc: 0.7743 - val_loss: 0.5631 - val_accuracy: 0.6953 - val_auc: 0.7765\n",
      "Epoch 446/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5666 - accuracy: 0.7111 - auc: 0.7755 - val_loss: 0.5632 - val_accuracy: 0.6923 - val_auc: 0.7765\n",
      "Epoch 447/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5637 - accuracy: 0.7046 - auc: 0.7775 - val_loss: 0.5631 - val_accuracy: 0.6923 - val_auc: 0.7768\n",
      "Epoch 448/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5611 - accuracy: 0.7111 - auc: 0.7822 - val_loss: 0.5630 - val_accuracy: 0.6923 - val_auc: 0.7772\n",
      "Epoch 449/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5598 - accuracy: 0.7093 - auc: 0.7823 - val_loss: 0.5631 - val_accuracy: 0.6953 - val_auc: 0.7770\n",
      "Epoch 450/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5555 - accuracy: 0.6954 - auc: 0.7856 - val_loss: 0.5636 - val_accuracy: 0.6923 - val_auc: 0.7766\n",
      "Epoch 451/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5612 - accuracy: 0.7380 - auc: 0.7882 - val_loss: 0.5625 - val_accuracy: 0.6953 - val_auc: 0.7769\n",
      "Epoch 452/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5537 - accuracy: 0.7204 - auc: 0.7880 - val_loss: 0.5629 - val_accuracy: 0.6953 - val_auc: 0.7766\n",
      "Epoch 453/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5552 - accuracy: 0.6954 - auc: 0.7845 - val_loss: 0.5622 - val_accuracy: 0.6953 - val_auc: 0.7771\n",
      "Epoch 454/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5603 - accuracy: 0.7167 - auc: 0.7826 - val_loss: 0.5620 - val_accuracy: 0.6953 - val_auc: 0.7772\n",
      "Epoch 455/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5659 - accuracy: 0.7083 - auc: 0.7788 - val_loss: 0.5613 - val_accuracy: 0.6953 - val_auc: 0.7778\n",
      "Epoch 456/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5556 - accuracy: 0.7148 - auc: 0.7870 - val_loss: 0.5611 - val_accuracy: 0.6953 - val_auc: 0.7786\n",
      "Epoch 457/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5639 - accuracy: 0.7250 - auc: 0.7800 - val_loss: 0.5611 - val_accuracy: 0.6953 - val_auc: 0.7778\n",
      "Epoch 458/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5556 - accuracy: 0.7148 - auc: 0.7894 - val_loss: 0.5617 - val_accuracy: 0.6923 - val_auc: 0.7775\n",
      "Epoch 459/700\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.5678 - accuracy: 0.7028 - auc: 0.7751 - val_loss: 0.5620 - val_accuracy: 0.6923 - val_auc: 0.7772\n",
      "Epoch 460/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5573 - accuracy: 0.7185 - auc: 0.7841 - val_loss: 0.5621 - val_accuracy: 0.6923 - val_auc: 0.7770\n",
      "Epoch 461/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5465 - accuracy: 0.7056 - auc: 0.7941 - val_loss: 0.5619 - val_accuracy: 0.6923 - val_auc: 0.7773\n",
      "Epoch 462/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5576 - accuracy: 0.7111 - auc: 0.7837 - val_loss: 0.5621 - val_accuracy: 0.6923 - val_auc: 0.7769\n",
      "Epoch 463/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5521 - accuracy: 0.7083 - auc: 0.7894 - val_loss: 0.5617 - val_accuracy: 0.6923 - val_auc: 0.7773\n",
      "Epoch 464/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5643 - accuracy: 0.7111 - auc: 0.7789 - val_loss: 0.5617 - val_accuracy: 0.6923 - val_auc: 0.7774\n",
      "Epoch 465/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5705 - accuracy: 0.7000 - auc: 0.7728 - val_loss: 0.5614 - val_accuracy: 0.6923 - val_auc: 0.7777\n",
      "Epoch 466/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5545 - accuracy: 0.7204 - auc: 0.7893 - val_loss: 0.5614 - val_accuracy: 0.6893 - val_auc: 0.7774\n",
      "Epoch 467/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5641 - accuracy: 0.7074 - auc: 0.7795 - val_loss: 0.5616 - val_accuracy: 0.6923 - val_auc: 0.7777\n",
      "Epoch 468/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5545 - accuracy: 0.7204 - auc: 0.7875 - val_loss: 0.5613 - val_accuracy: 0.6923 - val_auc: 0.7778\n",
      "Epoch 469/700\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.5640 - accuracy: 0.7000 - auc: 0.7752 - val_loss: 0.5606 - val_accuracy: 0.6923 - val_auc: 0.7783\n",
      "Epoch 470/700\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.5601 - accuracy: 0.7204 - auc: 0.7834 - val_loss: 0.5601 - val_accuracy: 0.6923 - val_auc: 0.7790\n",
      "Epoch 471/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5641 - accuracy: 0.7083 - auc: 0.7780 - val_loss: 0.5606 - val_accuracy: 0.6923 - val_auc: 0.7783\n",
      "Epoch 472/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5645 - accuracy: 0.6898 - auc: 0.7739 - val_loss: 0.5604 - val_accuracy: 0.6923 - val_auc: 0.7789\n",
      "Epoch 473/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5626 - accuracy: 0.7037 - auc: 0.7789 - val_loss: 0.5601 - val_accuracy: 0.6923 - val_auc: 0.7795\n",
      "Epoch 474/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5560 - accuracy: 0.7028 - auc: 0.7844 - val_loss: 0.5602 - val_accuracy: 0.6953 - val_auc: 0.7787\n",
      "Epoch 475/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5670 - accuracy: 0.7157 - auc: 0.7757 - val_loss: 0.5607 - val_accuracy: 0.6923 - val_auc: 0.7792\n",
      "Epoch 476/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5607 - accuracy: 0.7139 - auc: 0.7823 - val_loss: 0.5607 - val_accuracy: 0.6923 - val_auc: 0.7791\n",
      "Epoch 477/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5633 - accuracy: 0.7185 - auc: 0.7818 - val_loss: 0.5605 - val_accuracy: 0.6864 - val_auc: 0.7791\n",
      "Epoch 478/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5608 - accuracy: 0.7009 - auc: 0.7793 - val_loss: 0.5607 - val_accuracy: 0.6893 - val_auc: 0.7786\n",
      "Epoch 479/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5708 - accuracy: 0.7037 - auc: 0.7732 - val_loss: 0.5608 - val_accuracy: 0.6893 - val_auc: 0.7788\n",
      "Epoch 480/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5542 - accuracy: 0.7204 - auc: 0.7890 - val_loss: 0.5604 - val_accuracy: 0.6864 - val_auc: 0.7786\n",
      "Epoch 481/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5625 - accuracy: 0.7148 - auc: 0.7796 - val_loss: 0.5605 - val_accuracy: 0.6864 - val_auc: 0.7790\n",
      "Epoch 482/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5623 - accuracy: 0.7009 - auc: 0.7814 - val_loss: 0.5604 - val_accuracy: 0.6923 - val_auc: 0.7790\n",
      "Epoch 483/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5558 - accuracy: 0.7120 - auc: 0.7862 - val_loss: 0.5611 - val_accuracy: 0.6893 - val_auc: 0.7784\n",
      "Epoch 484/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5598 - accuracy: 0.7148 - auc: 0.7849 - val_loss: 0.5610 - val_accuracy: 0.6893 - val_auc: 0.7784\n",
      "Epoch 485/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5604 - accuracy: 0.7093 - auc: 0.7833 - val_loss: 0.5606 - val_accuracy: 0.6864 - val_auc: 0.7791\n",
      "Epoch 486/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5585 - accuracy: 0.7056 - auc: 0.7821 - val_loss: 0.5605 - val_accuracy: 0.6864 - val_auc: 0.7792\n",
      "Epoch 487/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5563 - accuracy: 0.7102 - auc: 0.7867 - val_loss: 0.5607 - val_accuracy: 0.6864 - val_auc: 0.7791\n",
      "Epoch 488/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5635 - accuracy: 0.7046 - auc: 0.7777 - val_loss: 0.5601 - val_accuracy: 0.6953 - val_auc: 0.7792\n",
      "Epoch 489/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5555 - accuracy: 0.6954 - auc: 0.7868 - val_loss: 0.5598 - val_accuracy: 0.6923 - val_auc: 0.7798\n",
      "Epoch 490/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5550 - accuracy: 0.7204 - auc: 0.7880 - val_loss: 0.5605 - val_accuracy: 0.6923 - val_auc: 0.7788\n",
      "Epoch 491/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5471 - accuracy: 0.7176 - auc: 0.7950 - val_loss: 0.5602 - val_accuracy: 0.6923 - val_auc: 0.7796\n",
      "Epoch 492/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5603 - accuracy: 0.7083 - auc: 0.7801 - val_loss: 0.5597 - val_accuracy: 0.6923 - val_auc: 0.7800\n",
      "Epoch 493/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5618 - accuracy: 0.7148 - auc: 0.7796 - val_loss: 0.5598 - val_accuracy: 0.6923 - val_auc: 0.7801\n",
      "Epoch 494/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5638 - accuracy: 0.7037 - auc: 0.7789 - val_loss: 0.5595 - val_accuracy: 0.6953 - val_auc: 0.7801\n",
      "Epoch 495/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5528 - accuracy: 0.7204 - auc: 0.7932 - val_loss: 0.5589 - val_accuracy: 0.6982 - val_auc: 0.7803\n",
      "Epoch 496/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5569 - accuracy: 0.7148 - auc: 0.7863 - val_loss: 0.5591 - val_accuracy: 0.6923 - val_auc: 0.7800\n",
      "Epoch 497/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5640 - accuracy: 0.7111 - auc: 0.7780 - val_loss: 0.5594 - val_accuracy: 0.6953 - val_auc: 0.7797\n",
      "Epoch 498/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5520 - accuracy: 0.7278 - auc: 0.7935 - val_loss: 0.5589 - val_accuracy: 0.6982 - val_auc: 0.7806\n",
      "Epoch 499/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5485 - accuracy: 0.7269 - auc: 0.7944 - val_loss: 0.5588 - val_accuracy: 0.6982 - val_auc: 0.7809\n",
      "Epoch 500/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5554 - accuracy: 0.7130 - auc: 0.7865 - val_loss: 0.5590 - val_accuracy: 0.6982 - val_auc: 0.7809\n",
      "Epoch 501/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5553 - accuracy: 0.7111 - auc: 0.7876 - val_loss: 0.5587 - val_accuracy: 0.6982 - val_auc: 0.7813\n",
      "Epoch 502/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5499 - accuracy: 0.7278 - auc: 0.7920 - val_loss: 0.5583 - val_accuracy: 0.6982 - val_auc: 0.7813\n",
      "Epoch 503/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5510 - accuracy: 0.7074 - auc: 0.7891 - val_loss: 0.5576 - val_accuracy: 0.6953 - val_auc: 0.7822\n",
      "Epoch 504/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5601 - accuracy: 0.7250 - auc: 0.7849 - val_loss: 0.5574 - val_accuracy: 0.6982 - val_auc: 0.7825\n",
      "Epoch 505/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5609 - accuracy: 0.7074 - auc: 0.7813 - val_loss: 0.5574 - val_accuracy: 0.7012 - val_auc: 0.7825\n",
      "Epoch 506/700\n",
      "17/17 [==============================] - 0s 24ms/step - loss: 0.5624 - accuracy: 0.7009 - auc: 0.7780 - val_loss: 0.5570 - val_accuracy: 0.6953 - val_auc: 0.7825\n",
      "Epoch 507/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5529 - accuracy: 0.7083 - auc: 0.7886 - val_loss: 0.5571 - val_accuracy: 0.6982 - val_auc: 0.7826\n",
      "Epoch 508/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5547 - accuracy: 0.7259 - auc: 0.7891 - val_loss: 0.5576 - val_accuracy: 0.6953 - val_auc: 0.7817\n",
      "Epoch 509/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5609 - accuracy: 0.7083 - auc: 0.7797 - val_loss: 0.5580 - val_accuracy: 0.6923 - val_auc: 0.7813\n",
      "Epoch 510/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5621 - accuracy: 0.7037 - auc: 0.7783 - val_loss: 0.5577 - val_accuracy: 0.6923 - val_auc: 0.7814\n",
      "Epoch 511/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5537 - accuracy: 0.7278 - auc: 0.7899 - val_loss: 0.5584 - val_accuracy: 0.6923 - val_auc: 0.7807\n",
      "Epoch 512/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5523 - accuracy: 0.7176 - auc: 0.7895 - val_loss: 0.5581 - val_accuracy: 0.7012 - val_auc: 0.7812\n",
      "Epoch 513/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5619 - accuracy: 0.7093 - auc: 0.7796 - val_loss: 0.5579 - val_accuracy: 0.6982 - val_auc: 0.7816\n",
      "Epoch 514/700\n",
      "17/17 [==============================] - 0s 23ms/step - loss: 0.5623 - accuracy: 0.7120 - auc: 0.7801 - val_loss: 0.5580 - val_accuracy: 0.6923 - val_auc: 0.7812\n",
      "Epoch 515/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5511 - accuracy: 0.7213 - auc: 0.7936 - val_loss: 0.5587 - val_accuracy: 0.7012 - val_auc: 0.7805\n",
      "Epoch 516/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5481 - accuracy: 0.7204 - auc: 0.7956 - val_loss: 0.5583 - val_accuracy: 0.7012 - val_auc: 0.7810\n",
      "Epoch 517/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5507 - accuracy: 0.7176 - auc: 0.7930 - val_loss: 0.5580 - val_accuracy: 0.7012 - val_auc: 0.7811\n",
      "Epoch 518/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5552 - accuracy: 0.7028 - auc: 0.7862 - val_loss: 0.5580 - val_accuracy: 0.7012 - val_auc: 0.7812\n",
      "Epoch 519/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5484 - accuracy: 0.7231 - auc: 0.7958 - val_loss: 0.5582 - val_accuracy: 0.7012 - val_auc: 0.7808\n",
      "Epoch 520/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5570 - accuracy: 0.7120 - auc: 0.7862 - val_loss: 0.5584 - val_accuracy: 0.7012 - val_auc: 0.7808\n",
      "Epoch 521/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5680 - accuracy: 0.7130 - auc: 0.7752 - val_loss: 0.5581 - val_accuracy: 0.7012 - val_auc: 0.7810\n",
      "Epoch 522/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5605 - accuracy: 0.7139 - auc: 0.7815 - val_loss: 0.5577 - val_accuracy: 0.7012 - val_auc: 0.7816\n",
      "Epoch 523/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5613 - accuracy: 0.7019 - auc: 0.7802 - val_loss: 0.5574 - val_accuracy: 0.7012 - val_auc: 0.7818\n",
      "Epoch 524/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5524 - accuracy: 0.7083 - auc: 0.7906 - val_loss: 0.5577 - val_accuracy: 0.7012 - val_auc: 0.7817\n",
      "Epoch 525/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5552 - accuracy: 0.7157 - auc: 0.7861 - val_loss: 0.5580 - val_accuracy: 0.7012 - val_auc: 0.7814\n",
      "Epoch 526/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5577 - accuracy: 0.7176 - auc: 0.7852 - val_loss: 0.5584 - val_accuracy: 0.6982 - val_auc: 0.7810\n",
      "Epoch 527/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5572 - accuracy: 0.7204 - auc: 0.7878 - val_loss: 0.5582 - val_accuracy: 0.7012 - val_auc: 0.7816\n",
      "Epoch 528/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5579 - accuracy: 0.7065 - auc: 0.7852 - val_loss: 0.5573 - val_accuracy: 0.7012 - val_auc: 0.7821\n",
      "Epoch 529/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5563 - accuracy: 0.7231 - auc: 0.7880 - val_loss: 0.5573 - val_accuracy: 0.7012 - val_auc: 0.7824\n",
      "Epoch 530/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5463 - accuracy: 0.7176 - auc: 0.7948 - val_loss: 0.5576 - val_accuracy: 0.7012 - val_auc: 0.7823\n",
      "Epoch 531/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5510 - accuracy: 0.7157 - auc: 0.7896 - val_loss: 0.5572 - val_accuracy: 0.7012 - val_auc: 0.7824\n",
      "Epoch 532/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5577 - accuracy: 0.7102 - auc: 0.7833 - val_loss: 0.5575 - val_accuracy: 0.7012 - val_auc: 0.7820\n",
      "Epoch 533/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5470 - accuracy: 0.7111 - auc: 0.7926 - val_loss: 0.5577 - val_accuracy: 0.7012 - val_auc: 0.7815\n",
      "Epoch 534/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5521 - accuracy: 0.7102 - auc: 0.7875 - val_loss: 0.5572 - val_accuracy: 0.7012 - val_auc: 0.7824\n",
      "Epoch 535/700\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.5518 - accuracy: 0.7231 - auc: 0.7894 - val_loss: 0.5575 - val_accuracy: 0.7041 - val_auc: 0.7818\n",
      "Epoch 536/700\n",
      "17/17 [==============================] - 0s 21ms/step - loss: 0.5577 - accuracy: 0.7241 - auc: 0.7849 - val_loss: 0.5582 - val_accuracy: 0.7012 - val_auc: 0.7806\n",
      "Epoch 00536: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('sad_ravdess.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1596118339512,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ddcJYxjpRmou"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('sad_ravdess.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1596118351484,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "w4snlhBmRqz8"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_predictions_baseline = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1596118360564,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1596118371920,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "59978a13-0a42-49ca-ba36-df79deef2436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5569942593574524\n",
      "accuracy :  0.6952662467956543\n",
      "auc :  0.7824787497520447\n",
      "\n",
      "(True Negatives):  153\n",
      "(False Positives):  70\n",
      "(False Negatives):  33\n",
      "(True Positives):  82\n",
      "Total emotions_happy:  115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75       223\n",
      "           1       0.54      0.71      0.61       115\n",
      "\n",
      "    accuracy                           0.70       338\n",
      "   macro avg       0.68      0.70      0.68       338\n",
      "weighted avg       0.73      0.70      0.70       338\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1596118412874,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "GJk2L3O8ImIn"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1596118426680,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "84ddcb35-8b1b-44ea-fcef-6a1f7f4b584c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5233929753303528\n",
      "accuracy :  0.7111111283302307\n",
      "auc :  0.8225171566009521\n",
      "\n",
      "(True Negatives):  132\n",
      "(False Positives):  48\n",
      "(False Negatives):  30\n",
      "(True Positives):  60\n",
      "Total emotions_happy:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       180\n",
      "           1       0.56      0.67      0.61        90\n",
      "\n",
      "    accuracy                           0.71       270\n",
      "   macro avg       0.69      0.70      0.69       270\n",
      "weighted avg       0.73      0.71      0.72       270\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNGfgseg0Dq1ehb/EMAVBPq",
   "name": "deep_sad_RAVDESS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
