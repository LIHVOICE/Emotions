{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9TmOS9AFg61"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12281,
     "status": "ok",
     "timestamp": 1598276310467,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "6c860c33-a0e6-46dc-dee5-7fb10d778574"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disgust/03-01-07-01-01-02-18_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad/03-01-04-01-02-01-09_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry/03-01-05-01-02-02-17_norm_outNoise.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy/03-01-03-01-01-01-15_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprised/03-01-08-01-02-02-07_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              audio label\n",
       "0    disgust/03-01-07-01-01-02-18_norm_outNoise.wav     0\n",
       "1        sad/03-01-04-01-02-01-09_norm_outNoise.wav     0\n",
       "2      angry/03-01-05-01-02-02-17_norm_outNoise.wav     1\n",
       "3      happy/03-01-03-01-01-01-15_norm_outNoise.wav     0\n",
       "4  surprised/03-01-08-01-02-02-07_norm_outNoise.wav     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "parent_dir = \"audio_emotion\"\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i[7] == '5':\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) # here at df defined, with the columns we add the values:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1598277264908,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "47435ecc-c2f6-44b2-d206-d9464541ed5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1053\n",
      "1     192\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tIXIHetGwKcQ"
   },
   "source": [
    "Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybQ8GfGIqkwp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "def get_all_features(audio_file):\n",
    " \n",
    "  x, sample_rate = librosa.load(audio_file)\n",
    "  ## Numpy array that will store all the features\n",
    "  result=np.array([])\n",
    "        \n",
    "        ## MFCCs\n",
    "  mfccs=np.mean(librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "  result=np.hstack((result, mfccs))\n",
    "\n",
    "          ## Mel Scale\n",
    "  mel=np.mean(librosa.feature.melspectrogram(x, sr=sample_rate).T,axis=0)\n",
    "  result=np.hstack((result, mel))\n",
    "\n",
    "        \n",
    "        ## Chroma\n",
    "  stft=np.abs(librosa.stft(x))\n",
    "  chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "  result=np.hstack((result, chroma))\n",
    "        \n",
    " \n",
    "        ##contrast\n",
    "  contrast=np.mean(librosa.feature.spectral_contrast( S = stft, sr=sample_rate).T,axis=0)\n",
    "  result=np.hstack((result, contrast))\n",
    "\n",
    "## tonnetz\n",
    "  y = librosa.effects.harmonic(x)\n",
    "  tonnetz=np.mean(librosa.feature.tonnetz(y, sr=sample_rate).T,axis=0)\n",
    "  result=np.hstack((result,  tonnetz))\n",
    "\n",
    "    \n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "folder ='audio_emotion'\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = get_all_features(folder+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1598278801579,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "e073d9fa-c959-4476-a4f5-45496e2306b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 999,
     "status": "ok",
     "timestamp": 1598279088918,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "03c3b8a3-b404-4be3-d36c-e6763b6a0343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 649\n",
      "After OverSampling, counts of label '0': 1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1598280484154,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "7f9c2fdf-a4fb-4bb9-cf1d-6663f097a014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088\n",
      "341\n",
      "273\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1431,
     "status": "ok",
     "timestamp": 1598280830108,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "TWis1PUVfK_4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Plot imports ###\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "### Warning ###\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1598280866958,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1598280879305,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "6629d924-c575-4990-f03f-62dfd793949f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1088, 193, 1)\n",
      "(341, 193, 1)\n",
      "(273, 193, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1598280915902,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "9361acce-21ee-4ae5-b26a-9e520ae42b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1088, 2)\n",
      "(341, 2)\n",
      "(273, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1598280955511,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (193,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 961,
     "status": "ok",
     "timestamp": 1598280960807,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "a919503b-55d6-4c7b-b516-d3e4df7c045b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 193, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 193, 128)          768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 193, 128)          512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 193, 128)          0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 193, 128)          0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 193, 128)          82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 24704)             0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 24704)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 49410     \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 132,746\n",
      "Trainable params: 132,486\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## First LFLB (local feature learning block)\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1598280972277,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56000,
     "status": "ok",
     "timestamp": 1598281064071,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "3da8edd8-3f2b-4e29-b6fe-891eb69f6238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.8714 - accuracy: 0.4789 - auc: 0.4897 - val_loss: 0.6812 - val_accuracy: 0.5249 - val_auc: 0.5862\n",
      "Epoch 2/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.6094 - auc: 0.6566 - val_loss: 0.6645 - val_accuracy: 0.5806 - val_auc: 0.6534\n",
      "Epoch 3/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.6075 - accuracy: 0.6728 - auc: 0.7328 - val_loss: 0.6518 - val_accuracy: 0.6276 - val_auc: 0.6927\n",
      "Epoch 4/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5597 - accuracy: 0.7132 - auc: 0.7827 - val_loss: 0.6415 - val_accuracy: 0.6276 - val_auc: 0.7139\n",
      "Epoch 5/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5157 - accuracy: 0.7748 - auc: 0.8304 - val_loss: 0.6342 - val_accuracy: 0.6364 - val_auc: 0.7216\n",
      "Epoch 6/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4891 - accuracy: 0.7803 - auc: 0.8512 - val_loss: 0.6270 - val_accuracy: 0.6393 - val_auc: 0.7295\n",
      "Epoch 7/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4616 - accuracy: 0.7950 - auc: 0.8720 - val_loss: 0.6219 - val_accuracy: 0.6364 - val_auc: 0.7322\n",
      "Epoch 8/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4532 - accuracy: 0.8116 - auc: 0.8797 - val_loss: 0.6152 - val_accuracy: 0.6422 - val_auc: 0.7391\n",
      "Epoch 9/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4412 - accuracy: 0.8125 - auc: 0.8872 - val_loss: 0.6091 - val_accuracy: 0.6481 - val_auc: 0.7433\n",
      "Epoch 10/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4255 - accuracy: 0.8208 - auc: 0.8973 - val_loss: 0.6031 - val_accuracy: 0.6510 - val_auc: 0.7498\n",
      "Epoch 11/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4150 - accuracy: 0.8180 - auc: 0.9036 - val_loss: 0.5975 - val_accuracy: 0.6510 - val_auc: 0.7537\n",
      "Epoch 12/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4124 - accuracy: 0.8254 - auc: 0.9033 - val_loss: 0.5887 - val_accuracy: 0.6569 - val_auc: 0.7649\n",
      "Epoch 13/700\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4026 - accuracy: 0.8318 - auc: 0.9124 - val_loss: 0.5855 - val_accuracy: 0.6598 - val_auc: 0.7653\n",
      "Epoch 14/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3861 - accuracy: 0.8392 - auc: 0.9240 - val_loss: 0.5774 - val_accuracy: 0.6657 - val_auc: 0.7737\n",
      "Epoch 15/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3789 - accuracy: 0.8428 - auc: 0.9258 - val_loss: 0.5711 - val_accuracy: 0.6686 - val_auc: 0.7801\n",
      "Epoch 16/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3836 - accuracy: 0.8447 - auc: 0.9235 - val_loss: 0.5617 - val_accuracy: 0.6862 - val_auc: 0.7896\n",
      "Epoch 17/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3746 - accuracy: 0.8401 - auc: 0.9294 - val_loss: 0.5542 - val_accuracy: 0.6862 - val_auc: 0.7973\n",
      "Epoch 18/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3775 - accuracy: 0.8575 - auc: 0.9287 - val_loss: 0.5464 - val_accuracy: 0.6921 - val_auc: 0.8031\n",
      "Epoch 19/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3560 - accuracy: 0.8778 - auc: 0.9385 - val_loss: 0.5388 - val_accuracy: 0.6950 - val_auc: 0.8111\n",
      "Epoch 20/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3663 - accuracy: 0.8557 - auc: 0.9332 - val_loss: 0.5313 - val_accuracy: 0.6950 - val_auc: 0.8171\n",
      "Epoch 21/700\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.3648 - accuracy: 0.8511 - auc: 0.9318 - val_loss: 0.5236 - val_accuracy: 0.7097 - val_auc: 0.8237\n",
      "Epoch 22/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3619 - accuracy: 0.8658 - auc: 0.9337 - val_loss: 0.5125 - val_accuracy: 0.7155 - val_auc: 0.8332\n",
      "Epoch 23/700\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.3532 - accuracy: 0.8686 - auc: 0.9387 - val_loss: 0.5008 - val_accuracy: 0.7449 - val_auc: 0.8431\n",
      "Epoch 24/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3526 - accuracy: 0.8759 - auc: 0.9400 - val_loss: 0.4903 - val_accuracy: 0.7478 - val_auc: 0.8513\n",
      "Epoch 25/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3515 - accuracy: 0.8722 - auc: 0.9397 - val_loss: 0.4821 - val_accuracy: 0.7566 - val_auc: 0.8573\n",
      "Epoch 26/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3521 - accuracy: 0.8640 - auc: 0.9379 - val_loss: 0.4726 - val_accuracy: 0.7537 - val_auc: 0.8643\n",
      "Epoch 27/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3505 - accuracy: 0.8603 - auc: 0.9402 - val_loss: 0.4608 - val_accuracy: 0.7625 - val_auc: 0.8727\n",
      "Epoch 28/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3419 - accuracy: 0.8750 - auc: 0.9470 - val_loss: 0.4544 - val_accuracy: 0.7771 - val_auc: 0.8778\n",
      "Epoch 29/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3397 - accuracy: 0.8750 - auc: 0.9472 - val_loss: 0.4462 - val_accuracy: 0.7801 - val_auc: 0.8840\n",
      "Epoch 30/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3395 - accuracy: 0.8686 - auc: 0.9465 - val_loss: 0.4407 - val_accuracy: 0.7801 - val_auc: 0.8862\n",
      "Epoch 31/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3363 - accuracy: 0.8796 - auc: 0.9482 - val_loss: 0.4347 - val_accuracy: 0.7918 - val_auc: 0.8903\n",
      "Epoch 32/700\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3429 - accuracy: 0.8704 - auc: 0.9440 - val_loss: 0.4308 - val_accuracy: 0.7889 - val_auc: 0.8925\n",
      "Epoch 33/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3359 - accuracy: 0.8759 - auc: 0.9482 - val_loss: 0.4248 - val_accuracy: 0.7918 - val_auc: 0.8965\n",
      "Epoch 34/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3251 - accuracy: 0.8787 - auc: 0.9546 - val_loss: 0.4208 - val_accuracy: 0.7918 - val_auc: 0.8987\n",
      "Epoch 35/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3274 - accuracy: 0.8915 - auc: 0.9520 - val_loss: 0.4151 - val_accuracy: 0.8006 - val_auc: 0.9022\n",
      "Epoch 36/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3262 - accuracy: 0.8796 - auc: 0.9535 - val_loss: 0.4126 - val_accuracy: 0.7918 - val_auc: 0.9029\n",
      "Epoch 37/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3337 - accuracy: 0.8759 - auc: 0.9485 - val_loss: 0.4065 - val_accuracy: 0.8065 - val_auc: 0.9066\n",
      "Epoch 38/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3286 - accuracy: 0.8759 - auc: 0.9526 - val_loss: 0.4042 - val_accuracy: 0.8035 - val_auc: 0.9081\n",
      "Epoch 39/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3253 - accuracy: 0.8842 - auc: 0.9529 - val_loss: 0.4018 - val_accuracy: 0.8065 - val_auc: 0.9092\n",
      "Epoch 40/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3219 - accuracy: 0.8851 - auc: 0.9552 - val_loss: 0.4003 - val_accuracy: 0.8065 - val_auc: 0.9097\n",
      "Epoch 41/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3178 - accuracy: 0.8961 - auc: 0.9575 - val_loss: 0.3984 - val_accuracy: 0.8094 - val_auc: 0.9106\n",
      "Epoch 42/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3128 - accuracy: 0.9035 - auc: 0.9617 - val_loss: 0.3938 - val_accuracy: 0.8182 - val_auc: 0.9141\n",
      "Epoch 43/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3188 - accuracy: 0.8906 - auc: 0.9581 - val_loss: 0.3927 - val_accuracy: 0.8152 - val_auc: 0.9148\n",
      "Epoch 44/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3204 - accuracy: 0.8943 - auc: 0.9553 - val_loss: 0.3915 - val_accuracy: 0.8152 - val_auc: 0.9154\n",
      "Epoch 45/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3098 - accuracy: 0.9026 - auc: 0.9622 - val_loss: 0.3894 - val_accuracy: 0.8211 - val_auc: 0.9164\n",
      "Epoch 46/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3124 - accuracy: 0.8961 - auc: 0.9586 - val_loss: 0.3882 - val_accuracy: 0.8211 - val_auc: 0.9173\n",
      "Epoch 47/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3000 - accuracy: 0.9136 - auc: 0.9665 - val_loss: 0.3878 - val_accuracy: 0.8240 - val_auc: 0.9174\n",
      "Epoch 48/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3041 - accuracy: 0.9026 - auc: 0.9643 - val_loss: 0.3881 - val_accuracy: 0.8299 - val_auc: 0.9174\n",
      "Epoch 49/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3091 - accuracy: 0.9053 - auc: 0.9622 - val_loss: 0.3867 - val_accuracy: 0.8299 - val_auc: 0.9178\n",
      "Epoch 50/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3022 - accuracy: 0.9035 - auc: 0.9649 - val_loss: 0.3849 - val_accuracy: 0.8270 - val_auc: 0.9189\n",
      "Epoch 51/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3066 - accuracy: 0.8961 - auc: 0.9633 - val_loss: 0.3868 - val_accuracy: 0.8240 - val_auc: 0.9173\n",
      "Epoch 52/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3030 - accuracy: 0.8989 - auc: 0.9657 - val_loss: 0.3853 - val_accuracy: 0.8240 - val_auc: 0.9181\n",
      "Epoch 53/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3068 - accuracy: 0.9035 - auc: 0.9640 - val_loss: 0.3859 - val_accuracy: 0.8240 - val_auc: 0.9175\n",
      "Epoch 54/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.3042 - accuracy: 0.9026 - auc: 0.9642 - val_loss: 0.3848 - val_accuracy: 0.8299 - val_auc: 0.9179\n",
      "Epoch 55/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2965 - accuracy: 0.8998 - auc: 0.9673 - val_loss: 0.3862 - val_accuracy: 0.8299 - val_auc: 0.9173\n",
      "Epoch 56/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3047 - accuracy: 0.9017 - auc: 0.9642 - val_loss: 0.3867 - val_accuracy: 0.8270 - val_auc: 0.9173\n",
      "Epoch 57/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3102 - accuracy: 0.8915 - auc: 0.9593 - val_loss: 0.3868 - val_accuracy: 0.8240 - val_auc: 0.9170\n",
      "Epoch 58/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2963 - accuracy: 0.8961 - auc: 0.9680 - val_loss: 0.3850 - val_accuracy: 0.8270 - val_auc: 0.9183\n",
      "Epoch 59/700\n",
      "17/17 [==============================] - 0s 20ms/step - loss: 0.3037 - accuracy: 0.9017 - auc: 0.9646 - val_loss: 0.3840 - val_accuracy: 0.8299 - val_auc: 0.9183\n",
      "Epoch 60/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2977 - accuracy: 0.9127 - auc: 0.9691 - val_loss: 0.3852 - val_accuracy: 0.8299 - val_auc: 0.9177\n",
      "Epoch 61/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3024 - accuracy: 0.9053 - auc: 0.9641 - val_loss: 0.3840 - val_accuracy: 0.8358 - val_auc: 0.9180\n",
      "Epoch 62/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2893 - accuracy: 0.9228 - auc: 0.9726 - val_loss: 0.3830 - val_accuracy: 0.8358 - val_auc: 0.9188\n",
      "Epoch 63/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2946 - accuracy: 0.9072 - auc: 0.9687 - val_loss: 0.3832 - val_accuracy: 0.8270 - val_auc: 0.9190\n",
      "Epoch 64/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2944 - accuracy: 0.8943 - auc: 0.9682 - val_loss: 0.3809 - val_accuracy: 0.8270 - val_auc: 0.9202\n",
      "Epoch 65/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2937 - accuracy: 0.9108 - auc: 0.9678 - val_loss: 0.3799 - val_accuracy: 0.8299 - val_auc: 0.9207\n",
      "Epoch 66/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2821 - accuracy: 0.9228 - auc: 0.9733 - val_loss: 0.3797 - val_accuracy: 0.8358 - val_auc: 0.9212\n",
      "Epoch 67/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2915 - accuracy: 0.9062 - auc: 0.9690 - val_loss: 0.3796 - val_accuracy: 0.8358 - val_auc: 0.9207\n",
      "Epoch 68/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2978 - accuracy: 0.9053 - auc: 0.9682 - val_loss: 0.3785 - val_accuracy: 0.8358 - val_auc: 0.9210\n",
      "Epoch 69/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3006 - accuracy: 0.9007 - auc: 0.9654 - val_loss: 0.3781 - val_accuracy: 0.8387 - val_auc: 0.9209\n",
      "Epoch 70/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2927 - accuracy: 0.9081 - auc: 0.9684 - val_loss: 0.3774 - val_accuracy: 0.8328 - val_auc: 0.9214\n",
      "Epoch 71/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2918 - accuracy: 0.9136 - auc: 0.9687 - val_loss: 0.3782 - val_accuracy: 0.8358 - val_auc: 0.9206\n",
      "Epoch 72/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2960 - accuracy: 0.9044 - auc: 0.9655 - val_loss: 0.3782 - val_accuracy: 0.8299 - val_auc: 0.9211\n",
      "Epoch 73/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2760 - accuracy: 0.9283 - auc: 0.9772 - val_loss: 0.3796 - val_accuracy: 0.8299 - val_auc: 0.9207\n",
      "Epoch 74/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2865 - accuracy: 0.9173 - auc: 0.9717 - val_loss: 0.3774 - val_accuracy: 0.8358 - val_auc: 0.9213\n",
      "Epoch 75/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2843 - accuracy: 0.9210 - auc: 0.9725 - val_loss: 0.3778 - val_accuracy: 0.8299 - val_auc: 0.9210\n",
      "Epoch 76/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2878 - accuracy: 0.9118 - auc: 0.9696 - val_loss: 0.3783 - val_accuracy: 0.8328 - val_auc: 0.9207\n",
      "Epoch 77/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2817 - accuracy: 0.9127 - auc: 0.9742 - val_loss: 0.3788 - val_accuracy: 0.8328 - val_auc: 0.9205\n",
      "Epoch 78/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2855 - accuracy: 0.9099 - auc: 0.9724 - val_loss: 0.3791 - val_accuracy: 0.8299 - val_auc: 0.9204\n",
      "Epoch 79/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2830 - accuracy: 0.9228 - auc: 0.9724 - val_loss: 0.3793 - val_accuracy: 0.8240 - val_auc: 0.9204\n",
      "Epoch 80/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2811 - accuracy: 0.9191 - auc: 0.9761 - val_loss: 0.3770 - val_accuracy: 0.8299 - val_auc: 0.9216\n",
      "Epoch 81/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2830 - accuracy: 0.9200 - auc: 0.9736 - val_loss: 0.3763 - val_accuracy: 0.8299 - val_auc: 0.9221\n",
      "Epoch 82/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2806 - accuracy: 0.9200 - auc: 0.9745 - val_loss: 0.3755 - val_accuracy: 0.8270 - val_auc: 0.9224\n",
      "Epoch 83/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2841 - accuracy: 0.9210 - auc: 0.9717 - val_loss: 0.3759 - val_accuracy: 0.8299 - val_auc: 0.9229\n",
      "Epoch 84/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2831 - accuracy: 0.9090 - auc: 0.9739 - val_loss: 0.3763 - val_accuracy: 0.8299 - val_auc: 0.9221\n",
      "Epoch 85/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2809 - accuracy: 0.9145 - auc: 0.9737 - val_loss: 0.3775 - val_accuracy: 0.8270 - val_auc: 0.9215\n",
      "Epoch 86/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2850 - accuracy: 0.9136 - auc: 0.9725 - val_loss: 0.3752 - val_accuracy: 0.8299 - val_auc: 0.9228\n",
      "Epoch 87/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2814 - accuracy: 0.9200 - auc: 0.9726 - val_loss: 0.3755 - val_accuracy: 0.8387 - val_auc: 0.9228\n",
      "Epoch 88/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2826 - accuracy: 0.9108 - auc: 0.9731 - val_loss: 0.3739 - val_accuracy: 0.8387 - val_auc: 0.9235\n",
      "Epoch 89/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2857 - accuracy: 0.9182 - auc: 0.9708 - val_loss: 0.3752 - val_accuracy: 0.8387 - val_auc: 0.9224\n",
      "Epoch 90/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2745 - accuracy: 0.9274 - auc: 0.9783 - val_loss: 0.3762 - val_accuracy: 0.8358 - val_auc: 0.9216\n",
      "Epoch 91/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2705 - accuracy: 0.9246 - auc: 0.9793 - val_loss: 0.3760 - val_accuracy: 0.8358 - val_auc: 0.9217\n",
      "Epoch 92/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2756 - accuracy: 0.9219 - auc: 0.9776 - val_loss: 0.3778 - val_accuracy: 0.8358 - val_auc: 0.9208\n",
      "Epoch 93/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2793 - accuracy: 0.9200 - auc: 0.9762 - val_loss: 0.3771 - val_accuracy: 0.8387 - val_auc: 0.9206\n",
      "Epoch 94/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2721 - accuracy: 0.9228 - auc: 0.9790 - val_loss: 0.3782 - val_accuracy: 0.8358 - val_auc: 0.9203\n",
      "Epoch 95/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2728 - accuracy: 0.9256 - auc: 0.9773 - val_loss: 0.3786 - val_accuracy: 0.8387 - val_auc: 0.9202\n",
      "Epoch 96/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2770 - accuracy: 0.9219 - auc: 0.9757 - val_loss: 0.3763 - val_accuracy: 0.8387 - val_auc: 0.9213\n",
      "Epoch 97/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2759 - accuracy: 0.9274 - auc: 0.9760 - val_loss: 0.3767 - val_accuracy: 0.8358 - val_auc: 0.9206\n",
      "Epoch 98/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2782 - accuracy: 0.9136 - auc: 0.9749 - val_loss: 0.3751 - val_accuracy: 0.8328 - val_auc: 0.9217\n",
      "Epoch 99/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2698 - accuracy: 0.9274 - auc: 0.9794 - val_loss: 0.3765 - val_accuracy: 0.8299 - val_auc: 0.9210\n",
      "Epoch 100/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2760 - accuracy: 0.9237 - auc: 0.9762 - val_loss: 0.3759 - val_accuracy: 0.8328 - val_auc: 0.9206\n",
      "Epoch 101/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2731 - accuracy: 0.9246 - auc: 0.9770 - val_loss: 0.3755 - val_accuracy: 0.8328 - val_auc: 0.9213\n",
      "Epoch 102/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2690 - accuracy: 0.9301 - auc: 0.9792 - val_loss: 0.3752 - val_accuracy: 0.8358 - val_auc: 0.9212\n",
      "Epoch 103/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2718 - accuracy: 0.9265 - auc: 0.9778 - val_loss: 0.3746 - val_accuracy: 0.8358 - val_auc: 0.9219\n",
      "Epoch 104/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2757 - accuracy: 0.9228 - auc: 0.9772 - val_loss: 0.3754 - val_accuracy: 0.8387 - val_auc: 0.9210\n",
      "Epoch 105/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2715 - accuracy: 0.9301 - auc: 0.9784 - val_loss: 0.3738 - val_accuracy: 0.8387 - val_auc: 0.9223\n",
      "Epoch 106/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2663 - accuracy: 0.9246 - auc: 0.9795 - val_loss: 0.3737 - val_accuracy: 0.8387 - val_auc: 0.9222\n",
      "Epoch 107/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2668 - accuracy: 0.9320 - auc: 0.9817 - val_loss: 0.3736 - val_accuracy: 0.8416 - val_auc: 0.9222\n",
      "Epoch 108/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2722 - accuracy: 0.9164 - auc: 0.9761 - val_loss: 0.3726 - val_accuracy: 0.8416 - val_auc: 0.9227\n",
      "Epoch 109/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2688 - accuracy: 0.9320 - auc: 0.9782 - val_loss: 0.3721 - val_accuracy: 0.8387 - val_auc: 0.9231\n",
      "Epoch 110/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2699 - accuracy: 0.9246 - auc: 0.9795 - val_loss: 0.3714 - val_accuracy: 0.8416 - val_auc: 0.9235\n",
      "Epoch 111/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2701 - accuracy: 0.9283 - auc: 0.9782 - val_loss: 0.3726 - val_accuracy: 0.8416 - val_auc: 0.9233\n",
      "Epoch 112/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2687 - accuracy: 0.9283 - auc: 0.9797 - val_loss: 0.3729 - val_accuracy: 0.8475 - val_auc: 0.9225\n",
      "Epoch 113/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2690 - accuracy: 0.9191 - auc: 0.9784 - val_loss: 0.3703 - val_accuracy: 0.8446 - val_auc: 0.9241\n",
      "Epoch 114/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2640 - accuracy: 0.9311 - auc: 0.9822 - val_loss: 0.3702 - val_accuracy: 0.8446 - val_auc: 0.9242\n",
      "Epoch 115/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2641 - accuracy: 0.9265 - auc: 0.9816 - val_loss: 0.3703 - val_accuracy: 0.8446 - val_auc: 0.9243\n",
      "Epoch 116/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2690 - accuracy: 0.9246 - auc: 0.9775 - val_loss: 0.3709 - val_accuracy: 0.8446 - val_auc: 0.9242\n",
      "Epoch 117/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2739 - accuracy: 0.9228 - auc: 0.9781 - val_loss: 0.3698 - val_accuracy: 0.8416 - val_auc: 0.9243\n",
      "Epoch 118/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2619 - accuracy: 0.9338 - auc: 0.9818 - val_loss: 0.3708 - val_accuracy: 0.8446 - val_auc: 0.9242\n",
      "Epoch 119/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2668 - accuracy: 0.9237 - auc: 0.9799 - val_loss: 0.3708 - val_accuracy: 0.8475 - val_auc: 0.9243\n",
      "Epoch 120/700\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2679 - accuracy: 0.9219 - auc: 0.9791 - val_loss: 0.3698 - val_accuracy: 0.8416 - val_auc: 0.9249\n",
      "Epoch 121/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2625 - accuracy: 0.9347 - auc: 0.9818 - val_loss: 0.3689 - val_accuracy: 0.8446 - val_auc: 0.9252\n",
      "Epoch 122/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2666 - accuracy: 0.9375 - auc: 0.9807 - val_loss: 0.3686 - val_accuracy: 0.8504 - val_auc: 0.9256\n",
      "Epoch 123/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2681 - accuracy: 0.9182 - auc: 0.9797 - val_loss: 0.3705 - val_accuracy: 0.8504 - val_auc: 0.9247\n",
      "Epoch 124/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2618 - accuracy: 0.9219 - auc: 0.9815 - val_loss: 0.3700 - val_accuracy: 0.8387 - val_auc: 0.9250\n",
      "Epoch 125/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2712 - accuracy: 0.9182 - auc: 0.9765 - val_loss: 0.3708 - val_accuracy: 0.8446 - val_auc: 0.9242\n",
      "Epoch 126/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2667 - accuracy: 0.9292 - auc: 0.9800 - val_loss: 0.3710 - val_accuracy: 0.8446 - val_auc: 0.9237\n",
      "Epoch 127/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2599 - accuracy: 0.9412 - auc: 0.9830 - val_loss: 0.3702 - val_accuracy: 0.8475 - val_auc: 0.9246\n",
      "Epoch 128/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2652 - accuracy: 0.9200 - auc: 0.9801 - val_loss: 0.3694 - val_accuracy: 0.8475 - val_auc: 0.9249\n",
      "Epoch 129/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2617 - accuracy: 0.9256 - auc: 0.9822 - val_loss: 0.3694 - val_accuracy: 0.8504 - val_auc: 0.9246\n",
      "Epoch 130/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2547 - accuracy: 0.9357 - auc: 0.9865 - val_loss: 0.3701 - val_accuracy: 0.8475 - val_auc: 0.9239\n",
      "Epoch 131/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2553 - accuracy: 0.9393 - auc: 0.9855 - val_loss: 0.3708 - val_accuracy: 0.8534 - val_auc: 0.9236\n",
      "Epoch 132/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2723 - accuracy: 0.9228 - auc: 0.9762 - val_loss: 0.3712 - val_accuracy: 0.8475 - val_auc: 0.9234\n",
      "Epoch 133/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2665 - accuracy: 0.9256 - auc: 0.9801 - val_loss: 0.3722 - val_accuracy: 0.8504 - val_auc: 0.9232\n",
      "Epoch 134/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2584 - accuracy: 0.9311 - auc: 0.9838 - val_loss: 0.3727 - val_accuracy: 0.8504 - val_auc: 0.9228\n",
      "Epoch 135/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2633 - accuracy: 0.9283 - auc: 0.9802 - val_loss: 0.3729 - val_accuracy: 0.8504 - val_auc: 0.9228\n",
      "Epoch 136/700\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2570 - accuracy: 0.9366 - auc: 0.9837 - val_loss: 0.3718 - val_accuracy: 0.8475 - val_auc: 0.9236\n",
      "Epoch 137/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2600 - accuracy: 0.9301 - auc: 0.9813 - val_loss: 0.3724 - val_accuracy: 0.8416 - val_auc: 0.9227\n",
      "Epoch 138/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2590 - accuracy: 0.9311 - auc: 0.9831 - val_loss: 0.3712 - val_accuracy: 0.8446 - val_auc: 0.9238\n",
      "Epoch 139/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2604 - accuracy: 0.9329 - auc: 0.9836 - val_loss: 0.3707 - val_accuracy: 0.8504 - val_auc: 0.9239\n",
      "Epoch 140/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2560 - accuracy: 0.9430 - auc: 0.9841 - val_loss: 0.3701 - val_accuracy: 0.8475 - val_auc: 0.9244\n",
      "Epoch 141/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2603 - accuracy: 0.9320 - auc: 0.9832 - val_loss: 0.3703 - val_accuracy: 0.8475 - val_auc: 0.9238\n",
      "Epoch 142/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2529 - accuracy: 0.9366 - auc: 0.9847 - val_loss: 0.3712 - val_accuracy: 0.8475 - val_auc: 0.9238\n",
      "Epoch 143/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2577 - accuracy: 0.9274 - auc: 0.9839 - val_loss: 0.3708 - val_accuracy: 0.8475 - val_auc: 0.9235\n",
      "Epoch 144/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2587 - accuracy: 0.9283 - auc: 0.9825 - val_loss: 0.3716 - val_accuracy: 0.8475 - val_auc: 0.9230\n",
      "Epoch 145/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2549 - accuracy: 0.9357 - auc: 0.9849 - val_loss: 0.3710 - val_accuracy: 0.8416 - val_auc: 0.9236\n",
      "Epoch 146/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2544 - accuracy: 0.9375 - auc: 0.9851 - val_loss: 0.3709 - val_accuracy: 0.8504 - val_auc: 0.9237\n",
      "Epoch 147/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2589 - accuracy: 0.9347 - auc: 0.9825 - val_loss: 0.3709 - val_accuracy: 0.8475 - val_auc: 0.9237\n",
      "Epoch 148/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2573 - accuracy: 0.9329 - auc: 0.9846 - val_loss: 0.3695 - val_accuracy: 0.8475 - val_auc: 0.9241\n",
      "Epoch 149/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2576 - accuracy: 0.9347 - auc: 0.9808 - val_loss: 0.3707 - val_accuracy: 0.8475 - val_auc: 0.9239\n",
      "Epoch 150/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2554 - accuracy: 0.9403 - auc: 0.9842 - val_loss: 0.3705 - val_accuracy: 0.8446 - val_auc: 0.9238\n",
      "Epoch 151/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2571 - accuracy: 0.9357 - auc: 0.9828 - val_loss: 0.3687 - val_accuracy: 0.8475 - val_auc: 0.9245\n",
      "Epoch 152/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2551 - accuracy: 0.9357 - auc: 0.9844 - val_loss: 0.3663 - val_accuracy: 0.8504 - val_auc: 0.9258\n",
      "Epoch 153/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2609 - accuracy: 0.9329 - auc: 0.9825 - val_loss: 0.3665 - val_accuracy: 0.8534 - val_auc: 0.9252\n",
      "Epoch 154/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2587 - accuracy: 0.9283 - auc: 0.9820 - val_loss: 0.3687 - val_accuracy: 0.8563 - val_auc: 0.9247\n",
      "Epoch 155/700\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.9504 - auc: 0.9865 - val_loss: 0.3690 - val_accuracy: 0.8504 - val_auc: 0.9252\n",
      "Epoch 156/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - accuracy: 0.9375 - auc: 0.9850 - val_loss: 0.3682 - val_accuracy: 0.8534 - val_auc: 0.9253\n",
      "Epoch 157/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2565 - accuracy: 0.9393 - auc: 0.9833 - val_loss: 0.3669 - val_accuracy: 0.8534 - val_auc: 0.9257\n",
      "Epoch 158/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2633 - accuracy: 0.9366 - auc: 0.9794 - val_loss: 0.3664 - val_accuracy: 0.8563 - val_auc: 0.9260\n",
      "Epoch 159/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2611 - accuracy: 0.9338 - auc: 0.9826 - val_loss: 0.3665 - val_accuracy: 0.8534 - val_auc: 0.9256\n",
      "Epoch 160/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2597 - accuracy: 0.9338 - auc: 0.9831 - val_loss: 0.3663 - val_accuracy: 0.8534 - val_auc: 0.9259\n",
      "Epoch 161/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2543 - accuracy: 0.9357 - auc: 0.9855 - val_loss: 0.3666 - val_accuracy: 0.8534 - val_auc: 0.9261\n",
      "Epoch 162/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2472 - accuracy: 0.9384 - auc: 0.9864 - val_loss: 0.3678 - val_accuracy: 0.8504 - val_auc: 0.9250\n",
      "Epoch 163/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2556 - accuracy: 0.9301 - auc: 0.9832 - val_loss: 0.3676 - val_accuracy: 0.8504 - val_auc: 0.9253\n",
      "Epoch 164/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2583 - accuracy: 0.9320 - auc: 0.9817 - val_loss: 0.3670 - val_accuracy: 0.8534 - val_auc: 0.9254\n",
      "Epoch 165/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2528 - accuracy: 0.9320 - auc: 0.9842 - val_loss: 0.3669 - val_accuracy: 0.8475 - val_auc: 0.9254\n",
      "Epoch 166/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2501 - accuracy: 0.9412 - auc: 0.9850 - val_loss: 0.3666 - val_accuracy: 0.8504 - val_auc: 0.9254\n",
      "Epoch 167/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2521 - accuracy: 0.9338 - auc: 0.9851 - val_loss: 0.3665 - val_accuracy: 0.8563 - val_auc: 0.9254\n",
      "Epoch 168/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2598 - accuracy: 0.9246 - auc: 0.9831 - val_loss: 0.3632 - val_accuracy: 0.8563 - val_auc: 0.9266\n",
      "Epoch 169/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2513 - accuracy: 0.9430 - auc: 0.9839 - val_loss: 0.3647 - val_accuracy: 0.8504 - val_auc: 0.9264\n",
      "Epoch 170/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2470 - accuracy: 0.9347 - auc: 0.9867 - val_loss: 0.3644 - val_accuracy: 0.8563 - val_auc: 0.9267\n",
      "Epoch 171/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2469 - accuracy: 0.9338 - auc: 0.9865 - val_loss: 0.3657 - val_accuracy: 0.8504 - val_auc: 0.9261\n",
      "Epoch 172/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2472 - accuracy: 0.9467 - auc: 0.9858 - val_loss: 0.3654 - val_accuracy: 0.8534 - val_auc: 0.9265\n",
      "Epoch 173/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2494 - accuracy: 0.9393 - auc: 0.9865 - val_loss: 0.3648 - val_accuracy: 0.8563 - val_auc: 0.9263\n",
      "Epoch 174/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2500 - accuracy: 0.9357 - auc: 0.9854 - val_loss: 0.3632 - val_accuracy: 0.8563 - val_auc: 0.9272\n",
      "Epoch 175/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2462 - accuracy: 0.9403 - auc: 0.9875 - val_loss: 0.3633 - val_accuracy: 0.8592 - val_auc: 0.9272\n",
      "Epoch 176/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2506 - accuracy: 0.9375 - auc: 0.9869 - val_loss: 0.3646 - val_accuracy: 0.8622 - val_auc: 0.9268\n",
      "Epoch 177/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2465 - accuracy: 0.9421 - auc: 0.9867 - val_loss: 0.3637 - val_accuracy: 0.8563 - val_auc: 0.9271\n",
      "Epoch 178/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2474 - accuracy: 0.9485 - auc: 0.9871 - val_loss: 0.3646 - val_accuracy: 0.8563 - val_auc: 0.9269\n",
      "Epoch 179/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2533 - accuracy: 0.9412 - auc: 0.9840 - val_loss: 0.3634 - val_accuracy: 0.8563 - val_auc: 0.9276\n",
      "Epoch 180/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2532 - accuracy: 0.9403 - auc: 0.9845 - val_loss: 0.3657 - val_accuracy: 0.8475 - val_auc: 0.9260\n",
      "Epoch 181/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2441 - accuracy: 0.9375 - auc: 0.9882 - val_loss: 0.3651 - val_accuracy: 0.8563 - val_auc: 0.9265\n",
      "Epoch 182/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2475 - accuracy: 0.9393 - auc: 0.9885 - val_loss: 0.3641 - val_accuracy: 0.8504 - val_auc: 0.9271\n",
      "Epoch 183/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2533 - accuracy: 0.9384 - auc: 0.9850 - val_loss: 0.3641 - val_accuracy: 0.8504 - val_auc: 0.9264\n",
      "Epoch 184/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2432 - accuracy: 0.9393 - auc: 0.9868 - val_loss: 0.3647 - val_accuracy: 0.8563 - val_auc: 0.9262\n",
      "Epoch 185/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2449 - accuracy: 0.9458 - auc: 0.9867 - val_loss: 0.3645 - val_accuracy: 0.8534 - val_auc: 0.9262\n",
      "Epoch 186/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2471 - accuracy: 0.9467 - auc: 0.9897 - val_loss: 0.3634 - val_accuracy: 0.8563 - val_auc: 0.9270\n",
      "Epoch 187/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2407 - accuracy: 0.9439 - auc: 0.9893 - val_loss: 0.3629 - val_accuracy: 0.8504 - val_auc: 0.9273\n",
      "Epoch 188/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2394 - accuracy: 0.9476 - auc: 0.9895 - val_loss: 0.3614 - val_accuracy: 0.8534 - val_auc: 0.9279\n",
      "Epoch 189/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2488 - accuracy: 0.9458 - auc: 0.9863 - val_loss: 0.3616 - val_accuracy: 0.8563 - val_auc: 0.9279\n",
      "Epoch 190/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2417 - accuracy: 0.9439 - auc: 0.9879 - val_loss: 0.3614 - val_accuracy: 0.8534 - val_auc: 0.9282\n",
      "Epoch 191/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2427 - accuracy: 0.9458 - auc: 0.9900 - val_loss: 0.3607 - val_accuracy: 0.8592 - val_auc: 0.9291\n",
      "Epoch 192/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2422 - accuracy: 0.9449 - auc: 0.9883 - val_loss: 0.3615 - val_accuracy: 0.8592 - val_auc: 0.9287\n",
      "Epoch 193/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2448 - accuracy: 0.9421 - auc: 0.9884 - val_loss: 0.3601 - val_accuracy: 0.8563 - val_auc: 0.9290\n",
      "Epoch 194/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2422 - accuracy: 0.9485 - auc: 0.9894 - val_loss: 0.3607 - val_accuracy: 0.8534 - val_auc: 0.9291\n",
      "Epoch 195/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2419 - accuracy: 0.9485 - auc: 0.9888 - val_loss: 0.3612 - val_accuracy: 0.8563 - val_auc: 0.9288\n",
      "Epoch 196/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2488 - accuracy: 0.9403 - auc: 0.9862 - val_loss: 0.3600 - val_accuracy: 0.8563 - val_auc: 0.9292\n",
      "Epoch 197/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2412 - accuracy: 0.9430 - auc: 0.9888 - val_loss: 0.3586 - val_accuracy: 0.8534 - val_auc: 0.9298\n",
      "Epoch 198/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2378 - accuracy: 0.9494 - auc: 0.9904 - val_loss: 0.3602 - val_accuracy: 0.8563 - val_auc: 0.9292\n",
      "Epoch 199/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2396 - accuracy: 0.9458 - auc: 0.9892 - val_loss: 0.3603 - val_accuracy: 0.8534 - val_auc: 0.9289\n",
      "Epoch 200/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2420 - accuracy: 0.9357 - auc: 0.9897 - val_loss: 0.3590 - val_accuracy: 0.8534 - val_auc: 0.9298\n",
      "Epoch 201/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2439 - accuracy: 0.9467 - auc: 0.9872 - val_loss: 0.3609 - val_accuracy: 0.8563 - val_auc: 0.9284\n",
      "Epoch 202/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2453 - accuracy: 0.9421 - auc: 0.9862 - val_loss: 0.3606 - val_accuracy: 0.8563 - val_auc: 0.9286\n",
      "Epoch 203/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2435 - accuracy: 0.9467 - auc: 0.9886 - val_loss: 0.3601 - val_accuracy: 0.8534 - val_auc: 0.9285\n",
      "Epoch 204/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2473 - accuracy: 0.9412 - auc: 0.9876 - val_loss: 0.3617 - val_accuracy: 0.8563 - val_auc: 0.9276\n",
      "Epoch 205/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2442 - accuracy: 0.9504 - auc: 0.9880 - val_loss: 0.3635 - val_accuracy: 0.8534 - val_auc: 0.9271\n",
      "Epoch 206/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2397 - accuracy: 0.9384 - auc: 0.9897 - val_loss: 0.3625 - val_accuracy: 0.8534 - val_auc: 0.9272\n",
      "Epoch 207/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2473 - accuracy: 0.9403 - auc: 0.9862 - val_loss: 0.3586 - val_accuracy: 0.8563 - val_auc: 0.9295\n",
      "Epoch 208/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2455 - accuracy: 0.9366 - auc: 0.9859 - val_loss: 0.3593 - val_accuracy: 0.8563 - val_auc: 0.9292\n",
      "Epoch 209/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2423 - accuracy: 0.9421 - auc: 0.9884 - val_loss: 0.3606 - val_accuracy: 0.8592 - val_auc: 0.9289\n",
      "Epoch 210/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2379 - accuracy: 0.9494 - auc: 0.9914 - val_loss: 0.3597 - val_accuracy: 0.8534 - val_auc: 0.9291\n",
      "Epoch 211/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2377 - accuracy: 0.9439 - auc: 0.9905 - val_loss: 0.3588 - val_accuracy: 0.8563 - val_auc: 0.9298\n",
      "Epoch 212/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2365 - accuracy: 0.9439 - auc: 0.9897 - val_loss: 0.3595 - val_accuracy: 0.8563 - val_auc: 0.9294\n",
      "Epoch 213/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2417 - accuracy: 0.9375 - auc: 0.9884 - val_loss: 0.3606 - val_accuracy: 0.8563 - val_auc: 0.9286\n",
      "Epoch 214/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2466 - accuracy: 0.9421 - auc: 0.9860 - val_loss: 0.3608 - val_accuracy: 0.8534 - val_auc: 0.9280\n",
      "Epoch 215/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2406 - accuracy: 0.9467 - auc: 0.9880 - val_loss: 0.3612 - val_accuracy: 0.8504 - val_auc: 0.9280\n",
      "Epoch 216/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2455 - accuracy: 0.9412 - auc: 0.9870 - val_loss: 0.3621 - val_accuracy: 0.8475 - val_auc: 0.9277\n",
      "Epoch 217/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2346 - accuracy: 0.9522 - auc: 0.9912 - val_loss: 0.3613 - val_accuracy: 0.8563 - val_auc: 0.9283\n",
      "Epoch 218/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2389 - accuracy: 0.9458 - auc: 0.9895 - val_loss: 0.3601 - val_accuracy: 0.8592 - val_auc: 0.9289\n",
      "Epoch 219/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2312 - accuracy: 0.9531 - auc: 0.9917 - val_loss: 0.3599 - val_accuracy: 0.8622 - val_auc: 0.9291\n",
      "Epoch 220/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2389 - accuracy: 0.9485 - auc: 0.9904 - val_loss: 0.3608 - val_accuracy: 0.8563 - val_auc: 0.9286\n",
      "Epoch 221/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2401 - accuracy: 0.9540 - auc: 0.9892 - val_loss: 0.3609 - val_accuracy: 0.8592 - val_auc: 0.9282\n",
      "Epoch 222/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2465 - accuracy: 0.9449 - auc: 0.9875 - val_loss: 0.3591 - val_accuracy: 0.8592 - val_auc: 0.9290\n",
      "Epoch 223/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2423 - accuracy: 0.9421 - auc: 0.9886 - val_loss: 0.3583 - val_accuracy: 0.8534 - val_auc: 0.9293\n",
      "Epoch 224/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2349 - accuracy: 0.9522 - auc: 0.9897 - val_loss: 0.3592 - val_accuracy: 0.8563 - val_auc: 0.9288\n",
      "Epoch 225/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2409 - accuracy: 0.9504 - auc: 0.9896 - val_loss: 0.3601 - val_accuracy: 0.8534 - val_auc: 0.9285\n",
      "Epoch 226/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2442 - accuracy: 0.9393 - auc: 0.9870 - val_loss: 0.3607 - val_accuracy: 0.8504 - val_auc: 0.9280\n",
      "Epoch 227/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2441 - accuracy: 0.9412 - auc: 0.9867 - val_loss: 0.3608 - val_accuracy: 0.8563 - val_auc: 0.9277\n",
      "Epoch 228/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2419 - accuracy: 0.9403 - auc: 0.9877 - val_loss: 0.3620 - val_accuracy: 0.8504 - val_auc: 0.9272\n",
      "Epoch 229/700\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2364 - accuracy: 0.9550 - auc: 0.9908 - val_loss: 0.3623 - val_accuracy: 0.8534 - val_auc: 0.9269\n",
      "Epoch 230/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9449 - auc: 0.9894 - val_loss: 0.3617 - val_accuracy: 0.8534 - val_auc: 0.9272\n",
      "Epoch 231/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2335 - accuracy: 0.9476 - auc: 0.9912 - val_loss: 0.3606 - val_accuracy: 0.8504 - val_auc: 0.9276\n",
      "Epoch 232/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2355 - accuracy: 0.9421 - auc: 0.9907 - val_loss: 0.3598 - val_accuracy: 0.8534 - val_auc: 0.9283\n",
      "Epoch 233/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2325 - accuracy: 0.9522 - auc: 0.9913 - val_loss: 0.3600 - val_accuracy: 0.8563 - val_auc: 0.9283\n",
      "Epoch 234/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2319 - accuracy: 0.9494 - auc: 0.9906 - val_loss: 0.3597 - val_accuracy: 0.8563 - val_auc: 0.9289\n",
      "Epoch 235/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2357 - accuracy: 0.9476 - auc: 0.9893 - val_loss: 0.3591 - val_accuracy: 0.8592 - val_auc: 0.9290\n",
      "Epoch 236/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2383 - accuracy: 0.9458 - auc: 0.9899 - val_loss: 0.3623 - val_accuracy: 0.8504 - val_auc: 0.9273\n",
      "Epoch 237/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2368 - accuracy: 0.9449 - auc: 0.9898 - val_loss: 0.3612 - val_accuracy: 0.8563 - val_auc: 0.9279\n",
      "Epoch 238/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2325 - accuracy: 0.9522 - auc: 0.9922 - val_loss: 0.3596 - val_accuracy: 0.8563 - val_auc: 0.9287\n",
      "Epoch 239/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2326 - accuracy: 0.9577 - auc: 0.9902 - val_loss: 0.3599 - val_accuracy: 0.8592 - val_auc: 0.9287\n",
      "Epoch 240/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2387 - accuracy: 0.9403 - auc: 0.9895 - val_loss: 0.3595 - val_accuracy: 0.8563 - val_auc: 0.9288\n",
      "Epoch 241/700\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.2318 - accuracy: 0.9540 - auc: 0.9911 - val_loss: 0.3579 - val_accuracy: 0.8622 - val_auc: 0.9294\n",
      "Epoch 242/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2432 - accuracy: 0.9403 - auc: 0.9867 - val_loss: 0.3593 - val_accuracy: 0.8592 - val_auc: 0.9294\n",
      "Epoch 243/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2309 - accuracy: 0.9513 - auc: 0.9918 - val_loss: 0.3589 - val_accuracy: 0.8592 - val_auc: 0.9293\n",
      "Epoch 244/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2345 - accuracy: 0.9522 - auc: 0.9910 - val_loss: 0.3564 - val_accuracy: 0.8563 - val_auc: 0.9302\n",
      "Epoch 245/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2387 - accuracy: 0.9550 - auc: 0.9887 - val_loss: 0.3564 - val_accuracy: 0.8563 - val_auc: 0.9306\n",
      "Epoch 246/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2362 - accuracy: 0.9485 - auc: 0.9893 - val_loss: 0.3567 - val_accuracy: 0.8563 - val_auc: 0.9301\n",
      "Epoch 247/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2332 - accuracy: 0.9485 - auc: 0.9909 - val_loss: 0.3578 - val_accuracy: 0.8475 - val_auc: 0.9293\n",
      "Epoch 248/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2252 - accuracy: 0.9586 - auc: 0.9936 - val_loss: 0.3591 - val_accuracy: 0.8504 - val_auc: 0.9285\n",
      "Epoch 249/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2294 - accuracy: 0.9522 - auc: 0.9923 - val_loss: 0.3574 - val_accuracy: 0.8592 - val_auc: 0.9293\n",
      "Epoch 250/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2320 - accuracy: 0.9568 - auc: 0.9917 - val_loss: 0.3572 - val_accuracy: 0.8563 - val_auc: 0.9293\n",
      "Epoch 251/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2330 - accuracy: 0.9540 - auc: 0.9911 - val_loss: 0.3561 - val_accuracy: 0.8592 - val_auc: 0.9299\n",
      "Epoch 252/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2321 - accuracy: 0.9467 - auc: 0.9919 - val_loss: 0.3573 - val_accuracy: 0.8534 - val_auc: 0.9292\n",
      "Epoch 253/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2329 - accuracy: 0.9586 - auc: 0.9918 - val_loss: 0.3559 - val_accuracy: 0.8563 - val_auc: 0.9299\n",
      "Epoch 254/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2355 - accuracy: 0.9504 - auc: 0.9888 - val_loss: 0.3553 - val_accuracy: 0.8563 - val_auc: 0.9306\n",
      "Epoch 255/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2333 - accuracy: 0.9531 - auc: 0.9904 - val_loss: 0.3550 - val_accuracy: 0.8563 - val_auc: 0.9309\n",
      "Epoch 256/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2337 - accuracy: 0.9485 - auc: 0.9907 - val_loss: 0.3538 - val_accuracy: 0.8622 - val_auc: 0.9313\n",
      "Epoch 257/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2288 - accuracy: 0.9550 - auc: 0.9910 - val_loss: 0.3538 - val_accuracy: 0.8622 - val_auc: 0.9316\n",
      "Epoch 258/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2324 - accuracy: 0.9467 - auc: 0.9906 - val_loss: 0.3549 - val_accuracy: 0.8563 - val_auc: 0.9310\n",
      "Epoch 259/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2356 - accuracy: 0.9494 - auc: 0.9911 - val_loss: 0.3545 - val_accuracy: 0.8563 - val_auc: 0.9313\n",
      "Epoch 260/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2313 - accuracy: 0.9540 - auc: 0.9904 - val_loss: 0.3544 - val_accuracy: 0.8534 - val_auc: 0.9309\n",
      "Epoch 261/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2275 - accuracy: 0.9577 - auc: 0.9929 - val_loss: 0.3541 - val_accuracy: 0.8563 - val_auc: 0.9311\n",
      "Epoch 262/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2293 - accuracy: 0.9540 - auc: 0.9917 - val_loss: 0.3533 - val_accuracy: 0.8534 - val_auc: 0.9316\n",
      "Epoch 263/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2319 - accuracy: 0.9485 - auc: 0.9901 - val_loss: 0.3530 - val_accuracy: 0.8592 - val_auc: 0.9324\n",
      "Epoch 264/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2252 - accuracy: 0.9550 - auc: 0.9938 - val_loss: 0.3531 - val_accuracy: 0.8592 - val_auc: 0.9320\n",
      "Epoch 265/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2280 - accuracy: 0.9642 - auc: 0.9920 - val_loss: 0.3528 - val_accuracy: 0.8592 - val_auc: 0.9322\n",
      "Epoch 266/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2319 - accuracy: 0.9531 - auc: 0.9925 - val_loss: 0.3524 - val_accuracy: 0.8534 - val_auc: 0.9323\n",
      "Epoch 267/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2309 - accuracy: 0.9531 - auc: 0.9916 - val_loss: 0.3544 - val_accuracy: 0.8563 - val_auc: 0.9308\n",
      "Epoch 268/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2226 - accuracy: 0.9642 - auc: 0.9942 - val_loss: 0.3551 - val_accuracy: 0.8563 - val_auc: 0.9310\n",
      "Epoch 269/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2287 - accuracy: 0.9522 - auc: 0.9920 - val_loss: 0.3529 - val_accuracy: 0.8563 - val_auc: 0.9320\n",
      "Epoch 270/700\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2334 - accuracy: 0.9458 - auc: 0.9914 - val_loss: 0.3519 - val_accuracy: 0.8563 - val_auc: 0.9326\n",
      "Epoch 271/700\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2288 - accuracy: 0.9623 - auc: 0.9925 - val_loss: 0.3506 - val_accuracy: 0.8563 - val_auc: 0.9329\n",
      "Epoch 272/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2295 - accuracy: 0.9504 - auc: 0.9929 - val_loss: 0.3510 - val_accuracy: 0.8592 - val_auc: 0.9332\n",
      "Epoch 273/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2323 - accuracy: 0.9494 - auc: 0.9911 - val_loss: 0.3506 - val_accuracy: 0.8592 - val_auc: 0.9331\n",
      "Epoch 274/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2248 - accuracy: 0.9540 - auc: 0.9920 - val_loss: 0.3521 - val_accuracy: 0.8563 - val_auc: 0.9323\n",
      "Epoch 275/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2275 - accuracy: 0.9522 - auc: 0.9923 - val_loss: 0.3528 - val_accuracy: 0.8592 - val_auc: 0.9316\n",
      "Epoch 276/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2266 - accuracy: 0.9550 - auc: 0.9924 - val_loss: 0.3534 - val_accuracy: 0.8563 - val_auc: 0.9315\n",
      "Epoch 277/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2276 - accuracy: 0.9550 - auc: 0.9921 - val_loss: 0.3528 - val_accuracy: 0.8592 - val_auc: 0.9320\n",
      "Epoch 278/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2255 - accuracy: 0.9614 - auc: 0.9937 - val_loss: 0.3526 - val_accuracy: 0.8563 - val_auc: 0.9319\n",
      "Epoch 279/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2265 - accuracy: 0.9522 - auc: 0.9917 - val_loss: 0.3528 - val_accuracy: 0.8622 - val_auc: 0.9321\n",
      "Epoch 280/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2247 - accuracy: 0.9605 - auc: 0.9937 - val_loss: 0.3529 - val_accuracy: 0.8592 - val_auc: 0.9319\n",
      "Epoch 281/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2238 - accuracy: 0.9568 - auc: 0.9939 - val_loss: 0.3539 - val_accuracy: 0.8622 - val_auc: 0.9313\n",
      "Epoch 282/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2222 - accuracy: 0.9577 - auc: 0.9943 - val_loss: 0.3532 - val_accuracy: 0.8622 - val_auc: 0.9319\n",
      "Epoch 283/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2296 - accuracy: 0.9540 - auc: 0.9921 - val_loss: 0.3532 - val_accuracy: 0.8622 - val_auc: 0.9319\n",
      "Epoch 284/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2364 - accuracy: 0.9467 - auc: 0.9895 - val_loss: 0.3544 - val_accuracy: 0.8592 - val_auc: 0.9308\n",
      "Epoch 285/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2276 - accuracy: 0.9559 - auc: 0.9931 - val_loss: 0.3530 - val_accuracy: 0.8592 - val_auc: 0.9313\n",
      "Epoch 286/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2293 - accuracy: 0.9531 - auc: 0.9916 - val_loss: 0.3521 - val_accuracy: 0.8592 - val_auc: 0.9315\n",
      "Epoch 287/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2292 - accuracy: 0.9550 - auc: 0.9925 - val_loss: 0.3529 - val_accuracy: 0.8592 - val_auc: 0.9313\n",
      "Epoch 288/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2235 - accuracy: 0.9577 - auc: 0.9927 - val_loss: 0.3532 - val_accuracy: 0.8592 - val_auc: 0.9313\n",
      "Epoch 289/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2266 - accuracy: 0.9540 - auc: 0.9925 - val_loss: 0.3519 - val_accuracy: 0.8622 - val_auc: 0.9323\n",
      "Epoch 290/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2278 - accuracy: 0.9494 - auc: 0.9916 - val_loss: 0.3522 - val_accuracy: 0.8592 - val_auc: 0.9323\n",
      "Epoch 291/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2242 - accuracy: 0.9596 - auc: 0.9944 - val_loss: 0.3523 - val_accuracy: 0.8592 - val_auc: 0.9321\n",
      "Epoch 292/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2282 - accuracy: 0.9623 - auc: 0.9919 - val_loss: 0.3523 - val_accuracy: 0.8592 - val_auc: 0.9317\n",
      "Epoch 293/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2266 - accuracy: 0.9559 - auc: 0.9918 - val_loss: 0.3533 - val_accuracy: 0.8592 - val_auc: 0.9309\n",
      "Epoch 294/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2274 - accuracy: 0.9568 - auc: 0.9922 - val_loss: 0.3527 - val_accuracy: 0.8592 - val_auc: 0.9312\n",
      "Epoch 295/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2300 - accuracy: 0.9531 - auc: 0.9910 - val_loss: 0.3526 - val_accuracy: 0.8592 - val_auc: 0.9314\n",
      "Epoch 296/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2249 - accuracy: 0.9568 - auc: 0.9929 - val_loss: 0.3534 - val_accuracy: 0.8592 - val_auc: 0.9305\n",
      "Epoch 297/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2230 - accuracy: 0.9577 - auc: 0.9934 - val_loss: 0.3529 - val_accuracy: 0.8622 - val_auc: 0.9309\n",
      "Epoch 298/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2235 - accuracy: 0.9623 - auc: 0.9932 - val_loss: 0.3537 - val_accuracy: 0.8622 - val_auc: 0.9306\n",
      "Epoch 299/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2277 - accuracy: 0.9550 - auc: 0.9927 - val_loss: 0.3542 - val_accuracy: 0.8622 - val_auc: 0.9301\n",
      "Epoch 300/700\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2202 - accuracy: 0.9531 - auc: 0.9941 - val_loss: 0.3508 - val_accuracy: 0.8622 - val_auc: 0.9321\n",
      "Epoch 301/700\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2264 - accuracy: 0.9531 - auc: 0.9912 - val_loss: 0.3511 - val_accuracy: 0.8563 - val_auc: 0.9321\n",
      "Epoch 00301: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('angry_other_features.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2229,
     "status": "ok",
     "timestamp": 1598281167358,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ddcJYxjpRmou"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('angry_other_features.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1598281171921,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "w4snlhBmRqz8"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_predictions_baseline = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1598281175675,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1598281221727,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "cace18cb-5d55-4a0e-d332-5e5365de511d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.3505951762199402\n",
      "accuracy :  0.8563050031661987\n",
      "auc :  0.9329297542572021\n",
      "\n",
      "(True Negatives):  176\n",
      "(False Positives):  43\n",
      "(False Negatives):  6\n",
      "(True Positives):  116\n",
      "Total emotions_happy:  122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88       219\n",
      "           1       0.73      0.95      0.83       122\n",
      "\n",
      "    accuracy                           0.86       341\n",
      "   macro avg       0.85      0.88      0.85       341\n",
      "weighted avg       0.88      0.86      0.86       341\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1182,
     "status": "ok",
     "timestamp": 1598281233777,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "GJk2L3O8ImIn"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 817,
     "status": "ok",
     "timestamp": 1598281240110,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "55c44ff8-a0c9-4cd0-d494-b3cd483acb8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.3232819139957428\n",
      "accuracy :  0.8827838897705078\n",
      "auc :  0.9454172849655151\n",
      "\n",
      "(True Negatives):  133\n",
      "(False Positives):  31\n",
      "(False Negatives):  1\n",
      "(True Positives):  108\n",
      "Total emotions_happy:  109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89       164\n",
      "           1       0.78      0.99      0.87       109\n",
      "\n",
      "    accuracy                           0.88       273\n",
      "   macro avg       0.88      0.90      0.88       273\n",
      "weighted avg       0.91      0.88      0.88       273\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNTgjNHxooHjQjBj0yG4dgQ",
   "name": "deep_angry_other_RAVDESS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
