{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "#Deep learning\n",
    "\n",
    "### Plot imports ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns \n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18096,
     "status": "ok",
     "timestamp": 1596185931465,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "ed600536-62e1-4748-f8cb-57ce1a654049"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy/happy_03-01-03-02-01-02-09_norm_outNoise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral/neutral_dia89_utt3_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust/disgust_03-01-07-02-01-02-16_norm_outN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad/sad_03-01-04-01-01-02-10_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral/neutral_dia34_utt5_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio label\n",
       "0  happy/happy_03-01-03-02-01-02-09_norm_outNoise...     0\n",
       "1       neutral/neutral_dia89_utt3_norm_outNoise.wav     0\n",
       "2  disgust/disgust_03-01-07-02-01-02-16_norm_outN...     0\n",
       "3     sad/sad_03-01-04-01-01-02-10_norm_outNoise.wav     0\n",
       "4       neutral/neutral_dia34_utt5_norm_outNoise.wav     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"ravdess_meld\" #audio data folder\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i.startswith(\"angry\"):     ##this specifies that we class angry emotion against the others\n",
    "                                    #the files corresponding to each emotion started by the name of the emotion\n",
    "                                    # for example for the emotion \"happy\" , it will be (if i.startswith(\"happy\"))\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) # adding values to the defined df:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1596185972739,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "9214a80f-ef92-490c-f204-1c2b80dacc45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1949\n",
      "1     339\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1596186030559,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    spec =  fram_window(audio_path) \n",
    "    \n",
    "    \n",
    "    #prosodics features\n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "    \n",
    "    \n",
    "    #spectrales features\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)         \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "    \n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    \n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    #voice activity features\n",
    "    \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "    \n",
    "    #voice quality features\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    \n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4419910,
     "status": "ok",
     "timestamp": 1596190539389,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(parent_dir+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1596190801939,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "0f67b050-b709-44fa-a43a-0e9feeb84a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1596190823675,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1596190848411,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1596190868194,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "07c0969a-ce8b-427b-bc0d-f07237580d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 1194\n",
      "After OverSampling, counts of label '0': 1949\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \"[1, 2, 3, 4, 7, 9, 10, 13, 15, 16, 17, 19, 20]     \" are deleted 584 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57398,
     "status": "ok",
     "timestamp": 1596190950095,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "9b3b9aaa-f2cf-4304-f073-acafeae805b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 19, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 19, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2, 3, 4, 7, 9, 10, 13, 15, 16, 17, 19, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 19, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 18, 19, 20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration                                          X_removed\n",
       "0         1        [1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 19, 20]\n",
       "1         2        [1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 19, 20]\n",
       "2         3     [1, 2, 3, 4, 7, 9, 10, 13, 15, 16, 17, 19, 20]\n",
       "3         4        [1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 19, 20]\n",
       "4         5  [1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 18, 19, 20..."
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 7, 9, 10, 13, 15, 16, 17, 19, 20]               584\n",
       "[1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 19, 20]                  271\n",
       "[1, 2, 3, 4, 7, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21]        68\n",
       "[1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21]           43\n",
       "[1, 2, 3, 4, 7, 10, 13, 15, 16, 17, 19, 20]                    7\n",
       "[1, 2, 3, 7, 9, 10, 13, 15, 16, 17, 20]                        4\n",
       "[1, 2, 3, 7, 10, 13, 15, 16, 17, 19, 20]                       4\n",
       "[1, 2, 3, 4, 6, 7, 9, 10, 13, 15, 16, 17, 19, 20]              3\n",
       "[1, 2, 3, 4, 7, 10, 13, 15, 16, 17, 20]                        3\n",
       "[1, 2, 3, 4, 6, 7, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21]      2\n",
       "[1, 2, 3, 4, 7, 9, 10, 13, 15, 16, 17, 20]                     2\n",
       "[1, 2, 3, 7, 10, 13, 15, 16, 17, 20]                           2\n",
       "[1, 2, 3, 6, 7, 9, 10, 13, 15, 16, 17, 19, 20]                 2\n",
       "[1, 2, 3, 4, 7, 9, 10, 15, 16, 17, 19, 20]                     2\n",
       "[1, 2, 3, 6, 7, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21]         2\n",
       "[1, 3, 7, 9, 10, 13, 15, 16, 17, 19, 20]                       1\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1596191225126,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6sTQj5wDWdev"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0],  X[i][5], X[i][6],  X[i][8],\n",
    "               X[i][11], X[i][12], X[i][14], \n",
    "                X[i][18],  X[i][21]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1596191247873,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "a660fd10-eec7-470a-fada-0c9816e0d359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n",
      "629\n",
      "503\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1596191303682,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1596191336792,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "43a546ff-9236-4cca-f5ae-650aed4478d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011, 9, 1)\n",
      "(629, 9, 1)\n",
      "(503, 9, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1596191360607,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "721b012a-0679-4632-892c-573869e04140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011, 2)\n",
      "(629, 2)\n",
      "(503, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1596191385295,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (9,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1140,
     "status": "ok",
     "timestamp": 1596191390539,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "e22c5f51-642b-4461-b9be-9ebbeeb65c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 9, 1)]            0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 9, 128)            768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 9, 128)            512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 9, 128)            82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2306      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 85,642\n",
      "Trainable params: 85,382\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1596191394140,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 424148,
     "status": "ok",
     "timestamp": 1596191839564,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "018728ca-9622-4a0f-bb16-dd53cce5b37d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.7898 - accuracy: 0.5500 - auc: 0.5728 - val_loss: 0.6601 - val_accuracy: 0.6598 - val_auc: 0.7221\n",
      "Epoch 2/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.7366 - accuracy: 0.5878 - auc: 0.6139 - val_loss: 0.6524 - val_accuracy: 0.6677 - val_auc: 0.7294\n",
      "Epoch 3/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.7174 - accuracy: 0.5962 - auc: 0.6251 - val_loss: 0.6486 - val_accuracy: 0.6709 - val_auc: 0.7268\n",
      "Epoch 4/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6928 - accuracy: 0.6057 - auc: 0.6418 - val_loss: 0.6463 - val_accuracy: 0.6661 - val_auc: 0.7224\n",
      "Epoch 5/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6769 - accuracy: 0.6077 - auc: 0.6599 - val_loss: 0.6450 - val_accuracy: 0.6677 - val_auc: 0.7135\n",
      "Epoch 6/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6757 - accuracy: 0.6111 - auc: 0.6557 - val_loss: 0.6444 - val_accuracy: 0.6502 - val_auc: 0.7073\n",
      "Epoch 7/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6609 - accuracy: 0.6151 - auc: 0.6636 - val_loss: 0.6420 - val_accuracy: 0.6518 - val_auc: 0.7053\n",
      "Epoch 8/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6537 - accuracy: 0.6216 - auc: 0.6744 - val_loss: 0.6408 - val_accuracy: 0.6471 - val_auc: 0.7007\n",
      "Epoch 9/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6521 - accuracy: 0.6330 - auc: 0.6784 - val_loss: 0.6373 - val_accuracy: 0.6550 - val_auc: 0.7040\n",
      "Epoch 10/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6465 - accuracy: 0.6340 - auc: 0.6830 - val_loss: 0.6339 - val_accuracy: 0.6598 - val_auc: 0.7076\n",
      "Epoch 11/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6377 - accuracy: 0.6415 - auc: 0.6932 - val_loss: 0.6292 - val_accuracy: 0.6709 - val_auc: 0.7127\n",
      "Epoch 12/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6358 - accuracy: 0.6385 - auc: 0.6937 - val_loss: 0.6244 - val_accuracy: 0.6789 - val_auc: 0.7180\n",
      "Epoch 13/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6264 - accuracy: 0.6410 - auc: 0.7047 - val_loss: 0.6203 - val_accuracy: 0.6868 - val_auc: 0.7227\n",
      "Epoch 14/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6268 - accuracy: 0.6459 - auc: 0.7011 - val_loss: 0.6151 - val_accuracy: 0.6948 - val_auc: 0.7288\n",
      "Epoch 15/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6280 - accuracy: 0.6435 - auc: 0.7038 - val_loss: 0.6113 - val_accuracy: 0.6948 - val_auc: 0.7328\n",
      "Epoch 16/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6191 - accuracy: 0.6544 - auc: 0.7137 - val_loss: 0.6078 - val_accuracy: 0.7059 - val_auc: 0.7357\n",
      "Epoch 17/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6400 - accuracy: 0.6305 - auc: 0.6885 - val_loss: 0.6061 - val_accuracy: 0.7043 - val_auc: 0.7374\n",
      "Epoch 18/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6145 - accuracy: 0.6564 - auc: 0.7186 - val_loss: 0.6038 - val_accuracy: 0.6979 - val_auc: 0.7395\n",
      "Epoch 19/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6223 - accuracy: 0.6524 - auc: 0.7129 - val_loss: 0.6011 - val_accuracy: 0.7011 - val_auc: 0.7424\n",
      "Epoch 20/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6219 - accuracy: 0.6464 - auc: 0.7108 - val_loss: 0.5993 - val_accuracy: 0.7011 - val_auc: 0.7441\n",
      "Epoch 21/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6221 - accuracy: 0.6514 - auc: 0.7095 - val_loss: 0.5990 - val_accuracy: 0.7027 - val_auc: 0.7446\n",
      "Epoch 22/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6171 - accuracy: 0.6544 - auc: 0.7145 - val_loss: 0.5963 - val_accuracy: 0.6995 - val_auc: 0.7475\n",
      "Epoch 23/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6162 - accuracy: 0.6504 - auc: 0.7159 - val_loss: 0.5948 - val_accuracy: 0.7011 - val_auc: 0.7488\n",
      "Epoch 24/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6203 - accuracy: 0.6549 - auc: 0.7135 - val_loss: 0.5949 - val_accuracy: 0.7027 - val_auc: 0.7491\n",
      "Epoch 25/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6193 - accuracy: 0.6519 - auc: 0.7123 - val_loss: 0.5937 - val_accuracy: 0.6995 - val_auc: 0.7500\n",
      "Epoch 26/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6145 - accuracy: 0.6569 - auc: 0.7188 - val_loss: 0.5934 - val_accuracy: 0.6995 - val_auc: 0.7502\n",
      "Epoch 27/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6155 - accuracy: 0.6469 - auc: 0.7158 - val_loss: 0.5932 - val_accuracy: 0.7011 - val_auc: 0.7509\n",
      "Epoch 28/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6161 - accuracy: 0.6579 - auc: 0.7143 - val_loss: 0.5929 - val_accuracy: 0.7027 - val_auc: 0.7513\n",
      "Epoch 29/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6068 - accuracy: 0.6648 - auc: 0.7276 - val_loss: 0.5929 - val_accuracy: 0.7027 - val_auc: 0.7512\n",
      "Epoch 30/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6097 - accuracy: 0.6529 - auc: 0.7234 - val_loss: 0.5927 - val_accuracy: 0.6995 - val_auc: 0.7514\n",
      "Epoch 31/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6188 - accuracy: 0.6544 - auc: 0.7156 - val_loss: 0.5918 - val_accuracy: 0.7027 - val_auc: 0.7522\n",
      "Epoch 32/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6154 - accuracy: 0.6559 - auc: 0.7149 - val_loss: 0.5913 - val_accuracy: 0.7043 - val_auc: 0.7530\n",
      "Epoch 33/700\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.6104 - accuracy: 0.6564 - auc: 0.7233 - val_loss: 0.5912 - val_accuracy: 0.7027 - val_auc: 0.7526\n",
      "Epoch 34/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6102 - accuracy: 0.6668 - auc: 0.7270 - val_loss: 0.5912 - val_accuracy: 0.7027 - val_auc: 0.7529\n",
      "Epoch 35/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6105 - accuracy: 0.6569 - auc: 0.7236 - val_loss: 0.5908 - val_accuracy: 0.7011 - val_auc: 0.7535\n",
      "Epoch 36/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6102 - accuracy: 0.6579 - auc: 0.7243 - val_loss: 0.5903 - val_accuracy: 0.7027 - val_auc: 0.7540\n",
      "Epoch 37/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6065 - accuracy: 0.6668 - auc: 0.7298 - val_loss: 0.5909 - val_accuracy: 0.7027 - val_auc: 0.7531\n",
      "Epoch 38/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6049 - accuracy: 0.6604 - auc: 0.7312 - val_loss: 0.5904 - val_accuracy: 0.7027 - val_auc: 0.7540\n",
      "Epoch 39/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6039 - accuracy: 0.6609 - auc: 0.7310 - val_loss: 0.5913 - val_accuracy: 0.7027 - val_auc: 0.7531\n",
      "Epoch 40/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6017 - accuracy: 0.6708 - auc: 0.7352 - val_loss: 0.5909 - val_accuracy: 0.7075 - val_auc: 0.7538\n",
      "Epoch 41/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6077 - accuracy: 0.6663 - auc: 0.7277 - val_loss: 0.5914 - val_accuracy: 0.7075 - val_auc: 0.7533\n",
      "Epoch 42/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6039 - accuracy: 0.6688 - auc: 0.7323 - val_loss: 0.5907 - val_accuracy: 0.7027 - val_auc: 0.7534\n",
      "Epoch 43/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6096 - accuracy: 0.6708 - auc: 0.7280 - val_loss: 0.5898 - val_accuracy: 0.7043 - val_auc: 0.7553\n",
      "Epoch 44/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6094 - accuracy: 0.6673 - auc: 0.7279 - val_loss: 0.5898 - val_accuracy: 0.7043 - val_auc: 0.7549\n",
      "Epoch 45/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6069 - accuracy: 0.6614 - auc: 0.7273 - val_loss: 0.5881 - val_accuracy: 0.7027 - val_auc: 0.7565\n",
      "Epoch 46/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6060 - accuracy: 0.6683 - auc: 0.7288 - val_loss: 0.5877 - val_accuracy: 0.7043 - val_auc: 0.7571\n",
      "Epoch 47/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6137 - accuracy: 0.6599 - auc: 0.7232 - val_loss: 0.5869 - val_accuracy: 0.7059 - val_auc: 0.7580\n",
      "Epoch 48/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6084 - accuracy: 0.6673 - auc: 0.7271 - val_loss: 0.5875 - val_accuracy: 0.7043 - val_auc: 0.7573\n",
      "Epoch 49/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6025 - accuracy: 0.6698 - auc: 0.7330 - val_loss: 0.5881 - val_accuracy: 0.7027 - val_auc: 0.7565\n",
      "Epoch 50/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6080 - accuracy: 0.6599 - auc: 0.7275 - val_loss: 0.5878 - val_accuracy: 0.7011 - val_auc: 0.7567\n",
      "Epoch 51/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6029 - accuracy: 0.6827 - auc: 0.7339 - val_loss: 0.5877 - val_accuracy: 0.7091 - val_auc: 0.7572\n",
      "Epoch 52/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6010 - accuracy: 0.6688 - auc: 0.7358 - val_loss: 0.5881 - val_accuracy: 0.7091 - val_auc: 0.7567\n",
      "Epoch 53/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6028 - accuracy: 0.6648 - auc: 0.7328 - val_loss: 0.5881 - val_accuracy: 0.7059 - val_auc: 0.7566\n",
      "Epoch 54/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6023 - accuracy: 0.6653 - auc: 0.7347 - val_loss: 0.5873 - val_accuracy: 0.7043 - val_auc: 0.7576\n",
      "Epoch 55/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5973 - accuracy: 0.6648 - auc: 0.7375 - val_loss: 0.5868 - val_accuracy: 0.7075 - val_auc: 0.7582\n",
      "Epoch 56/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6035 - accuracy: 0.6589 - auc: 0.7305 - val_loss: 0.5869 - val_accuracy: 0.7027 - val_auc: 0.7582\n",
      "Epoch 57/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6077 - accuracy: 0.6564 - auc: 0.7277 - val_loss: 0.5871 - val_accuracy: 0.7027 - val_auc: 0.7577\n",
      "Epoch 58/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6056 - accuracy: 0.6678 - auc: 0.7308 - val_loss: 0.5873 - val_accuracy: 0.7075 - val_auc: 0.7576\n",
      "Epoch 59/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5973 - accuracy: 0.6773 - auc: 0.7388 - val_loss: 0.5873 - val_accuracy: 0.7043 - val_auc: 0.7578\n",
      "Epoch 60/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6056 - accuracy: 0.6653 - auc: 0.7284 - val_loss: 0.5869 - val_accuracy: 0.7043 - val_auc: 0.7582\n",
      "Epoch 61/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5998 - accuracy: 0.6842 - auc: 0.7390 - val_loss: 0.5871 - val_accuracy: 0.7122 - val_auc: 0.7578\n",
      "Epoch 62/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6026 - accuracy: 0.6728 - auc: 0.7350 - val_loss: 0.5872 - val_accuracy: 0.7091 - val_auc: 0.7581\n",
      "Epoch 63/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6011 - accuracy: 0.6683 - auc: 0.7339 - val_loss: 0.5875 - val_accuracy: 0.7059 - val_auc: 0.7574\n",
      "Epoch 64/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5988 - accuracy: 0.6728 - auc: 0.7402 - val_loss: 0.5868 - val_accuracy: 0.7043 - val_auc: 0.7588\n",
      "Epoch 65/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6001 - accuracy: 0.6643 - auc: 0.7366 - val_loss: 0.5866 - val_accuracy: 0.7043 - val_auc: 0.7589\n",
      "Epoch 66/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6019 - accuracy: 0.6733 - auc: 0.7347 - val_loss: 0.5868 - val_accuracy: 0.7075 - val_auc: 0.7586\n",
      "Epoch 67/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5933 - accuracy: 0.6832 - auc: 0.7457 - val_loss: 0.5854 - val_accuracy: 0.7075 - val_auc: 0.7600\n",
      "Epoch 68/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5991 - accuracy: 0.6698 - auc: 0.7365 - val_loss: 0.5852 - val_accuracy: 0.7091 - val_auc: 0.7604\n",
      "Epoch 69/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6065 - accuracy: 0.6723 - auc: 0.7297 - val_loss: 0.5851 - val_accuracy: 0.7091 - val_auc: 0.7607\n",
      "Epoch 70/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5985 - accuracy: 0.6718 - auc: 0.7394 - val_loss: 0.5850 - val_accuracy: 0.7122 - val_auc: 0.7606\n",
      "Epoch 71/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5956 - accuracy: 0.6743 - auc: 0.7413 - val_loss: 0.5851 - val_accuracy: 0.7091 - val_auc: 0.7606\n",
      "Epoch 72/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.6009 - accuracy: 0.6763 - auc: 0.7396 - val_loss: 0.5842 - val_accuracy: 0.7138 - val_auc: 0.7612\n",
      "Epoch 73/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5924 - accuracy: 0.6798 - auc: 0.7471 - val_loss: 0.5846 - val_accuracy: 0.7122 - val_auc: 0.7610\n",
      "Epoch 74/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5968 - accuracy: 0.6803 - auc: 0.7415 - val_loss: 0.5844 - val_accuracy: 0.7186 - val_auc: 0.7609\n",
      "Epoch 75/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5995 - accuracy: 0.6758 - auc: 0.7407 - val_loss: 0.5837 - val_accuracy: 0.7154 - val_auc: 0.7619\n",
      "Epoch 76/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5955 - accuracy: 0.6872 - auc: 0.7430 - val_loss: 0.5841 - val_accuracy: 0.7170 - val_auc: 0.7614\n",
      "Epoch 77/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5932 - accuracy: 0.6738 - auc: 0.7457 - val_loss: 0.5838 - val_accuracy: 0.7138 - val_auc: 0.7620\n",
      "Epoch 78/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5968 - accuracy: 0.6723 - auc: 0.7421 - val_loss: 0.5835 - val_accuracy: 0.7138 - val_auc: 0.7622\n",
      "Epoch 79/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5901 - accuracy: 0.6852 - auc: 0.7493 - val_loss: 0.5828 - val_accuracy: 0.7154 - val_auc: 0.7631\n",
      "Epoch 80/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.6000 - accuracy: 0.6718 - auc: 0.7392 - val_loss: 0.5838 - val_accuracy: 0.7154 - val_auc: 0.7623\n",
      "Epoch 81/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5981 - accuracy: 0.6842 - auc: 0.7426 - val_loss: 0.5840 - val_accuracy: 0.7138 - val_auc: 0.7618\n",
      "Epoch 82/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5949 - accuracy: 0.6758 - auc: 0.7430 - val_loss: 0.5840 - val_accuracy: 0.7186 - val_auc: 0.7617\n",
      "Epoch 83/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5890 - accuracy: 0.6847 - auc: 0.7515 - val_loss: 0.5828 - val_accuracy: 0.7138 - val_auc: 0.7632\n",
      "Epoch 84/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5871 - accuracy: 0.6842 - auc: 0.7532 - val_loss: 0.5818 - val_accuracy: 0.7186 - val_auc: 0.7648\n",
      "Epoch 85/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5973 - accuracy: 0.6708 - auc: 0.7414 - val_loss: 0.5820 - val_accuracy: 0.7170 - val_auc: 0.7642\n",
      "Epoch 86/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5889 - accuracy: 0.6813 - auc: 0.7524 - val_loss: 0.5817 - val_accuracy: 0.7154 - val_auc: 0.7649\n",
      "Epoch 87/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5981 - accuracy: 0.6788 - auc: 0.7406 - val_loss: 0.5828 - val_accuracy: 0.7170 - val_auc: 0.7638\n",
      "Epoch 88/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5972 - accuracy: 0.6728 - auc: 0.7396 - val_loss: 0.5822 - val_accuracy: 0.7154 - val_auc: 0.7643\n",
      "Epoch 89/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5977 - accuracy: 0.6738 - auc: 0.7398 - val_loss: 0.5828 - val_accuracy: 0.7154 - val_auc: 0.7636\n",
      "Epoch 90/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5902 - accuracy: 0.6783 - auc: 0.7480 - val_loss: 0.5830 - val_accuracy: 0.7170 - val_auc: 0.7633\n",
      "Epoch 91/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5953 - accuracy: 0.6743 - auc: 0.7442 - val_loss: 0.5823 - val_accuracy: 0.7122 - val_auc: 0.7639\n",
      "Epoch 92/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5959 - accuracy: 0.6718 - auc: 0.7422 - val_loss: 0.5836 - val_accuracy: 0.7154 - val_auc: 0.7631\n",
      "Epoch 93/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5974 - accuracy: 0.6748 - auc: 0.7429 - val_loss: 0.5829 - val_accuracy: 0.7138 - val_auc: 0.7639\n",
      "Epoch 94/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5972 - accuracy: 0.6793 - auc: 0.7436 - val_loss: 0.5831 - val_accuracy: 0.7170 - val_auc: 0.7633\n",
      "Epoch 95/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5968 - accuracy: 0.6768 - auc: 0.7404 - val_loss: 0.5826 - val_accuracy: 0.7138 - val_auc: 0.7641\n",
      "Epoch 96/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5889 - accuracy: 0.6818 - auc: 0.7496 - val_loss: 0.5819 - val_accuracy: 0.7154 - val_auc: 0.7648\n",
      "Epoch 97/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5894 - accuracy: 0.6882 - auc: 0.7500 - val_loss: 0.5819 - val_accuracy: 0.7170 - val_auc: 0.7645\n",
      "Epoch 98/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5847 - accuracy: 0.6872 - auc: 0.7554 - val_loss: 0.5817 - val_accuracy: 0.7170 - val_auc: 0.7650\n",
      "Epoch 99/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5925 - accuracy: 0.6788 - auc: 0.7471 - val_loss: 0.5819 - val_accuracy: 0.7170 - val_auc: 0.7647\n",
      "Epoch 100/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5917 - accuracy: 0.6758 - auc: 0.7456 - val_loss: 0.5819 - val_accuracy: 0.7154 - val_auc: 0.7649\n",
      "Epoch 101/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5942 - accuracy: 0.6718 - auc: 0.7421 - val_loss: 0.5825 - val_accuracy: 0.7186 - val_auc: 0.7643\n",
      "Epoch 102/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5921 - accuracy: 0.6808 - auc: 0.7492 - val_loss: 0.5826 - val_accuracy: 0.7186 - val_auc: 0.7643\n",
      "Epoch 103/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5880 - accuracy: 0.6897 - auc: 0.7533 - val_loss: 0.5823 - val_accuracy: 0.7202 - val_auc: 0.7644\n",
      "Epoch 104/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5918 - accuracy: 0.6827 - auc: 0.7468 - val_loss: 0.5823 - val_accuracy: 0.7170 - val_auc: 0.7649\n",
      "Epoch 105/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5872 - accuracy: 0.6852 - auc: 0.7538 - val_loss: 0.5817 - val_accuracy: 0.7170 - val_auc: 0.7649\n",
      "Epoch 106/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5863 - accuracy: 0.6847 - auc: 0.7543 - val_loss: 0.5813 - val_accuracy: 0.7170 - val_auc: 0.7654\n",
      "Epoch 107/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5924 - accuracy: 0.6763 - auc: 0.7462 - val_loss: 0.5817 - val_accuracy: 0.7202 - val_auc: 0.7657\n",
      "Epoch 108/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5912 - accuracy: 0.6768 - auc: 0.7474 - val_loss: 0.5810 - val_accuracy: 0.7170 - val_auc: 0.7662\n",
      "Epoch 109/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5918 - accuracy: 0.6877 - auc: 0.7492 - val_loss: 0.5802 - val_accuracy: 0.7202 - val_auc: 0.7670\n",
      "Epoch 110/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5880 - accuracy: 0.6852 - auc: 0.7522 - val_loss: 0.5802 - val_accuracy: 0.7202 - val_auc: 0.7673\n",
      "Epoch 111/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5897 - accuracy: 0.6832 - auc: 0.7499 - val_loss: 0.5799 - val_accuracy: 0.7186 - val_auc: 0.7674\n",
      "Epoch 112/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5935 - accuracy: 0.6818 - auc: 0.7458 - val_loss: 0.5802 - val_accuracy: 0.7186 - val_auc: 0.7672\n",
      "Epoch 113/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5955 - accuracy: 0.6778 - auc: 0.7449 - val_loss: 0.5804 - val_accuracy: 0.7202 - val_auc: 0.7671\n",
      "Epoch 114/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5927 - accuracy: 0.6808 - auc: 0.7470 - val_loss: 0.5795 - val_accuracy: 0.7218 - val_auc: 0.7683\n",
      "Epoch 115/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5882 - accuracy: 0.6842 - auc: 0.7523 - val_loss: 0.5797 - val_accuracy: 0.7218 - val_auc: 0.7679\n",
      "Epoch 116/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5878 - accuracy: 0.6837 - auc: 0.7522 - val_loss: 0.5798 - val_accuracy: 0.7218 - val_auc: 0.7675\n",
      "Epoch 117/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5833 - accuracy: 0.6882 - auc: 0.7572 - val_loss: 0.5801 - val_accuracy: 0.7218 - val_auc: 0.7672\n",
      "Epoch 118/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5936 - accuracy: 0.6803 - auc: 0.7456 - val_loss: 0.5799 - val_accuracy: 0.7202 - val_auc: 0.7679\n",
      "Epoch 119/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5877 - accuracy: 0.6927 - auc: 0.7534 - val_loss: 0.5804 - val_accuracy: 0.7218 - val_auc: 0.7672\n",
      "Epoch 120/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5924 - accuracy: 0.6813 - auc: 0.7479 - val_loss: 0.5808 - val_accuracy: 0.7202 - val_auc: 0.7668\n",
      "Epoch 121/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5916 - accuracy: 0.6847 - auc: 0.7467 - val_loss: 0.5813 - val_accuracy: 0.7202 - val_auc: 0.7664\n",
      "Epoch 122/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5915 - accuracy: 0.6798 - auc: 0.7459 - val_loss: 0.5812 - val_accuracy: 0.7234 - val_auc: 0.7664\n",
      "Epoch 123/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5861 - accuracy: 0.6857 - auc: 0.7522 - val_loss: 0.5801 - val_accuracy: 0.7266 - val_auc: 0.7677\n",
      "Epoch 124/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5911 - accuracy: 0.6932 - auc: 0.7497 - val_loss: 0.5796 - val_accuracy: 0.7266 - val_auc: 0.7682\n",
      "Epoch 125/700\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.5876 - accuracy: 0.6822 - auc: 0.7529 - val_loss: 0.5792 - val_accuracy: 0.7266 - val_auc: 0.7691\n",
      "Epoch 126/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5853 - accuracy: 0.6887 - auc: 0.7588 - val_loss: 0.5798 - val_accuracy: 0.7234 - val_auc: 0.7683\n",
      "Epoch 127/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5845 - accuracy: 0.6837 - auc: 0.7569 - val_loss: 0.5794 - val_accuracy: 0.7250 - val_auc: 0.7684\n",
      "Epoch 128/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5891 - accuracy: 0.6827 - auc: 0.7525 - val_loss: 0.5802 - val_accuracy: 0.7266 - val_auc: 0.7680\n",
      "Epoch 129/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5844 - accuracy: 0.6847 - auc: 0.7570 - val_loss: 0.5801 - val_accuracy: 0.7218 - val_auc: 0.7679\n",
      "Epoch 130/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5823 - accuracy: 0.6892 - auc: 0.7601 - val_loss: 0.5791 - val_accuracy: 0.7234 - val_auc: 0.7692\n",
      "Epoch 131/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5850 - accuracy: 0.6922 - auc: 0.7568 - val_loss: 0.5782 - val_accuracy: 0.7281 - val_auc: 0.7700\n",
      "Epoch 132/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5886 - accuracy: 0.6783 - auc: 0.7521 - val_loss: 0.5783 - val_accuracy: 0.7250 - val_auc: 0.7698\n",
      "Epoch 133/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5897 - accuracy: 0.6803 - auc: 0.7482 - val_loss: 0.5788 - val_accuracy: 0.7297 - val_auc: 0.7693\n",
      "Epoch 134/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5877 - accuracy: 0.6778 - auc: 0.7518 - val_loss: 0.5781 - val_accuracy: 0.7281 - val_auc: 0.7698\n",
      "Epoch 135/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5918 - accuracy: 0.6808 - auc: 0.7497 - val_loss: 0.5784 - val_accuracy: 0.7250 - val_auc: 0.7695\n",
      "Epoch 136/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5831 - accuracy: 0.6902 - auc: 0.7570 - val_loss: 0.5785 - val_accuracy: 0.7266 - val_auc: 0.7692\n",
      "Epoch 137/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5856 - accuracy: 0.6822 - auc: 0.7544 - val_loss: 0.5779 - val_accuracy: 0.7218 - val_auc: 0.7704\n",
      "Epoch 138/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5849 - accuracy: 0.6813 - auc: 0.7565 - val_loss: 0.5779 - val_accuracy: 0.7234 - val_auc: 0.7709\n",
      "Epoch 139/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5875 - accuracy: 0.6788 - auc: 0.7532 - val_loss: 0.5779 - val_accuracy: 0.7234 - val_auc: 0.7710\n",
      "Epoch 140/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5923 - accuracy: 0.6852 - auc: 0.7470 - val_loss: 0.5783 - val_accuracy: 0.7250 - val_auc: 0.7704\n",
      "Epoch 141/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5856 - accuracy: 0.6872 - auc: 0.7549 - val_loss: 0.5783 - val_accuracy: 0.7250 - val_auc: 0.7706\n",
      "Epoch 142/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5880 - accuracy: 0.6862 - auc: 0.7542 - val_loss: 0.5777 - val_accuracy: 0.7266 - val_auc: 0.7708\n",
      "Epoch 143/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5878 - accuracy: 0.6842 - auc: 0.7527 - val_loss: 0.5771 - val_accuracy: 0.7234 - val_auc: 0.7714\n",
      "Epoch 144/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5816 - accuracy: 0.6942 - auc: 0.7612 - val_loss: 0.5764 - val_accuracy: 0.7250 - val_auc: 0.7721\n",
      "Epoch 145/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5876 - accuracy: 0.6882 - auc: 0.7519 - val_loss: 0.5768 - val_accuracy: 0.7266 - val_auc: 0.7718\n",
      "Epoch 146/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5866 - accuracy: 0.6917 - auc: 0.7571 - val_loss: 0.5772 - val_accuracy: 0.7281 - val_auc: 0.7717\n",
      "Epoch 147/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5830 - accuracy: 0.6867 - auc: 0.7587 - val_loss: 0.5770 - val_accuracy: 0.7297 - val_auc: 0.7720\n",
      "Epoch 148/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5803 - accuracy: 0.7011 - auc: 0.7639 - val_loss: 0.5772 - val_accuracy: 0.7266 - val_auc: 0.7716\n",
      "Epoch 149/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5813 - accuracy: 0.6907 - auc: 0.7602 - val_loss: 0.5769 - val_accuracy: 0.7266 - val_auc: 0.7722\n",
      "Epoch 150/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5831 - accuracy: 0.6922 - auc: 0.7579 - val_loss: 0.5761 - val_accuracy: 0.7281 - val_auc: 0.7730\n",
      "Epoch 151/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5794 - accuracy: 0.6937 - auc: 0.7631 - val_loss: 0.5762 - val_accuracy: 0.7281 - val_auc: 0.7724\n",
      "Epoch 152/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5857 - accuracy: 0.6957 - auc: 0.7558 - val_loss: 0.5765 - val_accuracy: 0.7281 - val_auc: 0.7721\n",
      "Epoch 153/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5864 - accuracy: 0.6902 - auc: 0.7535 - val_loss: 0.5764 - val_accuracy: 0.7297 - val_auc: 0.7725\n",
      "Epoch 154/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5837 - accuracy: 0.6927 - auc: 0.7580 - val_loss: 0.5766 - val_accuracy: 0.7250 - val_auc: 0.7725\n",
      "Epoch 155/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5873 - accuracy: 0.6847 - auc: 0.7511 - val_loss: 0.5774 - val_accuracy: 0.7218 - val_auc: 0.7715\n",
      "Epoch 156/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5836 - accuracy: 0.6897 - auc: 0.7591 - val_loss: 0.5773 - val_accuracy: 0.7250 - val_auc: 0.7714\n",
      "Epoch 157/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5874 - accuracy: 0.6887 - auc: 0.7533 - val_loss: 0.5771 - val_accuracy: 0.7281 - val_auc: 0.7715\n",
      "Epoch 158/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5762 - accuracy: 0.6882 - auc: 0.7651 - val_loss: 0.5765 - val_accuracy: 0.7281 - val_auc: 0.7723\n",
      "Epoch 159/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5863 - accuracy: 0.6768 - auc: 0.7511 - val_loss: 0.5765 - val_accuracy: 0.7234 - val_auc: 0.7728\n",
      "Epoch 160/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5834 - accuracy: 0.6867 - auc: 0.7575 - val_loss: 0.5755 - val_accuracy: 0.7297 - val_auc: 0.7734\n",
      "Epoch 161/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5792 - accuracy: 0.7026 - auc: 0.7629 - val_loss: 0.5750 - val_accuracy: 0.7297 - val_auc: 0.7743\n",
      "Epoch 162/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5851 - accuracy: 0.6852 - auc: 0.7557 - val_loss: 0.5756 - val_accuracy: 0.7266 - val_auc: 0.7735\n",
      "Epoch 163/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5760 - accuracy: 0.6992 - auc: 0.7664 - val_loss: 0.5751 - val_accuracy: 0.7266 - val_auc: 0.7742\n",
      "Epoch 164/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5816 - accuracy: 0.6992 - auc: 0.7626 - val_loss: 0.5749 - val_accuracy: 0.7297 - val_auc: 0.7747\n",
      "Epoch 165/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5786 - accuracy: 0.7006 - auc: 0.7642 - val_loss: 0.5755 - val_accuracy: 0.7266 - val_auc: 0.7740\n",
      "Epoch 166/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5793 - accuracy: 0.6942 - auc: 0.7640 - val_loss: 0.5755 - val_accuracy: 0.7297 - val_auc: 0.7739\n",
      "Epoch 167/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5839 - accuracy: 0.6907 - auc: 0.7589 - val_loss: 0.5762 - val_accuracy: 0.7234 - val_auc: 0.7728\n",
      "Epoch 168/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5747 - accuracy: 0.6942 - auc: 0.7668 - val_loss: 0.5755 - val_accuracy: 0.7266 - val_auc: 0.7734\n",
      "Epoch 169/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5844 - accuracy: 0.6758 - auc: 0.7550 - val_loss: 0.5752 - val_accuracy: 0.7281 - val_auc: 0.7742\n",
      "Epoch 170/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5807 - accuracy: 0.6922 - auc: 0.7603 - val_loss: 0.5757 - val_accuracy: 0.7250 - val_auc: 0.7735\n",
      "Epoch 171/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5849 - accuracy: 0.6927 - auc: 0.7584 - val_loss: 0.5750 - val_accuracy: 0.7266 - val_auc: 0.7743\n",
      "Epoch 172/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5757 - accuracy: 0.6947 - auc: 0.7658 - val_loss: 0.5746 - val_accuracy: 0.7250 - val_auc: 0.7746\n",
      "Epoch 173/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5779 - accuracy: 0.6922 - auc: 0.7645 - val_loss: 0.5744 - val_accuracy: 0.7250 - val_auc: 0.7746\n",
      "Epoch 174/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5825 - accuracy: 0.6977 - auc: 0.7588 - val_loss: 0.5742 - val_accuracy: 0.7266 - val_auc: 0.7751\n",
      "Epoch 175/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5813 - accuracy: 0.6882 - auc: 0.7603 - val_loss: 0.5741 - val_accuracy: 0.7250 - val_auc: 0.7752\n",
      "Epoch 176/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5772 - accuracy: 0.6942 - auc: 0.7622 - val_loss: 0.5735 - val_accuracy: 0.7250 - val_auc: 0.7754\n",
      "Epoch 177/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5779 - accuracy: 0.6997 - auc: 0.7633 - val_loss: 0.5739 - val_accuracy: 0.7266 - val_auc: 0.7755\n",
      "Epoch 178/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5817 - accuracy: 0.6987 - auc: 0.7614 - val_loss: 0.5738 - val_accuracy: 0.7234 - val_auc: 0.7756\n",
      "Epoch 179/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5776 - accuracy: 0.6987 - auc: 0.7659 - val_loss: 0.5735 - val_accuracy: 0.7250 - val_auc: 0.7756\n",
      "Epoch 180/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5774 - accuracy: 0.6912 - auc: 0.7643 - val_loss: 0.5734 - val_accuracy: 0.7202 - val_auc: 0.7759\n",
      "Epoch 181/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5769 - accuracy: 0.6937 - auc: 0.7644 - val_loss: 0.5754 - val_accuracy: 0.7266 - val_auc: 0.7742\n",
      "Epoch 182/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5767 - accuracy: 0.6972 - auc: 0.7646 - val_loss: 0.5753 - val_accuracy: 0.7250 - val_auc: 0.7742\n",
      "Epoch 183/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5766 - accuracy: 0.6982 - auc: 0.7654 - val_loss: 0.5751 - val_accuracy: 0.7218 - val_auc: 0.7745\n",
      "Epoch 184/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5794 - accuracy: 0.7026 - auc: 0.7613 - val_loss: 0.5742 - val_accuracy: 0.7218 - val_auc: 0.7754\n",
      "Epoch 185/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5758 - accuracy: 0.6967 - auc: 0.7665 - val_loss: 0.5735 - val_accuracy: 0.7266 - val_auc: 0.7761\n",
      "Epoch 186/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5787 - accuracy: 0.6912 - auc: 0.7633 - val_loss: 0.5728 - val_accuracy: 0.7297 - val_auc: 0.7764\n",
      "Epoch 187/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5792 - accuracy: 0.6967 - auc: 0.7643 - val_loss: 0.5733 - val_accuracy: 0.7266 - val_auc: 0.7765\n",
      "Epoch 188/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5774 - accuracy: 0.6887 - auc: 0.7658 - val_loss: 0.5736 - val_accuracy: 0.7234 - val_auc: 0.7761\n",
      "Epoch 189/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5720 - accuracy: 0.6947 - auc: 0.7716 - val_loss: 0.5739 - val_accuracy: 0.7250 - val_auc: 0.7759\n",
      "Epoch 190/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5796 - accuracy: 0.7016 - auc: 0.7651 - val_loss: 0.5730 - val_accuracy: 0.7266 - val_auc: 0.7769\n",
      "Epoch 191/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5737 - accuracy: 0.6922 - auc: 0.7690 - val_loss: 0.5734 - val_accuracy: 0.7281 - val_auc: 0.7763\n",
      "Epoch 192/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5742 - accuracy: 0.6912 - auc: 0.7671 - val_loss: 0.5723 - val_accuracy: 0.7297 - val_auc: 0.7770\n",
      "Epoch 193/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5740 - accuracy: 0.6982 - auc: 0.7692 - val_loss: 0.5729 - val_accuracy: 0.7266 - val_auc: 0.7766\n",
      "Epoch 194/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5753 - accuracy: 0.6982 - auc: 0.7682 - val_loss: 0.5722 - val_accuracy: 0.7281 - val_auc: 0.7775\n",
      "Epoch 195/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5846 - accuracy: 0.6832 - auc: 0.7575 - val_loss: 0.5723 - val_accuracy: 0.7218 - val_auc: 0.7769\n",
      "Epoch 196/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5788 - accuracy: 0.7026 - auc: 0.7644 - val_loss: 0.5726 - val_accuracy: 0.7281 - val_auc: 0.7771\n",
      "Epoch 197/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5841 - accuracy: 0.6703 - auc: 0.7544 - val_loss: 0.5737 - val_accuracy: 0.7250 - val_auc: 0.7762\n",
      "Epoch 198/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5771 - accuracy: 0.7021 - auc: 0.7647 - val_loss: 0.5739 - val_accuracy: 0.7234 - val_auc: 0.7760\n",
      "Epoch 199/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5792 - accuracy: 0.7001 - auc: 0.7631 - val_loss: 0.5734 - val_accuracy: 0.7266 - val_auc: 0.7763\n",
      "Epoch 200/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5792 - accuracy: 0.6892 - auc: 0.7626 - val_loss: 0.5725 - val_accuracy: 0.7266 - val_auc: 0.7771\n",
      "Epoch 201/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5781 - accuracy: 0.6972 - auc: 0.7658 - val_loss: 0.5722 - val_accuracy: 0.7234 - val_auc: 0.7777\n",
      "Epoch 202/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5770 - accuracy: 0.6922 - auc: 0.7649 - val_loss: 0.5724 - val_accuracy: 0.7218 - val_auc: 0.7775\n",
      "Epoch 203/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5793 - accuracy: 0.6932 - auc: 0.7627 - val_loss: 0.5726 - val_accuracy: 0.7234 - val_auc: 0.7772\n",
      "Epoch 204/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5710 - accuracy: 0.6997 - auc: 0.7714 - val_loss: 0.5740 - val_accuracy: 0.7250 - val_auc: 0.7767\n",
      "Epoch 205/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5826 - accuracy: 0.7006 - auc: 0.7620 - val_loss: 0.5731 - val_accuracy: 0.7250 - val_auc: 0.7770\n",
      "Epoch 206/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5745 - accuracy: 0.7101 - auc: 0.7724 - val_loss: 0.5729 - val_accuracy: 0.7234 - val_auc: 0.7779\n",
      "Epoch 207/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5754 - accuracy: 0.6962 - auc: 0.7683 - val_loss: 0.5732 - val_accuracy: 0.7266 - val_auc: 0.7778\n",
      "Epoch 208/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5726 - accuracy: 0.7036 - auc: 0.7714 - val_loss: 0.5728 - val_accuracy: 0.7281 - val_auc: 0.7781\n",
      "Epoch 209/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5805 - accuracy: 0.6937 - auc: 0.7637 - val_loss: 0.5725 - val_accuracy: 0.7266 - val_auc: 0.7782\n",
      "Epoch 210/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5705 - accuracy: 0.7051 - auc: 0.7733 - val_loss: 0.5718 - val_accuracy: 0.7266 - val_auc: 0.7784\n",
      "Epoch 211/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5777 - accuracy: 0.6942 - auc: 0.7659 - val_loss: 0.5723 - val_accuracy: 0.7250 - val_auc: 0.7781\n",
      "Epoch 212/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5720 - accuracy: 0.7006 - auc: 0.7707 - val_loss: 0.5715 - val_accuracy: 0.7218 - val_auc: 0.7786\n",
      "Epoch 213/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5756 - accuracy: 0.6997 - auc: 0.7658 - val_loss: 0.5712 - val_accuracy: 0.7218 - val_auc: 0.7788\n",
      "Epoch 214/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5788 - accuracy: 0.7046 - auc: 0.7644 - val_loss: 0.5711 - val_accuracy: 0.7234 - val_auc: 0.7792\n",
      "Epoch 215/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5765 - accuracy: 0.7011 - auc: 0.7671 - val_loss: 0.5713 - val_accuracy: 0.7234 - val_auc: 0.7788\n",
      "Epoch 216/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5713 - accuracy: 0.6937 - auc: 0.7717 - val_loss: 0.5718 - val_accuracy: 0.7234 - val_auc: 0.7782\n",
      "Epoch 217/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5723 - accuracy: 0.6977 - auc: 0.7695 - val_loss: 0.5726 - val_accuracy: 0.7250 - val_auc: 0.7776\n",
      "Epoch 218/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5719 - accuracy: 0.7021 - auc: 0.7706 - val_loss: 0.5718 - val_accuracy: 0.7250 - val_auc: 0.7785\n",
      "Epoch 219/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5748 - accuracy: 0.7016 - auc: 0.7691 - val_loss: 0.5717 - val_accuracy: 0.7250 - val_auc: 0.7785\n",
      "Epoch 220/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5755 - accuracy: 0.7046 - auc: 0.7678 - val_loss: 0.5719 - val_accuracy: 0.7266 - val_auc: 0.7785\n",
      "Epoch 221/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5740 - accuracy: 0.7081 - auc: 0.7699 - val_loss: 0.5715 - val_accuracy: 0.7234 - val_auc: 0.7788\n",
      "Epoch 222/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5815 - accuracy: 0.6962 - auc: 0.7613 - val_loss: 0.5705 - val_accuracy: 0.7218 - val_auc: 0.7798\n",
      "Epoch 223/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5783 - accuracy: 0.6932 - auc: 0.7620 - val_loss: 0.5705 - val_accuracy: 0.7234 - val_auc: 0.7798\n",
      "Epoch 224/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5796 - accuracy: 0.6947 - auc: 0.7637 - val_loss: 0.5701 - val_accuracy: 0.7234 - val_auc: 0.7799\n",
      "Epoch 225/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5730 - accuracy: 0.6927 - auc: 0.7682 - val_loss: 0.5702 - val_accuracy: 0.7250 - val_auc: 0.7800\n",
      "Epoch 226/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5717 - accuracy: 0.7006 - auc: 0.7717 - val_loss: 0.5701 - val_accuracy: 0.7250 - val_auc: 0.7802\n",
      "Epoch 227/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5732 - accuracy: 0.7016 - auc: 0.7674 - val_loss: 0.5700 - val_accuracy: 0.7281 - val_auc: 0.7805\n",
      "Epoch 228/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5733 - accuracy: 0.7006 - auc: 0.7693 - val_loss: 0.5697 - val_accuracy: 0.7297 - val_auc: 0.7808\n",
      "Epoch 229/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5703 - accuracy: 0.7051 - auc: 0.7737 - val_loss: 0.5697 - val_accuracy: 0.7266 - val_auc: 0.7808\n",
      "Epoch 230/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5732 - accuracy: 0.6972 - auc: 0.7697 - val_loss: 0.5695 - val_accuracy: 0.7234 - val_auc: 0.7812\n",
      "Epoch 231/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5778 - accuracy: 0.6907 - auc: 0.7635 - val_loss: 0.5697 - val_accuracy: 0.7266 - val_auc: 0.7807\n",
      "Epoch 232/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5784 - accuracy: 0.6967 - auc: 0.7639 - val_loss: 0.5708 - val_accuracy: 0.7281 - val_auc: 0.7798\n",
      "Epoch 233/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5727 - accuracy: 0.7141 - auc: 0.7733 - val_loss: 0.5706 - val_accuracy: 0.7297 - val_auc: 0.7800\n",
      "Epoch 234/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5766 - accuracy: 0.6932 - auc: 0.7646 - val_loss: 0.5708 - val_accuracy: 0.7250 - val_auc: 0.7797\n",
      "Epoch 235/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5710 - accuracy: 0.7086 - auc: 0.7711 - val_loss: 0.5703 - val_accuracy: 0.7250 - val_auc: 0.7801\n",
      "Epoch 236/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5735 - accuracy: 0.6932 - auc: 0.7689 - val_loss: 0.5707 - val_accuracy: 0.7250 - val_auc: 0.7797\n",
      "Epoch 237/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5713 - accuracy: 0.7151 - auc: 0.7737 - val_loss: 0.5700 - val_accuracy: 0.7218 - val_auc: 0.7801\n",
      "Epoch 238/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5724 - accuracy: 0.6977 - auc: 0.7694 - val_loss: 0.5698 - val_accuracy: 0.7234 - val_auc: 0.7804\n",
      "Epoch 239/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5762 - accuracy: 0.6997 - auc: 0.7660 - val_loss: 0.5694 - val_accuracy: 0.7218 - val_auc: 0.7806\n",
      "Epoch 240/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5771 - accuracy: 0.6813 - auc: 0.7624 - val_loss: 0.5706 - val_accuracy: 0.7202 - val_auc: 0.7797\n",
      "Epoch 241/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5720 - accuracy: 0.7081 - auc: 0.7715 - val_loss: 0.5705 - val_accuracy: 0.7266 - val_auc: 0.7797\n",
      "Epoch 242/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5733 - accuracy: 0.6942 - auc: 0.7708 - val_loss: 0.5702 - val_accuracy: 0.7186 - val_auc: 0.7799\n",
      "Epoch 243/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5723 - accuracy: 0.6972 - auc: 0.7699 - val_loss: 0.5703 - val_accuracy: 0.7250 - val_auc: 0.7801\n",
      "Epoch 244/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5710 - accuracy: 0.6947 - auc: 0.7692 - val_loss: 0.5700 - val_accuracy: 0.7202 - val_auc: 0.7805\n",
      "Epoch 245/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5711 - accuracy: 0.7006 - auc: 0.7729 - val_loss: 0.5699 - val_accuracy: 0.7218 - val_auc: 0.7807\n",
      "Epoch 246/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5731 - accuracy: 0.7051 - auc: 0.7697 - val_loss: 0.5701 - val_accuracy: 0.7218 - val_auc: 0.7806\n",
      "Epoch 247/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5735 - accuracy: 0.6987 - auc: 0.7712 - val_loss: 0.5698 - val_accuracy: 0.7218 - val_auc: 0.7805\n",
      "Epoch 248/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5690 - accuracy: 0.7016 - auc: 0.7745 - val_loss: 0.5699 - val_accuracy: 0.7218 - val_auc: 0.7805\n",
      "Epoch 249/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5703 - accuracy: 0.6987 - auc: 0.7733 - val_loss: 0.5704 - val_accuracy: 0.7281 - val_auc: 0.7802\n",
      "Epoch 250/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5723 - accuracy: 0.6987 - auc: 0.7719 - val_loss: 0.5703 - val_accuracy: 0.7281 - val_auc: 0.7805\n",
      "Epoch 251/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5684 - accuracy: 0.6977 - auc: 0.7735 - val_loss: 0.5699 - val_accuracy: 0.7313 - val_auc: 0.7809\n",
      "Epoch 252/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5689 - accuracy: 0.7011 - auc: 0.7739 - val_loss: 0.5687 - val_accuracy: 0.7313 - val_auc: 0.7821\n",
      "Epoch 253/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5666 - accuracy: 0.7071 - auc: 0.7782 - val_loss: 0.5689 - val_accuracy: 0.7250 - val_auc: 0.7814\n",
      "Epoch 254/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5701 - accuracy: 0.7021 - auc: 0.7728 - val_loss: 0.5696 - val_accuracy: 0.7186 - val_auc: 0.7810\n",
      "Epoch 255/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5771 - accuracy: 0.6957 - auc: 0.7657 - val_loss: 0.5701 - val_accuracy: 0.7154 - val_auc: 0.7810\n",
      "Epoch 256/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5697 - accuracy: 0.7026 - auc: 0.7735 - val_loss: 0.5698 - val_accuracy: 0.7186 - val_auc: 0.7811\n",
      "Epoch 257/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5689 - accuracy: 0.6992 - auc: 0.7729 - val_loss: 0.5697 - val_accuracy: 0.7234 - val_auc: 0.7814\n",
      "Epoch 258/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5704 - accuracy: 0.6982 - auc: 0.7726 - val_loss: 0.5699 - val_accuracy: 0.7218 - val_auc: 0.7813\n",
      "Epoch 259/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5667 - accuracy: 0.7086 - auc: 0.7757 - val_loss: 0.5698 - val_accuracy: 0.7234 - val_auc: 0.7814\n",
      "Epoch 260/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5678 - accuracy: 0.7076 - auc: 0.7761 - val_loss: 0.5683 - val_accuracy: 0.7313 - val_auc: 0.7825\n",
      "Epoch 261/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5692 - accuracy: 0.7036 - auc: 0.7751 - val_loss: 0.5682 - val_accuracy: 0.7297 - val_auc: 0.7828\n",
      "Epoch 262/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5707 - accuracy: 0.7001 - auc: 0.7718 - val_loss: 0.5680 - val_accuracy: 0.7313 - val_auc: 0.7829\n",
      "Epoch 263/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5770 - accuracy: 0.7021 - auc: 0.7668 - val_loss: 0.5683 - val_accuracy: 0.7297 - val_auc: 0.7827\n",
      "Epoch 264/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5752 - accuracy: 0.6982 - auc: 0.7675 - val_loss: 0.5690 - val_accuracy: 0.7297 - val_auc: 0.7821\n",
      "Epoch 265/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5692 - accuracy: 0.7056 - auc: 0.7742 - val_loss: 0.5695 - val_accuracy: 0.7281 - val_auc: 0.7816\n",
      "Epoch 266/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5696 - accuracy: 0.7171 - auc: 0.7769 - val_loss: 0.5699 - val_accuracy: 0.7234 - val_auc: 0.7812\n",
      "Epoch 267/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5738 - accuracy: 0.6952 - auc: 0.7704 - val_loss: 0.5698 - val_accuracy: 0.7297 - val_auc: 0.7814\n",
      "Epoch 268/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5719 - accuracy: 0.7001 - auc: 0.7716 - val_loss: 0.5692 - val_accuracy: 0.7266 - val_auc: 0.7821\n",
      "Epoch 269/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5737 - accuracy: 0.6922 - auc: 0.7680 - val_loss: 0.5684 - val_accuracy: 0.7281 - val_auc: 0.7825\n",
      "Epoch 270/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5707 - accuracy: 0.7071 - auc: 0.7753 - val_loss: 0.5686 - val_accuracy: 0.7266 - val_auc: 0.7826\n",
      "Epoch 271/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5703 - accuracy: 0.6992 - auc: 0.7744 - val_loss: 0.5683 - val_accuracy: 0.7234 - val_auc: 0.7827\n",
      "Epoch 272/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5714 - accuracy: 0.7096 - auc: 0.7733 - val_loss: 0.5685 - val_accuracy: 0.7234 - val_auc: 0.7828\n",
      "Epoch 273/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5724 - accuracy: 0.7071 - auc: 0.7714 - val_loss: 0.5687 - val_accuracy: 0.7218 - val_auc: 0.7826\n",
      "Epoch 274/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5695 - accuracy: 0.7036 - auc: 0.7750 - val_loss: 0.5683 - val_accuracy: 0.7250 - val_auc: 0.7827\n",
      "Epoch 275/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5620 - accuracy: 0.7076 - auc: 0.7832 - val_loss: 0.5674 - val_accuracy: 0.7266 - val_auc: 0.7834\n",
      "Epoch 276/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5682 - accuracy: 0.7146 - auc: 0.7770 - val_loss: 0.5678 - val_accuracy: 0.7266 - val_auc: 0.7832\n",
      "Epoch 277/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5640 - accuracy: 0.7056 - auc: 0.7802 - val_loss: 0.5673 - val_accuracy: 0.7250 - val_auc: 0.7837\n",
      "Epoch 278/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5689 - accuracy: 0.7031 - auc: 0.7743 - val_loss: 0.5671 - val_accuracy: 0.7281 - val_auc: 0.7836\n",
      "Epoch 279/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5703 - accuracy: 0.7011 - auc: 0.7754 - val_loss: 0.5674 - val_accuracy: 0.7281 - val_auc: 0.7834\n",
      "Epoch 280/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5684 - accuracy: 0.7076 - auc: 0.7767 - val_loss: 0.5669 - val_accuracy: 0.7297 - val_auc: 0.7843\n",
      "Epoch 281/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5728 - accuracy: 0.7066 - auc: 0.7703 - val_loss: 0.5669 - val_accuracy: 0.7297 - val_auc: 0.7840\n",
      "Epoch 282/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5681 - accuracy: 0.7185 - auc: 0.7776 - val_loss: 0.5674 - val_accuracy: 0.7297 - val_auc: 0.7836\n",
      "Epoch 283/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5698 - accuracy: 0.7091 - auc: 0.7745 - val_loss: 0.5670 - val_accuracy: 0.7313 - val_auc: 0.7843\n",
      "Epoch 284/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5669 - accuracy: 0.7011 - auc: 0.7767 - val_loss: 0.5662 - val_accuracy: 0.7313 - val_auc: 0.7847\n",
      "Epoch 285/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5664 - accuracy: 0.7091 - auc: 0.7773 - val_loss: 0.5665 - val_accuracy: 0.7297 - val_auc: 0.7848\n",
      "Epoch 286/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5703 - accuracy: 0.7046 - auc: 0.7723 - val_loss: 0.5667 - val_accuracy: 0.7329 - val_auc: 0.7845\n",
      "Epoch 287/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5675 - accuracy: 0.7021 - auc: 0.7759 - val_loss: 0.5664 - val_accuracy: 0.7345 - val_auc: 0.7848\n",
      "Epoch 288/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5698 - accuracy: 0.7011 - auc: 0.7728 - val_loss: 0.5657 - val_accuracy: 0.7361 - val_auc: 0.7851\n",
      "Epoch 289/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5657 - accuracy: 0.7061 - auc: 0.7779 - val_loss: 0.5661 - val_accuracy: 0.7329 - val_auc: 0.7850\n",
      "Epoch 290/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5674 - accuracy: 0.7161 - auc: 0.7788 - val_loss: 0.5662 - val_accuracy: 0.7329 - val_auc: 0.7847\n",
      "Epoch 291/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5738 - accuracy: 0.7016 - auc: 0.7691 - val_loss: 0.5660 - val_accuracy: 0.7329 - val_auc: 0.7849\n",
      "Epoch 292/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5733 - accuracy: 0.7086 - auc: 0.7715 - val_loss: 0.5660 - val_accuracy: 0.7297 - val_auc: 0.7849\n",
      "Epoch 293/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5727 - accuracy: 0.7001 - auc: 0.7710 - val_loss: 0.5666 - val_accuracy: 0.7345 - val_auc: 0.7845\n",
      "Epoch 294/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5656 - accuracy: 0.7036 - auc: 0.7786 - val_loss: 0.5671 - val_accuracy: 0.7345 - val_auc: 0.7839\n",
      "Epoch 295/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5651 - accuracy: 0.7141 - auc: 0.7808 - val_loss: 0.5667 - val_accuracy: 0.7313 - val_auc: 0.7840\n",
      "Epoch 296/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5683 - accuracy: 0.7086 - auc: 0.7752 - val_loss: 0.5662 - val_accuracy: 0.7313 - val_auc: 0.7845\n",
      "Epoch 297/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5652 - accuracy: 0.7001 - auc: 0.7766 - val_loss: 0.5667 - val_accuracy: 0.7313 - val_auc: 0.7844\n",
      "Epoch 298/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5687 - accuracy: 0.7021 - auc: 0.7745 - val_loss: 0.5664 - val_accuracy: 0.7250 - val_auc: 0.7845\n",
      "Epoch 299/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5674 - accuracy: 0.7041 - auc: 0.7756 - val_loss: 0.5663 - val_accuracy: 0.7297 - val_auc: 0.7847\n",
      "Epoch 300/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5655 - accuracy: 0.7111 - auc: 0.7783 - val_loss: 0.5664 - val_accuracy: 0.7329 - val_auc: 0.7846\n",
      "Epoch 301/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5644 - accuracy: 0.7091 - auc: 0.7794 - val_loss: 0.5665 - val_accuracy: 0.7313 - val_auc: 0.7842\n",
      "Epoch 302/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5681 - accuracy: 0.7081 - auc: 0.7772 - val_loss: 0.5668 - val_accuracy: 0.7329 - val_auc: 0.7843\n",
      "Epoch 303/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5687 - accuracy: 0.6922 - auc: 0.7736 - val_loss: 0.5659 - val_accuracy: 0.7329 - val_auc: 0.7850\n",
      "Epoch 304/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5691 - accuracy: 0.7121 - auc: 0.7756 - val_loss: 0.5660 - val_accuracy: 0.7345 - val_auc: 0.7852\n",
      "Epoch 305/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5691 - accuracy: 0.7016 - auc: 0.7714 - val_loss: 0.5666 - val_accuracy: 0.7313 - val_auc: 0.7848\n",
      "Epoch 306/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5687 - accuracy: 0.7071 - auc: 0.7751 - val_loss: 0.5659 - val_accuracy: 0.7329 - val_auc: 0.7853\n",
      "Epoch 307/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5685 - accuracy: 0.6997 - auc: 0.7739 - val_loss: 0.5658 - val_accuracy: 0.7313 - val_auc: 0.7856\n",
      "Epoch 308/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5708 - accuracy: 0.6902 - auc: 0.7699 - val_loss: 0.5652 - val_accuracy: 0.7345 - val_auc: 0.7859\n",
      "Epoch 309/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5682 - accuracy: 0.7006 - auc: 0.7730 - val_loss: 0.5648 - val_accuracy: 0.7313 - val_auc: 0.7863\n",
      "Epoch 310/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5658 - accuracy: 0.7001 - auc: 0.7765 - val_loss: 0.5641 - val_accuracy: 0.7297 - val_auc: 0.7868\n",
      "Epoch 311/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5646 - accuracy: 0.7031 - auc: 0.7783 - val_loss: 0.5645 - val_accuracy: 0.7297 - val_auc: 0.7863\n",
      "Epoch 312/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5672 - accuracy: 0.7006 - auc: 0.7775 - val_loss: 0.5648 - val_accuracy: 0.7297 - val_auc: 0.7866\n",
      "Epoch 313/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5680 - accuracy: 0.7126 - auc: 0.7766 - val_loss: 0.5653 - val_accuracy: 0.7250 - val_auc: 0.7857\n",
      "Epoch 314/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5630 - accuracy: 0.7016 - auc: 0.7814 - val_loss: 0.5654 - val_accuracy: 0.7266 - val_auc: 0.7856\n",
      "Epoch 315/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5636 - accuracy: 0.7086 - auc: 0.7794 - val_loss: 0.5654 - val_accuracy: 0.7313 - val_auc: 0.7859\n",
      "Epoch 316/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5741 - accuracy: 0.7001 - auc: 0.7693 - val_loss: 0.5650 - val_accuracy: 0.7297 - val_auc: 0.7862\n",
      "Epoch 317/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5667 - accuracy: 0.7106 - auc: 0.7732 - val_loss: 0.5652 - val_accuracy: 0.7313 - val_auc: 0.7861\n",
      "Epoch 318/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5665 - accuracy: 0.7121 - auc: 0.7805 - val_loss: 0.5653 - val_accuracy: 0.7329 - val_auc: 0.7860\n",
      "Epoch 319/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5754 - accuracy: 0.6972 - auc: 0.7689 - val_loss: 0.5653 - val_accuracy: 0.7329 - val_auc: 0.7862\n",
      "Epoch 320/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5649 - accuracy: 0.7126 - auc: 0.7815 - val_loss: 0.5651 - val_accuracy: 0.7313 - val_auc: 0.7861\n",
      "Epoch 321/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5637 - accuracy: 0.7086 - auc: 0.7813 - val_loss: 0.5647 - val_accuracy: 0.7329 - val_auc: 0.7866\n",
      "Epoch 322/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5699 - accuracy: 0.7011 - auc: 0.7726 - val_loss: 0.5650 - val_accuracy: 0.7313 - val_auc: 0.7862\n",
      "Epoch 323/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5649 - accuracy: 0.7081 - auc: 0.7793 - val_loss: 0.5649 - val_accuracy: 0.7313 - val_auc: 0.7863\n",
      "Epoch 324/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5654 - accuracy: 0.7156 - auc: 0.7786 - val_loss: 0.5654 - val_accuracy: 0.7329 - val_auc: 0.7859\n",
      "Epoch 325/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5650 - accuracy: 0.7111 - auc: 0.7775 - val_loss: 0.5657 - val_accuracy: 0.7329 - val_auc: 0.7858\n",
      "Epoch 326/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5628 - accuracy: 0.7026 - auc: 0.7791 - val_loss: 0.5663 - val_accuracy: 0.7329 - val_auc: 0.7853\n",
      "Epoch 327/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5639 - accuracy: 0.7101 - auc: 0.7803 - val_loss: 0.5658 - val_accuracy: 0.7329 - val_auc: 0.7855\n",
      "Epoch 328/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5615 - accuracy: 0.7126 - auc: 0.7846 - val_loss: 0.5654 - val_accuracy: 0.7329 - val_auc: 0.7860\n",
      "Epoch 329/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5643 - accuracy: 0.7101 - auc: 0.7786 - val_loss: 0.5646 - val_accuracy: 0.7313 - val_auc: 0.7865\n",
      "Epoch 330/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5671 - accuracy: 0.7031 - auc: 0.7758 - val_loss: 0.5639 - val_accuracy: 0.7297 - val_auc: 0.7869\n",
      "Epoch 331/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5613 - accuracy: 0.7166 - auc: 0.7828 - val_loss: 0.5644 - val_accuracy: 0.7297 - val_auc: 0.7868\n",
      "Epoch 332/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5686 - accuracy: 0.6977 - auc: 0.7711 - val_loss: 0.5652 - val_accuracy: 0.7281 - val_auc: 0.7861\n",
      "Epoch 333/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5674 - accuracy: 0.7056 - auc: 0.7756 - val_loss: 0.5650 - val_accuracy: 0.7297 - val_auc: 0.7860\n",
      "Epoch 334/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5607 - accuracy: 0.7185 - auc: 0.7843 - val_loss: 0.5653 - val_accuracy: 0.7329 - val_auc: 0.7861\n",
      "Epoch 335/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5549 - accuracy: 0.7046 - auc: 0.7883 - val_loss: 0.5640 - val_accuracy: 0.7329 - val_auc: 0.7869\n",
      "Epoch 336/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5667 - accuracy: 0.7016 - auc: 0.7771 - val_loss: 0.5642 - val_accuracy: 0.7297 - val_auc: 0.7867\n",
      "Epoch 337/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5630 - accuracy: 0.7166 - auc: 0.7821 - val_loss: 0.5638 - val_accuracy: 0.7297 - val_auc: 0.7869\n",
      "Epoch 338/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5660 - accuracy: 0.7006 - auc: 0.7752 - val_loss: 0.5649 - val_accuracy: 0.7313 - val_auc: 0.7861\n",
      "Epoch 339/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5659 - accuracy: 0.7026 - auc: 0.7784 - val_loss: 0.5646 - val_accuracy: 0.7329 - val_auc: 0.7864\n",
      "Epoch 340/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5628 - accuracy: 0.7086 - auc: 0.7805 - val_loss: 0.5640 - val_accuracy: 0.7361 - val_auc: 0.7870\n",
      "Epoch 341/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5616 - accuracy: 0.7096 - auc: 0.7815 - val_loss: 0.5645 - val_accuracy: 0.7329 - val_auc: 0.7867\n",
      "Epoch 342/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5687 - accuracy: 0.7091 - auc: 0.7746 - val_loss: 0.5642 - val_accuracy: 0.7313 - val_auc: 0.7868\n",
      "Epoch 343/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5675 - accuracy: 0.7026 - auc: 0.7754 - val_loss: 0.5641 - val_accuracy: 0.7297 - val_auc: 0.7868\n",
      "Epoch 344/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5674 - accuracy: 0.7096 - auc: 0.7756 - val_loss: 0.5647 - val_accuracy: 0.7313 - val_auc: 0.7866\n",
      "Epoch 345/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5606 - accuracy: 0.7016 - auc: 0.7840 - val_loss: 0.5651 - val_accuracy: 0.7329 - val_auc: 0.7861\n",
      "Epoch 346/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5666 - accuracy: 0.7056 - auc: 0.7760 - val_loss: 0.5652 - val_accuracy: 0.7361 - val_auc: 0.7859\n",
      "Epoch 347/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5604 - accuracy: 0.7071 - auc: 0.7829 - val_loss: 0.5649 - val_accuracy: 0.7345 - val_auc: 0.7863\n",
      "Epoch 348/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5590 - accuracy: 0.7136 - auc: 0.7855 - val_loss: 0.5645 - val_accuracy: 0.7329 - val_auc: 0.7863\n",
      "Epoch 349/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5668 - accuracy: 0.7021 - auc: 0.7761 - val_loss: 0.5643 - val_accuracy: 0.7313 - val_auc: 0.7870\n",
      "Epoch 350/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5636 - accuracy: 0.7106 - auc: 0.7796 - val_loss: 0.5644 - val_accuracy: 0.7281 - val_auc: 0.7869\n",
      "Epoch 351/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5695 - accuracy: 0.7011 - auc: 0.7732 - val_loss: 0.5641 - val_accuracy: 0.7329 - val_auc: 0.7873\n",
      "Epoch 352/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5578 - accuracy: 0.7171 - auc: 0.7866 - val_loss: 0.5638 - val_accuracy: 0.7297 - val_auc: 0.7875\n",
      "Epoch 353/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5669 - accuracy: 0.7016 - auc: 0.7752 - val_loss: 0.5637 - val_accuracy: 0.7297 - val_auc: 0.7875\n",
      "Epoch 354/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5653 - accuracy: 0.7081 - auc: 0.7784 - val_loss: 0.5638 - val_accuracy: 0.7345 - val_auc: 0.7874\n",
      "Epoch 355/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5631 - accuracy: 0.7046 - auc: 0.7804 - val_loss: 0.5631 - val_accuracy: 0.7345 - val_auc: 0.7882\n",
      "Epoch 356/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5580 - accuracy: 0.7141 - auc: 0.7861 - val_loss: 0.5628 - val_accuracy: 0.7329 - val_auc: 0.7879\n",
      "Epoch 357/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5607 - accuracy: 0.7091 - auc: 0.7825 - val_loss: 0.5626 - val_accuracy: 0.7345 - val_auc: 0.7887\n",
      "Epoch 358/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5621 - accuracy: 0.7096 - auc: 0.7794 - val_loss: 0.5627 - val_accuracy: 0.7297 - val_auc: 0.7881\n",
      "Epoch 359/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5659 - accuracy: 0.7071 - auc: 0.7780 - val_loss: 0.5631 - val_accuracy: 0.7297 - val_auc: 0.7882\n",
      "Epoch 360/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5624 - accuracy: 0.7006 - auc: 0.7801 - val_loss: 0.5630 - val_accuracy: 0.7313 - val_auc: 0.7883\n",
      "Epoch 361/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5616 - accuracy: 0.7026 - auc: 0.7797 - val_loss: 0.5628 - val_accuracy: 0.7281 - val_auc: 0.7884\n",
      "Epoch 362/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5643 - accuracy: 0.7036 - auc: 0.7792 - val_loss: 0.5625 - val_accuracy: 0.7297 - val_auc: 0.7887\n",
      "Epoch 363/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5659 - accuracy: 0.7121 - auc: 0.7759 - val_loss: 0.5623 - val_accuracy: 0.7281 - val_auc: 0.7888\n",
      "Epoch 364/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5659 - accuracy: 0.7036 - auc: 0.7785 - val_loss: 0.5617 - val_accuracy: 0.7313 - val_auc: 0.7893\n",
      "Epoch 365/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5633 - accuracy: 0.7091 - auc: 0.7820 - val_loss: 0.5619 - val_accuracy: 0.7297 - val_auc: 0.7892\n",
      "Epoch 366/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5558 - accuracy: 0.7185 - auc: 0.7867 - val_loss: 0.5617 - val_accuracy: 0.7313 - val_auc: 0.7895\n",
      "Epoch 367/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5621 - accuracy: 0.7036 - auc: 0.7804 - val_loss: 0.5616 - val_accuracy: 0.7297 - val_auc: 0.7897\n",
      "Epoch 368/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5671 - accuracy: 0.7061 - auc: 0.7766 - val_loss: 0.5624 - val_accuracy: 0.7345 - val_auc: 0.7885\n",
      "Epoch 369/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5653 - accuracy: 0.7156 - auc: 0.7801 - val_loss: 0.5623 - val_accuracy: 0.7297 - val_auc: 0.7888\n",
      "Epoch 370/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5603 - accuracy: 0.7161 - auc: 0.7835 - val_loss: 0.5626 - val_accuracy: 0.7281 - val_auc: 0.7887\n",
      "Epoch 371/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5663 - accuracy: 0.6937 - auc: 0.7761 - val_loss: 0.5626 - val_accuracy: 0.7297 - val_auc: 0.7889\n",
      "Epoch 372/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5610 - accuracy: 0.7156 - auc: 0.7833 - val_loss: 0.5626 - val_accuracy: 0.7281 - val_auc: 0.7885\n",
      "Epoch 373/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5584 - accuracy: 0.7190 - auc: 0.7840 - val_loss: 0.5627 - val_accuracy: 0.7313 - val_auc: 0.7886\n",
      "Epoch 374/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5590 - accuracy: 0.7141 - auc: 0.7853 - val_loss: 0.5622 - val_accuracy: 0.7297 - val_auc: 0.7890\n",
      "Epoch 375/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5647 - accuracy: 0.7071 - auc: 0.7797 - val_loss: 0.5616 - val_accuracy: 0.7313 - val_auc: 0.7894\n",
      "Epoch 376/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5692 - accuracy: 0.7011 - auc: 0.7751 - val_loss: 0.5621 - val_accuracy: 0.7345 - val_auc: 0.7892\n",
      "Epoch 377/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5634 - accuracy: 0.7086 - auc: 0.7805 - val_loss: 0.5618 - val_accuracy: 0.7361 - val_auc: 0.7894\n",
      "Epoch 378/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5624 - accuracy: 0.7081 - auc: 0.7816 - val_loss: 0.5618 - val_accuracy: 0.7345 - val_auc: 0.7893\n",
      "Epoch 379/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5614 - accuracy: 0.7101 - auc: 0.7829 - val_loss: 0.5612 - val_accuracy: 0.7345 - val_auc: 0.7896\n",
      "Epoch 380/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5616 - accuracy: 0.7061 - auc: 0.7821 - val_loss: 0.5616 - val_accuracy: 0.7345 - val_auc: 0.7898\n",
      "Epoch 381/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5689 - accuracy: 0.7131 - auc: 0.7759 - val_loss: 0.5621 - val_accuracy: 0.7313 - val_auc: 0.7890\n",
      "Epoch 382/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5656 - accuracy: 0.7021 - auc: 0.7778 - val_loss: 0.5615 - val_accuracy: 0.7329 - val_auc: 0.7893\n",
      "Epoch 383/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5621 - accuracy: 0.7051 - auc: 0.7810 - val_loss: 0.5612 - val_accuracy: 0.7329 - val_auc: 0.7898\n",
      "Epoch 384/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5611 - accuracy: 0.7056 - auc: 0.7831 - val_loss: 0.5614 - val_accuracy: 0.7297 - val_auc: 0.7891\n",
      "Epoch 385/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5577 - accuracy: 0.7076 - auc: 0.7859 - val_loss: 0.5618 - val_accuracy: 0.7297 - val_auc: 0.7892\n",
      "Epoch 386/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5673 - accuracy: 0.7081 - auc: 0.7771 - val_loss: 0.5622 - val_accuracy: 0.7313 - val_auc: 0.7889\n",
      "Epoch 387/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5618 - accuracy: 0.7101 - auc: 0.7826 - val_loss: 0.5625 - val_accuracy: 0.7329 - val_auc: 0.7889\n",
      "Epoch 388/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5634 - accuracy: 0.7091 - auc: 0.7830 - val_loss: 0.5626 - val_accuracy: 0.7329 - val_auc: 0.7888\n",
      "Epoch 389/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5593 - accuracy: 0.7156 - auc: 0.7868 - val_loss: 0.5625 - val_accuracy: 0.7313 - val_auc: 0.7889\n",
      "Epoch 390/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5619 - accuracy: 0.7061 - auc: 0.7814 - val_loss: 0.5624 - val_accuracy: 0.7329 - val_auc: 0.7891\n",
      "Epoch 391/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5638 - accuracy: 0.7066 - auc: 0.7781 - val_loss: 0.5621 - val_accuracy: 0.7329 - val_auc: 0.7889\n",
      "Epoch 392/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5597 - accuracy: 0.7166 - auc: 0.7862 - val_loss: 0.5615 - val_accuracy: 0.7297 - val_auc: 0.7895\n",
      "Epoch 393/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5592 - accuracy: 0.7146 - auc: 0.7839 - val_loss: 0.5613 - val_accuracy: 0.7345 - val_auc: 0.7897\n",
      "Epoch 394/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5664 - accuracy: 0.7046 - auc: 0.7765 - val_loss: 0.5617 - val_accuracy: 0.7313 - val_auc: 0.7893\n",
      "Epoch 395/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5603 - accuracy: 0.7091 - auc: 0.7838 - val_loss: 0.5615 - val_accuracy: 0.7345 - val_auc: 0.7895\n",
      "Epoch 396/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5567 - accuracy: 0.7066 - auc: 0.7861 - val_loss: 0.5612 - val_accuracy: 0.7345 - val_auc: 0.7896\n",
      "Epoch 397/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5564 - accuracy: 0.7121 - auc: 0.7872 - val_loss: 0.5613 - val_accuracy: 0.7313 - val_auc: 0.7897\n",
      "Epoch 398/700\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5638 - accuracy: 0.6952 - auc: 0.7785 - val_loss: 0.5603 - val_accuracy: 0.7313 - val_auc: 0.7904\n",
      "Epoch 399/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5591 - accuracy: 0.7190 - auc: 0.7855 - val_loss: 0.5610 - val_accuracy: 0.7313 - val_auc: 0.7899\n",
      "Epoch 400/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5527 - accuracy: 0.7190 - auc: 0.7915 - val_loss: 0.5610 - val_accuracy: 0.7313 - val_auc: 0.7901\n",
      "Epoch 401/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5738 - accuracy: 0.7006 - auc: 0.7687 - val_loss: 0.5611 - val_accuracy: 0.7345 - val_auc: 0.7899\n",
      "Epoch 402/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5576 - accuracy: 0.7096 - auc: 0.7841 - val_loss: 0.5611 - val_accuracy: 0.7345 - val_auc: 0.7897\n",
      "Epoch 403/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5597 - accuracy: 0.7126 - auc: 0.7843 - val_loss: 0.5614 - val_accuracy: 0.7361 - val_auc: 0.7898\n",
      "Epoch 404/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5653 - accuracy: 0.6997 - auc: 0.7764 - val_loss: 0.5615 - val_accuracy: 0.7329 - val_auc: 0.7896\n",
      "Epoch 405/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5648 - accuracy: 0.7041 - auc: 0.7791 - val_loss: 0.5619 - val_accuracy: 0.7313 - val_auc: 0.7892\n",
      "Epoch 406/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5579 - accuracy: 0.7106 - auc: 0.7846 - val_loss: 0.5612 - val_accuracy: 0.7329 - val_auc: 0.7900\n",
      "Epoch 407/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5618 - accuracy: 0.7156 - auc: 0.7823 - val_loss: 0.5609 - val_accuracy: 0.7345 - val_auc: 0.7902\n",
      "Epoch 408/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5598 - accuracy: 0.7111 - auc: 0.7834 - val_loss: 0.5609 - val_accuracy: 0.7329 - val_auc: 0.7900\n",
      "Epoch 409/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5591 - accuracy: 0.7161 - auc: 0.7828 - val_loss: 0.5608 - val_accuracy: 0.7329 - val_auc: 0.7900\n",
      "Epoch 410/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5543 - accuracy: 0.7255 - auc: 0.7900 - val_loss: 0.5607 - val_accuracy: 0.7345 - val_auc: 0.7905\n",
      "Epoch 411/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5602 - accuracy: 0.7071 - auc: 0.7817 - val_loss: 0.5609 - val_accuracy: 0.7361 - val_auc: 0.7903\n",
      "Epoch 412/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5608 - accuracy: 0.7111 - auc: 0.7835 - val_loss: 0.5607 - val_accuracy: 0.7377 - val_auc: 0.7905\n",
      "Epoch 413/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5627 - accuracy: 0.7026 - auc: 0.7802 - val_loss: 0.5607 - val_accuracy: 0.7345 - val_auc: 0.7903\n",
      "Epoch 414/700\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5509 - accuracy: 0.7265 - auc: 0.7937 - val_loss: 0.5602 - val_accuracy: 0.7361 - val_auc: 0.7906\n",
      "Epoch 415/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5592 - accuracy: 0.7156 - auc: 0.7860 - val_loss: 0.5600 - val_accuracy: 0.7361 - val_auc: 0.7910\n",
      "Epoch 416/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5567 - accuracy: 0.7146 - auc: 0.7859 - val_loss: 0.5600 - val_accuracy: 0.7377 - val_auc: 0.7909\n",
      "Epoch 417/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5607 - accuracy: 0.7066 - auc: 0.7845 - val_loss: 0.5596 - val_accuracy: 0.7329 - val_auc: 0.7913\n",
      "Epoch 418/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5576 - accuracy: 0.7111 - auc: 0.7856 - val_loss: 0.5592 - val_accuracy: 0.7345 - val_auc: 0.7917\n",
      "Epoch 419/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5551 - accuracy: 0.7096 - auc: 0.7876 - val_loss: 0.5593 - val_accuracy: 0.7313 - val_auc: 0.7915\n",
      "Epoch 420/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5566 - accuracy: 0.7121 - auc: 0.7859 - val_loss: 0.5595 - val_accuracy: 0.7361 - val_auc: 0.7913\n",
      "Epoch 421/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5605 - accuracy: 0.7011 - auc: 0.7818 - val_loss: 0.5591 - val_accuracy: 0.7361 - val_auc: 0.7916\n",
      "Epoch 422/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5592 - accuracy: 0.7086 - auc: 0.7837 - val_loss: 0.5600 - val_accuracy: 0.7329 - val_auc: 0.7908\n",
      "Epoch 423/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5594 - accuracy: 0.7126 - auc: 0.7835 - val_loss: 0.5607 - val_accuracy: 0.7361 - val_auc: 0.7908\n",
      "Epoch 424/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5566 - accuracy: 0.7121 - auc: 0.7862 - val_loss: 0.5602 - val_accuracy: 0.7313 - val_auc: 0.7912\n",
      "Epoch 425/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5620 - accuracy: 0.7131 - auc: 0.7813 - val_loss: 0.5602 - val_accuracy: 0.7345 - val_auc: 0.7906\n",
      "Epoch 426/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5568 - accuracy: 0.7051 - auc: 0.7849 - val_loss: 0.5604 - val_accuracy: 0.7345 - val_auc: 0.7907\n",
      "Epoch 427/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5552 - accuracy: 0.7200 - auc: 0.7883 - val_loss: 0.5601 - val_accuracy: 0.7377 - val_auc: 0.7907\n",
      "Epoch 428/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5565 - accuracy: 0.7161 - auc: 0.7881 - val_loss: 0.5601 - val_accuracy: 0.7345 - val_auc: 0.7907\n",
      "Epoch 429/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5578 - accuracy: 0.7091 - auc: 0.7858 - val_loss: 0.5604 - val_accuracy: 0.7345 - val_auc: 0.7910\n",
      "Epoch 430/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5568 - accuracy: 0.7106 - auc: 0.7854 - val_loss: 0.5604 - val_accuracy: 0.7361 - val_auc: 0.7907\n",
      "Epoch 431/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5554 - accuracy: 0.7041 - auc: 0.7867 - val_loss: 0.5607 - val_accuracy: 0.7377 - val_auc: 0.7905\n",
      "Epoch 432/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5558 - accuracy: 0.7220 - auc: 0.7888 - val_loss: 0.5607 - val_accuracy: 0.7377 - val_auc: 0.7902\n",
      "Epoch 433/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5625 - accuracy: 0.7111 - auc: 0.7810 - val_loss: 0.5613 - val_accuracy: 0.7377 - val_auc: 0.7898\n",
      "Epoch 434/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5601 - accuracy: 0.7111 - auc: 0.7841 - val_loss: 0.5604 - val_accuracy: 0.7361 - val_auc: 0.7909\n",
      "Epoch 435/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5494 - accuracy: 0.7190 - auc: 0.7942 - val_loss: 0.5595 - val_accuracy: 0.7345 - val_auc: 0.7914\n",
      "Epoch 436/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5475 - accuracy: 0.7195 - auc: 0.7947 - val_loss: 0.5594 - val_accuracy: 0.7361 - val_auc: 0.7917\n",
      "Epoch 437/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5557 - accuracy: 0.7161 - auc: 0.7863 - val_loss: 0.5596 - val_accuracy: 0.7345 - val_auc: 0.7913\n",
      "Epoch 438/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5565 - accuracy: 0.7161 - auc: 0.7871 - val_loss: 0.5593 - val_accuracy: 0.7345 - val_auc: 0.7919\n",
      "Epoch 439/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5622 - accuracy: 0.7101 - auc: 0.7800 - val_loss: 0.5584 - val_accuracy: 0.7377 - val_auc: 0.7925\n",
      "Epoch 440/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5638 - accuracy: 0.7001 - auc: 0.7775 - val_loss: 0.5583 - val_accuracy: 0.7377 - val_auc: 0.7924\n",
      "Epoch 441/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5548 - accuracy: 0.7181 - auc: 0.7902 - val_loss: 0.5584 - val_accuracy: 0.7377 - val_auc: 0.7923\n",
      "Epoch 442/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5604 - accuracy: 0.7081 - auc: 0.7840 - val_loss: 0.5586 - val_accuracy: 0.7361 - val_auc: 0.7920\n",
      "Epoch 443/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5504 - accuracy: 0.7230 - auc: 0.7936 - val_loss: 0.5586 - val_accuracy: 0.7393 - val_auc: 0.7922\n",
      "Epoch 444/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5518 - accuracy: 0.7225 - auc: 0.7918 - val_loss: 0.5582 - val_accuracy: 0.7393 - val_auc: 0.7922\n",
      "Epoch 445/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5563 - accuracy: 0.7171 - auc: 0.7877 - val_loss: 0.5580 - val_accuracy: 0.7409 - val_auc: 0.7926\n",
      "Epoch 446/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5563 - accuracy: 0.7245 - auc: 0.7884 - val_loss: 0.5586 - val_accuracy: 0.7393 - val_auc: 0.7921\n",
      "Epoch 447/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5579 - accuracy: 0.7086 - auc: 0.7860 - val_loss: 0.5583 - val_accuracy: 0.7393 - val_auc: 0.7923\n",
      "Epoch 448/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5592 - accuracy: 0.7096 - auc: 0.7840 - val_loss: 0.5586 - val_accuracy: 0.7377 - val_auc: 0.7918\n",
      "Epoch 449/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5561 - accuracy: 0.7181 - auc: 0.7879 - val_loss: 0.5586 - val_accuracy: 0.7393 - val_auc: 0.7920\n",
      "Epoch 450/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5564 - accuracy: 0.7166 - auc: 0.7876 - val_loss: 0.5586 - val_accuracy: 0.7377 - val_auc: 0.7920\n",
      "Epoch 451/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5538 - accuracy: 0.7181 - auc: 0.7891 - val_loss: 0.5583 - val_accuracy: 0.7377 - val_auc: 0.7924\n",
      "Epoch 452/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5575 - accuracy: 0.7210 - auc: 0.7862 - val_loss: 0.5583 - val_accuracy: 0.7345 - val_auc: 0.7926\n",
      "Epoch 453/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5558 - accuracy: 0.7171 - auc: 0.7896 - val_loss: 0.5587 - val_accuracy: 0.7377 - val_auc: 0.7920\n",
      "Epoch 454/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5593 - accuracy: 0.7121 - auc: 0.7830 - val_loss: 0.5589 - val_accuracy: 0.7377 - val_auc: 0.7919\n",
      "Epoch 455/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5626 - accuracy: 0.7076 - auc: 0.7802 - val_loss: 0.5590 - val_accuracy: 0.7377 - val_auc: 0.7920\n",
      "Epoch 456/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5572 - accuracy: 0.7111 - auc: 0.7862 - val_loss: 0.5589 - val_accuracy: 0.7377 - val_auc: 0.7920\n",
      "Epoch 457/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5539 - accuracy: 0.7195 - auc: 0.7902 - val_loss: 0.5592 - val_accuracy: 0.7377 - val_auc: 0.7918\n",
      "Epoch 458/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5571 - accuracy: 0.7106 - auc: 0.7863 - val_loss: 0.5589 - val_accuracy: 0.7409 - val_auc: 0.7918\n",
      "Epoch 459/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5620 - accuracy: 0.7091 - auc: 0.7818 - val_loss: 0.5591 - val_accuracy: 0.7377 - val_auc: 0.7922\n",
      "Epoch 460/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5560 - accuracy: 0.7205 - auc: 0.7875 - val_loss: 0.5592 - val_accuracy: 0.7377 - val_auc: 0.7919\n",
      "Epoch 461/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5561 - accuracy: 0.7210 - auc: 0.7886 - val_loss: 0.5593 - val_accuracy: 0.7377 - val_auc: 0.7917\n",
      "Epoch 462/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5519 - accuracy: 0.7101 - auc: 0.7915 - val_loss: 0.5589 - val_accuracy: 0.7440 - val_auc: 0.7917\n",
      "Epoch 463/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5584 - accuracy: 0.7056 - auc: 0.7850 - val_loss: 0.5588 - val_accuracy: 0.7440 - val_auc: 0.7917\n",
      "Epoch 464/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5512 - accuracy: 0.7161 - auc: 0.7905 - val_loss: 0.5584 - val_accuracy: 0.7393 - val_auc: 0.7921\n",
      "Epoch 465/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5555 - accuracy: 0.7176 - auc: 0.7878 - val_loss: 0.5584 - val_accuracy: 0.7440 - val_auc: 0.7921\n",
      "Epoch 466/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5575 - accuracy: 0.7066 - auc: 0.7864 - val_loss: 0.5580 - val_accuracy: 0.7409 - val_auc: 0.7923\n",
      "Epoch 467/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5565 - accuracy: 0.7166 - auc: 0.7888 - val_loss: 0.5566 - val_accuracy: 0.7409 - val_auc: 0.7936\n",
      "Epoch 468/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5531 - accuracy: 0.7056 - auc: 0.7872 - val_loss: 0.5563 - val_accuracy: 0.7424 - val_auc: 0.7936\n",
      "Epoch 469/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5549 - accuracy: 0.7076 - auc: 0.7879 - val_loss: 0.5567 - val_accuracy: 0.7409 - val_auc: 0.7933\n",
      "Epoch 470/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5542 - accuracy: 0.7136 - auc: 0.7884 - val_loss: 0.5572 - val_accuracy: 0.7409 - val_auc: 0.7933\n",
      "Epoch 471/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5564 - accuracy: 0.7176 - auc: 0.7864 - val_loss: 0.5579 - val_accuracy: 0.7440 - val_auc: 0.7927\n",
      "Epoch 472/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5578 - accuracy: 0.7091 - auc: 0.7855 - val_loss: 0.5576 - val_accuracy: 0.7440 - val_auc: 0.7927\n",
      "Epoch 473/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5599 - accuracy: 0.7126 - auc: 0.7849 - val_loss: 0.5575 - val_accuracy: 0.7409 - val_auc: 0.7928\n",
      "Epoch 474/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5569 - accuracy: 0.7126 - auc: 0.7861 - val_loss: 0.5573 - val_accuracy: 0.7409 - val_auc: 0.7930\n",
      "Epoch 475/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5618 - accuracy: 0.7240 - auc: 0.7840 - val_loss: 0.5572 - val_accuracy: 0.7424 - val_auc: 0.7932\n",
      "Epoch 476/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5599 - accuracy: 0.7061 - auc: 0.7819 - val_loss: 0.5579 - val_accuracy: 0.7424 - val_auc: 0.7927\n",
      "Epoch 477/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5552 - accuracy: 0.7141 - auc: 0.7862 - val_loss: 0.5575 - val_accuracy: 0.7440 - val_auc: 0.7929\n",
      "Epoch 478/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5574 - accuracy: 0.7195 - auc: 0.7867 - val_loss: 0.5573 - val_accuracy: 0.7424 - val_auc: 0.7933\n",
      "Epoch 479/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5529 - accuracy: 0.7240 - auc: 0.7931 - val_loss: 0.5574 - val_accuracy: 0.7424 - val_auc: 0.7930\n",
      "Epoch 480/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5552 - accuracy: 0.7101 - auc: 0.7882 - val_loss: 0.5571 - val_accuracy: 0.7440 - val_auc: 0.7930\n",
      "Epoch 481/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5548 - accuracy: 0.7176 - auc: 0.7902 - val_loss: 0.5576 - val_accuracy: 0.7409 - val_auc: 0.7930\n",
      "Epoch 482/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5561 - accuracy: 0.7086 - auc: 0.7866 - val_loss: 0.5576 - val_accuracy: 0.7393 - val_auc: 0.7930\n",
      "Epoch 483/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5563 - accuracy: 0.7096 - auc: 0.7863 - val_loss: 0.5578 - val_accuracy: 0.7440 - val_auc: 0.7928\n",
      "Epoch 484/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5519 - accuracy: 0.7126 - auc: 0.7903 - val_loss: 0.5578 - val_accuracy: 0.7424 - val_auc: 0.7930\n",
      "Epoch 485/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5568 - accuracy: 0.7230 - auc: 0.7881 - val_loss: 0.5580 - val_accuracy: 0.7440 - val_auc: 0.7928\n",
      "Epoch 486/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5584 - accuracy: 0.7156 - auc: 0.7851 - val_loss: 0.5573 - val_accuracy: 0.7440 - val_auc: 0.7931\n",
      "Epoch 487/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5514 - accuracy: 0.7205 - auc: 0.7919 - val_loss: 0.5567 - val_accuracy: 0.7440 - val_auc: 0.7935\n",
      "Epoch 488/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5530 - accuracy: 0.7141 - auc: 0.7889 - val_loss: 0.5567 - val_accuracy: 0.7440 - val_auc: 0.7936\n",
      "Epoch 489/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5543 - accuracy: 0.7151 - auc: 0.7890 - val_loss: 0.5566 - val_accuracy: 0.7472 - val_auc: 0.7937\n",
      "Epoch 490/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5552 - accuracy: 0.7240 - auc: 0.7902 - val_loss: 0.5564 - val_accuracy: 0.7456 - val_auc: 0.7936\n",
      "Epoch 491/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5555 - accuracy: 0.7151 - auc: 0.7893 - val_loss: 0.5562 - val_accuracy: 0.7472 - val_auc: 0.7935\n",
      "Epoch 492/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5527 - accuracy: 0.7205 - auc: 0.7912 - val_loss: 0.5565 - val_accuracy: 0.7424 - val_auc: 0.7937\n",
      "Epoch 493/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5567 - accuracy: 0.7136 - auc: 0.7863 - val_loss: 0.5566 - val_accuracy: 0.7440 - val_auc: 0.7937\n",
      "Epoch 494/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5501 - accuracy: 0.7245 - auc: 0.7932 - val_loss: 0.5564 - val_accuracy: 0.7440 - val_auc: 0.7938\n",
      "Epoch 495/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5555 - accuracy: 0.7106 - auc: 0.7866 - val_loss: 0.5568 - val_accuracy: 0.7440 - val_auc: 0.7936\n",
      "Epoch 496/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5611 - accuracy: 0.7111 - auc: 0.7823 - val_loss: 0.5570 - val_accuracy: 0.7424 - val_auc: 0.7933\n",
      "Epoch 497/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5564 - accuracy: 0.7181 - auc: 0.7880 - val_loss: 0.5569 - val_accuracy: 0.7472 - val_auc: 0.7933\n",
      "Epoch 498/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5588 - accuracy: 0.7161 - auc: 0.7863 - val_loss: 0.5569 - val_accuracy: 0.7440 - val_auc: 0.7934\n",
      "Epoch 499/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5549 - accuracy: 0.7166 - auc: 0.7877 - val_loss: 0.5567 - val_accuracy: 0.7456 - val_auc: 0.7936\n",
      "Epoch 500/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5543 - accuracy: 0.7116 - auc: 0.7888 - val_loss: 0.5564 - val_accuracy: 0.7456 - val_auc: 0.7934\n",
      "Epoch 501/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5492 - accuracy: 0.7205 - auc: 0.7946 - val_loss: 0.5572 - val_accuracy: 0.7424 - val_auc: 0.7931\n",
      "Epoch 502/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5504 - accuracy: 0.7195 - auc: 0.7923 - val_loss: 0.5569 - val_accuracy: 0.7456 - val_auc: 0.7931\n",
      "Epoch 503/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5550 - accuracy: 0.7076 - auc: 0.7866 - val_loss: 0.5568 - val_accuracy: 0.7456 - val_auc: 0.7932\n",
      "Epoch 504/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5606 - accuracy: 0.7046 - auc: 0.7826 - val_loss: 0.5566 - val_accuracy: 0.7440 - val_auc: 0.7934\n",
      "Epoch 505/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5576 - accuracy: 0.7106 - auc: 0.7826 - val_loss: 0.5556 - val_accuracy: 0.7424 - val_auc: 0.7944\n",
      "Epoch 506/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5495 - accuracy: 0.7220 - auc: 0.7945 - val_loss: 0.5553 - val_accuracy: 0.7409 - val_auc: 0.7946\n",
      "Epoch 507/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5568 - accuracy: 0.7210 - auc: 0.7891 - val_loss: 0.5551 - val_accuracy: 0.7440 - val_auc: 0.7948\n",
      "Epoch 508/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5562 - accuracy: 0.7190 - auc: 0.7883 - val_loss: 0.5549 - val_accuracy: 0.7424 - val_auc: 0.7947\n",
      "Epoch 509/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5501 - accuracy: 0.7111 - auc: 0.7909 - val_loss: 0.5557 - val_accuracy: 0.7424 - val_auc: 0.7942\n",
      "Epoch 510/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5582 - accuracy: 0.7151 - auc: 0.7847 - val_loss: 0.5562 - val_accuracy: 0.7424 - val_auc: 0.7936\n",
      "Epoch 511/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5516 - accuracy: 0.7176 - auc: 0.7915 - val_loss: 0.5562 - val_accuracy: 0.7424 - val_auc: 0.7936\n",
      "Epoch 512/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5584 - accuracy: 0.7116 - auc: 0.7852 - val_loss: 0.5563 - val_accuracy: 0.7440 - val_auc: 0.7934\n",
      "Epoch 513/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5507 - accuracy: 0.7185 - auc: 0.7925 - val_loss: 0.5565 - val_accuracy: 0.7456 - val_auc: 0.7934\n",
      "Epoch 514/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5509 - accuracy: 0.7205 - auc: 0.7927 - val_loss: 0.5568 - val_accuracy: 0.7456 - val_auc: 0.7933\n",
      "Epoch 515/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5511 - accuracy: 0.7171 - auc: 0.7938 - val_loss: 0.5560 - val_accuracy: 0.7456 - val_auc: 0.7939\n",
      "Epoch 516/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5578 - accuracy: 0.7185 - auc: 0.7866 - val_loss: 0.5560 - val_accuracy: 0.7440 - val_auc: 0.7939\n",
      "Epoch 517/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5543 - accuracy: 0.7230 - auc: 0.7881 - val_loss: 0.5554 - val_accuracy: 0.7456 - val_auc: 0.7947\n",
      "Epoch 518/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5527 - accuracy: 0.7156 - auc: 0.7900 - val_loss: 0.5554 - val_accuracy: 0.7440 - val_auc: 0.7947\n",
      "Epoch 519/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5526 - accuracy: 0.7220 - auc: 0.7924 - val_loss: 0.5549 - val_accuracy: 0.7488 - val_auc: 0.7953\n",
      "Epoch 520/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5546 - accuracy: 0.7036 - auc: 0.7858 - val_loss: 0.5546 - val_accuracy: 0.7456 - val_auc: 0.7950\n",
      "Epoch 521/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5509 - accuracy: 0.7255 - auc: 0.7922 - val_loss: 0.5550 - val_accuracy: 0.7424 - val_auc: 0.7946\n",
      "Epoch 522/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5571 - accuracy: 0.7131 - auc: 0.7844 - val_loss: 0.5551 - val_accuracy: 0.7456 - val_auc: 0.7946\n",
      "Epoch 523/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5560 - accuracy: 0.7106 - auc: 0.7869 - val_loss: 0.5550 - val_accuracy: 0.7440 - val_auc: 0.7946\n",
      "Epoch 524/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5475 - accuracy: 0.7220 - auc: 0.7949 - val_loss: 0.5552 - val_accuracy: 0.7472 - val_auc: 0.7946\n",
      "Epoch 525/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5523 - accuracy: 0.7240 - auc: 0.7912 - val_loss: 0.5553 - val_accuracy: 0.7456 - val_auc: 0.7947\n",
      "Epoch 526/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5524 - accuracy: 0.7166 - auc: 0.7911 - val_loss: 0.5549 - val_accuracy: 0.7424 - val_auc: 0.7949\n",
      "Epoch 527/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5541 - accuracy: 0.7121 - auc: 0.7892 - val_loss: 0.5546 - val_accuracy: 0.7424 - val_auc: 0.7954\n",
      "Epoch 528/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5532 - accuracy: 0.7235 - auc: 0.7905 - val_loss: 0.5548 - val_accuracy: 0.7440 - val_auc: 0.7948\n",
      "Epoch 529/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5463 - accuracy: 0.7240 - auc: 0.7967 - val_loss: 0.5545 - val_accuracy: 0.7456 - val_auc: 0.7950\n",
      "Epoch 530/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5590 - accuracy: 0.7101 - auc: 0.7828 - val_loss: 0.5545 - val_accuracy: 0.7440 - val_auc: 0.7951\n",
      "Epoch 531/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5519 - accuracy: 0.7290 - auc: 0.7913 - val_loss: 0.5547 - val_accuracy: 0.7440 - val_auc: 0.7948\n",
      "Epoch 532/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5511 - accuracy: 0.7195 - auc: 0.7921 - val_loss: 0.5548 - val_accuracy: 0.7440 - val_auc: 0.7949\n",
      "Epoch 533/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5490 - accuracy: 0.7106 - auc: 0.7928 - val_loss: 0.5541 - val_accuracy: 0.7440 - val_auc: 0.7954\n",
      "Epoch 534/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5504 - accuracy: 0.7146 - auc: 0.7906 - val_loss: 0.5547 - val_accuracy: 0.7456 - val_auc: 0.7950\n",
      "Epoch 535/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5506 - accuracy: 0.7215 - auc: 0.7925 - val_loss: 0.5545 - val_accuracy: 0.7440 - val_auc: 0.7947\n",
      "Epoch 536/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5582 - accuracy: 0.7181 - auc: 0.7816 - val_loss: 0.5541 - val_accuracy: 0.7456 - val_auc: 0.7953\n",
      "Epoch 537/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5551 - accuracy: 0.7096 - auc: 0.7871 - val_loss: 0.5544 - val_accuracy: 0.7440 - val_auc: 0.7955\n",
      "Epoch 538/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5504 - accuracy: 0.7181 - auc: 0.7923 - val_loss: 0.5547 - val_accuracy: 0.7472 - val_auc: 0.7950\n",
      "Epoch 539/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5445 - accuracy: 0.7305 - auc: 0.7991 - val_loss: 0.5546 - val_accuracy: 0.7472 - val_auc: 0.7953\n",
      "Epoch 540/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5519 - accuracy: 0.7205 - auc: 0.7917 - val_loss: 0.5545 - val_accuracy: 0.7472 - val_auc: 0.7953\n",
      "Epoch 541/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5517 - accuracy: 0.7131 - auc: 0.7910 - val_loss: 0.5544 - val_accuracy: 0.7472 - val_auc: 0.7954\n",
      "Epoch 542/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5527 - accuracy: 0.7176 - auc: 0.7896 - val_loss: 0.5548 - val_accuracy: 0.7456 - val_auc: 0.7951\n",
      "Epoch 543/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5506 - accuracy: 0.7081 - auc: 0.7903 - val_loss: 0.5553 - val_accuracy: 0.7456 - val_auc: 0.7947\n",
      "Epoch 544/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5560 - accuracy: 0.7131 - auc: 0.7856 - val_loss: 0.5554 - val_accuracy: 0.7424 - val_auc: 0.7946\n",
      "Epoch 545/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5476 - accuracy: 0.7176 - auc: 0.7951 - val_loss: 0.5558 - val_accuracy: 0.7456 - val_auc: 0.7944\n",
      "Epoch 546/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5526 - accuracy: 0.7285 - auc: 0.7930 - val_loss: 0.5554 - val_accuracy: 0.7472 - val_auc: 0.7944\n",
      "Epoch 547/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5438 - accuracy: 0.7315 - auc: 0.8016 - val_loss: 0.5554 - val_accuracy: 0.7456 - val_auc: 0.7946\n",
      "Epoch 548/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5575 - accuracy: 0.7131 - auc: 0.7860 - val_loss: 0.5545 - val_accuracy: 0.7456 - val_auc: 0.7950\n",
      "Epoch 549/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5416 - accuracy: 0.7181 - auc: 0.8003 - val_loss: 0.5542 - val_accuracy: 0.7440 - val_auc: 0.7953\n",
      "Epoch 550/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5522 - accuracy: 0.7270 - auc: 0.7931 - val_loss: 0.5543 - val_accuracy: 0.7456 - val_auc: 0.7955\n",
      "Epoch 551/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5483 - accuracy: 0.7146 - auc: 0.7936 - val_loss: 0.5546 - val_accuracy: 0.7440 - val_auc: 0.7950\n",
      "Epoch 552/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5520 - accuracy: 0.7225 - auc: 0.7936 - val_loss: 0.5551 - val_accuracy: 0.7472 - val_auc: 0.7948\n",
      "Epoch 553/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5544 - accuracy: 0.7151 - auc: 0.7883 - val_loss: 0.5543 - val_accuracy: 0.7472 - val_auc: 0.7954\n",
      "Epoch 554/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5547 - accuracy: 0.7086 - auc: 0.7870 - val_loss: 0.5546 - val_accuracy: 0.7424 - val_auc: 0.7951\n",
      "Epoch 555/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5465 - accuracy: 0.7245 - auc: 0.7974 - val_loss: 0.5537 - val_accuracy: 0.7440 - val_auc: 0.7957\n",
      "Epoch 556/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5506 - accuracy: 0.7210 - auc: 0.7941 - val_loss: 0.5529 - val_accuracy: 0.7456 - val_auc: 0.7962\n",
      "Epoch 557/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.7305 - auc: 0.8004 - val_loss: 0.5531 - val_accuracy: 0.7456 - val_auc: 0.7959\n",
      "Epoch 558/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5502 - accuracy: 0.7131 - auc: 0.7930 - val_loss: 0.5529 - val_accuracy: 0.7424 - val_auc: 0.7966\n",
      "Epoch 559/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5507 - accuracy: 0.7171 - auc: 0.7928 - val_loss: 0.5524 - val_accuracy: 0.7440 - val_auc: 0.7969\n",
      "Epoch 560/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5540 - accuracy: 0.7215 - auc: 0.7911 - val_loss: 0.5530 - val_accuracy: 0.7456 - val_auc: 0.7966\n",
      "Epoch 561/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5490 - accuracy: 0.7161 - auc: 0.7943 - val_loss: 0.5532 - val_accuracy: 0.7456 - val_auc: 0.7964\n",
      "Epoch 562/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5469 - accuracy: 0.7166 - auc: 0.7956 - val_loss: 0.5528 - val_accuracy: 0.7456 - val_auc: 0.7966\n",
      "Epoch 563/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5466 - accuracy: 0.7255 - auc: 0.7961 - val_loss: 0.5530 - val_accuracy: 0.7440 - val_auc: 0.7964\n",
      "Epoch 564/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5474 - accuracy: 0.7260 - auc: 0.7938 - val_loss: 0.5533 - val_accuracy: 0.7440 - val_auc: 0.7965\n",
      "Epoch 565/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5507 - accuracy: 0.7141 - auc: 0.7934 - val_loss: 0.5538 - val_accuracy: 0.7488 - val_auc: 0.7961\n",
      "Epoch 566/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5492 - accuracy: 0.7146 - auc: 0.7930 - val_loss: 0.5544 - val_accuracy: 0.7456 - val_auc: 0.7956\n",
      "Epoch 567/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5489 - accuracy: 0.7275 - auc: 0.7969 - val_loss: 0.5542 - val_accuracy: 0.7440 - val_auc: 0.7957\n",
      "Epoch 568/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5518 - accuracy: 0.7106 - auc: 0.7909 - val_loss: 0.5537 - val_accuracy: 0.7472 - val_auc: 0.7963\n",
      "Epoch 569/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5512 - accuracy: 0.7056 - auc: 0.7910 - val_loss: 0.5534 - val_accuracy: 0.7440 - val_auc: 0.7962\n",
      "Epoch 570/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5485 - accuracy: 0.7265 - auc: 0.7952 - val_loss: 0.5531 - val_accuracy: 0.7456 - val_auc: 0.7963\n",
      "Epoch 571/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5514 - accuracy: 0.7270 - auc: 0.7909 - val_loss: 0.5526 - val_accuracy: 0.7456 - val_auc: 0.7968\n",
      "Epoch 572/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5498 - accuracy: 0.7166 - auc: 0.7916 - val_loss: 0.5523 - val_accuracy: 0.7456 - val_auc: 0.7970\n",
      "Epoch 573/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5492 - accuracy: 0.7210 - auc: 0.7932 - val_loss: 0.5520 - val_accuracy: 0.7424 - val_auc: 0.7970\n",
      "Epoch 574/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.7255 - auc: 0.7987 - val_loss: 0.5523 - val_accuracy: 0.7456 - val_auc: 0.7970\n",
      "Epoch 575/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5469 - accuracy: 0.7210 - auc: 0.7960 - val_loss: 0.5526 - val_accuracy: 0.7440 - val_auc: 0.7968\n",
      "Epoch 576/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5451 - accuracy: 0.7185 - auc: 0.7973 - val_loss: 0.5523 - val_accuracy: 0.7440 - val_auc: 0.7970\n",
      "Epoch 577/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5489 - accuracy: 0.7181 - auc: 0.7963 - val_loss: 0.5521 - val_accuracy: 0.7456 - val_auc: 0.7972\n",
      "Epoch 578/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5531 - accuracy: 0.7156 - auc: 0.7878 - val_loss: 0.5524 - val_accuracy: 0.7440 - val_auc: 0.7969\n",
      "Epoch 579/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5500 - accuracy: 0.7131 - auc: 0.7906 - val_loss: 0.5520 - val_accuracy: 0.7456 - val_auc: 0.7972\n",
      "Epoch 580/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5490 - accuracy: 0.7096 - auc: 0.7934 - val_loss: 0.5525 - val_accuracy: 0.7456 - val_auc: 0.7969\n",
      "Epoch 581/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5522 - accuracy: 0.7195 - auc: 0.7937 - val_loss: 0.5523 - val_accuracy: 0.7456 - val_auc: 0.7971\n",
      "Epoch 582/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5472 - accuracy: 0.7181 - auc: 0.7945 - val_loss: 0.5529 - val_accuracy: 0.7456 - val_auc: 0.7965\n",
      "Epoch 583/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5627 - accuracy: 0.7096 - auc: 0.7814 - val_loss: 0.5530 - val_accuracy: 0.7456 - val_auc: 0.7964\n",
      "Epoch 584/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5490 - accuracy: 0.7260 - auc: 0.7943 - val_loss: 0.5530 - val_accuracy: 0.7440 - val_auc: 0.7968\n",
      "Epoch 585/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5475 - accuracy: 0.7310 - auc: 0.7977 - val_loss: 0.5527 - val_accuracy: 0.7440 - val_auc: 0.7968\n",
      "Epoch 586/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5462 - accuracy: 0.7200 - auc: 0.7938 - val_loss: 0.5523 - val_accuracy: 0.7472 - val_auc: 0.7968\n",
      "Epoch 587/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5442 - accuracy: 0.7230 - auc: 0.7958 - val_loss: 0.5525 - val_accuracy: 0.7488 - val_auc: 0.7970\n",
      "Epoch 588/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5484 - accuracy: 0.7141 - auc: 0.7933 - val_loss: 0.5518 - val_accuracy: 0.7488 - val_auc: 0.7976\n",
      "Epoch 589/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5471 - accuracy: 0.7205 - auc: 0.7953 - val_loss: 0.5518 - val_accuracy: 0.7440 - val_auc: 0.7973\n",
      "Epoch 590/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5491 - accuracy: 0.7215 - auc: 0.7953 - val_loss: 0.5521 - val_accuracy: 0.7456 - val_auc: 0.7973\n",
      "Epoch 591/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5498 - accuracy: 0.7290 - auc: 0.7943 - val_loss: 0.5524 - val_accuracy: 0.7456 - val_auc: 0.7971\n",
      "Epoch 592/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5473 - accuracy: 0.7225 - auc: 0.7947 - val_loss: 0.5520 - val_accuracy: 0.7440 - val_auc: 0.7972\n",
      "Epoch 593/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5511 - accuracy: 0.7235 - auc: 0.7918 - val_loss: 0.5523 - val_accuracy: 0.7456 - val_auc: 0.7968\n",
      "Epoch 594/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5528 - accuracy: 0.7200 - auc: 0.7895 - val_loss: 0.5531 - val_accuracy: 0.7472 - val_auc: 0.7965\n",
      "Epoch 595/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5500 - accuracy: 0.7156 - auc: 0.7934 - val_loss: 0.5532 - val_accuracy: 0.7456 - val_auc: 0.7965\n",
      "Epoch 596/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.7275 - auc: 0.8004 - val_loss: 0.5528 - val_accuracy: 0.7472 - val_auc: 0.7969\n",
      "Epoch 597/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5479 - accuracy: 0.7230 - auc: 0.7975 - val_loss: 0.5523 - val_accuracy: 0.7456 - val_auc: 0.7971\n",
      "Epoch 598/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5540 - accuracy: 0.7151 - auc: 0.7889 - val_loss: 0.5521 - val_accuracy: 0.7472 - val_auc: 0.7972\n",
      "Epoch 599/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5546 - accuracy: 0.7071 - auc: 0.7882 - val_loss: 0.5523 - val_accuracy: 0.7456 - val_auc: 0.7969\n",
      "Epoch 600/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5521 - accuracy: 0.7141 - auc: 0.7903 - val_loss: 0.5521 - val_accuracy: 0.7456 - val_auc: 0.7972\n",
      "Epoch 601/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5525 - accuracy: 0.7190 - auc: 0.7904 - val_loss: 0.5521 - val_accuracy: 0.7472 - val_auc: 0.7974\n",
      "Epoch 602/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5483 - accuracy: 0.7200 - auc: 0.7956 - val_loss: 0.5518 - val_accuracy: 0.7472 - val_auc: 0.7976\n",
      "Epoch 603/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5487 - accuracy: 0.7161 - auc: 0.7945 - val_loss: 0.5521 - val_accuracy: 0.7472 - val_auc: 0.7974\n",
      "Epoch 604/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5514 - accuracy: 0.7220 - auc: 0.7936 - val_loss: 0.5524 - val_accuracy: 0.7472 - val_auc: 0.7971\n",
      "Epoch 605/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5477 - accuracy: 0.7270 - auc: 0.7975 - val_loss: 0.5520 - val_accuracy: 0.7488 - val_auc: 0.7972\n",
      "Epoch 606/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5446 - accuracy: 0.7205 - auc: 0.7984 - val_loss: 0.5520 - val_accuracy: 0.7440 - val_auc: 0.7973\n",
      "Epoch 607/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5522 - accuracy: 0.7116 - auc: 0.7901 - val_loss: 0.5521 - val_accuracy: 0.7472 - val_auc: 0.7973\n",
      "Epoch 608/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5527 - accuracy: 0.7210 - auc: 0.7914 - val_loss: 0.5515 - val_accuracy: 0.7456 - val_auc: 0.7976\n",
      "Epoch 609/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5528 - accuracy: 0.7096 - auc: 0.7896 - val_loss: 0.5517 - val_accuracy: 0.7472 - val_auc: 0.7977\n",
      "Epoch 610/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5482 - accuracy: 0.7146 - auc: 0.7944 - val_loss: 0.5516 - val_accuracy: 0.7424 - val_auc: 0.7979\n",
      "Epoch 611/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5487 - accuracy: 0.7280 - auc: 0.7955 - val_loss: 0.5519 - val_accuracy: 0.7440 - val_auc: 0.7975\n",
      "Epoch 612/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5427 - accuracy: 0.7240 - auc: 0.7997 - val_loss: 0.5523 - val_accuracy: 0.7472 - val_auc: 0.7972\n",
      "Epoch 613/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5474 - accuracy: 0.7185 - auc: 0.7940 - val_loss: 0.5525 - val_accuracy: 0.7488 - val_auc: 0.7971\n",
      "Epoch 614/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5477 - accuracy: 0.7215 - auc: 0.7955 - val_loss: 0.5517 - val_accuracy: 0.7472 - val_auc: 0.7973\n",
      "Epoch 615/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5531 - accuracy: 0.7200 - auc: 0.7891 - val_loss: 0.5516 - val_accuracy: 0.7504 - val_auc: 0.7974\n",
      "Epoch 616/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5442 - accuracy: 0.7200 - auc: 0.7982 - val_loss: 0.5517 - val_accuracy: 0.7472 - val_auc: 0.7972\n",
      "Epoch 617/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5458 - accuracy: 0.7166 - auc: 0.7963 - val_loss: 0.5529 - val_accuracy: 0.7472 - val_auc: 0.7964\n",
      "Epoch 618/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5508 - accuracy: 0.7181 - auc: 0.7930 - val_loss: 0.5525 - val_accuracy: 0.7456 - val_auc: 0.7966\n",
      "Epoch 619/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5505 - accuracy: 0.7056 - auc: 0.7905 - val_loss: 0.5517 - val_accuracy: 0.7472 - val_auc: 0.7973\n",
      "Epoch 620/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5457 - accuracy: 0.7161 - auc: 0.7974 - val_loss: 0.5522 - val_accuracy: 0.7488 - val_auc: 0.7970\n",
      "Epoch 621/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5477 - accuracy: 0.7176 - auc: 0.7954 - val_loss: 0.5521 - val_accuracy: 0.7488 - val_auc: 0.7972\n",
      "Epoch 622/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5478 - accuracy: 0.7151 - auc: 0.7941 - val_loss: 0.5511 - val_accuracy: 0.7472 - val_auc: 0.7979\n",
      "Epoch 623/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5447 - accuracy: 0.7295 - auc: 0.7991 - val_loss: 0.5508 - val_accuracy: 0.7456 - val_auc: 0.7979\n",
      "Epoch 624/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5486 - accuracy: 0.7195 - auc: 0.7940 - val_loss: 0.5512 - val_accuracy: 0.7472 - val_auc: 0.7980\n",
      "Epoch 625/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5444 - accuracy: 0.7280 - auc: 0.7977 - val_loss: 0.5512 - val_accuracy: 0.7472 - val_auc: 0.7977\n",
      "Epoch 626/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5459 - accuracy: 0.7225 - auc: 0.7967 - val_loss: 0.5513 - val_accuracy: 0.7456 - val_auc: 0.7977\n",
      "Epoch 627/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5491 - accuracy: 0.7275 - auc: 0.7934 - val_loss: 0.5514 - val_accuracy: 0.7456 - val_auc: 0.7976\n",
      "Epoch 628/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5499 - accuracy: 0.7171 - auc: 0.7941 - val_loss: 0.5510 - val_accuracy: 0.7456 - val_auc: 0.7977\n",
      "Epoch 629/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5574 - accuracy: 0.7141 - auc: 0.7864 - val_loss: 0.5512 - val_accuracy: 0.7472 - val_auc: 0.7974\n",
      "Epoch 630/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5434 - accuracy: 0.7200 - auc: 0.7975 - val_loss: 0.5505 - val_accuracy: 0.7520 - val_auc: 0.7980\n",
      "Epoch 631/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5497 - accuracy: 0.7161 - auc: 0.7921 - val_loss: 0.5509 - val_accuracy: 0.7456 - val_auc: 0.7980\n",
      "Epoch 632/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5438 - accuracy: 0.7181 - auc: 0.7992 - val_loss: 0.5506 - val_accuracy: 0.7456 - val_auc: 0.7980\n",
      "Epoch 633/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5474 - accuracy: 0.7250 - auc: 0.7954 - val_loss: 0.5511 - val_accuracy: 0.7456 - val_auc: 0.7977\n",
      "Epoch 634/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5517 - accuracy: 0.7131 - auc: 0.7894 - val_loss: 0.5511 - val_accuracy: 0.7472 - val_auc: 0.7974\n",
      "Epoch 635/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5478 - accuracy: 0.7066 - auc: 0.7957 - val_loss: 0.5514 - val_accuracy: 0.7472 - val_auc: 0.7976\n",
      "Epoch 636/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5511 - accuracy: 0.7200 - auc: 0.7902 - val_loss: 0.5506 - val_accuracy: 0.7472 - val_auc: 0.7980\n",
      "Epoch 637/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5415 - accuracy: 0.7240 - auc: 0.8010 - val_loss: 0.5512 - val_accuracy: 0.7488 - val_auc: 0.7975\n",
      "Epoch 638/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5461 - accuracy: 0.7156 - auc: 0.7961 - val_loss: 0.5509 - val_accuracy: 0.7472 - val_auc: 0.7977\n",
      "Epoch 639/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5487 - accuracy: 0.7230 - auc: 0.7925 - val_loss: 0.5507 - val_accuracy: 0.7488 - val_auc: 0.7977\n",
      "Epoch 640/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5493 - accuracy: 0.7081 - auc: 0.7924 - val_loss: 0.5504 - val_accuracy: 0.7472 - val_auc: 0.7984\n",
      "Epoch 641/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5419 - accuracy: 0.7171 - auc: 0.8022 - val_loss: 0.5508 - val_accuracy: 0.7472 - val_auc: 0.7978\n",
      "Epoch 642/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5471 - accuracy: 0.7235 - auc: 0.7950 - val_loss: 0.5515 - val_accuracy: 0.7456 - val_auc: 0.7975\n",
      "Epoch 643/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5490 - accuracy: 0.7195 - auc: 0.7940 - val_loss: 0.5510 - val_accuracy: 0.7456 - val_auc: 0.7978\n",
      "Epoch 644/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5491 - accuracy: 0.7146 - auc: 0.7923 - val_loss: 0.5510 - val_accuracy: 0.7488 - val_auc: 0.7981\n",
      "Epoch 645/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5496 - accuracy: 0.7210 - auc: 0.7952 - val_loss: 0.5512 - val_accuracy: 0.7472 - val_auc: 0.7977\n",
      "Epoch 646/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5473 - accuracy: 0.7200 - auc: 0.7946 - val_loss: 0.5511 - val_accuracy: 0.7456 - val_auc: 0.7976\n",
      "Epoch 647/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5442 - accuracy: 0.7161 - auc: 0.7967 - val_loss: 0.5512 - val_accuracy: 0.7472 - val_auc: 0.7975\n",
      "Epoch 648/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5505 - accuracy: 0.7166 - auc: 0.7909 - val_loss: 0.5516 - val_accuracy: 0.7456 - val_auc: 0.7974\n",
      "Epoch 649/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5424 - accuracy: 0.7235 - auc: 0.8000 - val_loss: 0.5515 - val_accuracy: 0.7456 - val_auc: 0.7973\n",
      "Epoch 650/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5431 - accuracy: 0.7200 - auc: 0.7986 - val_loss: 0.5511 - val_accuracy: 0.7472 - val_auc: 0.7977\n",
      "Epoch 651/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5507 - accuracy: 0.7225 - auc: 0.7921 - val_loss: 0.5511 - val_accuracy: 0.7504 - val_auc: 0.7976\n",
      "Epoch 652/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5451 - accuracy: 0.7171 - auc: 0.7961 - val_loss: 0.5510 - val_accuracy: 0.7472 - val_auc: 0.7980\n",
      "Epoch 653/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5427 - accuracy: 0.7310 - auc: 0.8006 - val_loss: 0.5509 - val_accuracy: 0.7488 - val_auc: 0.7976\n",
      "Epoch 654/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5459 - accuracy: 0.7190 - auc: 0.7976 - val_loss: 0.5506 - val_accuracy: 0.7472 - val_auc: 0.7980\n",
      "Epoch 655/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5477 - accuracy: 0.7200 - auc: 0.7956 - val_loss: 0.5509 - val_accuracy: 0.7488 - val_auc: 0.7976\n",
      "Epoch 656/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5563 - accuracy: 0.7126 - auc: 0.7842 - val_loss: 0.5509 - val_accuracy: 0.7488 - val_auc: 0.7980\n",
      "Epoch 657/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5455 - accuracy: 0.7225 - auc: 0.7978 - val_loss: 0.5508 - val_accuracy: 0.7472 - val_auc: 0.7978\n",
      "Epoch 658/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5383 - accuracy: 0.7325 - auc: 0.8045 - val_loss: 0.5501 - val_accuracy: 0.7504 - val_auc: 0.7984\n",
      "Epoch 659/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5513 - accuracy: 0.7185 - auc: 0.7928 - val_loss: 0.5508 - val_accuracy: 0.7472 - val_auc: 0.7976\n",
      "Epoch 660/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5506 - accuracy: 0.7161 - auc: 0.7904 - val_loss: 0.5511 - val_accuracy: 0.7472 - val_auc: 0.7974\n",
      "Epoch 661/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5460 - accuracy: 0.7141 - auc: 0.7954 - val_loss: 0.5509 - val_accuracy: 0.7456 - val_auc: 0.7978\n",
      "Epoch 662/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5441 - accuracy: 0.7205 - auc: 0.7974 - val_loss: 0.5505 - val_accuracy: 0.7456 - val_auc: 0.7978\n",
      "Epoch 663/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5431 - accuracy: 0.7235 - auc: 0.8001 - val_loss: 0.5502 - val_accuracy: 0.7488 - val_auc: 0.7981\n",
      "Epoch 664/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5425 - accuracy: 0.7245 - auc: 0.7998 - val_loss: 0.5502 - val_accuracy: 0.7472 - val_auc: 0.7983\n",
      "Epoch 665/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5477 - accuracy: 0.7151 - auc: 0.7932 - val_loss: 0.5506 - val_accuracy: 0.7472 - val_auc: 0.7982\n",
      "Epoch 666/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5495 - accuracy: 0.7111 - auc: 0.7936 - val_loss: 0.5509 - val_accuracy: 0.7488 - val_auc: 0.7980\n",
      "Epoch 667/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5481 - accuracy: 0.7280 - auc: 0.7928 - val_loss: 0.5508 - val_accuracy: 0.7472 - val_auc: 0.7978\n",
      "Epoch 668/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5496 - accuracy: 0.7176 - auc: 0.7929 - val_loss: 0.5505 - val_accuracy: 0.7440 - val_auc: 0.7980\n",
      "Epoch 669/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5508 - accuracy: 0.7126 - auc: 0.7900 - val_loss: 0.5508 - val_accuracy: 0.7440 - val_auc: 0.7978\n",
      "Epoch 670/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5454 - accuracy: 0.7185 - auc: 0.7983 - val_loss: 0.5503 - val_accuracy: 0.7440 - val_auc: 0.7983\n",
      "Epoch 671/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5419 - accuracy: 0.7176 - auc: 0.7996 - val_loss: 0.5499 - val_accuracy: 0.7488 - val_auc: 0.7985\n",
      "Epoch 672/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5515 - accuracy: 0.7230 - auc: 0.7911 - val_loss: 0.5501 - val_accuracy: 0.7472 - val_auc: 0.7984\n",
      "Epoch 673/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5486 - accuracy: 0.7310 - auc: 0.7959 - val_loss: 0.5493 - val_accuracy: 0.7472 - val_auc: 0.7987\n",
      "Epoch 674/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5417 - accuracy: 0.7210 - auc: 0.8011 - val_loss: 0.5495 - val_accuracy: 0.7488 - val_auc: 0.7986\n",
      "Epoch 675/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5468 - accuracy: 0.7176 - auc: 0.7957 - val_loss: 0.5497 - val_accuracy: 0.7472 - val_auc: 0.7986\n",
      "Epoch 676/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5422 - accuracy: 0.7205 - auc: 0.8010 - val_loss: 0.5492 - val_accuracy: 0.7472 - val_auc: 0.7988\n",
      "Epoch 677/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5459 - accuracy: 0.7285 - auc: 0.7973 - val_loss: 0.5490 - val_accuracy: 0.7472 - val_auc: 0.7989\n",
      "Epoch 678/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5450 - accuracy: 0.7156 - auc: 0.7977 - val_loss: 0.5495 - val_accuracy: 0.7472 - val_auc: 0.7989\n",
      "Epoch 679/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5489 - accuracy: 0.7111 - auc: 0.7897 - val_loss: 0.5494 - val_accuracy: 0.7488 - val_auc: 0.7990\n",
      "Epoch 680/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5433 - accuracy: 0.7275 - auc: 0.8004 - val_loss: 0.5499 - val_accuracy: 0.7504 - val_auc: 0.7986\n",
      "Epoch 681/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5447 - accuracy: 0.7151 - auc: 0.7964 - val_loss: 0.5500 - val_accuracy: 0.7520 - val_auc: 0.7987\n",
      "Epoch 682/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5411 - accuracy: 0.7335 - auc: 0.8026 - val_loss: 0.5498 - val_accuracy: 0.7472 - val_auc: 0.7988\n",
      "Epoch 683/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5460 - accuracy: 0.7146 - auc: 0.7952 - val_loss: 0.5497 - val_accuracy: 0.7472 - val_auc: 0.7987\n",
      "Epoch 684/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5438 - accuracy: 0.7156 - auc: 0.7973 - val_loss: 0.5499 - val_accuracy: 0.7488 - val_auc: 0.7987\n",
      "Epoch 685/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5464 - accuracy: 0.7146 - auc: 0.7941 - val_loss: 0.5502 - val_accuracy: 0.7472 - val_auc: 0.7984\n",
      "Epoch 686/700\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.5449 - accuracy: 0.7171 - auc: 0.7977 - val_loss: 0.5497 - val_accuracy: 0.7504 - val_auc: 0.7986\n",
      "Epoch 687/700\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.5400 - accuracy: 0.7230 - auc: 0.8024 - val_loss: 0.5492 - val_accuracy: 0.7504 - val_auc: 0.7990\n",
      "Epoch 688/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5447 - accuracy: 0.7195 - auc: 0.7960 - val_loss: 0.5488 - val_accuracy: 0.7488 - val_auc: 0.7994\n",
      "Epoch 689/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5513 - accuracy: 0.7181 - auc: 0.7907 - val_loss: 0.5489 - val_accuracy: 0.7472 - val_auc: 0.7991\n",
      "Epoch 690/700\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.5477 - accuracy: 0.7096 - auc: 0.7931 - val_loss: 0.5486 - val_accuracy: 0.7472 - val_auc: 0.7994\n",
      "Epoch 691/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5470 - accuracy: 0.7161 - auc: 0.7952 - val_loss: 0.5489 - val_accuracy: 0.7504 - val_auc: 0.7991\n",
      "Epoch 692/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5428 - accuracy: 0.7230 - auc: 0.7986 - val_loss: 0.5487 - val_accuracy: 0.7504 - val_auc: 0.7995\n",
      "Epoch 693/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5495 - accuracy: 0.7126 - auc: 0.7922 - val_loss: 0.5494 - val_accuracy: 0.7472 - val_auc: 0.7990\n",
      "Epoch 694/700\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5522 - accuracy: 0.7161 - auc: 0.7907 - val_loss: 0.5486 - val_accuracy: 0.7504 - val_auc: 0.7994\n",
      "Epoch 695/700\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.5443 - accuracy: 0.7230 - auc: 0.7967 - val_loss: 0.5486 - val_accuracy: 0.7520 - val_auc: 0.7993\n",
      "Epoch 696/700\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5486 - accuracy: 0.7131 - auc: 0.7952 - val_loss: 0.5484 - val_accuracy: 0.7520 - val_auc: 0.7993\n",
      "Epoch 697/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5373 - accuracy: 0.7295 - auc: 0.8046 - val_loss: 0.5484 - val_accuracy: 0.7536 - val_auc: 0.7994\n",
      "Epoch 698/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5431 - accuracy: 0.7200 - auc: 0.8000 - val_loss: 0.5487 - val_accuracy: 0.7472 - val_auc: 0.7991\n",
      "Epoch 699/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5501 - accuracy: 0.7126 - auc: 0.7914 - val_loss: 0.5483 - val_accuracy: 0.7488 - val_auc: 0.7995\n",
      "Epoch 700/700\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5420 - accuracy: 0.7210 - auc: 0.7989 - val_loss: 0.5480 - val_accuracy: 0.7488 - val_auc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('angry_ravdess_meld.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1596191859428,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1142,
     "status": "ok",
     "timestamp": 1596191862578,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "a0e63b3c-5a81-4315-9c7f-c86670b72c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5479972958564758\n",
      "accuracy :  0.7488076090812683\n",
      "auc :  0.8000231981277466\n",
      "\n",
      "(True Negatives):  304\n",
      "(False Positives):  87\n",
      "(False Negatives):  71\n",
      "(True Positives):  167\n",
      "Total emotions_happy:  238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79       391\n",
      "           1       0.66      0.70      0.68       238\n",
      "\n",
      "    accuracy                           0.75       629\n",
      "   macro avg       0.73      0.74      0.74       629\n",
      "weighted avg       0.75      0.75      0.75       629\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('angry_ravdess_meld.hdf5')\n",
    "test_predictions_baseline = model.predict(X_test)\n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1596191871661,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "85943932-955c-4170-8c02-7f298d5b4ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5688241720199585\n",
      "accuracy :  0.7196819186210632\n",
      "auc :  0.7803398370742798\n",
      "\n",
      "(True Negatives):  238\n",
      "(False Positives):  85\n",
      "(False Negatives):  56\n",
      "(True Positives):  124\n",
      "Total emotions_happy:  180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77       323\n",
      "           1       0.59      0.69      0.64       180\n",
      "\n",
      "    accuracy                           0.72       503\n",
      "   macro avg       0.70      0.71      0.70       503\n",
      "weighted avg       0.73      0.72      0.72       503\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val)\n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO+73nS+lNxg0qPmbCGMiN4",
   "name": "deep_angry_RAVDESS_MELD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
