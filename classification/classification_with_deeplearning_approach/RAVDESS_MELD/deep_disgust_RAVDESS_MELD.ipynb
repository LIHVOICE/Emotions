{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "#Deep learning\n",
    "\n",
    "### Plot imports ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns \n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22308,
     "status": "ok",
     "timestamp": 1596284253921,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "4a58f0eb-b8be-42b9-df9d-68e3c753aaa8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surprised/suprised_03-01-08-02-02-01-09_norm_o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fearfull/fearfull_03-01-06-02-01-02-10_norm_ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fearfull/fearfull_03-01-06-01-02-01-24_norm_ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry/angry_dia105_utt11_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral/neutral_dia83_utt6_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio label\n",
       "0  surprised/suprised_03-01-08-02-02-01-09_norm_o...     0\n",
       "1  fearfull/fearfull_03-01-06-02-01-02-10_norm_ou...     0\n",
       "2  fearfull/fearfull_03-01-06-01-02-01-24_norm_ou...     0\n",
       "3         angry/angry_dia105_utt11_norm_outNoise.wav     0\n",
       "4       neutral/neutral_dia83_utt6_norm_outNoise.wav     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"ravdess_meld\" #audio data folder\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i.startswith(\"disgust\"): ##this specifies that we class disgust emotion against the others\n",
    "                                    #the files corresponding to each emotion started by the name of the emotion\n",
    "                                    # for example for the emotion \"happy\" , it will be (if i.startswith(\"happy\"))\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) # adding values to the defined df:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1272,
     "status": "ok",
     "timestamp": 1596284279385,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "b76e9131-c46b-448f-b261-a2ded1ccc2d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2075\n",
      "1     213\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1596284328021,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1596284358293,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "AjNAMwsfG2C8"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    fs, sig = scipy.io.wavfile.read(audio_path) \n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    spec =  fram_window(audio_path) \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)\n",
    "            \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "               \n",
    "    #gfccs = gfcc(sig= spec, fs=fs, num_ceps=13)    \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    #features.append(np.mean(gfccs))\n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4598248,
     "status": "ok",
     "timestamp": 1596288992244,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(parent_dir+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 918,
     "status": "ok",
     "timestamp": 1596289580290,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "84011897-b5bd-49ed-8ce8-22f950ace862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1596289607181,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1596289638134,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1596289672007,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "2eed2fa2-1816-4285-eb30-ffcf9b245ceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 1243\n",
      "After OverSampling, counts of label '0': 2075\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \" [1, 3, 7, 16]   \" are deleted 681 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43140,
     "status": "ok",
     "timestamp": 1596289776704,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "7b6fd90e-edda-494e-9ce9-cc63d15cd582"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 7, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 3, 7, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 3, 7, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 3, 7, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 3, 7, 14, 16]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration          X_removed\n",
       "0         1      [1, 3, 7, 16]\n",
       "1         2      [1, 3, 7, 16]\n",
       "2         3      [1, 3, 7, 16]\n",
       "3         4      [1, 3, 7, 16]\n",
       "4         5  [1, 3, 7, 14, 16]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 7, 16]        681\n",
       "[1, 3, 7, 14, 16]    319\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1596290574791,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6sTQj5wDWdev"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0],  X[i][2], X[i][4], X[i][5], X[i][6],  X[i][8],\n",
    "             X[i][9] , X[i][10],  X[i][11], X[i][12], X[i][13], X[i][14], X[i][15], X[i][17], \n",
    "                X[i][18], X[i][19], X[i][20], X[i][21]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1596290694466,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "8b4e8ceb-f679-4d9d-8109-580db6ff8c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2123\n",
      "664\n",
      "531\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1596290743477,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1596290755795,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "a8ea3ce6-90be-4de3-de57-ae13382f4f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2123, 18, 1)\n",
      "(664, 18, 1)\n",
      "(531, 18, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1596290780093,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "b1ca80f2-b16e-4cdd-c9db-409184d2b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2123, 2)\n",
      "(664, 2)\n",
      "(531, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1071,
     "status": "ok",
     "timestamp": 1596290818286,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (18,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1267,
     "status": "ok",
     "timestamp": 1596290822800,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "c08132b0-4c6d-442e-bed2-574359736bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 18, 1)]           0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 18, 128)           768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 18, 128)           512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 18, 128)           82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4610      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 87,946\n",
      "Trainable params: 87,686\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1596290831282,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 621376,
     "status": "ok",
     "timestamp": 1596291480511,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "c5f61b15-44fc-45d8-8090-9cd40dfdc5d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.7322 - accuracy: 0.5747 - auc: 0.5952 - val_loss: 0.6990 - val_accuracy: 0.4623 - val_auc: 0.5132\n",
      "Epoch 2/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6592 - accuracy: 0.6317 - auc: 0.6752 - val_loss: 0.7008 - val_accuracy: 0.4563 - val_auc: 0.5357\n",
      "Epoch 3/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6159 - accuracy: 0.6693 - auc: 0.7251 - val_loss: 0.6975 - val_accuracy: 0.4834 - val_auc: 0.5534\n",
      "Epoch 4/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6044 - accuracy: 0.6750 - auc: 0.7373 - val_loss: 0.6871 - val_accuracy: 0.5105 - val_auc: 0.5793\n",
      "Epoch 5/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5879 - accuracy: 0.6825 - auc: 0.7543 - val_loss: 0.6787 - val_accuracy: 0.5301 - val_auc: 0.6023\n",
      "Epoch 6/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5863 - accuracy: 0.6863 - auc: 0.7583 - val_loss: 0.6683 - val_accuracy: 0.5602 - val_auc: 0.6254\n",
      "Epoch 7/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5899 - accuracy: 0.6726 - auc: 0.7506 - val_loss: 0.6555 - val_accuracy: 0.5873 - val_auc: 0.6516\n",
      "Epoch 8/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5757 - accuracy: 0.6896 - auc: 0.7647 - val_loss: 0.6449 - val_accuracy: 0.6084 - val_auc: 0.6724\n",
      "Epoch 9/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5735 - accuracy: 0.6901 - auc: 0.7663 - val_loss: 0.6305 - val_accuracy: 0.6370 - val_auc: 0.6970\n",
      "Epoch 10/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5780 - accuracy: 0.6797 - auc: 0.7642 - val_loss: 0.6190 - val_accuracy: 0.6566 - val_auc: 0.7146\n",
      "Epoch 11/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5698 - accuracy: 0.7028 - auc: 0.7717 - val_loss: 0.6083 - val_accuracy: 0.6627 - val_auc: 0.7289\n",
      "Epoch 12/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5691 - accuracy: 0.7000 - auc: 0.7744 - val_loss: 0.5975 - val_accuracy: 0.6672 - val_auc: 0.7425\n",
      "Epoch 13/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5716 - accuracy: 0.6976 - auc: 0.7704 - val_loss: 0.5902 - val_accuracy: 0.6792 - val_auc: 0.7510\n",
      "Epoch 14/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5690 - accuracy: 0.6981 - auc: 0.7719 - val_loss: 0.5810 - val_accuracy: 0.6822 - val_auc: 0.7618\n",
      "Epoch 15/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5616 - accuracy: 0.6967 - auc: 0.7799 - val_loss: 0.5740 - val_accuracy: 0.6898 - val_auc: 0.7690\n",
      "Epoch 16/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5671 - accuracy: 0.6990 - auc: 0.7749 - val_loss: 0.5691 - val_accuracy: 0.6943 - val_auc: 0.7743\n",
      "Epoch 17/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5710 - accuracy: 0.6976 - auc: 0.7698 - val_loss: 0.5647 - val_accuracy: 0.6958 - val_auc: 0.7785\n",
      "Epoch 18/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5587 - accuracy: 0.7018 - auc: 0.7819 - val_loss: 0.5597 - val_accuracy: 0.7033 - val_auc: 0.7833\n",
      "Epoch 19/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5567 - accuracy: 0.7070 - auc: 0.7849 - val_loss: 0.5571 - val_accuracy: 0.7048 - val_auc: 0.7861\n",
      "Epoch 20/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5586 - accuracy: 0.7004 - auc: 0.7828 - val_loss: 0.5543 - val_accuracy: 0.7078 - val_auc: 0.7889\n",
      "Epoch 21/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5612 - accuracy: 0.6910 - auc: 0.7777 - val_loss: 0.5540 - val_accuracy: 0.7033 - val_auc: 0.7891\n",
      "Epoch 22/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5637 - accuracy: 0.6929 - auc: 0.7768 - val_loss: 0.5531 - val_accuracy: 0.7063 - val_auc: 0.7900\n",
      "Epoch 23/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5550 - accuracy: 0.7042 - auc: 0.7847 - val_loss: 0.5523 - val_accuracy: 0.7033 - val_auc: 0.7909\n",
      "Epoch 24/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5553 - accuracy: 0.7075 - auc: 0.7851 - val_loss: 0.5509 - val_accuracy: 0.7093 - val_auc: 0.7919\n",
      "Epoch 25/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5584 - accuracy: 0.7037 - auc: 0.7832 - val_loss: 0.5495 - val_accuracy: 0.7063 - val_auc: 0.7934\n",
      "Epoch 26/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5516 - accuracy: 0.7080 - auc: 0.7881 - val_loss: 0.5504 - val_accuracy: 0.7093 - val_auc: 0.7926\n",
      "Epoch 27/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5572 - accuracy: 0.6962 - auc: 0.7819 - val_loss: 0.5477 - val_accuracy: 0.7154 - val_auc: 0.7949\n",
      "Epoch 28/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5546 - accuracy: 0.7061 - auc: 0.7851 - val_loss: 0.5472 - val_accuracy: 0.7154 - val_auc: 0.7953\n",
      "Epoch 29/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5545 - accuracy: 0.7047 - auc: 0.7872 - val_loss: 0.5468 - val_accuracy: 0.7139 - val_auc: 0.7958\n",
      "Epoch 30/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5586 - accuracy: 0.6934 - auc: 0.7815 - val_loss: 0.5468 - val_accuracy: 0.7108 - val_auc: 0.7958\n",
      "Epoch 31/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5502 - accuracy: 0.7098 - auc: 0.7896 - val_loss: 0.5458 - val_accuracy: 0.7139 - val_auc: 0.7971\n",
      "Epoch 32/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5497 - accuracy: 0.7075 - auc: 0.7909 - val_loss: 0.5458 - val_accuracy: 0.7108 - val_auc: 0.7970\n",
      "Epoch 33/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5524 - accuracy: 0.6990 - auc: 0.7881 - val_loss: 0.5458 - val_accuracy: 0.7078 - val_auc: 0.7970\n",
      "Epoch 34/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5579 - accuracy: 0.7000 - auc: 0.7840 - val_loss: 0.5457 - val_accuracy: 0.7139 - val_auc: 0.7970\n",
      "Epoch 35/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5477 - accuracy: 0.7042 - auc: 0.7924 - val_loss: 0.5449 - val_accuracy: 0.7154 - val_auc: 0.7977\n",
      "Epoch 36/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5546 - accuracy: 0.6990 - auc: 0.7858 - val_loss: 0.5447 - val_accuracy: 0.7169 - val_auc: 0.7979\n",
      "Epoch 37/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5477 - accuracy: 0.7056 - auc: 0.7921 - val_loss: 0.5441 - val_accuracy: 0.7154 - val_auc: 0.7987\n",
      "Epoch 38/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5514 - accuracy: 0.7018 - auc: 0.7874 - val_loss: 0.5427 - val_accuracy: 0.7154 - val_auc: 0.7999\n",
      "Epoch 39/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5496 - accuracy: 0.6967 - auc: 0.7901 - val_loss: 0.5440 - val_accuracy: 0.7139 - val_auc: 0.7990\n",
      "Epoch 40/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5521 - accuracy: 0.6995 - auc: 0.7865 - val_loss: 0.5425 - val_accuracy: 0.7169 - val_auc: 0.8002\n",
      "Epoch 41/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5507 - accuracy: 0.7009 - auc: 0.7895 - val_loss: 0.5413 - val_accuracy: 0.7154 - val_auc: 0.8015\n",
      "Epoch 42/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5550 - accuracy: 0.7004 - auc: 0.7863 - val_loss: 0.5415 - val_accuracy: 0.7184 - val_auc: 0.8011\n",
      "Epoch 43/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5509 - accuracy: 0.6976 - auc: 0.7889 - val_loss: 0.5411 - val_accuracy: 0.7169 - val_auc: 0.8014\n",
      "Epoch 44/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5458 - accuracy: 0.7131 - auc: 0.7960 - val_loss: 0.5409 - val_accuracy: 0.7169 - val_auc: 0.8017\n",
      "Epoch 45/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5415 - accuracy: 0.7150 - auc: 0.7992 - val_loss: 0.5396 - val_accuracy: 0.7229 - val_auc: 0.8027\n",
      "Epoch 46/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5504 - accuracy: 0.7009 - auc: 0.7897 - val_loss: 0.5404 - val_accuracy: 0.7214 - val_auc: 0.8020\n",
      "Epoch 47/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5493 - accuracy: 0.7004 - auc: 0.7902 - val_loss: 0.5395 - val_accuracy: 0.7169 - val_auc: 0.8030\n",
      "Epoch 48/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5499 - accuracy: 0.6985 - auc: 0.7915 - val_loss: 0.5390 - val_accuracy: 0.7214 - val_auc: 0.8030\n",
      "Epoch 49/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5477 - accuracy: 0.7061 - auc: 0.7906 - val_loss: 0.5394 - val_accuracy: 0.7199 - val_auc: 0.8029\n",
      "Epoch 50/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5482 - accuracy: 0.7047 - auc: 0.7916 - val_loss: 0.5388 - val_accuracy: 0.7214 - val_auc: 0.8034\n",
      "Epoch 51/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5469 - accuracy: 0.7117 - auc: 0.7931 - val_loss: 0.5388 - val_accuracy: 0.7199 - val_auc: 0.8035\n",
      "Epoch 52/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5439 - accuracy: 0.7056 - auc: 0.7959 - val_loss: 0.5382 - val_accuracy: 0.7184 - val_auc: 0.8042\n",
      "Epoch 53/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5472 - accuracy: 0.7051 - auc: 0.7921 - val_loss: 0.5374 - val_accuracy: 0.7214 - val_auc: 0.8049\n",
      "Epoch 54/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5417 - accuracy: 0.7141 - auc: 0.7982 - val_loss: 0.5374 - val_accuracy: 0.7214 - val_auc: 0.8049\n",
      "Epoch 55/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5479 - accuracy: 0.7103 - auc: 0.7917 - val_loss: 0.5362 - val_accuracy: 0.7214 - val_auc: 0.8061\n",
      "Epoch 56/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5443 - accuracy: 0.7037 - auc: 0.7943 - val_loss: 0.5362 - val_accuracy: 0.7244 - val_auc: 0.8063\n",
      "Epoch 57/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5402 - accuracy: 0.7094 - auc: 0.7995 - val_loss: 0.5358 - val_accuracy: 0.7244 - val_auc: 0.8064\n",
      "Epoch 58/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5487 - accuracy: 0.7094 - auc: 0.7923 - val_loss: 0.5358 - val_accuracy: 0.7244 - val_auc: 0.8063\n",
      "Epoch 59/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5411 - accuracy: 0.7179 - auc: 0.7996 - val_loss: 0.5349 - val_accuracy: 0.7259 - val_auc: 0.8073\n",
      "Epoch 60/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5384 - accuracy: 0.7131 - auc: 0.8017 - val_loss: 0.5359 - val_accuracy: 0.7244 - val_auc: 0.8066\n",
      "Epoch 61/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5407 - accuracy: 0.7084 - auc: 0.7987 - val_loss: 0.5340 - val_accuracy: 0.7244 - val_auc: 0.8079\n",
      "Epoch 62/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5401 - accuracy: 0.7174 - auc: 0.7999 - val_loss: 0.5340 - val_accuracy: 0.7244 - val_auc: 0.8082\n",
      "Epoch 63/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5360 - accuracy: 0.7150 - auc: 0.8029 - val_loss: 0.5340 - val_accuracy: 0.7259 - val_auc: 0.8081\n",
      "Epoch 64/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5425 - accuracy: 0.7108 - auc: 0.7968 - val_loss: 0.5350 - val_accuracy: 0.7244 - val_auc: 0.8071\n",
      "Epoch 65/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5382 - accuracy: 0.7179 - auc: 0.8022 - val_loss: 0.5349 - val_accuracy: 0.7259 - val_auc: 0.8068\n",
      "Epoch 66/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5325 - accuracy: 0.7188 - auc: 0.8076 - val_loss: 0.5351 - val_accuracy: 0.7229 - val_auc: 0.8070\n",
      "Epoch 67/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5379 - accuracy: 0.7103 - auc: 0.8011 - val_loss: 0.5359 - val_accuracy: 0.7214 - val_auc: 0.8061\n",
      "Epoch 68/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5410 - accuracy: 0.7080 - auc: 0.7997 - val_loss: 0.5343 - val_accuracy: 0.7229 - val_auc: 0.8076\n",
      "Epoch 69/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5400 - accuracy: 0.7179 - auc: 0.8003 - val_loss: 0.5325 - val_accuracy: 0.7259 - val_auc: 0.8095\n",
      "Epoch 70/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5355 - accuracy: 0.7127 - auc: 0.8035 - val_loss: 0.5312 - val_accuracy: 0.7304 - val_auc: 0.8107\n",
      "Epoch 71/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5368 - accuracy: 0.7160 - auc: 0.8037 - val_loss: 0.5299 - val_accuracy: 0.7319 - val_auc: 0.8118\n",
      "Epoch 72/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5311 - accuracy: 0.7174 - auc: 0.8076 - val_loss: 0.5308 - val_accuracy: 0.7259 - val_auc: 0.8108\n",
      "Epoch 73/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5355 - accuracy: 0.7188 - auc: 0.8030 - val_loss: 0.5327 - val_accuracy: 0.7274 - val_auc: 0.8088\n",
      "Epoch 74/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5331 - accuracy: 0.7160 - auc: 0.8067 - val_loss: 0.5306 - val_accuracy: 0.7274 - val_auc: 0.8109\n",
      "Epoch 75/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5368 - accuracy: 0.7164 - auc: 0.8028 - val_loss: 0.5318 - val_accuracy: 0.7274 - val_auc: 0.8100\n",
      "Epoch 76/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5316 - accuracy: 0.7141 - auc: 0.8058 - val_loss: 0.5323 - val_accuracy: 0.7289 - val_auc: 0.8099\n",
      "Epoch 77/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5353 - accuracy: 0.7207 - auc: 0.8041 - val_loss: 0.5307 - val_accuracy: 0.7304 - val_auc: 0.8110\n",
      "Epoch 78/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5310 - accuracy: 0.7179 - auc: 0.8088 - val_loss: 0.5288 - val_accuracy: 0.7319 - val_auc: 0.8128\n",
      "Epoch 79/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5339 - accuracy: 0.7164 - auc: 0.8059 - val_loss: 0.5299 - val_accuracy: 0.7319 - val_auc: 0.8116\n",
      "Epoch 80/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5319 - accuracy: 0.7141 - auc: 0.8069 - val_loss: 0.5290 - val_accuracy: 0.7334 - val_auc: 0.8125\n",
      "Epoch 81/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5232 - accuracy: 0.7315 - auc: 0.8150 - val_loss: 0.5284 - val_accuracy: 0.7349 - val_auc: 0.8129\n",
      "Epoch 82/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5325 - accuracy: 0.7211 - auc: 0.8077 - val_loss: 0.5289 - val_accuracy: 0.7334 - val_auc: 0.8125\n",
      "Epoch 83/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5313 - accuracy: 0.7197 - auc: 0.8085 - val_loss: 0.5277 - val_accuracy: 0.7319 - val_auc: 0.8137\n",
      "Epoch 84/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5300 - accuracy: 0.7164 - auc: 0.8095 - val_loss: 0.5264 - val_accuracy: 0.7349 - val_auc: 0.8147\n",
      "Epoch 85/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5279 - accuracy: 0.7287 - auc: 0.8113 - val_loss: 0.5264 - val_accuracy: 0.7364 - val_auc: 0.8147\n",
      "Epoch 86/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5274 - accuracy: 0.7084 - auc: 0.8108 - val_loss: 0.5265 - val_accuracy: 0.7349 - val_auc: 0.8145\n",
      "Epoch 87/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5266 - accuracy: 0.7193 - auc: 0.8118 - val_loss: 0.5264 - val_accuracy: 0.7349 - val_auc: 0.8148\n",
      "Epoch 88/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5349 - accuracy: 0.7127 - auc: 0.8045 - val_loss: 0.5246 - val_accuracy: 0.7364 - val_auc: 0.8164\n",
      "Epoch 89/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5238 - accuracy: 0.7277 - auc: 0.8157 - val_loss: 0.5258 - val_accuracy: 0.7364 - val_auc: 0.8153\n",
      "Epoch 90/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5270 - accuracy: 0.7263 - auc: 0.8113 - val_loss: 0.5263 - val_accuracy: 0.7380 - val_auc: 0.8145\n",
      "Epoch 91/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5238 - accuracy: 0.7287 - auc: 0.8136 - val_loss: 0.5270 - val_accuracy: 0.7319 - val_auc: 0.8142\n",
      "Epoch 92/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5255 - accuracy: 0.7263 - auc: 0.8129 - val_loss: 0.5266 - val_accuracy: 0.7364 - val_auc: 0.8144\n",
      "Epoch 93/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5269 - accuracy: 0.7230 - auc: 0.8110 - val_loss: 0.5258 - val_accuracy: 0.7364 - val_auc: 0.8154\n",
      "Epoch 94/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5285 - accuracy: 0.7230 - auc: 0.8111 - val_loss: 0.5257 - val_accuracy: 0.7395 - val_auc: 0.8154\n",
      "Epoch 95/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5265 - accuracy: 0.7249 - auc: 0.8113 - val_loss: 0.5256 - val_accuracy: 0.7349 - val_auc: 0.8154\n",
      "Epoch 96/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5296 - accuracy: 0.7211 - auc: 0.8084 - val_loss: 0.5260 - val_accuracy: 0.7349 - val_auc: 0.8153\n",
      "Epoch 97/700\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.5276 - accuracy: 0.7202 - auc: 0.8105 - val_loss: 0.5244 - val_accuracy: 0.7334 - val_auc: 0.8169\n",
      "Epoch 98/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5270 - accuracy: 0.7277 - auc: 0.8136 - val_loss: 0.5241 - val_accuracy: 0.7410 - val_auc: 0.8169\n",
      "Epoch 99/700\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.5261 - accuracy: 0.7197 - auc: 0.8126 - val_loss: 0.5227 - val_accuracy: 0.7455 - val_auc: 0.8182\n",
      "Epoch 100/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5295 - accuracy: 0.7244 - auc: 0.8098 - val_loss: 0.5207 - val_accuracy: 0.7425 - val_auc: 0.8203\n",
      "Epoch 101/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5294 - accuracy: 0.7155 - auc: 0.8103 - val_loss: 0.5232 - val_accuracy: 0.7364 - val_auc: 0.8177\n",
      "Epoch 102/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5247 - accuracy: 0.7268 - auc: 0.8150 - val_loss: 0.5217 - val_accuracy: 0.7425 - val_auc: 0.8192\n",
      "Epoch 103/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5275 - accuracy: 0.7310 - auc: 0.8119 - val_loss: 0.5231 - val_accuracy: 0.7364 - val_auc: 0.8174\n",
      "Epoch 104/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5221 - accuracy: 0.7240 - auc: 0.8154 - val_loss: 0.5238 - val_accuracy: 0.7410 - val_auc: 0.8171\n",
      "Epoch 105/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.5280 - accuracy: 0.7292 - auc: 0.8112 - val_loss: 0.5233 - val_accuracy: 0.7364 - val_auc: 0.8177\n",
      "Epoch 106/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.5246 - accuracy: 0.7301 - auc: 0.8141 - val_loss: 0.5228 - val_accuracy: 0.7364 - val_auc: 0.8182\n",
      "Epoch 107/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5250 - accuracy: 0.7296 - auc: 0.8150 - val_loss: 0.5213 - val_accuracy: 0.7410 - val_auc: 0.8195\n",
      "Epoch 108/700\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.5254 - accuracy: 0.7320 - auc: 0.8148 - val_loss: 0.5202 - val_accuracy: 0.7470 - val_auc: 0.8206\n",
      "Epoch 109/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5276 - accuracy: 0.7306 - auc: 0.8125 - val_loss: 0.5207 - val_accuracy: 0.7455 - val_auc: 0.8202\n",
      "Epoch 110/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5195 - accuracy: 0.7254 - auc: 0.8180 - val_loss: 0.5199 - val_accuracy: 0.7455 - val_auc: 0.8212\n",
      "Epoch 111/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5252 - accuracy: 0.7301 - auc: 0.8144 - val_loss: 0.5200 - val_accuracy: 0.7440 - val_auc: 0.8211\n",
      "Epoch 112/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5191 - accuracy: 0.7315 - auc: 0.8192 - val_loss: 0.5199 - val_accuracy: 0.7425 - val_auc: 0.8210\n",
      "Epoch 113/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5207 - accuracy: 0.7183 - auc: 0.8171 - val_loss: 0.5177 - val_accuracy: 0.7440 - val_auc: 0.8229\n",
      "Epoch 114/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5206 - accuracy: 0.7329 - auc: 0.8195 - val_loss: 0.5172 - val_accuracy: 0.7440 - val_auc: 0.8234\n",
      "Epoch 115/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5235 - accuracy: 0.7310 - auc: 0.8160 - val_loss: 0.5152 - val_accuracy: 0.7500 - val_auc: 0.8254\n",
      "Epoch 116/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5226 - accuracy: 0.7423 - auc: 0.8181 - val_loss: 0.5154 - val_accuracy: 0.7530 - val_auc: 0.8254\n",
      "Epoch 117/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5224 - accuracy: 0.7207 - auc: 0.8162 - val_loss: 0.5158 - val_accuracy: 0.7530 - val_auc: 0.8247\n",
      "Epoch 118/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5191 - accuracy: 0.7372 - auc: 0.8190 - val_loss: 0.5154 - val_accuracy: 0.7485 - val_auc: 0.8249\n",
      "Epoch 119/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5194 - accuracy: 0.7372 - auc: 0.8191 - val_loss: 0.5168 - val_accuracy: 0.7485 - val_auc: 0.8236\n",
      "Epoch 120/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5305 - accuracy: 0.7254 - auc: 0.8082 - val_loss: 0.5161 - val_accuracy: 0.7545 - val_auc: 0.8243\n",
      "Epoch 121/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5207 - accuracy: 0.7310 - auc: 0.8176 - val_loss: 0.5159 - val_accuracy: 0.7485 - val_auc: 0.8243\n",
      "Epoch 122/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5157 - accuracy: 0.7325 - auc: 0.8226 - val_loss: 0.5173 - val_accuracy: 0.7455 - val_auc: 0.8230\n",
      "Epoch 123/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5142 - accuracy: 0.7268 - auc: 0.8221 - val_loss: 0.5165 - val_accuracy: 0.7500 - val_auc: 0.8239\n",
      "Epoch 124/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5229 - accuracy: 0.7310 - auc: 0.8167 - val_loss: 0.5182 - val_accuracy: 0.7425 - val_auc: 0.8224\n",
      "Epoch 125/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.5220 - accuracy: 0.7259 - auc: 0.8155 - val_loss: 0.5149 - val_accuracy: 0.7455 - val_auc: 0.8256\n",
      "Epoch 126/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5174 - accuracy: 0.7414 - auc: 0.8212 - val_loss: 0.5144 - val_accuracy: 0.7500 - val_auc: 0.8258\n",
      "Epoch 127/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5233 - accuracy: 0.7334 - auc: 0.8149 - val_loss: 0.5139 - val_accuracy: 0.7485 - val_auc: 0.8262\n",
      "Epoch 128/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5135 - accuracy: 0.7343 - auc: 0.8236 - val_loss: 0.5117 - val_accuracy: 0.7485 - val_auc: 0.8283\n",
      "Epoch 129/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5166 - accuracy: 0.7367 - auc: 0.8198 - val_loss: 0.5126 - val_accuracy: 0.7470 - val_auc: 0.8278\n",
      "Epoch 130/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5160 - accuracy: 0.7353 - auc: 0.8222 - val_loss: 0.5133 - val_accuracy: 0.7440 - val_auc: 0.8274\n",
      "Epoch 131/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5220 - accuracy: 0.7277 - auc: 0.8160 - val_loss: 0.5130 - val_accuracy: 0.7485 - val_auc: 0.8271\n",
      "Epoch 132/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5180 - accuracy: 0.7287 - auc: 0.8201 - val_loss: 0.5139 - val_accuracy: 0.7485 - val_auc: 0.8260\n",
      "Epoch 133/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5118 - accuracy: 0.7409 - auc: 0.8246 - val_loss: 0.5148 - val_accuracy: 0.7500 - val_auc: 0.8254\n",
      "Epoch 134/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5153 - accuracy: 0.7428 - auc: 0.8236 - val_loss: 0.5128 - val_accuracy: 0.7515 - val_auc: 0.8271\n",
      "Epoch 135/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5106 - accuracy: 0.7466 - auc: 0.8261 - val_loss: 0.5126 - val_accuracy: 0.7515 - val_auc: 0.8274\n",
      "Epoch 136/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5083 - accuracy: 0.7325 - auc: 0.8278 - val_loss: 0.5119 - val_accuracy: 0.7530 - val_auc: 0.8281\n",
      "Epoch 137/700\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.5141 - accuracy: 0.7343 - auc: 0.8235 - val_loss: 0.5113 - val_accuracy: 0.7515 - val_auc: 0.8282\n",
      "Epoch 138/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5116 - accuracy: 0.7372 - auc: 0.8249 - val_loss: 0.5122 - val_accuracy: 0.7530 - val_auc: 0.8273\n",
      "Epoch 139/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5145 - accuracy: 0.7226 - auc: 0.8214 - val_loss: 0.5126 - val_accuracy: 0.7545 - val_auc: 0.8271\n",
      "Epoch 140/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5128 - accuracy: 0.7277 - auc: 0.8239 - val_loss: 0.5127 - val_accuracy: 0.7530 - val_auc: 0.8271\n",
      "Epoch 141/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5207 - accuracy: 0.7353 - auc: 0.8183 - val_loss: 0.5124 - val_accuracy: 0.7500 - val_auc: 0.8275\n",
      "Epoch 142/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5234 - accuracy: 0.7362 - auc: 0.8158 - val_loss: 0.5124 - val_accuracy: 0.7515 - val_auc: 0.8276\n",
      "Epoch 143/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5160 - accuracy: 0.7301 - auc: 0.8205 - val_loss: 0.5124 - val_accuracy: 0.7500 - val_auc: 0.8278\n",
      "Epoch 144/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5179 - accuracy: 0.7282 - auc: 0.8189 - val_loss: 0.5126 - val_accuracy: 0.7515 - val_auc: 0.8276\n",
      "Epoch 145/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5209 - accuracy: 0.7390 - auc: 0.8182 - val_loss: 0.5120 - val_accuracy: 0.7515 - val_auc: 0.8280\n",
      "Epoch 146/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.5099 - accuracy: 0.7287 - auc: 0.8267 - val_loss: 0.5098 - val_accuracy: 0.7530 - val_auc: 0.8298\n",
      "Epoch 147/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5151 - accuracy: 0.7287 - auc: 0.8218 - val_loss: 0.5104 - val_accuracy: 0.7530 - val_auc: 0.8294\n",
      "Epoch 148/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5185 - accuracy: 0.7320 - auc: 0.8204 - val_loss: 0.5096 - val_accuracy: 0.7515 - val_auc: 0.8298\n",
      "Epoch 149/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5119 - accuracy: 0.7282 - auc: 0.8242 - val_loss: 0.5096 - val_accuracy: 0.7605 - val_auc: 0.8297\n",
      "Epoch 150/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5147 - accuracy: 0.7339 - auc: 0.8235 - val_loss: 0.5097 - val_accuracy: 0.7560 - val_auc: 0.8299\n",
      "Epoch 151/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5097 - accuracy: 0.7522 - auc: 0.8296 - val_loss: 0.5096 - val_accuracy: 0.7545 - val_auc: 0.8300\n",
      "Epoch 152/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5139 - accuracy: 0.7358 - auc: 0.8233 - val_loss: 0.5093 - val_accuracy: 0.7560 - val_auc: 0.8303\n",
      "Epoch 153/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5104 - accuracy: 0.7409 - auc: 0.8274 - val_loss: 0.5070 - val_accuracy: 0.7545 - val_auc: 0.8323\n",
      "Epoch 154/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5085 - accuracy: 0.7390 - auc: 0.8277 - val_loss: 0.5071 - val_accuracy: 0.7530 - val_auc: 0.8323\n",
      "Epoch 155/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5004 - accuracy: 0.7494 - auc: 0.8349 - val_loss: 0.5064 - val_accuracy: 0.7560 - val_auc: 0.8326\n",
      "Epoch 156/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5055 - accuracy: 0.7386 - auc: 0.8306 - val_loss: 0.5065 - val_accuracy: 0.7545 - val_auc: 0.8326\n",
      "Epoch 157/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5038 - accuracy: 0.7376 - auc: 0.8312 - val_loss: 0.5057 - val_accuracy: 0.7530 - val_auc: 0.8331\n",
      "Epoch 158/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5101 - accuracy: 0.7400 - auc: 0.8260 - val_loss: 0.5053 - val_accuracy: 0.7545 - val_auc: 0.8337\n",
      "Epoch 159/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5114 - accuracy: 0.7353 - auc: 0.8242 - val_loss: 0.5060 - val_accuracy: 0.7545 - val_auc: 0.8331\n",
      "Epoch 160/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5120 - accuracy: 0.7423 - auc: 0.8241 - val_loss: 0.5066 - val_accuracy: 0.7545 - val_auc: 0.8326\n",
      "Epoch 161/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5073 - accuracy: 0.7423 - auc: 0.8294 - val_loss: 0.5060 - val_accuracy: 0.7560 - val_auc: 0.8332\n",
      "Epoch 162/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5139 - accuracy: 0.7343 - auc: 0.8226 - val_loss: 0.5068 - val_accuracy: 0.7590 - val_auc: 0.8322\n",
      "Epoch 163/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5041 - accuracy: 0.7428 - auc: 0.8304 - val_loss: 0.5056 - val_accuracy: 0.7545 - val_auc: 0.8335\n",
      "Epoch 164/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5098 - accuracy: 0.7400 - auc: 0.8262 - val_loss: 0.5071 - val_accuracy: 0.7545 - val_auc: 0.8322\n",
      "Epoch 165/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5143 - accuracy: 0.7334 - auc: 0.8240 - val_loss: 0.5077 - val_accuracy: 0.7530 - val_auc: 0.8319\n",
      "Epoch 166/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5019 - accuracy: 0.7508 - auc: 0.8340 - val_loss: 0.5070 - val_accuracy: 0.7560 - val_auc: 0.8323\n",
      "Epoch 167/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4983 - accuracy: 0.7409 - auc: 0.8359 - val_loss: 0.5062 - val_accuracy: 0.7575 - val_auc: 0.8335\n",
      "Epoch 168/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5110 - accuracy: 0.7428 - auc: 0.8267 - val_loss: 0.5064 - val_accuracy: 0.7560 - val_auc: 0.8331\n",
      "Epoch 169/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5068 - accuracy: 0.7508 - auc: 0.8298 - val_loss: 0.5056 - val_accuracy: 0.7560 - val_auc: 0.8334\n",
      "Epoch 170/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4992 - accuracy: 0.7513 - auc: 0.8362 - val_loss: 0.5053 - val_accuracy: 0.7560 - val_auc: 0.8337\n",
      "Epoch 171/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5038 - accuracy: 0.7555 - auc: 0.8337 - val_loss: 0.5058 - val_accuracy: 0.7560 - val_auc: 0.8332\n",
      "Epoch 172/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5044 - accuracy: 0.7489 - auc: 0.8311 - val_loss: 0.5078 - val_accuracy: 0.7575 - val_auc: 0.8311\n",
      "Epoch 173/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5049 - accuracy: 0.7438 - auc: 0.8301 - val_loss: 0.5075 - val_accuracy: 0.7560 - val_auc: 0.8319\n",
      "Epoch 174/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5007 - accuracy: 0.7461 - auc: 0.8344 - val_loss: 0.5058 - val_accuracy: 0.7560 - val_auc: 0.8330\n",
      "Epoch 175/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5079 - accuracy: 0.7409 - auc: 0.8287 - val_loss: 0.5056 - val_accuracy: 0.7575 - val_auc: 0.8331\n",
      "Epoch 176/700\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.5027 - accuracy: 0.7527 - auc: 0.8331 - val_loss: 0.5047 - val_accuracy: 0.7560 - val_auc: 0.8337\n",
      "Epoch 177/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5050 - accuracy: 0.7419 - auc: 0.8302 - val_loss: 0.5045 - val_accuracy: 0.7575 - val_auc: 0.8342\n",
      "Epoch 178/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5087 - accuracy: 0.7400 - auc: 0.8275 - val_loss: 0.5047 - val_accuracy: 0.7560 - val_auc: 0.8337\n",
      "Epoch 179/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5047 - accuracy: 0.7423 - auc: 0.8310 - val_loss: 0.5038 - val_accuracy: 0.7575 - val_auc: 0.8343\n",
      "Epoch 180/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5041 - accuracy: 0.7471 - auc: 0.8316 - val_loss: 0.5020 - val_accuracy: 0.7560 - val_auc: 0.8362\n",
      "Epoch 181/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5061 - accuracy: 0.7489 - auc: 0.8313 - val_loss: 0.5011 - val_accuracy: 0.7590 - val_auc: 0.8372\n",
      "Epoch 182/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5047 - accuracy: 0.7423 - auc: 0.8326 - val_loss: 0.5003 - val_accuracy: 0.7636 - val_auc: 0.8378\n",
      "Epoch 183/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5054 - accuracy: 0.7447 - auc: 0.8310 - val_loss: 0.5003 - val_accuracy: 0.7620 - val_auc: 0.8375\n",
      "Epoch 184/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5026 - accuracy: 0.7499 - auc: 0.8339 - val_loss: 0.5008 - val_accuracy: 0.7636 - val_auc: 0.8374\n",
      "Epoch 185/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5073 - accuracy: 0.7433 - auc: 0.8288 - val_loss: 0.5025 - val_accuracy: 0.7620 - val_auc: 0.8359\n",
      "Epoch 186/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5021 - accuracy: 0.7522 - auc: 0.8356 - val_loss: 0.5023 - val_accuracy: 0.7605 - val_auc: 0.8362\n",
      "Epoch 187/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5038 - accuracy: 0.7494 - auc: 0.8312 - val_loss: 0.5036 - val_accuracy: 0.7560 - val_auc: 0.8350\n",
      "Epoch 188/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5082 - accuracy: 0.7405 - auc: 0.8273 - val_loss: 0.5034 - val_accuracy: 0.7636 - val_auc: 0.8353\n",
      "Epoch 189/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5019 - accuracy: 0.7527 - auc: 0.8349 - val_loss: 0.5035 - val_accuracy: 0.7605 - val_auc: 0.8355\n",
      "Epoch 190/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5039 - accuracy: 0.7461 - auc: 0.8331 - val_loss: 0.5019 - val_accuracy: 0.7620 - val_auc: 0.8363\n",
      "Epoch 191/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4972 - accuracy: 0.7466 - auc: 0.8372 - val_loss: 0.5006 - val_accuracy: 0.7620 - val_auc: 0.8375\n",
      "Epoch 192/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4998 - accuracy: 0.7569 - auc: 0.8351 - val_loss: 0.4999 - val_accuracy: 0.7605 - val_auc: 0.8383\n",
      "Epoch 193/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4985 - accuracy: 0.7555 - auc: 0.8369 - val_loss: 0.4988 - val_accuracy: 0.7605 - val_auc: 0.8393\n",
      "Epoch 194/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4995 - accuracy: 0.7499 - auc: 0.8351 - val_loss: 0.4990 - val_accuracy: 0.7620 - val_auc: 0.8391\n",
      "Epoch 195/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4955 - accuracy: 0.7569 - auc: 0.8397 - val_loss: 0.4982 - val_accuracy: 0.7636 - val_auc: 0.8398\n",
      "Epoch 196/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5070 - accuracy: 0.7381 - auc: 0.8278 - val_loss: 0.4995 - val_accuracy: 0.7605 - val_auc: 0.8386\n",
      "Epoch 197/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5037 - accuracy: 0.7456 - auc: 0.8332 - val_loss: 0.4980 - val_accuracy: 0.7605 - val_auc: 0.8397\n",
      "Epoch 198/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5030 - accuracy: 0.7508 - auc: 0.8327 - val_loss: 0.4982 - val_accuracy: 0.7636 - val_auc: 0.8397\n",
      "Epoch 199/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5021 - accuracy: 0.7433 - auc: 0.8334 - val_loss: 0.4995 - val_accuracy: 0.7636 - val_auc: 0.8384\n",
      "Epoch 200/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5052 - accuracy: 0.7499 - auc: 0.8316 - val_loss: 0.4987 - val_accuracy: 0.7605 - val_auc: 0.8392\n",
      "Epoch 201/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5057 - accuracy: 0.7485 - auc: 0.8291 - val_loss: 0.4978 - val_accuracy: 0.7605 - val_auc: 0.8398\n",
      "Epoch 202/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5040 - accuracy: 0.7466 - auc: 0.8320 - val_loss: 0.4982 - val_accuracy: 0.7590 - val_auc: 0.8393\n",
      "Epoch 203/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5069 - accuracy: 0.7456 - auc: 0.8293 - val_loss: 0.5003 - val_accuracy: 0.7605 - val_auc: 0.8378\n",
      "Epoch 204/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5003 - accuracy: 0.7438 - auc: 0.8346 - val_loss: 0.4987 - val_accuracy: 0.7620 - val_auc: 0.8391\n",
      "Epoch 205/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4982 - accuracy: 0.7423 - auc: 0.8356 - val_loss: 0.5001 - val_accuracy: 0.7590 - val_auc: 0.8381\n",
      "Epoch 206/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4952 - accuracy: 0.7508 - auc: 0.8404 - val_loss: 0.5013 - val_accuracy: 0.7575 - val_auc: 0.8370\n",
      "Epoch 207/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5028 - accuracy: 0.7513 - auc: 0.8336 - val_loss: 0.5009 - val_accuracy: 0.7605 - val_auc: 0.8372\n",
      "Epoch 208/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4944 - accuracy: 0.7537 - auc: 0.8390 - val_loss: 0.5013 - val_accuracy: 0.7575 - val_auc: 0.8370\n",
      "Epoch 209/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4934 - accuracy: 0.7414 - auc: 0.8398 - val_loss: 0.5010 - val_accuracy: 0.7636 - val_auc: 0.8373\n",
      "Epoch 210/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5031 - accuracy: 0.7537 - auc: 0.8331 - val_loss: 0.5013 - val_accuracy: 0.7605 - val_auc: 0.8370\n",
      "Epoch 211/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5037 - accuracy: 0.7414 - auc: 0.8326 - val_loss: 0.5000 - val_accuracy: 0.7605 - val_auc: 0.8382\n",
      "Epoch 212/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4978 - accuracy: 0.7569 - auc: 0.8369 - val_loss: 0.4987 - val_accuracy: 0.7620 - val_auc: 0.8396\n",
      "Epoch 213/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4999 - accuracy: 0.7471 - auc: 0.8355 - val_loss: 0.4986 - val_accuracy: 0.7651 - val_auc: 0.8392\n",
      "Epoch 214/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4930 - accuracy: 0.7654 - auc: 0.8419 - val_loss: 0.4983 - val_accuracy: 0.7636 - val_auc: 0.8394\n",
      "Epoch 215/700\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.5005 - accuracy: 0.7522 - auc: 0.8349 - val_loss: 0.4972 - val_accuracy: 0.7605 - val_auc: 0.8404\n",
      "Epoch 216/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5054 - accuracy: 0.7518 - auc: 0.8318 - val_loss: 0.4981 - val_accuracy: 0.7636 - val_auc: 0.8399\n",
      "Epoch 217/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4958 - accuracy: 0.7617 - auc: 0.8400 - val_loss: 0.4978 - val_accuracy: 0.7636 - val_auc: 0.8401\n",
      "Epoch 218/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4946 - accuracy: 0.7475 - auc: 0.8391 - val_loss: 0.4977 - val_accuracy: 0.7620 - val_auc: 0.8403\n",
      "Epoch 219/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4934 - accuracy: 0.7555 - auc: 0.8393 - val_loss: 0.4967 - val_accuracy: 0.7636 - val_auc: 0.8411\n",
      "Epoch 220/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4943 - accuracy: 0.7438 - auc: 0.8390 - val_loss: 0.4961 - val_accuracy: 0.7605 - val_auc: 0.8414\n",
      "Epoch 221/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4980 - accuracy: 0.7574 - auc: 0.8368 - val_loss: 0.4954 - val_accuracy: 0.7636 - val_auc: 0.8423\n",
      "Epoch 222/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4903 - accuracy: 0.7631 - auc: 0.8435 - val_loss: 0.4937 - val_accuracy: 0.7636 - val_auc: 0.8434\n",
      "Epoch 223/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5017 - accuracy: 0.7471 - auc: 0.8333 - val_loss: 0.4942 - val_accuracy: 0.7636 - val_auc: 0.8428\n",
      "Epoch 224/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4983 - accuracy: 0.7447 - auc: 0.8368 - val_loss: 0.4953 - val_accuracy: 0.7651 - val_auc: 0.8416\n",
      "Epoch 225/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4901 - accuracy: 0.7602 - auc: 0.8421 - val_loss: 0.4947 - val_accuracy: 0.7651 - val_auc: 0.8421\n",
      "Epoch 226/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4989 - accuracy: 0.7489 - auc: 0.8360 - val_loss: 0.4963 - val_accuracy: 0.7636 - val_auc: 0.8411\n",
      "Epoch 227/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4989 - accuracy: 0.7466 - auc: 0.8360 - val_loss: 0.4973 - val_accuracy: 0.7636 - val_auc: 0.8402\n",
      "Epoch 228/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4896 - accuracy: 0.7626 - auc: 0.8437 - val_loss: 0.4953 - val_accuracy: 0.7605 - val_auc: 0.8419\n",
      "Epoch 229/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5074 - accuracy: 0.7466 - auc: 0.8293 - val_loss: 0.4959 - val_accuracy: 0.7636 - val_auc: 0.8419\n",
      "Epoch 230/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5058 - accuracy: 0.7504 - auc: 0.8299 - val_loss: 0.4961 - val_accuracy: 0.7605 - val_auc: 0.8413\n",
      "Epoch 231/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4914 - accuracy: 0.7522 - auc: 0.8433 - val_loss: 0.4970 - val_accuracy: 0.7620 - val_auc: 0.8405\n",
      "Epoch 232/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4945 - accuracy: 0.7537 - auc: 0.8370 - val_loss: 0.4965 - val_accuracy: 0.7666 - val_auc: 0.8409\n",
      "Epoch 233/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4999 - accuracy: 0.7565 - auc: 0.8350 - val_loss: 0.4963 - val_accuracy: 0.7651 - val_auc: 0.8411\n",
      "Epoch 234/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4970 - accuracy: 0.7546 - auc: 0.8372 - val_loss: 0.4952 - val_accuracy: 0.7651 - val_auc: 0.8421\n",
      "Epoch 235/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4916 - accuracy: 0.7584 - auc: 0.8415 - val_loss: 0.4957 - val_accuracy: 0.7620 - val_auc: 0.8416\n",
      "Epoch 236/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4968 - accuracy: 0.7551 - auc: 0.8375 - val_loss: 0.4958 - val_accuracy: 0.7636 - val_auc: 0.8414\n",
      "Epoch 237/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4951 - accuracy: 0.7569 - auc: 0.8389 - val_loss: 0.4958 - val_accuracy: 0.7681 - val_auc: 0.8413\n",
      "Epoch 238/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4941 - accuracy: 0.7569 - auc: 0.8411 - val_loss: 0.4960 - val_accuracy: 0.7651 - val_auc: 0.8413\n",
      "Epoch 239/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4926 - accuracy: 0.7551 - auc: 0.8411 - val_loss: 0.4974 - val_accuracy: 0.7620 - val_auc: 0.8395\n",
      "Epoch 240/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4943 - accuracy: 0.7541 - auc: 0.8391 - val_loss: 0.4959 - val_accuracy: 0.7636 - val_auc: 0.8413\n",
      "Epoch 241/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4912 - accuracy: 0.7584 - auc: 0.8423 - val_loss: 0.4973 - val_accuracy: 0.7620 - val_auc: 0.8400\n",
      "Epoch 242/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4998 - accuracy: 0.7508 - auc: 0.8353 - val_loss: 0.4945 - val_accuracy: 0.7620 - val_auc: 0.8426\n",
      "Epoch 243/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4863 - accuracy: 0.7579 - auc: 0.8454 - val_loss: 0.4939 - val_accuracy: 0.7666 - val_auc: 0.8429\n",
      "Epoch 244/700\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.4940 - accuracy: 0.7537 - auc: 0.8391 - val_loss: 0.4930 - val_accuracy: 0.7651 - val_auc: 0.8438\n",
      "Epoch 245/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4932 - accuracy: 0.7607 - auc: 0.8419 - val_loss: 0.4934 - val_accuracy: 0.7651 - val_auc: 0.8434\n",
      "Epoch 246/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4959 - accuracy: 0.7555 - auc: 0.8379 - val_loss: 0.4930 - val_accuracy: 0.7651 - val_auc: 0.8439\n",
      "Epoch 247/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4957 - accuracy: 0.7537 - auc: 0.8396 - val_loss: 0.4931 - val_accuracy: 0.7651 - val_auc: 0.8438\n",
      "Epoch 248/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4945 - accuracy: 0.7560 - auc: 0.8401 - val_loss: 0.4933 - val_accuracy: 0.7636 - val_auc: 0.8437\n",
      "Epoch 249/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4934 - accuracy: 0.7560 - auc: 0.8415 - val_loss: 0.4932 - val_accuracy: 0.7666 - val_auc: 0.8439\n",
      "Epoch 250/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4927 - accuracy: 0.7560 - auc: 0.8406 - val_loss: 0.4928 - val_accuracy: 0.7636 - val_auc: 0.8441\n",
      "Epoch 251/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4948 - accuracy: 0.7461 - auc: 0.8385 - val_loss: 0.4914 - val_accuracy: 0.7651 - val_auc: 0.8454\n",
      "Epoch 252/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4964 - accuracy: 0.7617 - auc: 0.8390 - val_loss: 0.4925 - val_accuracy: 0.7666 - val_auc: 0.8447\n",
      "Epoch 253/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4920 - accuracy: 0.7555 - auc: 0.8428 - val_loss: 0.4915 - val_accuracy: 0.7651 - val_auc: 0.8454\n",
      "Epoch 254/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4889 - accuracy: 0.7626 - auc: 0.8426 - val_loss: 0.4924 - val_accuracy: 0.7666 - val_auc: 0.8444\n",
      "Epoch 255/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4925 - accuracy: 0.7480 - auc: 0.8418 - val_loss: 0.4926 - val_accuracy: 0.7666 - val_auc: 0.8442\n",
      "Epoch 256/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4952 - accuracy: 0.7593 - auc: 0.8388 - val_loss: 0.4921 - val_accuracy: 0.7651 - val_auc: 0.8446\n",
      "Epoch 257/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4922 - accuracy: 0.7588 - auc: 0.8433 - val_loss: 0.4936 - val_accuracy: 0.7651 - val_auc: 0.8435\n",
      "Epoch 258/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4900 - accuracy: 0.7659 - auc: 0.8440 - val_loss: 0.4927 - val_accuracy: 0.7666 - val_auc: 0.8443\n",
      "Epoch 259/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4920 - accuracy: 0.7635 - auc: 0.8437 - val_loss: 0.4919 - val_accuracy: 0.7651 - val_auc: 0.8448\n",
      "Epoch 260/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4920 - accuracy: 0.7626 - auc: 0.8429 - val_loss: 0.4894 - val_accuracy: 0.7666 - val_auc: 0.8471\n",
      "Epoch 261/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4830 - accuracy: 0.7593 - auc: 0.8488 - val_loss: 0.4898 - val_accuracy: 0.7681 - val_auc: 0.8467\n",
      "Epoch 262/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4918 - accuracy: 0.7537 - auc: 0.8420 - val_loss: 0.4894 - val_accuracy: 0.7666 - val_auc: 0.8472\n",
      "Epoch 263/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4918 - accuracy: 0.7522 - auc: 0.8416 - val_loss: 0.4882 - val_accuracy: 0.7696 - val_auc: 0.8481\n",
      "Epoch 264/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4895 - accuracy: 0.7645 - auc: 0.8438 - val_loss: 0.4884 - val_accuracy: 0.7681 - val_auc: 0.8480\n",
      "Epoch 265/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4902 - accuracy: 0.7574 - auc: 0.8434 - val_loss: 0.4885 - val_accuracy: 0.7651 - val_auc: 0.8480\n",
      "Epoch 266/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4894 - accuracy: 0.7645 - auc: 0.8461 - val_loss: 0.4899 - val_accuracy: 0.7666 - val_auc: 0.8466\n",
      "Epoch 267/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4894 - accuracy: 0.7635 - auc: 0.8439 - val_loss: 0.4904 - val_accuracy: 0.7666 - val_auc: 0.8462\n",
      "Epoch 268/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5026 - accuracy: 0.7565 - auc: 0.8349 - val_loss: 0.4913 - val_accuracy: 0.7666 - val_auc: 0.8453\n",
      "Epoch 269/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4861 - accuracy: 0.7753 - auc: 0.8471 - val_loss: 0.4910 - val_accuracy: 0.7651 - val_auc: 0.8455\n",
      "Epoch 270/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4820 - accuracy: 0.7537 - auc: 0.8488 - val_loss: 0.4893 - val_accuracy: 0.7651 - val_auc: 0.8472\n",
      "Epoch 271/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4929 - accuracy: 0.7551 - auc: 0.8412 - val_loss: 0.4888 - val_accuracy: 0.7681 - val_auc: 0.8477\n",
      "Epoch 272/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4871 - accuracy: 0.7593 - auc: 0.8466 - val_loss: 0.4896 - val_accuracy: 0.7666 - val_auc: 0.8468\n",
      "Epoch 273/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4837 - accuracy: 0.7650 - auc: 0.8500 - val_loss: 0.4889 - val_accuracy: 0.7681 - val_auc: 0.8475\n",
      "Epoch 274/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.4827 - accuracy: 0.7588 - auc: 0.8499 - val_loss: 0.4879 - val_accuracy: 0.7696 - val_auc: 0.8484\n",
      "Epoch 275/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4872 - accuracy: 0.7640 - auc: 0.8469 - val_loss: 0.4889 - val_accuracy: 0.7681 - val_auc: 0.8474\n",
      "Epoch 276/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5006 - accuracy: 0.7546 - auc: 0.8351 - val_loss: 0.4892 - val_accuracy: 0.7681 - val_auc: 0.8470\n",
      "Epoch 277/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4824 - accuracy: 0.7701 - auc: 0.8491 - val_loss: 0.4896 - val_accuracy: 0.7651 - val_auc: 0.8467\n",
      "Epoch 278/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4843 - accuracy: 0.7659 - auc: 0.8479 - val_loss: 0.4886 - val_accuracy: 0.7636 - val_auc: 0.8473\n",
      "Epoch 279/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4856 - accuracy: 0.7626 - auc: 0.8474 - val_loss: 0.4897 - val_accuracy: 0.7651 - val_auc: 0.8465\n",
      "Epoch 280/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4821 - accuracy: 0.7701 - auc: 0.8483 - val_loss: 0.4897 - val_accuracy: 0.7651 - val_auc: 0.8467\n",
      "Epoch 281/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4926 - accuracy: 0.7551 - auc: 0.8414 - val_loss: 0.4892 - val_accuracy: 0.7651 - val_auc: 0.8472\n",
      "Epoch 282/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4911 - accuracy: 0.7607 - auc: 0.8425 - val_loss: 0.4899 - val_accuracy: 0.7666 - val_auc: 0.8464\n",
      "Epoch 283/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4942 - accuracy: 0.7560 - auc: 0.8398 - val_loss: 0.4900 - val_accuracy: 0.7666 - val_auc: 0.8462\n",
      "Epoch 284/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4904 - accuracy: 0.7621 - auc: 0.8430 - val_loss: 0.4901 - val_accuracy: 0.7666 - val_auc: 0.8463\n",
      "Epoch 285/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4908 - accuracy: 0.7579 - auc: 0.8436 - val_loss: 0.4889 - val_accuracy: 0.7696 - val_auc: 0.8472\n",
      "Epoch 286/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.4827 - accuracy: 0.7645 - auc: 0.8492 - val_loss: 0.4876 - val_accuracy: 0.7666 - val_auc: 0.8482\n",
      "Epoch 287/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4885 - accuracy: 0.7621 - auc: 0.8432 - val_loss: 0.4892 - val_accuracy: 0.7666 - val_auc: 0.8470\n",
      "Epoch 288/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4871 - accuracy: 0.7635 - auc: 0.8463 - val_loss: 0.4870 - val_accuracy: 0.7666 - val_auc: 0.8490\n",
      "Epoch 289/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4900 - accuracy: 0.7565 - auc: 0.8431 - val_loss: 0.4861 - val_accuracy: 0.7651 - val_auc: 0.8498\n",
      "Epoch 290/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4791 - accuracy: 0.7777 - auc: 0.8534 - val_loss: 0.4859 - val_accuracy: 0.7696 - val_auc: 0.8496\n",
      "Epoch 291/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4808 - accuracy: 0.7635 - auc: 0.8511 - val_loss: 0.4871 - val_accuracy: 0.7696 - val_auc: 0.8487\n",
      "Epoch 292/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4831 - accuracy: 0.7631 - auc: 0.8482 - val_loss: 0.4884 - val_accuracy: 0.7681 - val_auc: 0.8475\n",
      "Epoch 293/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4921 - accuracy: 0.7541 - auc: 0.8416 - val_loss: 0.4868 - val_accuracy: 0.7681 - val_auc: 0.8492\n",
      "Epoch 294/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4928 - accuracy: 0.7607 - auc: 0.8425 - val_loss: 0.4865 - val_accuracy: 0.7666 - val_auc: 0.8492\n",
      "Epoch 295/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4759 - accuracy: 0.7701 - auc: 0.8539 - val_loss: 0.4863 - val_accuracy: 0.7636 - val_auc: 0.8496\n",
      "Epoch 296/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4915 - accuracy: 0.7588 - auc: 0.8422 - val_loss: 0.4866 - val_accuracy: 0.7681 - val_auc: 0.8492\n",
      "Epoch 297/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4770 - accuracy: 0.7706 - auc: 0.8543 - val_loss: 0.4872 - val_accuracy: 0.7696 - val_auc: 0.8485\n",
      "Epoch 298/700\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.4852 - accuracy: 0.7645 - auc: 0.8467 - val_loss: 0.4855 - val_accuracy: 0.7696 - val_auc: 0.8501\n",
      "Epoch 299/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4782 - accuracy: 0.7786 - auc: 0.8555 - val_loss: 0.4856 - val_accuracy: 0.7696 - val_auc: 0.8500\n",
      "Epoch 300/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4778 - accuracy: 0.7598 - auc: 0.8521 - val_loss: 0.4845 - val_accuracy: 0.7726 - val_auc: 0.8507\n",
      "Epoch 301/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4885 - accuracy: 0.7697 - auc: 0.8457 - val_loss: 0.4856 - val_accuracy: 0.7651 - val_auc: 0.8500\n",
      "Epoch 302/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4894 - accuracy: 0.7621 - auc: 0.8439 - val_loss: 0.4852 - val_accuracy: 0.7666 - val_auc: 0.8501\n",
      "Epoch 303/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4799 - accuracy: 0.7650 - auc: 0.8523 - val_loss: 0.4854 - val_accuracy: 0.7666 - val_auc: 0.8499\n",
      "Epoch 304/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4731 - accuracy: 0.7711 - auc: 0.8558 - val_loss: 0.4856 - val_accuracy: 0.7681 - val_auc: 0.8499\n",
      "Epoch 305/700\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.4856 - accuracy: 0.7607 - auc: 0.8469 - val_loss: 0.4869 - val_accuracy: 0.7666 - val_auc: 0.8488\n",
      "Epoch 306/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4934 - accuracy: 0.7635 - auc: 0.8421 - val_loss: 0.4865 - val_accuracy: 0.7666 - val_auc: 0.8491\n",
      "Epoch 307/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4856 - accuracy: 0.7579 - auc: 0.8457 - val_loss: 0.4861 - val_accuracy: 0.7651 - val_auc: 0.8490\n",
      "Epoch 308/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4840 - accuracy: 0.7706 - auc: 0.8481 - val_loss: 0.4834 - val_accuracy: 0.7711 - val_auc: 0.8514\n",
      "Epoch 309/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4834 - accuracy: 0.7654 - auc: 0.8490 - val_loss: 0.4822 - val_accuracy: 0.7696 - val_auc: 0.8523\n",
      "Epoch 310/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4788 - accuracy: 0.7701 - auc: 0.8520 - val_loss: 0.4830 - val_accuracy: 0.7696 - val_auc: 0.8519\n",
      "Epoch 311/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4873 - accuracy: 0.7711 - auc: 0.8452 - val_loss: 0.4844 - val_accuracy: 0.7696 - val_auc: 0.8504\n",
      "Epoch 312/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4853 - accuracy: 0.7631 - auc: 0.8470 - val_loss: 0.4846 - val_accuracy: 0.7711 - val_auc: 0.8507\n",
      "Epoch 313/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4734 - accuracy: 0.7753 - auc: 0.8560 - val_loss: 0.4853 - val_accuracy: 0.7726 - val_auc: 0.8500\n",
      "Epoch 314/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4836 - accuracy: 0.7683 - auc: 0.8484 - val_loss: 0.4858 - val_accuracy: 0.7741 - val_auc: 0.8495\n",
      "Epoch 315/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4782 - accuracy: 0.7678 - auc: 0.8525 - val_loss: 0.4852 - val_accuracy: 0.7726 - val_auc: 0.8499\n",
      "Epoch 316/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4802 - accuracy: 0.7621 - auc: 0.8499 - val_loss: 0.4849 - val_accuracy: 0.7711 - val_auc: 0.8503\n",
      "Epoch 317/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4816 - accuracy: 0.7659 - auc: 0.8499 - val_loss: 0.4855 - val_accuracy: 0.7711 - val_auc: 0.8497\n",
      "Epoch 318/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4854 - accuracy: 0.7678 - auc: 0.8473 - val_loss: 0.4862 - val_accuracy: 0.7666 - val_auc: 0.8490\n",
      "Epoch 319/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4847 - accuracy: 0.7579 - auc: 0.8471 - val_loss: 0.4860 - val_accuracy: 0.7696 - val_auc: 0.8493\n",
      "Epoch 320/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4795 - accuracy: 0.7725 - auc: 0.8508 - val_loss: 0.4846 - val_accuracy: 0.7696 - val_auc: 0.8505\n",
      "Epoch 321/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4789 - accuracy: 0.7659 - auc: 0.8524 - val_loss: 0.4849 - val_accuracy: 0.7696 - val_auc: 0.8500\n",
      "Epoch 322/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4826 - accuracy: 0.7697 - auc: 0.8489 - val_loss: 0.4852 - val_accuracy: 0.7681 - val_auc: 0.8499\n",
      "Epoch 323/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4888 - accuracy: 0.7631 - auc: 0.8449 - val_loss: 0.4839 - val_accuracy: 0.7696 - val_auc: 0.8510\n",
      "Epoch 324/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4869 - accuracy: 0.7668 - auc: 0.8456 - val_loss: 0.4851 - val_accuracy: 0.7696 - val_auc: 0.8501\n",
      "Epoch 325/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4833 - accuracy: 0.7631 - auc: 0.8477 - val_loss: 0.4847 - val_accuracy: 0.7681 - val_auc: 0.8504\n",
      "Epoch 326/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4816 - accuracy: 0.7650 - auc: 0.8501 - val_loss: 0.4829 - val_accuracy: 0.7711 - val_auc: 0.8521\n",
      "Epoch 327/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4864 - accuracy: 0.7720 - auc: 0.8472 - val_loss: 0.4837 - val_accuracy: 0.7726 - val_auc: 0.8515\n",
      "Epoch 328/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4770 - accuracy: 0.7744 - auc: 0.8540 - val_loss: 0.4823 - val_accuracy: 0.7696 - val_auc: 0.8526\n",
      "Epoch 329/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4797 - accuracy: 0.7664 - auc: 0.8513 - val_loss: 0.4834 - val_accuracy: 0.7696 - val_auc: 0.8514\n",
      "Epoch 330/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4807 - accuracy: 0.7692 - auc: 0.8509 - val_loss: 0.4839 - val_accuracy: 0.7726 - val_auc: 0.8510\n",
      "Epoch 331/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4796 - accuracy: 0.7739 - auc: 0.8518 - val_loss: 0.4838 - val_accuracy: 0.7741 - val_auc: 0.8511\n",
      "Epoch 332/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4834 - accuracy: 0.7593 - auc: 0.8478 - val_loss: 0.4848 - val_accuracy: 0.7726 - val_auc: 0.8503\n",
      "Epoch 333/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4813 - accuracy: 0.7626 - auc: 0.8500 - val_loss: 0.4836 - val_accuracy: 0.7711 - val_auc: 0.8513\n",
      "Epoch 334/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4725 - accuracy: 0.7781 - auc: 0.8558 - val_loss: 0.4824 - val_accuracy: 0.7711 - val_auc: 0.8523\n",
      "Epoch 335/700\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.4800 - accuracy: 0.7701 - auc: 0.8503 - val_loss: 0.4813 - val_accuracy: 0.7696 - val_auc: 0.8532\n",
      "Epoch 336/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4695 - accuracy: 0.7683 - auc: 0.8583 - val_loss: 0.4817 - val_accuracy: 0.7771 - val_auc: 0.8531\n",
      "Epoch 337/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4763 - accuracy: 0.7692 - auc: 0.8553 - val_loss: 0.4823 - val_accuracy: 0.7786 - val_auc: 0.8525\n",
      "Epoch 338/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4836 - accuracy: 0.7607 - auc: 0.8473 - val_loss: 0.4832 - val_accuracy: 0.7741 - val_auc: 0.8517\n",
      "Epoch 339/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4775 - accuracy: 0.7706 - auc: 0.8525 - val_loss: 0.4841 - val_accuracy: 0.7741 - val_auc: 0.8511\n",
      "Epoch 340/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4817 - accuracy: 0.7720 - auc: 0.8509 - val_loss: 0.4841 - val_accuracy: 0.7726 - val_auc: 0.8510\n",
      "Epoch 341/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4755 - accuracy: 0.7711 - auc: 0.8539 - val_loss: 0.4840 - val_accuracy: 0.7696 - val_auc: 0.8512\n",
      "Epoch 342/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4749 - accuracy: 0.7753 - auc: 0.8546 - val_loss: 0.4825 - val_accuracy: 0.7756 - val_auc: 0.8524\n",
      "Epoch 343/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4853 - accuracy: 0.7602 - auc: 0.8478 - val_loss: 0.4826 - val_accuracy: 0.7741 - val_auc: 0.8521\n",
      "Epoch 344/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4796 - accuracy: 0.7664 - auc: 0.8527 - val_loss: 0.4823 - val_accuracy: 0.7681 - val_auc: 0.8523\n",
      "Epoch 345/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4753 - accuracy: 0.7711 - auc: 0.8539 - val_loss: 0.4819 - val_accuracy: 0.7756 - val_auc: 0.8526\n",
      "Epoch 346/700\n",
      "34/34 [==============================] - 2s 46ms/step - loss: 0.4818 - accuracy: 0.7664 - auc: 0.8502 - val_loss: 0.4826 - val_accuracy: 0.7741 - val_auc: 0.8521\n",
      "Epoch 347/700\n",
      "34/34 [==============================] - 2s 45ms/step - loss: 0.4787 - accuracy: 0.7683 - auc: 0.8510 - val_loss: 0.4820 - val_accuracy: 0.7741 - val_auc: 0.8526\n",
      "Epoch 348/700\n",
      "34/34 [==============================] - 2s 45ms/step - loss: 0.4816 - accuracy: 0.7701 - auc: 0.8507 - val_loss: 0.4824 - val_accuracy: 0.7771 - val_auc: 0.8525\n",
      "Epoch 349/700\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 0.4786 - accuracy: 0.7673 - auc: 0.8526 - val_loss: 0.4801 - val_accuracy: 0.7816 - val_auc: 0.8542\n",
      "Epoch 350/700\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.4768 - accuracy: 0.7791 - auc: 0.8550 - val_loss: 0.4787 - val_accuracy: 0.7756 - val_auc: 0.8553\n",
      "Epoch 351/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4751 - accuracy: 0.7687 - auc: 0.8549 - val_loss: 0.4797 - val_accuracy: 0.7786 - val_auc: 0.8544\n",
      "Epoch 352/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4789 - accuracy: 0.7626 - auc: 0.8511 - val_loss: 0.4797 - val_accuracy: 0.7726 - val_auc: 0.8541\n",
      "Epoch 353/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4861 - accuracy: 0.7593 - auc: 0.8464 - val_loss: 0.4813 - val_accuracy: 0.7696 - val_auc: 0.8525\n",
      "Epoch 354/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4805 - accuracy: 0.7659 - auc: 0.8488 - val_loss: 0.4811 - val_accuracy: 0.7756 - val_auc: 0.8533\n",
      "Epoch 355/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4739 - accuracy: 0.7772 - auc: 0.8567 - val_loss: 0.4797 - val_accuracy: 0.7726 - val_auc: 0.8543\n",
      "Epoch 356/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4733 - accuracy: 0.7748 - auc: 0.8569 - val_loss: 0.4810 - val_accuracy: 0.7711 - val_auc: 0.8531\n",
      "Epoch 357/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4787 - accuracy: 0.7786 - auc: 0.8525 - val_loss: 0.4817 - val_accuracy: 0.7711 - val_auc: 0.8525\n",
      "Epoch 358/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4842 - accuracy: 0.7617 - auc: 0.8480 - val_loss: 0.4807 - val_accuracy: 0.7711 - val_auc: 0.8532\n",
      "Epoch 359/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4844 - accuracy: 0.7654 - auc: 0.8476 - val_loss: 0.4821 - val_accuracy: 0.7741 - val_auc: 0.8521\n",
      "Epoch 360/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4761 - accuracy: 0.7777 - auc: 0.8544 - val_loss: 0.4827 - val_accuracy: 0.7711 - val_auc: 0.8517\n",
      "Epoch 361/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4738 - accuracy: 0.7744 - auc: 0.8549 - val_loss: 0.4817 - val_accuracy: 0.7756 - val_auc: 0.8526\n",
      "Epoch 362/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4787 - accuracy: 0.7697 - auc: 0.8514 - val_loss: 0.4815 - val_accuracy: 0.7741 - val_auc: 0.8529\n",
      "Epoch 363/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4812 - accuracy: 0.7763 - auc: 0.8512 - val_loss: 0.4802 - val_accuracy: 0.7711 - val_auc: 0.8537\n",
      "Epoch 364/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4742 - accuracy: 0.7753 - auc: 0.8548 - val_loss: 0.4801 - val_accuracy: 0.7681 - val_auc: 0.8540\n",
      "Epoch 365/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4742 - accuracy: 0.7678 - auc: 0.8546 - val_loss: 0.4795 - val_accuracy: 0.7681 - val_auc: 0.8545\n",
      "Epoch 366/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4813 - accuracy: 0.7650 - auc: 0.8515 - val_loss: 0.4807 - val_accuracy: 0.7696 - val_auc: 0.8537\n",
      "Epoch 367/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4774 - accuracy: 0.7701 - auc: 0.8535 - val_loss: 0.4807 - val_accuracy: 0.7666 - val_auc: 0.8535\n",
      "Epoch 368/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4796 - accuracy: 0.7706 - auc: 0.8514 - val_loss: 0.4795 - val_accuracy: 0.7696 - val_auc: 0.8546\n",
      "Epoch 369/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4781 - accuracy: 0.7720 - auc: 0.8533 - val_loss: 0.4797 - val_accuracy: 0.7696 - val_auc: 0.8542\n",
      "Epoch 370/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4740 - accuracy: 0.7739 - auc: 0.8564 - val_loss: 0.4803 - val_accuracy: 0.7726 - val_auc: 0.8540\n",
      "Epoch 371/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4854 - accuracy: 0.7687 - auc: 0.8475 - val_loss: 0.4788 - val_accuracy: 0.7756 - val_auc: 0.8550\n",
      "Epoch 372/700\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.4785 - accuracy: 0.7631 - auc: 0.8511 - val_loss: 0.4787 - val_accuracy: 0.7726 - val_auc: 0.8550\n",
      "Epoch 373/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4807 - accuracy: 0.7692 - auc: 0.8505 - val_loss: 0.4796 - val_accuracy: 0.7726 - val_auc: 0.8545\n",
      "Epoch 374/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4761 - accuracy: 0.7748 - auc: 0.8547 - val_loss: 0.4797 - val_accuracy: 0.7741 - val_auc: 0.8544\n",
      "Epoch 375/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4755 - accuracy: 0.7777 - auc: 0.8535 - val_loss: 0.4789 - val_accuracy: 0.7711 - val_auc: 0.8546\n",
      "Epoch 376/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4697 - accuracy: 0.7772 - auc: 0.8590 - val_loss: 0.4796 - val_accuracy: 0.7681 - val_auc: 0.8541\n",
      "Epoch 377/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4727 - accuracy: 0.7833 - auc: 0.8565 - val_loss: 0.4790 - val_accuracy: 0.7696 - val_auc: 0.8545\n",
      "Epoch 378/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.4755 - accuracy: 0.7777 - auc: 0.8546 - val_loss: 0.4772 - val_accuracy: 0.7726 - val_auc: 0.8562\n",
      "Epoch 379/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4787 - accuracy: 0.7701 - auc: 0.8525 - val_loss: 0.4795 - val_accuracy: 0.7756 - val_auc: 0.8543\n",
      "Epoch 380/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4727 - accuracy: 0.7777 - auc: 0.8573 - val_loss: 0.4795 - val_accuracy: 0.7726 - val_auc: 0.8544\n",
      "Epoch 381/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4670 - accuracy: 0.7734 - auc: 0.8610 - val_loss: 0.4781 - val_accuracy: 0.7726 - val_auc: 0.8552\n",
      "Epoch 382/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4753 - accuracy: 0.7687 - auc: 0.8549 - val_loss: 0.4760 - val_accuracy: 0.7771 - val_auc: 0.8569\n",
      "Epoch 383/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4722 - accuracy: 0.7725 - auc: 0.8576 - val_loss: 0.4774 - val_accuracy: 0.7756 - val_auc: 0.8556\n",
      "Epoch 384/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4806 - accuracy: 0.7668 - auc: 0.8498 - val_loss: 0.4796 - val_accuracy: 0.7726 - val_auc: 0.8540\n",
      "Epoch 385/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4771 - accuracy: 0.7767 - auc: 0.8545 - val_loss: 0.4783 - val_accuracy: 0.7741 - val_auc: 0.8551\n",
      "Epoch 386/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4697 - accuracy: 0.7796 - auc: 0.8593 - val_loss: 0.4762 - val_accuracy: 0.7741 - val_auc: 0.8571\n",
      "Epoch 387/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4700 - accuracy: 0.7758 - auc: 0.8592 - val_loss: 0.4754 - val_accuracy: 0.7756 - val_auc: 0.8571\n",
      "Epoch 388/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4630 - accuracy: 0.7753 - auc: 0.8626 - val_loss: 0.4763 - val_accuracy: 0.7771 - val_auc: 0.8566\n",
      "Epoch 389/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4775 - accuracy: 0.7664 - auc: 0.8521 - val_loss: 0.4768 - val_accuracy: 0.7756 - val_auc: 0.8562\n",
      "Epoch 390/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4780 - accuracy: 0.7753 - auc: 0.8524 - val_loss: 0.4756 - val_accuracy: 0.7711 - val_auc: 0.8570\n",
      "Epoch 391/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4743 - accuracy: 0.7739 - auc: 0.8549 - val_loss: 0.4767 - val_accuracy: 0.7756 - val_auc: 0.8565\n",
      "Epoch 392/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4707 - accuracy: 0.7744 - auc: 0.8576 - val_loss: 0.4795 - val_accuracy: 0.7741 - val_auc: 0.8543\n",
      "Epoch 393/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4733 - accuracy: 0.7673 - auc: 0.8558 - val_loss: 0.4796 - val_accuracy: 0.7756 - val_auc: 0.8542\n",
      "Epoch 394/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4711 - accuracy: 0.7805 - auc: 0.8590 - val_loss: 0.4787 - val_accuracy: 0.7726 - val_auc: 0.8548\n",
      "Epoch 395/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4748 - accuracy: 0.7720 - auc: 0.8549 - val_loss: 0.4763 - val_accuracy: 0.7741 - val_auc: 0.8568\n",
      "Epoch 396/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4729 - accuracy: 0.7767 - auc: 0.8567 - val_loss: 0.4760 - val_accuracy: 0.7741 - val_auc: 0.8570\n",
      "Epoch 397/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4650 - accuracy: 0.7866 - auc: 0.8619 - val_loss: 0.4764 - val_accuracy: 0.7786 - val_auc: 0.8568\n",
      "Epoch 398/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4730 - accuracy: 0.7692 - auc: 0.8560 - val_loss: 0.4771 - val_accuracy: 0.7741 - val_auc: 0.8566\n",
      "Epoch 399/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4653 - accuracy: 0.7725 - auc: 0.8612 - val_loss: 0.4765 - val_accuracy: 0.7771 - val_auc: 0.8569\n",
      "Epoch 400/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4720 - accuracy: 0.7767 - auc: 0.8570 - val_loss: 0.4779 - val_accuracy: 0.7741 - val_auc: 0.8557\n",
      "Epoch 401/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4712 - accuracy: 0.7725 - auc: 0.8571 - val_loss: 0.4785 - val_accuracy: 0.7741 - val_auc: 0.8551\n",
      "Epoch 402/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4732 - accuracy: 0.7767 - auc: 0.8557 - val_loss: 0.4770 - val_accuracy: 0.7771 - val_auc: 0.8563\n",
      "Epoch 403/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4717 - accuracy: 0.7725 - auc: 0.8572 - val_loss: 0.4762 - val_accuracy: 0.7786 - val_auc: 0.8570\n",
      "Epoch 404/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4726 - accuracy: 0.7838 - auc: 0.8583 - val_loss: 0.4770 - val_accuracy: 0.7756 - val_auc: 0.8564\n",
      "Epoch 405/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4693 - accuracy: 0.7748 - auc: 0.8601 - val_loss: 0.4757 - val_accuracy: 0.7771 - val_auc: 0.8573\n",
      "Epoch 406/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.4717 - accuracy: 0.7730 - auc: 0.8578 - val_loss: 0.4752 - val_accuracy: 0.7756 - val_auc: 0.8579\n",
      "Epoch 407/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4667 - accuracy: 0.7786 - auc: 0.8600 - val_loss: 0.4771 - val_accuracy: 0.7756 - val_auc: 0.8562\n",
      "Epoch 408/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4745 - accuracy: 0.7692 - auc: 0.8535 - val_loss: 0.4762 - val_accuracy: 0.7756 - val_auc: 0.8570\n",
      "Epoch 409/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4682 - accuracy: 0.7866 - auc: 0.8604 - val_loss: 0.4757 - val_accuracy: 0.7756 - val_auc: 0.8575\n",
      "Epoch 410/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4759 - accuracy: 0.7706 - auc: 0.8548 - val_loss: 0.4771 - val_accuracy: 0.7756 - val_auc: 0.8564\n",
      "Epoch 411/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4717 - accuracy: 0.7800 - auc: 0.8576 - val_loss: 0.4765 - val_accuracy: 0.7771 - val_auc: 0.8567\n",
      "Epoch 412/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4747 - accuracy: 0.7635 - auc: 0.8540 - val_loss: 0.4758 - val_accuracy: 0.7786 - val_auc: 0.8573\n",
      "Epoch 413/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4668 - accuracy: 0.7772 - auc: 0.8609 - val_loss: 0.4759 - val_accuracy: 0.7786 - val_auc: 0.8574\n",
      "Epoch 414/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4747 - accuracy: 0.7772 - auc: 0.8552 - val_loss: 0.4761 - val_accuracy: 0.7771 - val_auc: 0.8572\n",
      "Epoch 415/700\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.4727 - accuracy: 0.7725 - auc: 0.8561 - val_loss: 0.4748 - val_accuracy: 0.7756 - val_auc: 0.8579\n",
      "Epoch 416/700\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.4780 - accuracy: 0.7645 - auc: 0.8515 - val_loss: 0.4740 - val_accuracy: 0.7801 - val_auc: 0.8586\n",
      "Epoch 417/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4693 - accuracy: 0.7730 - auc: 0.8592 - val_loss: 0.4739 - val_accuracy: 0.7786 - val_auc: 0.8586\n",
      "Epoch 418/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4802 - accuracy: 0.7730 - auc: 0.8501 - val_loss: 0.4747 - val_accuracy: 0.7831 - val_auc: 0.8580\n",
      "Epoch 419/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4679 - accuracy: 0.7725 - auc: 0.8586 - val_loss: 0.4759 - val_accuracy: 0.7741 - val_auc: 0.8570\n",
      "Epoch 420/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4736 - accuracy: 0.7824 - auc: 0.8568 - val_loss: 0.4749 - val_accuracy: 0.7771 - val_auc: 0.8581\n",
      "Epoch 421/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4681 - accuracy: 0.7847 - auc: 0.8604 - val_loss: 0.4747 - val_accuracy: 0.7741 - val_auc: 0.8579\n",
      "Epoch 422/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4608 - accuracy: 0.7904 - auc: 0.8665 - val_loss: 0.4737 - val_accuracy: 0.7771 - val_auc: 0.8589\n",
      "Epoch 423/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4694 - accuracy: 0.7852 - auc: 0.8599 - val_loss: 0.4738 - val_accuracy: 0.7741 - val_auc: 0.8586\n",
      "Epoch 424/700\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4690 - accuracy: 0.7711 - auc: 0.8595 - val_loss: 0.4736 - val_accuracy: 0.7771 - val_auc: 0.8586\n",
      "Epoch 425/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4708 - accuracy: 0.7758 - auc: 0.8583 - val_loss: 0.4742 - val_accuracy: 0.7741 - val_auc: 0.8576\n",
      "Epoch 426/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4671 - accuracy: 0.7706 - auc: 0.8601 - val_loss: 0.4743 - val_accuracy: 0.7771 - val_auc: 0.8579\n",
      "Epoch 427/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4724 - accuracy: 0.7781 - auc: 0.8576 - val_loss: 0.4736 - val_accuracy: 0.7741 - val_auc: 0.8587\n",
      "Epoch 428/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4659 - accuracy: 0.7899 - auc: 0.8628 - val_loss: 0.4747 - val_accuracy: 0.7726 - val_auc: 0.8576\n",
      "Epoch 429/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4641 - accuracy: 0.7800 - auc: 0.8638 - val_loss: 0.4740 - val_accuracy: 0.7741 - val_auc: 0.8583\n",
      "Epoch 430/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4712 - accuracy: 0.7781 - auc: 0.8573 - val_loss: 0.4738 - val_accuracy: 0.7741 - val_auc: 0.8581\n",
      "Epoch 431/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4634 - accuracy: 0.7796 - auc: 0.8642 - val_loss: 0.4743 - val_accuracy: 0.7726 - val_auc: 0.8578\n",
      "Epoch 432/700\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4666 - accuracy: 0.7857 - auc: 0.8607 - val_loss: 0.4730 - val_accuracy: 0.7756 - val_auc: 0.8589\n",
      "Epoch 433/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4699 - accuracy: 0.7763 - auc: 0.8592 - val_loss: 0.4739 - val_accuracy: 0.7771 - val_auc: 0.8584\n",
      "Epoch 434/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4680 - accuracy: 0.7819 - auc: 0.8595 - val_loss: 0.4736 - val_accuracy: 0.7756 - val_auc: 0.8586\n",
      "Epoch 435/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4721 - accuracy: 0.7720 - auc: 0.8567 - val_loss: 0.4749 - val_accuracy: 0.7786 - val_auc: 0.8576\n",
      "Epoch 436/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4716 - accuracy: 0.7748 - auc: 0.8574 - val_loss: 0.4746 - val_accuracy: 0.7831 - val_auc: 0.8580\n",
      "Epoch 437/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4670 - accuracy: 0.7758 - auc: 0.8597 - val_loss: 0.4726 - val_accuracy: 0.7771 - val_auc: 0.8592\n",
      "Epoch 438/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4682 - accuracy: 0.7687 - auc: 0.8586 - val_loss: 0.4727 - val_accuracy: 0.7786 - val_auc: 0.8593\n",
      "Epoch 439/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4601 - accuracy: 0.7904 - auc: 0.8661 - val_loss: 0.4728 - val_accuracy: 0.7771 - val_auc: 0.8591\n",
      "Epoch 440/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4709 - accuracy: 0.7706 - auc: 0.8582 - val_loss: 0.4728 - val_accuracy: 0.7756 - val_auc: 0.8591\n",
      "Epoch 441/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4674 - accuracy: 0.7833 - auc: 0.8606 - val_loss: 0.4740 - val_accuracy: 0.7786 - val_auc: 0.8584\n",
      "Epoch 442/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4681 - accuracy: 0.7763 - auc: 0.8592 - val_loss: 0.4733 - val_accuracy: 0.7726 - val_auc: 0.8588\n",
      "Epoch 443/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4679 - accuracy: 0.7777 - auc: 0.8610 - val_loss: 0.4714 - val_accuracy: 0.7801 - val_auc: 0.8604\n",
      "Epoch 444/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4617 - accuracy: 0.7814 - auc: 0.8633 - val_loss: 0.4723 - val_accuracy: 0.7786 - val_auc: 0.8596\n",
      "Epoch 445/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4625 - accuracy: 0.7800 - auc: 0.8642 - val_loss: 0.4709 - val_accuracy: 0.7756 - val_auc: 0.8607\n",
      "Epoch 446/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4638 - accuracy: 0.7781 - auc: 0.8635 - val_loss: 0.4705 - val_accuracy: 0.7831 - val_auc: 0.8607\n",
      "Epoch 447/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4722 - accuracy: 0.7734 - auc: 0.8553 - val_loss: 0.4726 - val_accuracy: 0.7786 - val_auc: 0.8592\n",
      "Epoch 448/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4723 - accuracy: 0.7744 - auc: 0.8567 - val_loss: 0.4711 - val_accuracy: 0.7771 - val_auc: 0.8603\n",
      "Epoch 449/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4768 - accuracy: 0.7711 - auc: 0.8526 - val_loss: 0.4710 - val_accuracy: 0.7801 - val_auc: 0.8606\n",
      "Epoch 450/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4732 - accuracy: 0.7725 - auc: 0.8549 - val_loss: 0.4706 - val_accuracy: 0.7786 - val_auc: 0.8604\n",
      "Epoch 451/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4644 - accuracy: 0.7800 - auc: 0.8632 - val_loss: 0.4710 - val_accuracy: 0.7741 - val_auc: 0.8600\n",
      "Epoch 452/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4643 - accuracy: 0.7819 - auc: 0.8631 - val_loss: 0.4717 - val_accuracy: 0.7816 - val_auc: 0.8601\n",
      "Epoch 453/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4631 - accuracy: 0.7814 - auc: 0.8651 - val_loss: 0.4730 - val_accuracy: 0.7786 - val_auc: 0.8590\n",
      "Epoch 454/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4681 - accuracy: 0.7753 - auc: 0.8607 - val_loss: 0.4740 - val_accuracy: 0.7801 - val_auc: 0.8584\n",
      "Epoch 455/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4708 - accuracy: 0.7786 - auc: 0.8585 - val_loss: 0.4730 - val_accuracy: 0.7756 - val_auc: 0.8589\n",
      "Epoch 456/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4686 - accuracy: 0.7777 - auc: 0.8595 - val_loss: 0.4734 - val_accuracy: 0.7756 - val_auc: 0.8587\n",
      "Epoch 457/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4698 - accuracy: 0.7744 - auc: 0.8586 - val_loss: 0.4727 - val_accuracy: 0.7801 - val_auc: 0.8594\n",
      "Epoch 458/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4653 - accuracy: 0.7852 - auc: 0.8611 - val_loss: 0.4725 - val_accuracy: 0.7786 - val_auc: 0.8598\n",
      "Epoch 459/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4629 - accuracy: 0.7758 - auc: 0.8634 - val_loss: 0.4728 - val_accuracy: 0.7816 - val_auc: 0.8594\n",
      "Epoch 460/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4703 - accuracy: 0.7701 - auc: 0.8584 - val_loss: 0.4738 - val_accuracy: 0.7831 - val_auc: 0.8592\n",
      "Epoch 461/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4619 - accuracy: 0.7796 - auc: 0.8652 - val_loss: 0.4725 - val_accuracy: 0.7816 - val_auc: 0.8597\n",
      "Epoch 462/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4664 - accuracy: 0.7777 - auc: 0.8609 - val_loss: 0.4721 - val_accuracy: 0.7771 - val_auc: 0.8594\n",
      "Epoch 463/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4611 - accuracy: 0.7876 - auc: 0.8664 - val_loss: 0.4716 - val_accuracy: 0.7816 - val_auc: 0.8601\n",
      "Epoch 464/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4720 - accuracy: 0.7763 - auc: 0.8578 - val_loss: 0.4718 - val_accuracy: 0.7771 - val_auc: 0.8599\n",
      "Epoch 465/700\n",
      "34/34 [==============================] - 2s 45ms/step - loss: 0.4603 - accuracy: 0.7838 - auc: 0.8661 - val_loss: 0.4699 - val_accuracy: 0.7801 - val_auc: 0.8614\n",
      "Epoch 466/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4639 - accuracy: 0.7800 - auc: 0.8626 - val_loss: 0.4699 - val_accuracy: 0.7846 - val_auc: 0.8620\n",
      "Epoch 467/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4584 - accuracy: 0.7866 - auc: 0.8682 - val_loss: 0.4704 - val_accuracy: 0.7831 - val_auc: 0.8614\n",
      "Epoch 468/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4695 - accuracy: 0.7852 - auc: 0.8607 - val_loss: 0.4697 - val_accuracy: 0.7786 - val_auc: 0.8612\n",
      "Epoch 469/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4696 - accuracy: 0.7763 - auc: 0.8590 - val_loss: 0.4714 - val_accuracy: 0.7786 - val_auc: 0.8602\n",
      "Epoch 470/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4610 - accuracy: 0.7862 - auc: 0.8650 - val_loss: 0.4724 - val_accuracy: 0.7786 - val_auc: 0.8596\n",
      "Epoch 471/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4661 - accuracy: 0.7739 - auc: 0.8601 - val_loss: 0.4732 - val_accuracy: 0.7801 - val_auc: 0.8591\n",
      "Epoch 472/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4690 - accuracy: 0.7819 - auc: 0.8598 - val_loss: 0.4730 - val_accuracy: 0.7801 - val_auc: 0.8591\n",
      "Epoch 473/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4672 - accuracy: 0.7890 - auc: 0.8619 - val_loss: 0.4723 - val_accuracy: 0.7786 - val_auc: 0.8596\n",
      "Epoch 474/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4574 - accuracy: 0.7862 - auc: 0.8681 - val_loss: 0.4726 - val_accuracy: 0.7816 - val_auc: 0.8593\n",
      "Epoch 475/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4641 - accuracy: 0.7852 - auc: 0.8631 - val_loss: 0.4718 - val_accuracy: 0.7816 - val_auc: 0.8600\n",
      "Epoch 476/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4618 - accuracy: 0.7805 - auc: 0.8634 - val_loss: 0.4726 - val_accuracy: 0.7816 - val_auc: 0.8595\n",
      "Epoch 477/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4726 - accuracy: 0.7800 - auc: 0.8568 - val_loss: 0.4710 - val_accuracy: 0.7816 - val_auc: 0.8604\n",
      "Epoch 478/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4653 - accuracy: 0.7843 - auc: 0.8619 - val_loss: 0.4699 - val_accuracy: 0.7831 - val_auc: 0.8612\n",
      "Epoch 479/700\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.4685 - accuracy: 0.7777 - auc: 0.8609 - val_loss: 0.4695 - val_accuracy: 0.7816 - val_auc: 0.8616\n",
      "Epoch 480/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4622 - accuracy: 0.7824 - auc: 0.8651 - val_loss: 0.4690 - val_accuracy: 0.7846 - val_auc: 0.8620\n",
      "Epoch 481/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4727 - accuracy: 0.7725 - auc: 0.8565 - val_loss: 0.4686 - val_accuracy: 0.7831 - val_auc: 0.8621\n",
      "Epoch 482/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4619 - accuracy: 0.7894 - auc: 0.8657 - val_loss: 0.4705 - val_accuracy: 0.7846 - val_auc: 0.8609\n",
      "Epoch 483/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4708 - accuracy: 0.7857 - auc: 0.8589 - val_loss: 0.4712 - val_accuracy: 0.7846 - val_auc: 0.8605\n",
      "Epoch 484/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4579 - accuracy: 0.7899 - auc: 0.8683 - val_loss: 0.4726 - val_accuracy: 0.7816 - val_auc: 0.8594\n",
      "Epoch 485/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4594 - accuracy: 0.7880 - auc: 0.8659 - val_loss: 0.4722 - val_accuracy: 0.7831 - val_auc: 0.8598\n",
      "Epoch 486/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4653 - accuracy: 0.7862 - auc: 0.8630 - val_loss: 0.4720 - val_accuracy: 0.7816 - val_auc: 0.8597\n",
      "Epoch 487/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4621 - accuracy: 0.7829 - auc: 0.8636 - val_loss: 0.4720 - val_accuracy: 0.7816 - val_auc: 0.8602\n",
      "Epoch 488/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4627 - accuracy: 0.7763 - auc: 0.8637 - val_loss: 0.4715 - val_accuracy: 0.7846 - val_auc: 0.8606\n",
      "Epoch 489/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4563 - accuracy: 0.7890 - auc: 0.8677 - val_loss: 0.4717 - val_accuracy: 0.7831 - val_auc: 0.8607\n",
      "Epoch 490/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4609 - accuracy: 0.7833 - auc: 0.8658 - val_loss: 0.4716 - val_accuracy: 0.7786 - val_auc: 0.8604\n",
      "Epoch 491/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4541 - accuracy: 0.7909 - auc: 0.8706 - val_loss: 0.4696 - val_accuracy: 0.7846 - val_auc: 0.8621\n",
      "Epoch 492/700\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.4637 - accuracy: 0.7819 - auc: 0.8630 - val_loss: 0.4684 - val_accuracy: 0.7816 - val_auc: 0.8628\n",
      "Epoch 493/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4586 - accuracy: 0.7918 - auc: 0.8666 - val_loss: 0.4698 - val_accuracy: 0.7801 - val_auc: 0.8619\n",
      "Epoch 494/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4642 - accuracy: 0.7796 - auc: 0.8622 - val_loss: 0.4688 - val_accuracy: 0.7861 - val_auc: 0.8625\n",
      "Epoch 495/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4625 - accuracy: 0.7866 - auc: 0.8648 - val_loss: 0.4693 - val_accuracy: 0.7846 - val_auc: 0.8620\n",
      "Epoch 496/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4712 - accuracy: 0.7706 - auc: 0.8576 - val_loss: 0.4678 - val_accuracy: 0.7877 - val_auc: 0.8632\n",
      "Epoch 497/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4624 - accuracy: 0.7758 - auc: 0.8638 - val_loss: 0.4687 - val_accuracy: 0.7861 - val_auc: 0.8624\n",
      "Epoch 498/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4652 - accuracy: 0.7833 - auc: 0.8632 - val_loss: 0.4687 - val_accuracy: 0.7816 - val_auc: 0.8622\n",
      "Epoch 499/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4642 - accuracy: 0.7800 - auc: 0.8608 - val_loss: 0.4702 - val_accuracy: 0.7907 - val_auc: 0.8610\n",
      "Epoch 500/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4610 - accuracy: 0.7833 - auc: 0.8644 - val_loss: 0.4703 - val_accuracy: 0.7801 - val_auc: 0.8607\n",
      "Epoch 501/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4660 - accuracy: 0.7833 - auc: 0.8616 - val_loss: 0.4707 - val_accuracy: 0.7846 - val_auc: 0.8604\n",
      "Epoch 502/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4603 - accuracy: 0.7876 - auc: 0.8651 - val_loss: 0.4714 - val_accuracy: 0.7786 - val_auc: 0.8600\n",
      "Epoch 503/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4624 - accuracy: 0.7833 - auc: 0.8632 - val_loss: 0.4692 - val_accuracy: 0.7801 - val_auc: 0.8620\n",
      "Epoch 504/700\n",
      "34/34 [==============================] - 1s 43ms/step - loss: 0.4554 - accuracy: 0.7838 - auc: 0.8680 - val_loss: 0.4677 - val_accuracy: 0.7786 - val_auc: 0.8631\n",
      "Epoch 505/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4632 - accuracy: 0.7772 - auc: 0.8628 - val_loss: 0.4674 - val_accuracy: 0.7877 - val_auc: 0.8635\n",
      "Epoch 506/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4664 - accuracy: 0.7772 - auc: 0.8606 - val_loss: 0.4673 - val_accuracy: 0.7861 - val_auc: 0.8632\n",
      "Epoch 507/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4624 - accuracy: 0.7786 - auc: 0.8638 - val_loss: 0.4662 - val_accuracy: 0.7846 - val_auc: 0.8640\n",
      "Epoch 508/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4563 - accuracy: 0.7852 - auc: 0.8695 - val_loss: 0.4670 - val_accuracy: 0.7816 - val_auc: 0.8633\n",
      "Epoch 509/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4597 - accuracy: 0.7956 - auc: 0.8663 - val_loss: 0.4664 - val_accuracy: 0.7846 - val_auc: 0.8638\n",
      "Epoch 510/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4618 - accuracy: 0.7843 - auc: 0.8638 - val_loss: 0.4662 - val_accuracy: 0.7861 - val_auc: 0.8641\n",
      "Epoch 511/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4683 - accuracy: 0.7824 - auc: 0.8611 - val_loss: 0.4676 - val_accuracy: 0.7816 - val_auc: 0.8629\n",
      "Epoch 512/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4639 - accuracy: 0.7763 - auc: 0.8635 - val_loss: 0.4679 - val_accuracy: 0.7846 - val_auc: 0.8629\n",
      "Epoch 513/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4575 - accuracy: 0.7885 - auc: 0.8677 - val_loss: 0.4685 - val_accuracy: 0.7756 - val_auc: 0.8625\n",
      "Epoch 514/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4556 - accuracy: 0.7824 - auc: 0.8699 - val_loss: 0.4672 - val_accuracy: 0.7771 - val_auc: 0.8636\n",
      "Epoch 515/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4544 - accuracy: 0.7829 - auc: 0.8697 - val_loss: 0.4664 - val_accuracy: 0.7756 - val_auc: 0.8644\n",
      "Epoch 516/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4610 - accuracy: 0.7913 - auc: 0.8657 - val_loss: 0.4663 - val_accuracy: 0.7831 - val_auc: 0.8639\n",
      "Epoch 517/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4650 - accuracy: 0.7720 - auc: 0.8622 - val_loss: 0.4676 - val_accuracy: 0.7831 - val_auc: 0.8630\n",
      "Epoch 518/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4648 - accuracy: 0.7814 - auc: 0.8614 - val_loss: 0.4673 - val_accuracy: 0.7892 - val_auc: 0.8634\n",
      "Epoch 519/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4546 - accuracy: 0.7800 - auc: 0.8708 - val_loss: 0.4667 - val_accuracy: 0.7816 - val_auc: 0.8636\n",
      "Epoch 520/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4589 - accuracy: 0.7857 - auc: 0.8669 - val_loss: 0.4665 - val_accuracy: 0.7846 - val_auc: 0.8638\n",
      "Epoch 521/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4621 - accuracy: 0.7781 - auc: 0.8639 - val_loss: 0.4673 - val_accuracy: 0.7861 - val_auc: 0.8634\n",
      "Epoch 522/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4597 - accuracy: 0.7777 - auc: 0.8644 - val_loss: 0.4671 - val_accuracy: 0.7861 - val_auc: 0.8633\n",
      "Epoch 523/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4595 - accuracy: 0.7862 - auc: 0.8660 - val_loss: 0.4672 - val_accuracy: 0.7786 - val_auc: 0.8633\n",
      "Epoch 524/700\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.4694 - accuracy: 0.7777 - auc: 0.8579 - val_loss: 0.4654 - val_accuracy: 0.7861 - val_auc: 0.8646\n",
      "Epoch 525/700\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4604 - accuracy: 0.7847 - auc: 0.8667 - val_loss: 0.4665 - val_accuracy: 0.7801 - val_auc: 0.8638\n",
      "Epoch 526/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4567 - accuracy: 0.7984 - auc: 0.8693 - val_loss: 0.4669 - val_accuracy: 0.7846 - val_auc: 0.8634\n",
      "Epoch 527/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4621 - accuracy: 0.7715 - auc: 0.8627 - val_loss: 0.4678 - val_accuracy: 0.7846 - val_auc: 0.8626\n",
      "Epoch 528/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4633 - accuracy: 0.7909 - auc: 0.8639 - val_loss: 0.4687 - val_accuracy: 0.7846 - val_auc: 0.8619\n",
      "Epoch 529/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4532 - accuracy: 0.7956 - auc: 0.8714 - val_loss: 0.4684 - val_accuracy: 0.7861 - val_auc: 0.8623\n",
      "Epoch 530/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4688 - accuracy: 0.7796 - auc: 0.8588 - val_loss: 0.4676 - val_accuracy: 0.7816 - val_auc: 0.8632\n",
      "Epoch 531/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4518 - accuracy: 0.7890 - auc: 0.8710 - val_loss: 0.4676 - val_accuracy: 0.7816 - val_auc: 0.8629\n",
      "Epoch 532/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4680 - accuracy: 0.7786 - auc: 0.8604 - val_loss: 0.4663 - val_accuracy: 0.7786 - val_auc: 0.8640\n",
      "Epoch 533/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.4580 - accuracy: 0.7847 - auc: 0.8658 - val_loss: 0.4653 - val_accuracy: 0.7861 - val_auc: 0.8651\n",
      "Epoch 534/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4595 - accuracy: 0.7871 - auc: 0.8667 - val_loss: 0.4660 - val_accuracy: 0.7892 - val_auc: 0.8645\n",
      "Epoch 535/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4559 - accuracy: 0.7890 - auc: 0.8690 - val_loss: 0.4661 - val_accuracy: 0.7831 - val_auc: 0.8646\n",
      "Epoch 536/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4625 - accuracy: 0.7876 - auc: 0.8642 - val_loss: 0.4670 - val_accuracy: 0.7877 - val_auc: 0.8640\n",
      "Epoch 537/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4596 - accuracy: 0.7829 - auc: 0.8659 - val_loss: 0.4666 - val_accuracy: 0.7922 - val_auc: 0.8641\n",
      "Epoch 538/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4524 - accuracy: 0.7862 - auc: 0.8711 - val_loss: 0.4667 - val_accuracy: 0.7816 - val_auc: 0.8640\n",
      "Epoch 539/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4569 - accuracy: 0.7819 - auc: 0.8681 - val_loss: 0.4667 - val_accuracy: 0.7816 - val_auc: 0.8638\n",
      "Epoch 540/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4599 - accuracy: 0.7876 - auc: 0.8651 - val_loss: 0.4660 - val_accuracy: 0.7801 - val_auc: 0.8643\n",
      "Epoch 541/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4579 - accuracy: 0.7862 - auc: 0.8665 - val_loss: 0.4659 - val_accuracy: 0.7846 - val_auc: 0.8646\n",
      "Epoch 542/700\n",
      "34/34 [==============================] - 2s 51ms/step - loss: 0.4654 - accuracy: 0.7739 - auc: 0.8622 - val_loss: 0.4641 - val_accuracy: 0.7907 - val_auc: 0.8658\n",
      "Epoch 543/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4693 - accuracy: 0.7748 - auc: 0.8591 - val_loss: 0.4644 - val_accuracy: 0.7922 - val_auc: 0.8656\n",
      "Epoch 544/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4610 - accuracy: 0.7852 - auc: 0.8645 - val_loss: 0.4657 - val_accuracy: 0.7907 - val_auc: 0.8647\n",
      "Epoch 545/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4604 - accuracy: 0.7847 - auc: 0.8648 - val_loss: 0.4670 - val_accuracy: 0.7907 - val_auc: 0.8637\n",
      "Epoch 546/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4562 - accuracy: 0.7824 - auc: 0.8680 - val_loss: 0.4669 - val_accuracy: 0.7831 - val_auc: 0.8637\n",
      "Epoch 547/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4590 - accuracy: 0.7857 - auc: 0.8660 - val_loss: 0.4666 - val_accuracy: 0.7892 - val_auc: 0.8638\n",
      "Epoch 548/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4579 - accuracy: 0.7923 - auc: 0.8669 - val_loss: 0.4673 - val_accuracy: 0.7877 - val_auc: 0.8633\n",
      "Epoch 549/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4496 - accuracy: 0.7932 - auc: 0.8749 - val_loss: 0.4666 - val_accuracy: 0.7846 - val_auc: 0.8639\n",
      "Epoch 550/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4571 - accuracy: 0.7876 - auc: 0.8680 - val_loss: 0.4666 - val_accuracy: 0.7907 - val_auc: 0.8640\n",
      "Epoch 551/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4545 - accuracy: 0.7824 - auc: 0.8706 - val_loss: 0.4660 - val_accuracy: 0.7907 - val_auc: 0.8641\n",
      "Epoch 552/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4585 - accuracy: 0.7885 - auc: 0.8674 - val_loss: 0.4660 - val_accuracy: 0.7922 - val_auc: 0.8641\n",
      "Epoch 553/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4535 - accuracy: 0.7866 - auc: 0.8696 - val_loss: 0.4653 - val_accuracy: 0.7937 - val_auc: 0.8648\n",
      "Epoch 554/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4600 - accuracy: 0.7814 - auc: 0.8661 - val_loss: 0.4648 - val_accuracy: 0.7922 - val_auc: 0.8658\n",
      "Epoch 555/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4605 - accuracy: 0.7814 - auc: 0.8648 - val_loss: 0.4650 - val_accuracy: 0.7922 - val_auc: 0.8651\n",
      "Epoch 556/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4600 - accuracy: 0.7843 - auc: 0.8668 - val_loss: 0.4652 - val_accuracy: 0.7922 - val_auc: 0.8650\n",
      "Epoch 557/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4559 - accuracy: 0.7829 - auc: 0.8689 - val_loss: 0.4653 - val_accuracy: 0.7937 - val_auc: 0.8650\n",
      "Epoch 558/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4530 - accuracy: 0.7890 - auc: 0.8713 - val_loss: 0.4646 - val_accuracy: 0.7831 - val_auc: 0.8654\n",
      "Epoch 559/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4538 - accuracy: 0.7979 - auc: 0.8699 - val_loss: 0.4643 - val_accuracy: 0.7877 - val_auc: 0.8656\n",
      "Epoch 560/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.4550 - accuracy: 0.7838 - auc: 0.8688 - val_loss: 0.4637 - val_accuracy: 0.7922 - val_auc: 0.8661\n",
      "Epoch 561/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4599 - accuracy: 0.7843 - auc: 0.8650 - val_loss: 0.4630 - val_accuracy: 0.7937 - val_auc: 0.8667\n",
      "Epoch 562/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4533 - accuracy: 0.7810 - auc: 0.8704 - val_loss: 0.4647 - val_accuracy: 0.7892 - val_auc: 0.8653\n",
      "Epoch 563/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4569 - accuracy: 0.7862 - auc: 0.8673 - val_loss: 0.4641 - val_accuracy: 0.7922 - val_auc: 0.8656\n",
      "Epoch 564/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4598 - accuracy: 0.7862 - auc: 0.8650 - val_loss: 0.4626 - val_accuracy: 0.7937 - val_auc: 0.8669\n",
      "Epoch 565/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4503 - accuracy: 0.7791 - auc: 0.8718 - val_loss: 0.4624 - val_accuracy: 0.7967 - val_auc: 0.8675\n",
      "Epoch 566/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4576 - accuracy: 0.7814 - auc: 0.8676 - val_loss: 0.4630 - val_accuracy: 0.7997 - val_auc: 0.8672\n",
      "Epoch 567/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4608 - accuracy: 0.7744 - auc: 0.8647 - val_loss: 0.4637 - val_accuracy: 0.7937 - val_auc: 0.8661\n",
      "Epoch 568/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4494 - accuracy: 0.7951 - auc: 0.8743 - val_loss: 0.4638 - val_accuracy: 0.7907 - val_auc: 0.8659\n",
      "Epoch 569/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4568 - accuracy: 0.7838 - auc: 0.8689 - val_loss: 0.4641 - val_accuracy: 0.7907 - val_auc: 0.8655\n",
      "Epoch 570/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4587 - accuracy: 0.7767 - auc: 0.8660 - val_loss: 0.4665 - val_accuracy: 0.7861 - val_auc: 0.8638\n",
      "Epoch 571/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4565 - accuracy: 0.7772 - auc: 0.8669 - val_loss: 0.4665 - val_accuracy: 0.7877 - val_auc: 0.8640\n",
      "Epoch 572/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4650 - accuracy: 0.7805 - auc: 0.8627 - val_loss: 0.4640 - val_accuracy: 0.7922 - val_auc: 0.8661\n",
      "Epoch 573/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4636 - accuracy: 0.7876 - auc: 0.8634 - val_loss: 0.4639 - val_accuracy: 0.7922 - val_auc: 0.8662\n",
      "Epoch 574/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4516 - accuracy: 0.7927 - auc: 0.8722 - val_loss: 0.4637 - val_accuracy: 0.7937 - val_auc: 0.8662\n",
      "Epoch 575/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4491 - accuracy: 0.7975 - auc: 0.8736 - val_loss: 0.4637 - val_accuracy: 0.7907 - val_auc: 0.8663\n",
      "Epoch 576/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.4605 - accuracy: 0.7843 - auc: 0.8656 - val_loss: 0.4623 - val_accuracy: 0.7907 - val_auc: 0.8670\n",
      "Epoch 577/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4532 - accuracy: 0.7862 - auc: 0.8706 - val_loss: 0.4629 - val_accuracy: 0.7892 - val_auc: 0.8666\n",
      "Epoch 578/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4522 - accuracy: 0.7866 - auc: 0.8710 - val_loss: 0.4626 - val_accuracy: 0.7907 - val_auc: 0.8672\n",
      "Epoch 579/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4590 - accuracy: 0.7862 - auc: 0.8673 - val_loss: 0.4632 - val_accuracy: 0.7892 - val_auc: 0.8665\n",
      "Epoch 580/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4552 - accuracy: 0.7838 - auc: 0.8694 - val_loss: 0.4629 - val_accuracy: 0.7892 - val_auc: 0.8668\n",
      "Epoch 581/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4533 - accuracy: 0.7993 - auc: 0.8715 - val_loss: 0.4622 - val_accuracy: 0.7922 - val_auc: 0.8673\n",
      "Epoch 582/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4548 - accuracy: 0.7819 - auc: 0.8694 - val_loss: 0.4620 - val_accuracy: 0.7982 - val_auc: 0.8676\n",
      "Epoch 583/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4539 - accuracy: 0.7909 - auc: 0.8706 - val_loss: 0.4623 - val_accuracy: 0.7922 - val_auc: 0.8669\n",
      "Epoch 584/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4546 - accuracy: 0.7871 - auc: 0.8699 - val_loss: 0.4625 - val_accuracy: 0.7846 - val_auc: 0.8668\n",
      "Epoch 585/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4543 - accuracy: 0.7772 - auc: 0.8689 - val_loss: 0.4625 - val_accuracy: 0.7877 - val_auc: 0.8670\n",
      "Epoch 586/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4544 - accuracy: 0.7814 - auc: 0.8693 - val_loss: 0.4631 - val_accuracy: 0.7907 - val_auc: 0.8667\n",
      "Epoch 587/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4541 - accuracy: 0.7824 - auc: 0.8702 - val_loss: 0.4625 - val_accuracy: 0.7861 - val_auc: 0.8669\n",
      "Epoch 588/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4548 - accuracy: 0.7871 - auc: 0.8699 - val_loss: 0.4613 - val_accuracy: 0.7922 - val_auc: 0.8677\n",
      "Epoch 589/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4600 - accuracy: 0.7810 - auc: 0.8651 - val_loss: 0.4625 - val_accuracy: 0.7922 - val_auc: 0.8669\n",
      "Epoch 590/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4595 - accuracy: 0.7899 - auc: 0.8679 - val_loss: 0.4629 - val_accuracy: 0.7892 - val_auc: 0.8661\n",
      "Epoch 591/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4525 - accuracy: 0.7847 - auc: 0.8704 - val_loss: 0.4621 - val_accuracy: 0.7937 - val_auc: 0.8671\n",
      "Epoch 592/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4485 - accuracy: 0.7970 - auc: 0.8745 - val_loss: 0.4609 - val_accuracy: 0.7922 - val_auc: 0.8680\n",
      "Epoch 593/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4528 - accuracy: 0.7805 - auc: 0.8715 - val_loss: 0.4604 - val_accuracy: 0.7937 - val_auc: 0.8685\n",
      "Epoch 594/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4502 - accuracy: 0.7843 - auc: 0.8727 - val_loss: 0.4590 - val_accuracy: 0.7967 - val_auc: 0.8697\n",
      "Epoch 595/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4551 - accuracy: 0.7885 - auc: 0.8695 - val_loss: 0.4594 - val_accuracy: 0.7982 - val_auc: 0.8698\n",
      "Epoch 596/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4525 - accuracy: 0.7880 - auc: 0.8717 - val_loss: 0.4598 - val_accuracy: 0.7952 - val_auc: 0.8691\n",
      "Epoch 597/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4457 - accuracy: 0.7876 - auc: 0.8749 - val_loss: 0.4589 - val_accuracy: 0.7952 - val_auc: 0.8699\n",
      "Epoch 598/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4485 - accuracy: 0.7927 - auc: 0.8733 - val_loss: 0.4588 - val_accuracy: 0.7952 - val_auc: 0.8699\n",
      "Epoch 599/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4528 - accuracy: 0.7946 - auc: 0.8708 - val_loss: 0.4596 - val_accuracy: 0.7937 - val_auc: 0.8693\n",
      "Epoch 600/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4527 - accuracy: 0.7923 - auc: 0.8720 - val_loss: 0.4580 - val_accuracy: 0.7952 - val_auc: 0.8702\n",
      "Epoch 601/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4513 - accuracy: 0.7857 - auc: 0.8711 - val_loss: 0.4587 - val_accuracy: 0.7967 - val_auc: 0.8697\n",
      "Epoch 602/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4471 - accuracy: 0.7918 - auc: 0.8741 - val_loss: 0.4607 - val_accuracy: 0.7952 - val_auc: 0.8681\n",
      "Epoch 603/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4620 - accuracy: 0.7777 - auc: 0.8645 - val_loss: 0.4609 - val_accuracy: 0.7861 - val_auc: 0.8676\n",
      "Epoch 604/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4524 - accuracy: 0.7885 - auc: 0.8706 - val_loss: 0.4610 - val_accuracy: 0.7937 - val_auc: 0.8674\n",
      "Epoch 605/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4548 - accuracy: 0.7904 - auc: 0.8696 - val_loss: 0.4602 - val_accuracy: 0.7937 - val_auc: 0.8682\n",
      "Epoch 606/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4499 - accuracy: 0.7946 - auc: 0.8732 - val_loss: 0.4613 - val_accuracy: 0.7952 - val_auc: 0.8674\n",
      "Epoch 607/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4450 - accuracy: 0.7909 - auc: 0.8753 - val_loss: 0.4605 - val_accuracy: 0.7937 - val_auc: 0.8681\n",
      "Epoch 608/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4556 - accuracy: 0.7904 - auc: 0.8687 - val_loss: 0.4609 - val_accuracy: 0.7952 - val_auc: 0.8678\n",
      "Epoch 609/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4498 - accuracy: 0.7918 - auc: 0.8727 - val_loss: 0.4611 - val_accuracy: 0.7952 - val_auc: 0.8678\n",
      "Epoch 610/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4432 - accuracy: 0.7960 - auc: 0.8774 - val_loss: 0.4588 - val_accuracy: 0.7937 - val_auc: 0.8693\n",
      "Epoch 611/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4498 - accuracy: 0.7894 - auc: 0.8733 - val_loss: 0.4598 - val_accuracy: 0.7967 - val_auc: 0.8686\n",
      "Epoch 612/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4524 - accuracy: 0.7942 - auc: 0.8705 - val_loss: 0.4602 - val_accuracy: 0.7967 - val_auc: 0.8683\n",
      "Epoch 613/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4534 - accuracy: 0.7937 - auc: 0.8710 - val_loss: 0.4597 - val_accuracy: 0.7952 - val_auc: 0.8688\n",
      "Epoch 614/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4500 - accuracy: 0.7904 - auc: 0.8741 - val_loss: 0.4600 - val_accuracy: 0.7937 - val_auc: 0.8685\n",
      "Epoch 615/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4522 - accuracy: 0.7838 - auc: 0.8703 - val_loss: 0.4606 - val_accuracy: 0.7922 - val_auc: 0.8679\n",
      "Epoch 616/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4449 - accuracy: 0.7946 - auc: 0.8767 - val_loss: 0.4592 - val_accuracy: 0.7922 - val_auc: 0.8691\n",
      "Epoch 617/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4537 - accuracy: 0.7819 - auc: 0.8707 - val_loss: 0.4610 - val_accuracy: 0.7937 - val_auc: 0.8678\n",
      "Epoch 618/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4554 - accuracy: 0.7824 - auc: 0.8689 - val_loss: 0.4597 - val_accuracy: 0.7877 - val_auc: 0.8683\n",
      "Epoch 619/700\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4524 - accuracy: 0.7885 - auc: 0.8710 - val_loss: 0.4589 - val_accuracy: 0.7982 - val_auc: 0.8695\n",
      "Epoch 620/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4579 - accuracy: 0.7838 - auc: 0.8673 - val_loss: 0.4610 - val_accuracy: 0.7922 - val_auc: 0.8675\n",
      "Epoch 621/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4539 - accuracy: 0.7824 - auc: 0.8689 - val_loss: 0.4603 - val_accuracy: 0.7922 - val_auc: 0.8684\n",
      "Epoch 622/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4553 - accuracy: 0.7862 - auc: 0.8699 - val_loss: 0.4604 - val_accuracy: 0.7922 - val_auc: 0.8684\n",
      "Epoch 623/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4512 - accuracy: 0.7814 - auc: 0.8721 - val_loss: 0.4598 - val_accuracy: 0.7922 - val_auc: 0.8689\n",
      "Epoch 624/700\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4465 - accuracy: 0.7918 - auc: 0.8759 - val_loss: 0.4595 - val_accuracy: 0.7982 - val_auc: 0.8692\n",
      "Epoch 625/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4493 - accuracy: 0.7909 - auc: 0.8721 - val_loss: 0.4585 - val_accuracy: 0.7937 - val_auc: 0.8698\n",
      "Epoch 626/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4528 - accuracy: 0.7904 - auc: 0.8692 - val_loss: 0.4587 - val_accuracy: 0.7922 - val_auc: 0.8696\n",
      "Epoch 627/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4550 - accuracy: 0.7852 - auc: 0.8683 - val_loss: 0.4587 - val_accuracy: 0.7937 - val_auc: 0.8697\n",
      "Epoch 628/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4565 - accuracy: 0.7890 - auc: 0.8690 - val_loss: 0.4606 - val_accuracy: 0.7937 - val_auc: 0.8678\n",
      "Epoch 629/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4474 - accuracy: 0.7951 - auc: 0.8738 - val_loss: 0.4609 - val_accuracy: 0.7937 - val_auc: 0.8682\n",
      "Epoch 630/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4456 - accuracy: 0.7876 - auc: 0.8760 - val_loss: 0.4598 - val_accuracy: 0.7952 - val_auc: 0.8692\n",
      "Epoch 00630: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('disgust_ravdess_meld.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1596291715344,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1302,
     "status": "ok",
     "timestamp": 1596291722104,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "b077a3f1-3c2c-4a28-8129-53ece44fcce7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.4579940736293793\n",
      "accuracy :  0.7951807379722595\n",
      "auc :  0.8702449202537537\n",
      "\n",
      "(True Negatives):  310\n",
      "(False Positives):  100\n",
      "(False Negatives):  36\n",
      "(True Positives):  218\n",
      "Total emotions_happy:  254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82       410\n",
      "           1       0.69      0.86      0.76       254\n",
      "\n",
      "    accuracy                           0.80       664\n",
      "   macro avg       0.79      0.81      0.79       664\n",
      "weighted avg       0.82      0.80      0.80       664\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('disgust_ravdess_meld.hdf5')\n",
    "test_predictions_baseline = model.predict(X_test)\n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 978,
     "status": "ok",
     "timestamp": 1596291733532,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "cda98f2f-37d9-4102-9391-8e02fb95feeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.44723138213157654\n",
      "accuracy :  0.7853107452392578\n",
      "auc :  0.8755253553390503\n",
      "\n",
      "(True Negatives):  249\n",
      "(False Positives):  76\n",
      "(False Negatives):  38\n",
      "(True Positives):  168\n",
      "Total emotions_happy:  206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.81       325\n",
      "           1       0.69      0.82      0.75       206\n",
      "\n",
      "    accuracy                           0.79       531\n",
      "   macro avg       0.78      0.79      0.78       531\n",
      "weighted avg       0.80      0.79      0.79       531\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_predictions_baseline = model.predict(X_val)\n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAKtOXEuRIxDJU6f0otKTA",
   "name": "deep_disgust_RAVDESS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
