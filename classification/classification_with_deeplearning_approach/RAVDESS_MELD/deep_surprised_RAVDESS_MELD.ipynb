{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "#Deep learning\n",
    "\n",
    "### Plot imports ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns \n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19708,
     "status": "ok",
     "timestamp": 1596308455350,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "4afc1758-6e96-40aa-ce2e-b3fc75fd42b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad/sad_03-01-04-01-02-01-08_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust/disgust_03-01-07-02-01-02-08_norm_outN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy/happy_03-01-03-01-02-02-23_norm_outNoise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral/neutral_dia88_utt5_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral/neutral_dia41_utt2_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio label\n",
       "0     sad/sad_03-01-04-01-02-01-08_norm_outNoise.wav     0\n",
       "1  disgust/disgust_03-01-07-02-01-02-08_norm_outN...     0\n",
       "2  happy/happy_03-01-03-01-02-02-23_norm_outNoise...     0\n",
       "3       neutral/neutral_dia88_utt5_norm_outNoise.wav     0\n",
       "4       neutral/neutral_dia41_utt2_norm_outNoise.wav     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"ravdess_meld\" #audio data folder\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i.startswith(\"suprised\"): ##this specifies that we class surprised emotion against the others\n",
    "                                    #the files corresponding to each emotion started by the name of the emotion\n",
    "                                    # for example for the emotion \"happy\" , it will be (if i.startswith(\"happy\"))\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) # adding values to the defined df:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1596308479731,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "2db63738-17e4-4b4a-9219-0320a4a980fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1959\n",
      "1     329\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1596308546467,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 981,
     "status": "ok",
     "timestamp": 1596308621508,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "AjNAMwsfG2C8"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    fs, sig = scipy.io.wavfile.read(audio_path) \n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    spec =  fram_window(audio_path) \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)\n",
    "            \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "               \n",
    "    #gfccs = gfcc(sig= spec, fs=fs, num_ceps=13)    \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    #features.append(np.mean(gfccs))\n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5334197,
     "status": "ok",
     "timestamp": 1596314269972,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(parent_dir+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1648,
     "status": "ok",
     "timestamp": 1596314317866,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "8aa42921-745a-40da-b24d-620f5c532989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1465,
     "status": "ok",
     "timestamp": 1596314321442,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1246,
     "status": "ok",
     "timestamp": 1596314329144,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1664,
     "status": "ok",
     "timestamp": 1596314336270,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "f25bb6a3-8cd5-4e60-99aa-e705530365e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 1129\n",
      "After OverSampling, counts of label '0': 1959\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \" [1, 2, 3, 4, 5, 11, 12, 13, 14]  \" are deleted 512 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57142,
     "status": "ok",
     "timestamp": 1596314415231,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "619a8d68-3d1f-473e-b1f6-671b1521d0d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4, 5, 12, 13, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 12, 13, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2, 3, 4, 11, 13, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 12, 13, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 2, 3, 4, 11, 13, 14]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration                        X_removed\n",
       "0         1      [1, 2, 3, 4, 5, 12, 13, 14]\n",
       "1         2  [1, 2, 3, 4, 5, 11, 12, 13, 14]\n",
       "2         3         [1, 2, 3, 4, 11, 13, 14]\n",
       "3         4  [1, 2, 3, 4, 5, 11, 12, 13, 14]\n",
       "4         5         [1, 2, 3, 4, 11, 13, 14]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 11, 12, 13, 14]    512\n",
       "[1, 2, 3, 4, 11, 12, 13, 14]       247\n",
       "[1, 2, 3, 4, 5, 12, 13, 14]         64\n",
       "[1, 2, 3, 4, 5, 11, 13, 14]         57\n",
       "[1, 2, 3, 4, 11, 13, 14]            52\n",
       "[1, 2, 3, 4, 5, 13, 14]             26\n",
       "[1, 2, 3, 4, 12, 13, 14]            22\n",
       "[1, 2, 3, 4, 13, 14]                19\n",
       "[1, 2, 3, 5, 11, 12, 13, 14]         1\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3461,
     "status": "ok",
     "timestamp": 1596314480797,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6sTQj5wDWdev"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0],  X[i][6] , X[i][7],  X[i][8],\n",
    "             X[i][9] , X[i][10],  X[i][15], X[i][16], X[i][17], \n",
    "                X[i][18], X[i][19], X[i][20], X[i][21]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2005,
     "status": "ok",
     "timestamp": 1596314647303,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "feee06eb-8d06-4eb1-efe5-8d9a321d2693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1976\n",
      "618\n",
      "494\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1596314726468,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2350,
     "status": "ok",
     "timestamp": 1596314740171,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "33fc25b2-c58f-4d1e-91b7-c2ed478a5c47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1976, 13, 1)\n",
      "(618, 13, 1)\n",
      "(494, 13, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1596314856766,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "bc5195e7-41d7-4789-c93e-6bc7ddd66c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1976, 2)\n",
      "(618, 2)\n",
      "(494, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1182,
     "status": "ok",
     "timestamp": 1596314848616,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (13,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1337,
     "status": "ok",
     "timestamp": 1596314866313,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "d7de96a6-6c93-44cf-f092-cac93b72ed2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 13, 1)]           0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 13, 128)           768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 13, 128)           512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 13, 128)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 13, 128)           0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 13, 128)           82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 3330      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 86,666\n",
      "Trainable params: 86,406\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1371,
     "status": "ok",
     "timestamp": 1596314878097,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 497395,
     "status": "ok",
     "timestamp": 1596315389595,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "0429da14-f03c-4ac9-8552-e80b0f1a685f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.7285 - accuracy: 0.5678 - auc: 0.5936 - val_loss: 0.6796 - val_accuracy: 0.6019 - val_auc: 0.6463\n",
      "Epoch 2/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6989 - accuracy: 0.5977 - auc: 0.6260 - val_loss: 0.6786 - val_accuracy: 0.6197 - val_auc: 0.6578\n",
      "Epoch 3/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6836 - accuracy: 0.5967 - auc: 0.6402 - val_loss: 0.6803 - val_accuracy: 0.6149 - val_auc: 0.6402\n",
      "Epoch 4/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6578 - accuracy: 0.6210 - auc: 0.6665 - val_loss: 0.6822 - val_accuracy: 0.5825 - val_auc: 0.6068\n",
      "Epoch 5/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6710 - accuracy: 0.6240 - auc: 0.6665 - val_loss: 0.6814 - val_accuracy: 0.5793 - val_auc: 0.6031\n",
      "Epoch 6/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6523 - accuracy: 0.6382 - auc: 0.6866 - val_loss: 0.6793 - val_accuracy: 0.5793 - val_auc: 0.6082\n",
      "Epoch 7/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6526 - accuracy: 0.6356 - auc: 0.6824 - val_loss: 0.6790 - val_accuracy: 0.5858 - val_auc: 0.6028\n",
      "Epoch 8/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6469 - accuracy: 0.6473 - auc: 0.6893 - val_loss: 0.6771 - val_accuracy: 0.5939 - val_auc: 0.6058\n",
      "Epoch 9/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6433 - accuracy: 0.6457 - auc: 0.6906 - val_loss: 0.6733 - val_accuracy: 0.5955 - val_auc: 0.6166\n",
      "Epoch 10/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6423 - accuracy: 0.6457 - auc: 0.6940 - val_loss: 0.6693 - val_accuracy: 0.6019 - val_auc: 0.6265\n",
      "Epoch 11/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6449 - accuracy: 0.6366 - auc: 0.6841 - val_loss: 0.6657 - val_accuracy: 0.6052 - val_auc: 0.6344\n",
      "Epoch 12/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6359 - accuracy: 0.6457 - auc: 0.6964 - val_loss: 0.6609 - val_accuracy: 0.6181 - val_auc: 0.6456\n",
      "Epoch 13/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6405 - accuracy: 0.6447 - auc: 0.6941 - val_loss: 0.6554 - val_accuracy: 0.6230 - val_auc: 0.6554\n",
      "Epoch 14/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6393 - accuracy: 0.6518 - auc: 0.6962 - val_loss: 0.6522 - val_accuracy: 0.6214 - val_auc: 0.6610\n",
      "Epoch 15/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6337 - accuracy: 0.6463 - auc: 0.6969 - val_loss: 0.6503 - val_accuracy: 0.6197 - val_auc: 0.6657\n",
      "Epoch 16/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6383 - accuracy: 0.6544 - auc: 0.6977 - val_loss: 0.6458 - val_accuracy: 0.6246 - val_auc: 0.6732\n",
      "Epoch 17/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6285 - accuracy: 0.6513 - auc: 0.7043 - val_loss: 0.6422 - val_accuracy: 0.6359 - val_auc: 0.6796\n",
      "Epoch 18/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6268 - accuracy: 0.6660 - auc: 0.7074 - val_loss: 0.6400 - val_accuracy: 0.6311 - val_auc: 0.6824\n",
      "Epoch 19/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6239 - accuracy: 0.6549 - auc: 0.7109 - val_loss: 0.6403 - val_accuracy: 0.6392 - val_auc: 0.6840\n",
      "Epoch 20/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6288 - accuracy: 0.6538 - auc: 0.7083 - val_loss: 0.6371 - val_accuracy: 0.6392 - val_auc: 0.6875\n",
      "Epoch 21/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6342 - accuracy: 0.6402 - auc: 0.6981 - val_loss: 0.6370 - val_accuracy: 0.6375 - val_auc: 0.6888\n",
      "Epoch 22/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6267 - accuracy: 0.6554 - auc: 0.7101 - val_loss: 0.6352 - val_accuracy: 0.6375 - val_auc: 0.6911\n",
      "Epoch 23/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6271 - accuracy: 0.6579 - auc: 0.7103 - val_loss: 0.6348 - val_accuracy: 0.6440 - val_auc: 0.6914\n",
      "Epoch 24/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6277 - accuracy: 0.6574 - auc: 0.7073 - val_loss: 0.6340 - val_accuracy: 0.6456 - val_auc: 0.6927\n",
      "Epoch 25/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6272 - accuracy: 0.6599 - auc: 0.7150 - val_loss: 0.6343 - val_accuracy: 0.6489 - val_auc: 0.6930\n",
      "Epoch 26/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6221 - accuracy: 0.6635 - auc: 0.7116 - val_loss: 0.6350 - val_accuracy: 0.6456 - val_auc: 0.6919\n",
      "Epoch 27/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6338 - accuracy: 0.6493 - auc: 0.7012 - val_loss: 0.6338 - val_accuracy: 0.6489 - val_auc: 0.6937\n",
      "Epoch 28/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6198 - accuracy: 0.6604 - auc: 0.7170 - val_loss: 0.6330 - val_accuracy: 0.6489 - val_auc: 0.6945\n",
      "Epoch 29/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6223 - accuracy: 0.6528 - auc: 0.7123 - val_loss: 0.6324 - val_accuracy: 0.6489 - val_auc: 0.6952\n",
      "Epoch 30/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6224 - accuracy: 0.6523 - auc: 0.7114 - val_loss: 0.6322 - val_accuracy: 0.6537 - val_auc: 0.6954\n",
      "Epoch 31/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6181 - accuracy: 0.6609 - auc: 0.7188 - val_loss: 0.6324 - val_accuracy: 0.6521 - val_auc: 0.6957\n",
      "Epoch 32/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6240 - accuracy: 0.6569 - auc: 0.7122 - val_loss: 0.6329 - val_accuracy: 0.6505 - val_auc: 0.6949\n",
      "Epoch 33/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6166 - accuracy: 0.6700 - auc: 0.7183 - val_loss: 0.6328 - val_accuracy: 0.6537 - val_auc: 0.6951\n",
      "Epoch 34/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6185 - accuracy: 0.6579 - auc: 0.7184 - val_loss: 0.6322 - val_accuracy: 0.6537 - val_auc: 0.6960\n",
      "Epoch 35/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6212 - accuracy: 0.6569 - auc: 0.7154 - val_loss: 0.6322 - val_accuracy: 0.6505 - val_auc: 0.6958\n",
      "Epoch 36/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6181 - accuracy: 0.6564 - auc: 0.7153 - val_loss: 0.6313 - val_accuracy: 0.6489 - val_auc: 0.6965\n",
      "Epoch 37/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6202 - accuracy: 0.6604 - auc: 0.7135 - val_loss: 0.6328 - val_accuracy: 0.6472 - val_auc: 0.6952\n",
      "Epoch 38/700\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6172 - accuracy: 0.6635 - auc: 0.7194 - val_loss: 0.6339 - val_accuracy: 0.6505 - val_auc: 0.6945\n",
      "Epoch 39/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6194 - accuracy: 0.6574 - auc: 0.7157 - val_loss: 0.6320 - val_accuracy: 0.6553 - val_auc: 0.6956\n",
      "Epoch 40/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6177 - accuracy: 0.6604 - auc: 0.7196 - val_loss: 0.6315 - val_accuracy: 0.6553 - val_auc: 0.6965\n",
      "Epoch 41/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6149 - accuracy: 0.6746 - auc: 0.7207 - val_loss: 0.6325 - val_accuracy: 0.6505 - val_auc: 0.6955\n",
      "Epoch 42/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6186 - accuracy: 0.6559 - auc: 0.7197 - val_loss: 0.6319 - val_accuracy: 0.6521 - val_auc: 0.6956\n",
      "Epoch 43/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6239 - accuracy: 0.6463 - auc: 0.7097 - val_loss: 0.6305 - val_accuracy: 0.6537 - val_auc: 0.6978\n",
      "Epoch 44/700\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6106 - accuracy: 0.6700 - auc: 0.7306 - val_loss: 0.6317 - val_accuracy: 0.6505 - val_auc: 0.6965\n",
      "Epoch 45/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6207 - accuracy: 0.6675 - auc: 0.7186 - val_loss: 0.6308 - val_accuracy: 0.6570 - val_auc: 0.6984\n",
      "Epoch 46/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6144 - accuracy: 0.6589 - auc: 0.7225 - val_loss: 0.6324 - val_accuracy: 0.6505 - val_auc: 0.6971\n",
      "Epoch 47/700\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6154 - accuracy: 0.6700 - auc: 0.7227 - val_loss: 0.6307 - val_accuracy: 0.6521 - val_auc: 0.6979\n",
      "Epoch 48/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6190 - accuracy: 0.6640 - auc: 0.7189 - val_loss: 0.6301 - val_accuracy: 0.6521 - val_auc: 0.6985\n",
      "Epoch 49/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6187 - accuracy: 0.6554 - auc: 0.7158 - val_loss: 0.6307 - val_accuracy: 0.6505 - val_auc: 0.6977\n",
      "Epoch 50/700\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6178 - accuracy: 0.6660 - auc: 0.7204 - val_loss: 0.6301 - val_accuracy: 0.6505 - val_auc: 0.6983\n",
      "Epoch 51/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6102 - accuracy: 0.6705 - auc: 0.7275 - val_loss: 0.6304 - val_accuracy: 0.6472 - val_auc: 0.6978\n",
      "Epoch 52/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6136 - accuracy: 0.6700 - auc: 0.7245 - val_loss: 0.6311 - val_accuracy: 0.6456 - val_auc: 0.6973\n",
      "Epoch 53/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6167 - accuracy: 0.6655 - auc: 0.7208 - val_loss: 0.6304 - val_accuracy: 0.6472 - val_auc: 0.6979\n",
      "Epoch 54/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6106 - accuracy: 0.6721 - auc: 0.7278 - val_loss: 0.6294 - val_accuracy: 0.6472 - val_auc: 0.6988\n",
      "Epoch 55/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6156 - accuracy: 0.6685 - auc: 0.7244 - val_loss: 0.6305 - val_accuracy: 0.6489 - val_auc: 0.6978\n",
      "Epoch 56/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6061 - accuracy: 0.6675 - auc: 0.7340 - val_loss: 0.6299 - val_accuracy: 0.6505 - val_auc: 0.6989\n",
      "Epoch 57/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6126 - accuracy: 0.6731 - auc: 0.7254 - val_loss: 0.6293 - val_accuracy: 0.6505 - val_auc: 0.6994\n",
      "Epoch 58/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6061 - accuracy: 0.6761 - auc: 0.7324 - val_loss: 0.6302 - val_accuracy: 0.6472 - val_auc: 0.6984\n",
      "Epoch 59/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6100 - accuracy: 0.6827 - auc: 0.7320 - val_loss: 0.6309 - val_accuracy: 0.6505 - val_auc: 0.6983\n",
      "Epoch 60/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6072 - accuracy: 0.6685 - auc: 0.7312 - val_loss: 0.6297 - val_accuracy: 0.6505 - val_auc: 0.6994\n",
      "Epoch 61/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6249 - accuracy: 0.6538 - auc: 0.7110 - val_loss: 0.6302 - val_accuracy: 0.6489 - val_auc: 0.6987\n",
      "Epoch 62/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6076 - accuracy: 0.6746 - auc: 0.7312 - val_loss: 0.6287 - val_accuracy: 0.6505 - val_auc: 0.7002\n",
      "Epoch 63/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6102 - accuracy: 0.6721 - auc: 0.7288 - val_loss: 0.6298 - val_accuracy: 0.6440 - val_auc: 0.6995\n",
      "Epoch 64/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6049 - accuracy: 0.6716 - auc: 0.7329 - val_loss: 0.6304 - val_accuracy: 0.6440 - val_auc: 0.6994\n",
      "Epoch 65/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6103 - accuracy: 0.6716 - auc: 0.7299 - val_loss: 0.6286 - val_accuracy: 0.6521 - val_auc: 0.6997\n",
      "Epoch 66/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6103 - accuracy: 0.6619 - auc: 0.7276 - val_loss: 0.6284 - val_accuracy: 0.6521 - val_auc: 0.7005\n",
      "Epoch 67/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6079 - accuracy: 0.6604 - auc: 0.7306 - val_loss: 0.6284 - val_accuracy: 0.6505 - val_auc: 0.7008\n",
      "Epoch 68/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6117 - accuracy: 0.6665 - auc: 0.7256 - val_loss: 0.6286 - val_accuracy: 0.6521 - val_auc: 0.7000\n",
      "Epoch 69/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6125 - accuracy: 0.6619 - auc: 0.7265 - val_loss: 0.6293 - val_accuracy: 0.6505 - val_auc: 0.6996\n",
      "Epoch 70/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6126 - accuracy: 0.6635 - auc: 0.7251 - val_loss: 0.6295 - val_accuracy: 0.6472 - val_auc: 0.7000\n",
      "Epoch 71/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6060 - accuracy: 0.6700 - auc: 0.7339 - val_loss: 0.6287 - val_accuracy: 0.6521 - val_auc: 0.7009\n",
      "Epoch 72/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6071 - accuracy: 0.6665 - auc: 0.7295 - val_loss: 0.6290 - val_accuracy: 0.6472 - val_auc: 0.7007\n",
      "Epoch 73/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6093 - accuracy: 0.6726 - auc: 0.7308 - val_loss: 0.6286 - val_accuracy: 0.6489 - val_auc: 0.7009\n",
      "Epoch 74/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6068 - accuracy: 0.6721 - auc: 0.7316 - val_loss: 0.6284 - val_accuracy: 0.6489 - val_auc: 0.7014\n",
      "Epoch 75/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6044 - accuracy: 0.6695 - auc: 0.7345 - val_loss: 0.6280 - val_accuracy: 0.6505 - val_auc: 0.7021\n",
      "Epoch 76/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6041 - accuracy: 0.6797 - auc: 0.7358 - val_loss: 0.6277 - val_accuracy: 0.6586 - val_auc: 0.7008\n",
      "Epoch 77/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6112 - accuracy: 0.6705 - auc: 0.7281 - val_loss: 0.6273 - val_accuracy: 0.6570 - val_auc: 0.7016\n",
      "Epoch 78/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6120 - accuracy: 0.6731 - auc: 0.7285 - val_loss: 0.6276 - val_accuracy: 0.6537 - val_auc: 0.7020\n",
      "Epoch 79/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6128 - accuracy: 0.6630 - auc: 0.7257 - val_loss: 0.6277 - val_accuracy: 0.6505 - val_auc: 0.7031\n",
      "Epoch 80/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6050 - accuracy: 0.6741 - auc: 0.7354 - val_loss: 0.6267 - val_accuracy: 0.6521 - val_auc: 0.7033\n",
      "Epoch 81/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6100 - accuracy: 0.6705 - auc: 0.7282 - val_loss: 0.6273 - val_accuracy: 0.6521 - val_auc: 0.7026\n",
      "Epoch 82/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6080 - accuracy: 0.6807 - auc: 0.7323 - val_loss: 0.6289 - val_accuracy: 0.6489 - val_auc: 0.7021\n",
      "Epoch 83/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6051 - accuracy: 0.6726 - auc: 0.7347 - val_loss: 0.6272 - val_accuracy: 0.6537 - val_auc: 0.7029\n",
      "Epoch 84/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6048 - accuracy: 0.6791 - auc: 0.7365 - val_loss: 0.6268 - val_accuracy: 0.6537 - val_auc: 0.7043\n",
      "Epoch 85/700\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.6096 - accuracy: 0.6736 - auc: 0.7295 - val_loss: 0.6265 - val_accuracy: 0.6521 - val_auc: 0.7040\n",
      "Epoch 86/700\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.6050 - accuracy: 0.6756 - auc: 0.7355 - val_loss: 0.6271 - val_accuracy: 0.6537 - val_auc: 0.7042\n",
      "Epoch 87/700\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.6073 - accuracy: 0.6807 - auc: 0.7322 - val_loss: 0.6265 - val_accuracy: 0.6505 - val_auc: 0.7041\n",
      "Epoch 88/700\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.6058 - accuracy: 0.6670 - auc: 0.7342 - val_loss: 0.6254 - val_accuracy: 0.6586 - val_auc: 0.7044\n",
      "Epoch 89/700\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.6041 - accuracy: 0.6630 - auc: 0.7344 - val_loss: 0.6251 - val_accuracy: 0.6553 - val_auc: 0.7052\n",
      "Epoch 90/700\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.6092 - accuracy: 0.6660 - auc: 0.7275 - val_loss: 0.6248 - val_accuracy: 0.6570 - val_auc: 0.7054\n",
      "Epoch 91/700\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.6036 - accuracy: 0.6756 - auc: 0.7356 - val_loss: 0.6245 - val_accuracy: 0.6553 - val_auc: 0.7060\n",
      "Epoch 92/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6092 - accuracy: 0.6731 - auc: 0.7293 - val_loss: 0.6250 - val_accuracy: 0.6505 - val_auc: 0.7062\n",
      "Epoch 93/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6015 - accuracy: 0.6716 - auc: 0.7367 - val_loss: 0.6255 - val_accuracy: 0.6521 - val_auc: 0.7057\n",
      "Epoch 94/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6096 - accuracy: 0.6711 - auc: 0.7281 - val_loss: 0.6254 - val_accuracy: 0.6489 - val_auc: 0.7057\n",
      "Epoch 95/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6081 - accuracy: 0.6731 - auc: 0.7293 - val_loss: 0.6253 - val_accuracy: 0.6537 - val_auc: 0.7049\n",
      "Epoch 96/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6035 - accuracy: 0.6695 - auc: 0.7384 - val_loss: 0.6254 - val_accuracy: 0.6537 - val_auc: 0.7056\n",
      "Epoch 97/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6099 - accuracy: 0.6705 - auc: 0.7285 - val_loss: 0.6249 - val_accuracy: 0.6521 - val_auc: 0.7059\n",
      "Epoch 98/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6005 - accuracy: 0.6731 - auc: 0.7400 - val_loss: 0.6261 - val_accuracy: 0.6553 - val_auc: 0.7047\n",
      "Epoch 99/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6025 - accuracy: 0.6635 - auc: 0.7343 - val_loss: 0.6263 - val_accuracy: 0.6537 - val_auc: 0.7051\n",
      "Epoch 100/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5999 - accuracy: 0.6776 - auc: 0.7404 - val_loss: 0.6256 - val_accuracy: 0.6553 - val_auc: 0.7053\n",
      "Epoch 101/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6034 - accuracy: 0.6761 - auc: 0.7361 - val_loss: 0.6261 - val_accuracy: 0.6505 - val_auc: 0.7051\n",
      "Epoch 102/700\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6074 - accuracy: 0.6776 - auc: 0.7339 - val_loss: 0.6257 - val_accuracy: 0.6537 - val_auc: 0.7059\n",
      "Epoch 103/700\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6046 - accuracy: 0.6665 - auc: 0.7333 - val_loss: 0.6262 - val_accuracy: 0.6521 - val_auc: 0.7052\n",
      "Epoch 104/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6057 - accuracy: 0.6786 - auc: 0.7365 - val_loss: 0.6257 - val_accuracy: 0.6505 - val_auc: 0.7057\n",
      "Epoch 105/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6133 - accuracy: 0.6812 - auc: 0.7289 - val_loss: 0.6254 - val_accuracy: 0.6489 - val_auc: 0.7061\n",
      "Epoch 106/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6067 - accuracy: 0.6665 - auc: 0.7326 - val_loss: 0.6262 - val_accuracy: 0.6521 - val_auc: 0.7051\n",
      "Epoch 107/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6039 - accuracy: 0.6771 - auc: 0.7369 - val_loss: 0.6251 - val_accuracy: 0.6537 - val_auc: 0.7057\n",
      "Epoch 108/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6039 - accuracy: 0.6807 - auc: 0.7381 - val_loss: 0.6255 - val_accuracy: 0.6537 - val_auc: 0.7053\n",
      "Epoch 109/700\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.6052 - accuracy: 0.6756 - auc: 0.7349 - val_loss: 0.6242 - val_accuracy: 0.6537 - val_auc: 0.7066\n",
      "Epoch 110/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5984 - accuracy: 0.6817 - auc: 0.7431 - val_loss: 0.6229 - val_accuracy: 0.6553 - val_auc: 0.7086\n",
      "Epoch 111/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6000 - accuracy: 0.6756 - auc: 0.7394 - val_loss: 0.6242 - val_accuracy: 0.6537 - val_auc: 0.7070\n",
      "Epoch 112/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6047 - accuracy: 0.6878 - auc: 0.7371 - val_loss: 0.6241 - val_accuracy: 0.6537 - val_auc: 0.7072\n",
      "Epoch 113/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6061 - accuracy: 0.6766 - auc: 0.7351 - val_loss: 0.6233 - val_accuracy: 0.6521 - val_auc: 0.7081\n",
      "Epoch 114/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6039 - accuracy: 0.6761 - auc: 0.7360 - val_loss: 0.6234 - val_accuracy: 0.6537 - val_auc: 0.7080\n",
      "Epoch 115/700\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 0.6010 - accuracy: 0.6847 - auc: 0.7405 - val_loss: 0.6228 - val_accuracy: 0.6570 - val_auc: 0.7088\n",
      "Epoch 116/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6039 - accuracy: 0.6756 - auc: 0.7357 - val_loss: 0.6222 - val_accuracy: 0.6553 - val_auc: 0.7100\n",
      "Epoch 117/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6035 - accuracy: 0.6776 - auc: 0.7394 - val_loss: 0.6237 - val_accuracy: 0.6505 - val_auc: 0.7087\n",
      "Epoch 118/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6003 - accuracy: 0.6832 - auc: 0.7413 - val_loss: 0.6233 - val_accuracy: 0.6521 - val_auc: 0.7088\n",
      "Epoch 119/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6018 - accuracy: 0.6695 - auc: 0.7398 - val_loss: 0.6224 - val_accuracy: 0.6618 - val_auc: 0.7101\n",
      "Epoch 120/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5984 - accuracy: 0.6751 - auc: 0.7416 - val_loss: 0.6224 - val_accuracy: 0.6553 - val_auc: 0.7099\n",
      "Epoch 121/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6031 - accuracy: 0.6700 - auc: 0.7352 - val_loss: 0.6235 - val_accuracy: 0.6537 - val_auc: 0.7090\n",
      "Epoch 122/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6019 - accuracy: 0.6786 - auc: 0.7373 - val_loss: 0.6229 - val_accuracy: 0.6553 - val_auc: 0.7093\n",
      "Epoch 123/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6007 - accuracy: 0.6776 - auc: 0.7396 - val_loss: 0.6240 - val_accuracy: 0.6521 - val_auc: 0.7084\n",
      "Epoch 124/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6009 - accuracy: 0.6797 - auc: 0.7410 - val_loss: 0.6231 - val_accuracy: 0.6553 - val_auc: 0.7093\n",
      "Epoch 125/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5990 - accuracy: 0.6761 - auc: 0.7428 - val_loss: 0.6226 - val_accuracy: 0.6553 - val_auc: 0.7094\n",
      "Epoch 126/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6028 - accuracy: 0.6812 - auc: 0.7364 - val_loss: 0.6219 - val_accuracy: 0.6537 - val_auc: 0.7107\n",
      "Epoch 127/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6075 - accuracy: 0.6746 - auc: 0.7316 - val_loss: 0.6237 - val_accuracy: 0.6489 - val_auc: 0.7091\n",
      "Epoch 128/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6064 - accuracy: 0.6630 - auc: 0.7321 - val_loss: 0.6224 - val_accuracy: 0.6537 - val_auc: 0.7102\n",
      "Epoch 129/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6032 - accuracy: 0.6695 - auc: 0.7347 - val_loss: 0.6224 - val_accuracy: 0.6537 - val_auc: 0.7106\n",
      "Epoch 130/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6017 - accuracy: 0.6867 - auc: 0.7404 - val_loss: 0.6225 - val_accuracy: 0.6553 - val_auc: 0.7107\n",
      "Epoch 131/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5996 - accuracy: 0.6741 - auc: 0.7404 - val_loss: 0.6224 - val_accuracy: 0.6537 - val_auc: 0.7109\n",
      "Epoch 132/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5993 - accuracy: 0.6812 - auc: 0.7408 - val_loss: 0.6217 - val_accuracy: 0.6570 - val_auc: 0.7112\n",
      "Epoch 133/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6022 - accuracy: 0.6781 - auc: 0.7391 - val_loss: 0.6217 - val_accuracy: 0.6602 - val_auc: 0.7110\n",
      "Epoch 134/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6035 - accuracy: 0.6731 - auc: 0.7381 - val_loss: 0.6219 - val_accuracy: 0.6586 - val_auc: 0.7109\n",
      "Epoch 135/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5968 - accuracy: 0.6817 - auc: 0.7470 - val_loss: 0.6212 - val_accuracy: 0.6570 - val_auc: 0.7119\n",
      "Epoch 136/700\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 0.5987 - accuracy: 0.6786 - auc: 0.7402 - val_loss: 0.6208 - val_accuracy: 0.6618 - val_auc: 0.7121\n",
      "Epoch 137/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5986 - accuracy: 0.6948 - auc: 0.7456 - val_loss: 0.6206 - val_accuracy: 0.6618 - val_auc: 0.7121\n",
      "Epoch 138/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6004 - accuracy: 0.6802 - auc: 0.7415 - val_loss: 0.6209 - val_accuracy: 0.6553 - val_auc: 0.7125\n",
      "Epoch 139/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6031 - accuracy: 0.6736 - auc: 0.7344 - val_loss: 0.6221 - val_accuracy: 0.6521 - val_auc: 0.7116\n",
      "Epoch 140/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5933 - accuracy: 0.6842 - auc: 0.7480 - val_loss: 0.6220 - val_accuracy: 0.6537 - val_auc: 0.7108\n",
      "Epoch 141/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6010 - accuracy: 0.6751 - auc: 0.7417 - val_loss: 0.6219 - val_accuracy: 0.6553 - val_auc: 0.7111\n",
      "Epoch 142/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6027 - accuracy: 0.6721 - auc: 0.7372 - val_loss: 0.6226 - val_accuracy: 0.6553 - val_auc: 0.7109\n",
      "Epoch 143/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5993 - accuracy: 0.6827 - auc: 0.7446 - val_loss: 0.6222 - val_accuracy: 0.6553 - val_auc: 0.7113\n",
      "Epoch 144/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5966 - accuracy: 0.6751 - auc: 0.7434 - val_loss: 0.6219 - val_accuracy: 0.6570 - val_auc: 0.7112\n",
      "Epoch 145/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6034 - accuracy: 0.6726 - auc: 0.7367 - val_loss: 0.6211 - val_accuracy: 0.6553 - val_auc: 0.7123\n",
      "Epoch 146/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5953 - accuracy: 0.6807 - auc: 0.7454 - val_loss: 0.6216 - val_accuracy: 0.6553 - val_auc: 0.7116\n",
      "Epoch 147/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6032 - accuracy: 0.6822 - auc: 0.7376 - val_loss: 0.6213 - val_accuracy: 0.6537 - val_auc: 0.7122\n",
      "Epoch 148/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5933 - accuracy: 0.6862 - auc: 0.7476 - val_loss: 0.6210 - val_accuracy: 0.6521 - val_auc: 0.7125\n",
      "Epoch 149/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5955 - accuracy: 0.6872 - auc: 0.7473 - val_loss: 0.6210 - val_accuracy: 0.6521 - val_auc: 0.7125\n",
      "Epoch 150/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5974 - accuracy: 0.6791 - auc: 0.7429 - val_loss: 0.6203 - val_accuracy: 0.6521 - val_auc: 0.7128\n",
      "Epoch 151/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5922 - accuracy: 0.6918 - auc: 0.7508 - val_loss: 0.6198 - val_accuracy: 0.6553 - val_auc: 0.7140\n",
      "Epoch 152/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5953 - accuracy: 0.6857 - auc: 0.7486 - val_loss: 0.6213 - val_accuracy: 0.6553 - val_auc: 0.7122\n",
      "Epoch 153/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5997 - accuracy: 0.6781 - auc: 0.7399 - val_loss: 0.6199 - val_accuracy: 0.6553 - val_auc: 0.7137\n",
      "Epoch 154/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6004 - accuracy: 0.6751 - auc: 0.7397 - val_loss: 0.6199 - val_accuracy: 0.6553 - val_auc: 0.7142\n",
      "Epoch 155/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.6004 - accuracy: 0.6807 - auc: 0.7406 - val_loss: 0.6196 - val_accuracy: 0.6537 - val_auc: 0.7142\n",
      "Epoch 156/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5963 - accuracy: 0.6883 - auc: 0.7454 - val_loss: 0.6205 - val_accuracy: 0.6553 - val_auc: 0.7130\n",
      "Epoch 157/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5947 - accuracy: 0.6842 - auc: 0.7497 - val_loss: 0.6194 - val_accuracy: 0.6537 - val_auc: 0.7144\n",
      "Epoch 158/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5988 - accuracy: 0.6791 - auc: 0.7431 - val_loss: 0.6199 - val_accuracy: 0.6553 - val_auc: 0.7137\n",
      "Epoch 159/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5972 - accuracy: 0.6842 - auc: 0.7429 - val_loss: 0.6197 - val_accuracy: 0.6553 - val_auc: 0.7140\n",
      "Epoch 160/700\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 0.5923 - accuracy: 0.6807 - auc: 0.7498 - val_loss: 0.6189 - val_accuracy: 0.6553 - val_auc: 0.7148\n",
      "Epoch 161/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5976 - accuracy: 0.6766 - auc: 0.7451 - val_loss: 0.6201 - val_accuracy: 0.6521 - val_auc: 0.7138\n",
      "Epoch 162/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5965 - accuracy: 0.6857 - auc: 0.7457 - val_loss: 0.6200 - val_accuracy: 0.6553 - val_auc: 0.7136\n",
      "Epoch 163/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5954 - accuracy: 0.6807 - auc: 0.7465 - val_loss: 0.6202 - val_accuracy: 0.6521 - val_auc: 0.7137\n",
      "Epoch 164/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5966 - accuracy: 0.6781 - auc: 0.7462 - val_loss: 0.6199 - val_accuracy: 0.6570 - val_auc: 0.7137\n",
      "Epoch 165/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5929 - accuracy: 0.6842 - auc: 0.7492 - val_loss: 0.6191 - val_accuracy: 0.6553 - val_auc: 0.7148\n",
      "Epoch 166/700\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 0.5985 - accuracy: 0.6771 - auc: 0.7409 - val_loss: 0.6181 - val_accuracy: 0.6553 - val_auc: 0.7167\n",
      "Epoch 167/700\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 0.5934 - accuracy: 0.6817 - auc: 0.7473 - val_loss: 0.6180 - val_accuracy: 0.6570 - val_auc: 0.7164\n",
      "Epoch 168/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6014 - accuracy: 0.6857 - auc: 0.7413 - val_loss: 0.6170 - val_accuracy: 0.6553 - val_auc: 0.7178\n",
      "Epoch 169/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5969 - accuracy: 0.6817 - auc: 0.7444 - val_loss: 0.6182 - val_accuracy: 0.6586 - val_auc: 0.7160\n",
      "Epoch 170/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5923 - accuracy: 0.6771 - auc: 0.7500 - val_loss: 0.6180 - val_accuracy: 0.6553 - val_auc: 0.7165\n",
      "Epoch 171/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5937 - accuracy: 0.6857 - auc: 0.7487 - val_loss: 0.6179 - val_accuracy: 0.6537 - val_auc: 0.7163\n",
      "Epoch 172/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5882 - accuracy: 0.6827 - auc: 0.7518 - val_loss: 0.6184 - val_accuracy: 0.6537 - val_auc: 0.7160\n",
      "Epoch 173/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5909 - accuracy: 0.6776 - auc: 0.7488 - val_loss: 0.6184 - val_accuracy: 0.6521 - val_auc: 0.7159\n",
      "Epoch 174/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5997 - accuracy: 0.6741 - auc: 0.7398 - val_loss: 0.6188 - val_accuracy: 0.6537 - val_auc: 0.7157\n",
      "Epoch 175/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5942 - accuracy: 0.6832 - auc: 0.7476 - val_loss: 0.6180 - val_accuracy: 0.6553 - val_auc: 0.7163\n",
      "Epoch 176/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5953 - accuracy: 0.6903 - auc: 0.7475 - val_loss: 0.6188 - val_accuracy: 0.6553 - val_auc: 0.7159\n",
      "Epoch 177/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5955 - accuracy: 0.6852 - auc: 0.7463 - val_loss: 0.6190 - val_accuracy: 0.6553 - val_auc: 0.7157\n",
      "Epoch 178/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5913 - accuracy: 0.6857 - auc: 0.7528 - val_loss: 0.6191 - val_accuracy: 0.6618 - val_auc: 0.7154\n",
      "Epoch 179/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5917 - accuracy: 0.6847 - auc: 0.7509 - val_loss: 0.6185 - val_accuracy: 0.6537 - val_auc: 0.7160\n",
      "Epoch 180/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5960 - accuracy: 0.6872 - auc: 0.7463 - val_loss: 0.6188 - val_accuracy: 0.6537 - val_auc: 0.7154\n",
      "Epoch 181/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5964 - accuracy: 0.6797 - auc: 0.7450 - val_loss: 0.6188 - val_accuracy: 0.6570 - val_auc: 0.7159\n",
      "Epoch 182/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5937 - accuracy: 0.6862 - auc: 0.7484 - val_loss: 0.6180 - val_accuracy: 0.6586 - val_auc: 0.7165\n",
      "Epoch 183/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5918 - accuracy: 0.6883 - auc: 0.7488 - val_loss: 0.6185 - val_accuracy: 0.6553 - val_auc: 0.7160\n",
      "Epoch 184/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5907 - accuracy: 0.6802 - auc: 0.7520 - val_loss: 0.6179 - val_accuracy: 0.6553 - val_auc: 0.7168\n",
      "Epoch 185/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5935 - accuracy: 0.6862 - auc: 0.7505 - val_loss: 0.6181 - val_accuracy: 0.6537 - val_auc: 0.7167\n",
      "Epoch 186/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5981 - accuracy: 0.6857 - auc: 0.7444 - val_loss: 0.6188 - val_accuracy: 0.6586 - val_auc: 0.7153\n",
      "Epoch 187/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5953 - accuracy: 0.6832 - auc: 0.7460 - val_loss: 0.6184 - val_accuracy: 0.6586 - val_auc: 0.7163\n",
      "Epoch 188/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5926 - accuracy: 0.6898 - auc: 0.7492 - val_loss: 0.6178 - val_accuracy: 0.6586 - val_auc: 0.7165\n",
      "Epoch 189/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5948 - accuracy: 0.6852 - auc: 0.7477 - val_loss: 0.6185 - val_accuracy: 0.6602 - val_auc: 0.7161\n",
      "Epoch 190/700\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.5900 - accuracy: 0.6953 - auc: 0.7515 - val_loss: 0.6167 - val_accuracy: 0.6570 - val_auc: 0.7187\n",
      "Epoch 191/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5904 - accuracy: 0.6938 - auc: 0.7526 - val_loss: 0.6167 - val_accuracy: 0.6602 - val_auc: 0.7183\n",
      "Epoch 192/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5934 - accuracy: 0.6878 - auc: 0.7490 - val_loss: 0.6175 - val_accuracy: 0.6602 - val_auc: 0.7178\n",
      "Epoch 193/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5926 - accuracy: 0.6842 - auc: 0.7496 - val_loss: 0.6157 - val_accuracy: 0.6570 - val_auc: 0.7195\n",
      "Epoch 194/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5921 - accuracy: 0.6847 - auc: 0.7504 - val_loss: 0.6160 - val_accuracy: 0.6618 - val_auc: 0.7194\n",
      "Epoch 195/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5952 - accuracy: 0.6822 - auc: 0.7454 - val_loss: 0.6157 - val_accuracy: 0.6586 - val_auc: 0.7197\n",
      "Epoch 196/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5887 - accuracy: 0.6862 - auc: 0.7531 - val_loss: 0.6166 - val_accuracy: 0.6602 - val_auc: 0.7187\n",
      "Epoch 197/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5932 - accuracy: 0.6883 - auc: 0.7505 - val_loss: 0.6167 - val_accuracy: 0.6602 - val_auc: 0.7187\n",
      "Epoch 198/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5992 - accuracy: 0.6781 - auc: 0.7401 - val_loss: 0.6164 - val_accuracy: 0.6618 - val_auc: 0.7191\n",
      "Epoch 199/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5881 - accuracy: 0.6903 - auc: 0.7545 - val_loss: 0.6167 - val_accuracy: 0.6602 - val_auc: 0.7190\n",
      "Epoch 200/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5889 - accuracy: 0.6812 - auc: 0.7512 - val_loss: 0.6175 - val_accuracy: 0.6602 - val_auc: 0.7176\n",
      "Epoch 201/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5893 - accuracy: 0.6832 - auc: 0.7528 - val_loss: 0.6179 - val_accuracy: 0.6602 - val_auc: 0.7171\n",
      "Epoch 202/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5917 - accuracy: 0.6832 - auc: 0.7499 - val_loss: 0.6164 - val_accuracy: 0.6570 - val_auc: 0.7191\n",
      "Epoch 203/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5899 - accuracy: 0.6928 - auc: 0.7550 - val_loss: 0.6156 - val_accuracy: 0.6602 - val_auc: 0.7201\n",
      "Epoch 204/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5982 - accuracy: 0.6761 - auc: 0.7433 - val_loss: 0.6148 - val_accuracy: 0.6618 - val_auc: 0.7215\n",
      "Epoch 205/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5924 - accuracy: 0.6807 - auc: 0.7493 - val_loss: 0.6151 - val_accuracy: 0.6634 - val_auc: 0.7209\n",
      "Epoch 206/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5969 - accuracy: 0.6797 - auc: 0.7424 - val_loss: 0.6157 - val_accuracy: 0.6586 - val_auc: 0.7201\n",
      "Epoch 207/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5922 - accuracy: 0.6797 - auc: 0.7499 - val_loss: 0.6156 - val_accuracy: 0.6602 - val_auc: 0.7198\n",
      "Epoch 208/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5920 - accuracy: 0.6862 - auc: 0.7501 - val_loss: 0.6158 - val_accuracy: 0.6618 - val_auc: 0.7195\n",
      "Epoch 209/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5891 - accuracy: 0.6883 - auc: 0.7545 - val_loss: 0.6161 - val_accuracy: 0.6602 - val_auc: 0.7193\n",
      "Epoch 210/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5889 - accuracy: 0.6893 - auc: 0.7542 - val_loss: 0.6156 - val_accuracy: 0.6618 - val_auc: 0.7199\n",
      "Epoch 211/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5930 - accuracy: 0.6817 - auc: 0.7514 - val_loss: 0.6155 - val_accuracy: 0.6634 - val_auc: 0.7199\n",
      "Epoch 212/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5914 - accuracy: 0.6852 - auc: 0.7511 - val_loss: 0.6152 - val_accuracy: 0.6618 - val_auc: 0.7201\n",
      "Epoch 213/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5910 - accuracy: 0.6878 - auc: 0.7529 - val_loss: 0.6160 - val_accuracy: 0.6602 - val_auc: 0.7190\n",
      "Epoch 214/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5935 - accuracy: 0.6852 - auc: 0.7487 - val_loss: 0.6159 - val_accuracy: 0.6602 - val_auc: 0.7196\n",
      "Epoch 215/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5885 - accuracy: 0.6938 - auc: 0.7577 - val_loss: 0.6158 - val_accuracy: 0.6602 - val_auc: 0.7196\n",
      "Epoch 216/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5902 - accuracy: 0.6878 - auc: 0.7522 - val_loss: 0.6163 - val_accuracy: 0.6602 - val_auc: 0.7193\n",
      "Epoch 217/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5950 - accuracy: 0.6883 - auc: 0.7475 - val_loss: 0.6158 - val_accuracy: 0.6618 - val_auc: 0.7197\n",
      "Epoch 218/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5932 - accuracy: 0.6918 - auc: 0.7510 - val_loss: 0.6161 - val_accuracy: 0.6602 - val_auc: 0.7193\n",
      "Epoch 219/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5896 - accuracy: 0.6893 - auc: 0.7542 - val_loss: 0.6158 - val_accuracy: 0.6634 - val_auc: 0.7198\n",
      "Epoch 220/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5911 - accuracy: 0.6867 - auc: 0.7506 - val_loss: 0.6153 - val_accuracy: 0.6650 - val_auc: 0.7206\n",
      "Epoch 221/700\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.5891 - accuracy: 0.6898 - auc: 0.7552 - val_loss: 0.6143 - val_accuracy: 0.6634 - val_auc: 0.7218\n",
      "Epoch 222/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5940 - accuracy: 0.6908 - auc: 0.7493 - val_loss: 0.6142 - val_accuracy: 0.6634 - val_auc: 0.7221\n",
      "Epoch 223/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5925 - accuracy: 0.6883 - auc: 0.7519 - val_loss: 0.6141 - val_accuracy: 0.6650 - val_auc: 0.7222\n",
      "Epoch 224/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5912 - accuracy: 0.6903 - auc: 0.7506 - val_loss: 0.6132 - val_accuracy: 0.6667 - val_auc: 0.7232\n",
      "Epoch 225/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5932 - accuracy: 0.6928 - auc: 0.7507 - val_loss: 0.6136 - val_accuracy: 0.6667 - val_auc: 0.7224\n",
      "Epoch 226/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5924 - accuracy: 0.6807 - auc: 0.7500 - val_loss: 0.6137 - val_accuracy: 0.6650 - val_auc: 0.7224\n",
      "Epoch 227/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5934 - accuracy: 0.6923 - auc: 0.7493 - val_loss: 0.6132 - val_accuracy: 0.6667 - val_auc: 0.7231\n",
      "Epoch 228/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5858 - accuracy: 0.6847 - auc: 0.7555 - val_loss: 0.6135 - val_accuracy: 0.6650 - val_auc: 0.7224\n",
      "Epoch 229/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5882 - accuracy: 0.6852 - auc: 0.7547 - val_loss: 0.6141 - val_accuracy: 0.6650 - val_auc: 0.7219\n",
      "Epoch 230/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5855 - accuracy: 0.6812 - auc: 0.7550 - val_loss: 0.6143 - val_accuracy: 0.6650 - val_auc: 0.7216\n",
      "Epoch 231/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5907 - accuracy: 0.6898 - auc: 0.7537 - val_loss: 0.6129 - val_accuracy: 0.6667 - val_auc: 0.7231\n",
      "Epoch 232/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5867 - accuracy: 0.6862 - auc: 0.7555 - val_loss: 0.6138 - val_accuracy: 0.6667 - val_auc: 0.7223\n",
      "Epoch 233/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5868 - accuracy: 0.6862 - auc: 0.7556 - val_loss: 0.6136 - val_accuracy: 0.6683 - val_auc: 0.7225\n",
      "Epoch 234/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5891 - accuracy: 0.6923 - auc: 0.7534 - val_loss: 0.6132 - val_accuracy: 0.6683 - val_auc: 0.7230\n",
      "Epoch 235/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5959 - accuracy: 0.6867 - auc: 0.7468 - val_loss: 0.6126 - val_accuracy: 0.6683 - val_auc: 0.7237\n",
      "Epoch 236/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5927 - accuracy: 0.6893 - auc: 0.7507 - val_loss: 0.6125 - val_accuracy: 0.6683 - val_auc: 0.7237\n",
      "Epoch 237/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5908 - accuracy: 0.6908 - auc: 0.7513 - val_loss: 0.6135 - val_accuracy: 0.6683 - val_auc: 0.7225\n",
      "Epoch 238/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5895 - accuracy: 0.6923 - auc: 0.7535 - val_loss: 0.6135 - val_accuracy: 0.6650 - val_auc: 0.7230\n",
      "Epoch 239/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5878 - accuracy: 0.6867 - auc: 0.7541 - val_loss: 0.6126 - val_accuracy: 0.6683 - val_auc: 0.7240\n",
      "Epoch 240/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5881 - accuracy: 0.6938 - auc: 0.7553 - val_loss: 0.6127 - val_accuracy: 0.6667 - val_auc: 0.7239\n",
      "Epoch 241/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5869 - accuracy: 0.6842 - auc: 0.7545 - val_loss: 0.6126 - val_accuracy: 0.6650 - val_auc: 0.7236\n",
      "Epoch 242/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5848 - accuracy: 0.7014 - auc: 0.7608 - val_loss: 0.6128 - val_accuracy: 0.6650 - val_auc: 0.7236\n",
      "Epoch 243/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5862 - accuracy: 0.6842 - auc: 0.7577 - val_loss: 0.6130 - val_accuracy: 0.6667 - val_auc: 0.7235\n",
      "Epoch 244/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5902 - accuracy: 0.6852 - auc: 0.7516 - val_loss: 0.6129 - val_accuracy: 0.6667 - val_auc: 0.7237\n",
      "Epoch 245/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5904 - accuracy: 0.6872 - auc: 0.7544 - val_loss: 0.6130 - val_accuracy: 0.6667 - val_auc: 0.7236\n",
      "Epoch 246/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5898 - accuracy: 0.6888 - auc: 0.7542 - val_loss: 0.6134 - val_accuracy: 0.6650 - val_auc: 0.7231\n",
      "Epoch 247/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5875 - accuracy: 0.6862 - auc: 0.7555 - val_loss: 0.6132 - val_accuracy: 0.6667 - val_auc: 0.7236\n",
      "Epoch 248/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5865 - accuracy: 0.6969 - auc: 0.7568 - val_loss: 0.6136 - val_accuracy: 0.6634 - val_auc: 0.7229\n",
      "Epoch 249/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5875 - accuracy: 0.6959 - auc: 0.7566 - val_loss: 0.6129 - val_accuracy: 0.6667 - val_auc: 0.7238\n",
      "Epoch 250/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5911 - accuracy: 0.6888 - auc: 0.7485 - val_loss: 0.6123 - val_accuracy: 0.6667 - val_auc: 0.7242\n",
      "Epoch 251/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5914 - accuracy: 0.6943 - auc: 0.7527 - val_loss: 0.6130 - val_accuracy: 0.6683 - val_auc: 0.7238\n",
      "Epoch 252/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5904 - accuracy: 0.6872 - auc: 0.7509 - val_loss: 0.6129 - val_accuracy: 0.6699 - val_auc: 0.7240\n",
      "Epoch 253/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5887 - accuracy: 0.6969 - auc: 0.7551 - val_loss: 0.6126 - val_accuracy: 0.6667 - val_auc: 0.7242\n",
      "Epoch 254/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5876 - accuracy: 0.6827 - auc: 0.7553 - val_loss: 0.6123 - val_accuracy: 0.6683 - val_auc: 0.7247\n",
      "Epoch 255/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5821 - accuracy: 0.6928 - auc: 0.7614 - val_loss: 0.6128 - val_accuracy: 0.6683 - val_auc: 0.7238\n",
      "Epoch 256/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5846 - accuracy: 0.6999 - auc: 0.7602 - val_loss: 0.6121 - val_accuracy: 0.6699 - val_auc: 0.7248\n",
      "Epoch 257/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5838 - accuracy: 0.7045 - auc: 0.7638 - val_loss: 0.6121 - val_accuracy: 0.6667 - val_auc: 0.7244\n",
      "Epoch 258/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5904 - accuracy: 0.6862 - auc: 0.7512 - val_loss: 0.6127 - val_accuracy: 0.6667 - val_auc: 0.7240\n",
      "Epoch 259/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5896 - accuracy: 0.6903 - auc: 0.7531 - val_loss: 0.6120 - val_accuracy: 0.6699 - val_auc: 0.7247\n",
      "Epoch 260/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5841 - accuracy: 0.6959 - auc: 0.7584 - val_loss: 0.6106 - val_accuracy: 0.6731 - val_auc: 0.7265\n",
      "Epoch 261/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5849 - accuracy: 0.6913 - auc: 0.7578 - val_loss: 0.6113 - val_accuracy: 0.6699 - val_auc: 0.7258\n",
      "Epoch 262/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5870 - accuracy: 0.6817 - auc: 0.7542 - val_loss: 0.6105 - val_accuracy: 0.6715 - val_auc: 0.7267\n",
      "Epoch 263/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5873 - accuracy: 0.6847 - auc: 0.7542 - val_loss: 0.6108 - val_accuracy: 0.6715 - val_auc: 0.7265\n",
      "Epoch 264/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5860 - accuracy: 0.6852 - auc: 0.7566 - val_loss: 0.6111 - val_accuracy: 0.6715 - val_auc: 0.7261\n",
      "Epoch 265/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5881 - accuracy: 0.6822 - auc: 0.7540 - val_loss: 0.6104 - val_accuracy: 0.6748 - val_auc: 0.7273\n",
      "Epoch 266/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5842 - accuracy: 0.6898 - auc: 0.7606 - val_loss: 0.6100 - val_accuracy: 0.6748 - val_auc: 0.7279\n",
      "Epoch 267/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5860 - accuracy: 0.7004 - auc: 0.7571 - val_loss: 0.6105 - val_accuracy: 0.6699 - val_auc: 0.7274\n",
      "Epoch 268/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5840 - accuracy: 0.6913 - auc: 0.7603 - val_loss: 0.6106 - val_accuracy: 0.6731 - val_auc: 0.7268\n",
      "Epoch 269/700\n",
      "31/31 [==============================] - 1s 27ms/step - loss: 0.5913 - accuracy: 0.6862 - auc: 0.7508 - val_loss: 0.6106 - val_accuracy: 0.6764 - val_auc: 0.7272\n",
      "Epoch 270/700\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5905 - accuracy: 0.6791 - auc: 0.7517 - val_loss: 0.6119 - val_accuracy: 0.6699 - val_auc: 0.7254\n",
      "Epoch 271/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5853 - accuracy: 0.6959 - auc: 0.7580 - val_loss: 0.6111 - val_accuracy: 0.6731 - val_auc: 0.7265\n",
      "Epoch 272/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5834 - accuracy: 0.6974 - auc: 0.7615 - val_loss: 0.6115 - val_accuracy: 0.6715 - val_auc: 0.7262\n",
      "Epoch 273/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5815 - accuracy: 0.6999 - auc: 0.7621 - val_loss: 0.6114 - val_accuracy: 0.6715 - val_auc: 0.7261\n",
      "Epoch 274/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5853 - accuracy: 0.7009 - auc: 0.7583 - val_loss: 0.6097 - val_accuracy: 0.6764 - val_auc: 0.7286\n",
      "Epoch 275/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5886 - accuracy: 0.6913 - auc: 0.7538 - val_loss: 0.6096 - val_accuracy: 0.6764 - val_auc: 0.7284\n",
      "Epoch 276/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5866 - accuracy: 0.6928 - auc: 0.7584 - val_loss: 0.6103 - val_accuracy: 0.6715 - val_auc: 0.7274\n",
      "Epoch 277/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5886 - accuracy: 0.6903 - auc: 0.7546 - val_loss: 0.6106 - val_accuracy: 0.6715 - val_auc: 0.7269\n",
      "Epoch 278/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5876 - accuracy: 0.6872 - auc: 0.7561 - val_loss: 0.6104 - val_accuracy: 0.6731 - val_auc: 0.7273\n",
      "Epoch 279/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5848 - accuracy: 0.6741 - auc: 0.7583 - val_loss: 0.6102 - val_accuracy: 0.6748 - val_auc: 0.7278\n",
      "Epoch 280/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5853 - accuracy: 0.7034 - auc: 0.7586 - val_loss: 0.6092 - val_accuracy: 0.6748 - val_auc: 0.7288\n",
      "Epoch 281/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5901 - accuracy: 0.6878 - auc: 0.7520 - val_loss: 0.6088 - val_accuracy: 0.6764 - val_auc: 0.7298\n",
      "Epoch 282/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5836 - accuracy: 0.6898 - auc: 0.7586 - val_loss: 0.6087 - val_accuracy: 0.6780 - val_auc: 0.7300\n",
      "Epoch 283/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5902 - accuracy: 0.6918 - auc: 0.7533 - val_loss: 0.6095 - val_accuracy: 0.6731 - val_auc: 0.7289\n",
      "Epoch 284/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5833 - accuracy: 0.6918 - auc: 0.7605 - val_loss: 0.6094 - val_accuracy: 0.6748 - val_auc: 0.7290\n",
      "Epoch 285/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5877 - accuracy: 0.6883 - auc: 0.7529 - val_loss: 0.6093 - val_accuracy: 0.6731 - val_auc: 0.7293\n",
      "Epoch 286/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5844 - accuracy: 0.6878 - auc: 0.7570 - val_loss: 0.6101 - val_accuracy: 0.6731 - val_auc: 0.7280\n",
      "Epoch 287/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5831 - accuracy: 0.6933 - auc: 0.7621 - val_loss: 0.6093 - val_accuracy: 0.6748 - val_auc: 0.7287\n",
      "Epoch 288/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5815 - accuracy: 0.6903 - auc: 0.7610 - val_loss: 0.6087 - val_accuracy: 0.6748 - val_auc: 0.7298\n",
      "Epoch 289/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5853 - accuracy: 0.6933 - auc: 0.7573 - val_loss: 0.6087 - val_accuracy: 0.6764 - val_auc: 0.7296\n",
      "Epoch 290/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5932 - accuracy: 0.6872 - auc: 0.7466 - val_loss: 0.6087 - val_accuracy: 0.6748 - val_auc: 0.7295\n",
      "Epoch 291/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5852 - accuracy: 0.6888 - auc: 0.7571 - val_loss: 0.6084 - val_accuracy: 0.6780 - val_auc: 0.7301\n",
      "Epoch 292/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5899 - accuracy: 0.6842 - auc: 0.7529 - val_loss: 0.6074 - val_accuracy: 0.6764 - val_auc: 0.7317\n",
      "Epoch 293/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5847 - accuracy: 0.7014 - auc: 0.7632 - val_loss: 0.6077 - val_accuracy: 0.6748 - val_auc: 0.7308\n",
      "Epoch 294/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5818 - accuracy: 0.6847 - auc: 0.7616 - val_loss: 0.6083 - val_accuracy: 0.6731 - val_auc: 0.7304\n",
      "Epoch 295/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5878 - accuracy: 0.6948 - auc: 0.7545 - val_loss: 0.6084 - val_accuracy: 0.6748 - val_auc: 0.7302\n",
      "Epoch 296/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5845 - accuracy: 0.7014 - auc: 0.7620 - val_loss: 0.6081 - val_accuracy: 0.6748 - val_auc: 0.7304\n",
      "Epoch 297/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5815 - accuracy: 0.7095 - auc: 0.7632 - val_loss: 0.6085 - val_accuracy: 0.6748 - val_auc: 0.7297\n",
      "Epoch 298/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5853 - accuracy: 0.6908 - auc: 0.7579 - val_loss: 0.6083 - val_accuracy: 0.6731 - val_auc: 0.7299\n",
      "Epoch 299/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5881 - accuracy: 0.6928 - auc: 0.7563 - val_loss: 0.6082 - val_accuracy: 0.6748 - val_auc: 0.7301\n",
      "Epoch 300/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5819 - accuracy: 0.7045 - auc: 0.7648 - val_loss: 0.6075 - val_accuracy: 0.6748 - val_auc: 0.7310\n",
      "Epoch 301/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5813 - accuracy: 0.6979 - auc: 0.7625 - val_loss: 0.6080 - val_accuracy: 0.6731 - val_auc: 0.7305\n",
      "Epoch 302/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5863 - accuracy: 0.6827 - auc: 0.7558 - val_loss: 0.6091 - val_accuracy: 0.6715 - val_auc: 0.7292\n",
      "Epoch 303/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5831 - accuracy: 0.6994 - auc: 0.7586 - val_loss: 0.6082 - val_accuracy: 0.6731 - val_auc: 0.7303\n",
      "Epoch 304/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5835 - accuracy: 0.6938 - auc: 0.7599 - val_loss: 0.6079 - val_accuracy: 0.6764 - val_auc: 0.7306\n",
      "Epoch 305/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5838 - accuracy: 0.6913 - auc: 0.7583 - val_loss: 0.6078 - val_accuracy: 0.6748 - val_auc: 0.7305\n",
      "Epoch 306/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5883 - accuracy: 0.6923 - auc: 0.7552 - val_loss: 0.6079 - val_accuracy: 0.6731 - val_auc: 0.7310\n",
      "Epoch 307/700\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.5865 - accuracy: 0.6872 - auc: 0.7538 - val_loss: 0.6074 - val_accuracy: 0.6780 - val_auc: 0.7316\n",
      "Epoch 308/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5822 - accuracy: 0.6893 - auc: 0.7611 - val_loss: 0.6076 - val_accuracy: 0.6764 - val_auc: 0.7308\n",
      "Epoch 309/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5837 - accuracy: 0.6903 - auc: 0.7592 - val_loss: 0.6081 - val_accuracy: 0.6731 - val_auc: 0.7307\n",
      "Epoch 310/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5868 - accuracy: 0.6842 - auc: 0.7558 - val_loss: 0.6071 - val_accuracy: 0.6796 - val_auc: 0.7317\n",
      "Epoch 311/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5825 - accuracy: 0.7004 - auc: 0.7648 - val_loss: 0.6070 - val_accuracy: 0.6780 - val_auc: 0.7320\n",
      "Epoch 312/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5865 - accuracy: 0.6933 - auc: 0.7564 - val_loss: 0.6065 - val_accuracy: 0.6796 - val_auc: 0.7325\n",
      "Epoch 313/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5830 - accuracy: 0.6938 - auc: 0.7607 - val_loss: 0.6065 - val_accuracy: 0.6796 - val_auc: 0.7324\n",
      "Epoch 314/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5855 - accuracy: 0.6959 - auc: 0.7571 - val_loss: 0.6067 - val_accuracy: 0.6764 - val_auc: 0.7323\n",
      "Epoch 315/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5866 - accuracy: 0.6959 - auc: 0.7560 - val_loss: 0.6062 - val_accuracy: 0.6812 - val_auc: 0.7329\n",
      "Epoch 316/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5768 - accuracy: 0.6964 - auc: 0.7668 - val_loss: 0.6074 - val_accuracy: 0.6764 - val_auc: 0.7315\n",
      "Epoch 317/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5847 - accuracy: 0.6903 - auc: 0.7570 - val_loss: 0.6074 - val_accuracy: 0.6780 - val_auc: 0.7312\n",
      "Epoch 318/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5781 - accuracy: 0.7009 - auc: 0.7666 - val_loss: 0.6079 - val_accuracy: 0.6780 - val_auc: 0.7304\n",
      "Epoch 319/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5791 - accuracy: 0.7065 - auc: 0.7674 - val_loss: 0.6080 - val_accuracy: 0.6764 - val_auc: 0.7304\n",
      "Epoch 320/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5818 - accuracy: 0.7014 - auc: 0.7646 - val_loss: 0.6078 - val_accuracy: 0.6748 - val_auc: 0.7311\n",
      "Epoch 321/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5785 - accuracy: 0.6948 - auc: 0.7663 - val_loss: 0.6082 - val_accuracy: 0.6764 - val_auc: 0.7308\n",
      "Epoch 322/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5816 - accuracy: 0.6893 - auc: 0.7633 - val_loss: 0.6093 - val_accuracy: 0.6780 - val_auc: 0.7295\n",
      "Epoch 323/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5803 - accuracy: 0.6913 - auc: 0.7634 - val_loss: 0.6072 - val_accuracy: 0.6780 - val_auc: 0.7317\n",
      "Epoch 324/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5793 - accuracy: 0.6974 - auc: 0.7647 - val_loss: 0.6070 - val_accuracy: 0.6812 - val_auc: 0.7322\n",
      "Epoch 325/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5850 - accuracy: 0.6928 - auc: 0.7580 - val_loss: 0.6064 - val_accuracy: 0.6828 - val_auc: 0.7332\n",
      "Epoch 326/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5803 - accuracy: 0.6913 - auc: 0.7619 - val_loss: 0.6058 - val_accuracy: 0.6845 - val_auc: 0.7335\n",
      "Epoch 327/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5818 - accuracy: 0.6948 - auc: 0.7613 - val_loss: 0.6059 - val_accuracy: 0.6828 - val_auc: 0.7335\n",
      "Epoch 328/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5862 - accuracy: 0.6979 - auc: 0.7572 - val_loss: 0.6067 - val_accuracy: 0.6796 - val_auc: 0.7325\n",
      "Epoch 329/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5858 - accuracy: 0.6878 - auc: 0.7573 - val_loss: 0.6055 - val_accuracy: 0.6828 - val_auc: 0.7339\n",
      "Epoch 330/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5877 - accuracy: 0.6953 - auc: 0.7553 - val_loss: 0.6056 - val_accuracy: 0.6812 - val_auc: 0.7337\n",
      "Epoch 331/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5799 - accuracy: 0.6984 - auc: 0.7654 - val_loss: 0.6065 - val_accuracy: 0.6828 - val_auc: 0.7332\n",
      "Epoch 332/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5857 - accuracy: 0.6979 - auc: 0.7585 - val_loss: 0.6055 - val_accuracy: 0.6861 - val_auc: 0.7343\n",
      "Epoch 333/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5804 - accuracy: 0.7085 - auc: 0.7672 - val_loss: 0.6055 - val_accuracy: 0.6845 - val_auc: 0.7342\n",
      "Epoch 334/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5810 - accuracy: 0.6898 - auc: 0.7612 - val_loss: 0.6053 - val_accuracy: 0.6845 - val_auc: 0.7341\n",
      "Epoch 335/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5850 - accuracy: 0.7085 - auc: 0.7597 - val_loss: 0.6052 - val_accuracy: 0.6861 - val_auc: 0.7343\n",
      "Epoch 336/700\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 0.5784 - accuracy: 0.7024 - auc: 0.7666 - val_loss: 0.6047 - val_accuracy: 0.6861 - val_auc: 0.7351\n",
      "Epoch 337/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5838 - accuracy: 0.6979 - auc: 0.7605 - val_loss: 0.6043 - val_accuracy: 0.6828 - val_auc: 0.7360\n",
      "Epoch 338/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5827 - accuracy: 0.6857 - auc: 0.7598 - val_loss: 0.6050 - val_accuracy: 0.6845 - val_auc: 0.7349\n",
      "Epoch 339/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5801 - accuracy: 0.6933 - auc: 0.7641 - val_loss: 0.6058 - val_accuracy: 0.6861 - val_auc: 0.7340\n",
      "Epoch 340/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5852 - accuracy: 0.6898 - auc: 0.7562 - val_loss: 0.6053 - val_accuracy: 0.6877 - val_auc: 0.7345\n",
      "Epoch 341/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5771 - accuracy: 0.7045 - auc: 0.7676 - val_loss: 0.6058 - val_accuracy: 0.6861 - val_auc: 0.7340\n",
      "Epoch 342/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5808 - accuracy: 0.6979 - auc: 0.7638 - val_loss: 0.6061 - val_accuracy: 0.6845 - val_auc: 0.7337\n",
      "Epoch 343/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5797 - accuracy: 0.7009 - auc: 0.7658 - val_loss: 0.6050 - val_accuracy: 0.6861 - val_auc: 0.7351\n",
      "Epoch 344/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5820 - accuracy: 0.6943 - auc: 0.7617 - val_loss: 0.6047 - val_accuracy: 0.6845 - val_auc: 0.7357\n",
      "Epoch 345/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5808 - accuracy: 0.6984 - auc: 0.7638 - val_loss: 0.6048 - val_accuracy: 0.6861 - val_auc: 0.7353\n",
      "Epoch 346/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5839 - accuracy: 0.6791 - auc: 0.7583 - val_loss: 0.6046 - val_accuracy: 0.6812 - val_auc: 0.7357\n",
      "Epoch 347/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5812 - accuracy: 0.6979 - auc: 0.7634 - val_loss: 0.6062 - val_accuracy: 0.6796 - val_auc: 0.7334\n",
      "Epoch 348/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5815 - accuracy: 0.6999 - auc: 0.7650 - val_loss: 0.6053 - val_accuracy: 0.6877 - val_auc: 0.7350\n",
      "Epoch 349/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5797 - accuracy: 0.6959 - auc: 0.7634 - val_loss: 0.6039 - val_accuracy: 0.6845 - val_auc: 0.7368\n",
      "Epoch 350/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5801 - accuracy: 0.6964 - auc: 0.7636 - val_loss: 0.6047 - val_accuracy: 0.6877 - val_auc: 0.7350\n",
      "Epoch 351/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5785 - accuracy: 0.6989 - auc: 0.7663 - val_loss: 0.6038 - val_accuracy: 0.6877 - val_auc: 0.7365\n",
      "Epoch 352/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5780 - accuracy: 0.6984 - auc: 0.7674 - val_loss: 0.6033 - val_accuracy: 0.6877 - val_auc: 0.7375\n",
      "Epoch 353/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5827 - accuracy: 0.6994 - auc: 0.7608 - val_loss: 0.6037 - val_accuracy: 0.6877 - val_auc: 0.7367\n",
      "Epoch 354/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5831 - accuracy: 0.6969 - auc: 0.7598 - val_loss: 0.6040 - val_accuracy: 0.6877 - val_auc: 0.7362\n",
      "Epoch 355/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5819 - accuracy: 0.6994 - auc: 0.7642 - val_loss: 0.6036 - val_accuracy: 0.6877 - val_auc: 0.7367\n",
      "Epoch 356/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5823 - accuracy: 0.6999 - auc: 0.7627 - val_loss: 0.6032 - val_accuracy: 0.6877 - val_auc: 0.7375\n",
      "Epoch 357/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5886 - accuracy: 0.6862 - auc: 0.7552 - val_loss: 0.6028 - val_accuracy: 0.6845 - val_auc: 0.7382\n",
      "Epoch 358/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5806 - accuracy: 0.6964 - auc: 0.7629 - val_loss: 0.6038 - val_accuracy: 0.6861 - val_auc: 0.7367\n",
      "Epoch 359/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5859 - accuracy: 0.6933 - auc: 0.7583 - val_loss: 0.6041 - val_accuracy: 0.6877 - val_auc: 0.7359\n",
      "Epoch 360/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5802 - accuracy: 0.6969 - auc: 0.7645 - val_loss: 0.6045 - val_accuracy: 0.6909 - val_auc: 0.7356\n",
      "Epoch 361/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5794 - accuracy: 0.6979 - auc: 0.7660 - val_loss: 0.6045 - val_accuracy: 0.6877 - val_auc: 0.7358\n",
      "Epoch 362/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5798 - accuracy: 0.6974 - auc: 0.7648 - val_loss: 0.6040 - val_accuracy: 0.6893 - val_auc: 0.7359\n",
      "Epoch 363/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5823 - accuracy: 0.6959 - auc: 0.7600 - val_loss: 0.6041 - val_accuracy: 0.6877 - val_auc: 0.7361\n",
      "Epoch 364/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5826 - accuracy: 0.6883 - auc: 0.7620 - val_loss: 0.6041 - val_accuracy: 0.6893 - val_auc: 0.7362\n",
      "Epoch 365/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5794 - accuracy: 0.6943 - auc: 0.7661 - val_loss: 0.6050 - val_accuracy: 0.6877 - val_auc: 0.7347\n",
      "Epoch 366/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5797 - accuracy: 0.6943 - auc: 0.7638 - val_loss: 0.6042 - val_accuracy: 0.6909 - val_auc: 0.7356\n",
      "Epoch 367/700\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5744 - accuracy: 0.7024 - auc: 0.7703 - val_loss: 0.6048 - val_accuracy: 0.6893 - val_auc: 0.7351\n",
      "Epoch 368/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5749 - accuracy: 0.6959 - auc: 0.7694 - val_loss: 0.6046 - val_accuracy: 0.6893 - val_auc: 0.7355\n",
      "Epoch 369/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5791 - accuracy: 0.6918 - auc: 0.7629 - val_loss: 0.6031 - val_accuracy: 0.6909 - val_auc: 0.7374\n",
      "Epoch 370/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5786 - accuracy: 0.6893 - auc: 0.7636 - val_loss: 0.6028 - val_accuracy: 0.6926 - val_auc: 0.7379\n",
      "Epoch 371/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5763 - accuracy: 0.6953 - auc: 0.7674 - val_loss: 0.6039 - val_accuracy: 0.6828 - val_auc: 0.7366\n",
      "Epoch 372/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5825 - accuracy: 0.6994 - auc: 0.7607 - val_loss: 0.6032 - val_accuracy: 0.6877 - val_auc: 0.7372\n",
      "Epoch 373/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5761 - accuracy: 0.7014 - auc: 0.7676 - val_loss: 0.6023 - val_accuracy: 0.6909 - val_auc: 0.7385\n",
      "Epoch 374/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5776 - accuracy: 0.7045 - auc: 0.7664 - val_loss: 0.6028 - val_accuracy: 0.6909 - val_auc: 0.7380\n",
      "Epoch 375/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5792 - accuracy: 0.6953 - auc: 0.7644 - val_loss: 0.6034 - val_accuracy: 0.6861 - val_auc: 0.7371\n",
      "Epoch 376/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5879 - accuracy: 0.6878 - auc: 0.7564 - val_loss: 0.6027 - val_accuracy: 0.6893 - val_auc: 0.7381\n",
      "Epoch 377/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5770 - accuracy: 0.6999 - auc: 0.7669 - val_loss: 0.6029 - val_accuracy: 0.6861 - val_auc: 0.7377\n",
      "Epoch 378/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5708 - accuracy: 0.7105 - auc: 0.7733 - val_loss: 0.6030 - val_accuracy: 0.6909 - val_auc: 0.7374\n",
      "Epoch 379/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5720 - accuracy: 0.7039 - auc: 0.7714 - val_loss: 0.6029 - val_accuracy: 0.6909 - val_auc: 0.7374\n",
      "Epoch 380/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5747 - accuracy: 0.6964 - auc: 0.7701 - val_loss: 0.6032 - val_accuracy: 0.6893 - val_auc: 0.7371\n",
      "Epoch 381/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5817 - accuracy: 0.6964 - auc: 0.7609 - val_loss: 0.6027 - val_accuracy: 0.6909 - val_auc: 0.7375\n",
      "Epoch 382/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5756 - accuracy: 0.7024 - auc: 0.7681 - val_loss: 0.6023 - val_accuracy: 0.6909 - val_auc: 0.7380\n",
      "Epoch 383/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5806 - accuracy: 0.6913 - auc: 0.7636 - val_loss: 0.6030 - val_accuracy: 0.6909 - val_auc: 0.7375\n",
      "Epoch 384/700\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.5814 - accuracy: 0.6984 - auc: 0.7642 - val_loss: 0.6018 - val_accuracy: 0.6926 - val_auc: 0.7392\n",
      "Epoch 385/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5762 - accuracy: 0.6969 - auc: 0.7673 - val_loss: 0.6026 - val_accuracy: 0.6909 - val_auc: 0.7379\n",
      "Epoch 386/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5776 - accuracy: 0.6984 - auc: 0.7675 - val_loss: 0.6013 - val_accuracy: 0.6926 - val_auc: 0.7400\n",
      "Epoch 387/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5782 - accuracy: 0.6847 - auc: 0.7643 - val_loss: 0.6011 - val_accuracy: 0.6893 - val_auc: 0.7401\n",
      "Epoch 388/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5785 - accuracy: 0.6913 - auc: 0.7651 - val_loss: 0.6006 - val_accuracy: 0.6926 - val_auc: 0.7412\n",
      "Epoch 389/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5807 - accuracy: 0.6948 - auc: 0.7635 - val_loss: 0.6006 - val_accuracy: 0.6893 - val_auc: 0.7409\n",
      "Epoch 390/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5758 - accuracy: 0.7024 - auc: 0.7699 - val_loss: 0.6016 - val_accuracy: 0.6893 - val_auc: 0.7397\n",
      "Epoch 391/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5779 - accuracy: 0.6999 - auc: 0.7649 - val_loss: 0.6014 - val_accuracy: 0.6893 - val_auc: 0.7401\n",
      "Epoch 392/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5792 - accuracy: 0.7014 - auc: 0.7661 - val_loss: 0.6015 - val_accuracy: 0.6909 - val_auc: 0.7399\n",
      "Epoch 393/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5761 - accuracy: 0.6984 - auc: 0.7679 - val_loss: 0.6014 - val_accuracy: 0.6909 - val_auc: 0.7403\n",
      "Epoch 394/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5818 - accuracy: 0.6959 - auc: 0.7626 - val_loss: 0.6021 - val_accuracy: 0.6909 - val_auc: 0.7389\n",
      "Epoch 395/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5783 - accuracy: 0.6979 - auc: 0.7653 - val_loss: 0.6014 - val_accuracy: 0.6909 - val_auc: 0.7396\n",
      "Epoch 396/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5750 - accuracy: 0.6928 - auc: 0.7650 - val_loss: 0.6012 - val_accuracy: 0.6909 - val_auc: 0.7402\n",
      "Epoch 397/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5754 - accuracy: 0.6974 - auc: 0.7683 - val_loss: 0.6009 - val_accuracy: 0.6893 - val_auc: 0.7404\n",
      "Epoch 398/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5728 - accuracy: 0.6964 - auc: 0.7707 - val_loss: 0.6011 - val_accuracy: 0.6893 - val_auc: 0.7403\n",
      "Epoch 399/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5699 - accuracy: 0.7075 - auc: 0.7764 - val_loss: 0.6018 - val_accuracy: 0.6877 - val_auc: 0.7392\n",
      "Epoch 400/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5733 - accuracy: 0.7050 - auc: 0.7719 - val_loss: 0.6011 - val_accuracy: 0.6877 - val_auc: 0.7404\n",
      "Epoch 401/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5737 - accuracy: 0.7019 - auc: 0.7705 - val_loss: 0.6014 - val_accuracy: 0.6909 - val_auc: 0.7402\n",
      "Epoch 402/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5779 - accuracy: 0.6974 - auc: 0.7652 - val_loss: 0.6020 - val_accuracy: 0.6893 - val_auc: 0.7393\n",
      "Epoch 403/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5760 - accuracy: 0.6984 - auc: 0.7699 - val_loss: 0.6015 - val_accuracy: 0.6926 - val_auc: 0.7401\n",
      "Epoch 404/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5780 - accuracy: 0.6903 - auc: 0.7645 - val_loss: 0.6014 - val_accuracy: 0.6909 - val_auc: 0.7404\n",
      "Epoch 405/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5780 - accuracy: 0.7029 - auc: 0.7649 - val_loss: 0.6020 - val_accuracy: 0.6909 - val_auc: 0.7394\n",
      "Epoch 406/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5752 - accuracy: 0.7070 - auc: 0.7688 - val_loss: 0.6016 - val_accuracy: 0.6909 - val_auc: 0.7403\n",
      "Epoch 407/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5783 - accuracy: 0.6903 - auc: 0.7658 - val_loss: 0.6009 - val_accuracy: 0.6909 - val_auc: 0.7407\n",
      "Epoch 408/700\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.5766 - accuracy: 0.7034 - auc: 0.7661 - val_loss: 0.6005 - val_accuracy: 0.6942 - val_auc: 0.7420\n",
      "Epoch 409/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5718 - accuracy: 0.6984 - auc: 0.7722 - val_loss: 0.6016 - val_accuracy: 0.6877 - val_auc: 0.7399\n",
      "Epoch 410/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5771 - accuracy: 0.6974 - auc: 0.7669 - val_loss: 0.6012 - val_accuracy: 0.6926 - val_auc: 0.7408\n",
      "Epoch 411/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5762 - accuracy: 0.7080 - auc: 0.7685 - val_loss: 0.6017 - val_accuracy: 0.6893 - val_auc: 0.7399\n",
      "Epoch 412/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5763 - accuracy: 0.7024 - auc: 0.7663 - val_loss: 0.6008 - val_accuracy: 0.6909 - val_auc: 0.7413\n",
      "Epoch 413/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5727 - accuracy: 0.6943 - auc: 0.7722 - val_loss: 0.6007 - val_accuracy: 0.6942 - val_auc: 0.7416\n",
      "Epoch 414/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5719 - accuracy: 0.7004 - auc: 0.7707 - val_loss: 0.6001 - val_accuracy: 0.6909 - val_auc: 0.7423\n",
      "Epoch 415/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5823 - accuracy: 0.6964 - auc: 0.7609 - val_loss: 0.6002 - val_accuracy: 0.6909 - val_auc: 0.7426\n",
      "Epoch 416/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5774 - accuracy: 0.6969 - auc: 0.7673 - val_loss: 0.6013 - val_accuracy: 0.6926 - val_auc: 0.7407\n",
      "Epoch 417/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5722 - accuracy: 0.7070 - auc: 0.7724 - val_loss: 0.6011 - val_accuracy: 0.6909 - val_auc: 0.7408\n",
      "Epoch 418/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5724 - accuracy: 0.7034 - auc: 0.7733 - val_loss: 0.6010 - val_accuracy: 0.6909 - val_auc: 0.7408\n",
      "Epoch 419/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5714 - accuracy: 0.7050 - auc: 0.7752 - val_loss: 0.6014 - val_accuracy: 0.6845 - val_auc: 0.7398\n",
      "Epoch 420/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5727 - accuracy: 0.7019 - auc: 0.7712 - val_loss: 0.6006 - val_accuracy: 0.6845 - val_auc: 0.7411\n",
      "Epoch 421/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5770 - accuracy: 0.6984 - auc: 0.7659 - val_loss: 0.6009 - val_accuracy: 0.6845 - val_auc: 0.7409\n",
      "Epoch 422/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5745 - accuracy: 0.6999 - auc: 0.7692 - val_loss: 0.5998 - val_accuracy: 0.6909 - val_auc: 0.7425\n",
      "Epoch 423/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5761 - accuracy: 0.6928 - auc: 0.7674 - val_loss: 0.6007 - val_accuracy: 0.6877 - val_auc: 0.7416\n",
      "Epoch 424/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5797 - accuracy: 0.6883 - auc: 0.7636 - val_loss: 0.6003 - val_accuracy: 0.6861 - val_auc: 0.7419\n",
      "Epoch 425/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5799 - accuracy: 0.6893 - auc: 0.7628 - val_loss: 0.5998 - val_accuracy: 0.6926 - val_auc: 0.7430\n",
      "Epoch 426/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5757 - accuracy: 0.7075 - auc: 0.7694 - val_loss: 0.5997 - val_accuracy: 0.6942 - val_auc: 0.7431\n",
      "Epoch 427/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5767 - accuracy: 0.7024 - auc: 0.7688 - val_loss: 0.6010 - val_accuracy: 0.6893 - val_auc: 0.7411\n",
      "Epoch 428/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5771 - accuracy: 0.6984 - auc: 0.7687 - val_loss: 0.6004 - val_accuracy: 0.6877 - val_auc: 0.7420\n",
      "Epoch 429/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5771 - accuracy: 0.6948 - auc: 0.7667 - val_loss: 0.6003 - val_accuracy: 0.6893 - val_auc: 0.7417\n",
      "Epoch 430/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5771 - accuracy: 0.6969 - auc: 0.7660 - val_loss: 0.5999 - val_accuracy: 0.6942 - val_auc: 0.7430\n",
      "Epoch 431/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5746 - accuracy: 0.7024 - auc: 0.7715 - val_loss: 0.5997 - val_accuracy: 0.6926 - val_auc: 0.7429\n",
      "Epoch 432/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5753 - accuracy: 0.7009 - auc: 0.7674 - val_loss: 0.6005 - val_accuracy: 0.6926 - val_auc: 0.7414\n",
      "Epoch 433/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5716 - accuracy: 0.6943 - auc: 0.7725 - val_loss: 0.5995 - val_accuracy: 0.6926 - val_auc: 0.7427\n",
      "Epoch 434/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5742 - accuracy: 0.7024 - auc: 0.7710 - val_loss: 0.5998 - val_accuracy: 0.6926 - val_auc: 0.7421\n",
      "Epoch 435/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5717 - accuracy: 0.6979 - auc: 0.7729 - val_loss: 0.5997 - val_accuracy: 0.6909 - val_auc: 0.7425\n",
      "Epoch 436/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5713 - accuracy: 0.7045 - auc: 0.7740 - val_loss: 0.6001 - val_accuracy: 0.6909 - val_auc: 0.7416\n",
      "Epoch 437/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5746 - accuracy: 0.6989 - auc: 0.7699 - val_loss: 0.6008 - val_accuracy: 0.6909 - val_auc: 0.7408\n",
      "Epoch 438/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5775 - accuracy: 0.6994 - auc: 0.7679 - val_loss: 0.5994 - val_accuracy: 0.6942 - val_auc: 0.7426\n",
      "Epoch 439/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5715 - accuracy: 0.7019 - auc: 0.7738 - val_loss: 0.5998 - val_accuracy: 0.6942 - val_auc: 0.7420\n",
      "Epoch 440/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5685 - accuracy: 0.6943 - auc: 0.7751 - val_loss: 0.5991 - val_accuracy: 0.6909 - val_auc: 0.7430\n",
      "Epoch 441/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5743 - accuracy: 0.6999 - auc: 0.7700 - val_loss: 0.5993 - val_accuracy: 0.6942 - val_auc: 0.7435\n",
      "Epoch 442/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5750 - accuracy: 0.6953 - auc: 0.7704 - val_loss: 0.5992 - val_accuracy: 0.6926 - val_auc: 0.7433\n",
      "Epoch 443/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5762 - accuracy: 0.7004 - auc: 0.7697 - val_loss: 0.5982 - val_accuracy: 0.6926 - val_auc: 0.7449\n",
      "Epoch 444/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5794 - accuracy: 0.6969 - auc: 0.7632 - val_loss: 0.5984 - val_accuracy: 0.6926 - val_auc: 0.7446\n",
      "Epoch 445/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5771 - accuracy: 0.7060 - auc: 0.7691 - val_loss: 0.5986 - val_accuracy: 0.6877 - val_auc: 0.7440\n",
      "Epoch 446/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5695 - accuracy: 0.7105 - auc: 0.7756 - val_loss: 0.5975 - val_accuracy: 0.6926 - val_auc: 0.7458\n",
      "Epoch 447/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5758 - accuracy: 0.6974 - auc: 0.7678 - val_loss: 0.5976 - val_accuracy: 0.6926 - val_auc: 0.7457\n",
      "Epoch 448/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5746 - accuracy: 0.7060 - auc: 0.7708 - val_loss: 0.5980 - val_accuracy: 0.6909 - val_auc: 0.7451\n",
      "Epoch 449/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5745 - accuracy: 0.6923 - auc: 0.7672 - val_loss: 0.5980 - val_accuracy: 0.6909 - val_auc: 0.7448\n",
      "Epoch 450/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5762 - accuracy: 0.6989 - auc: 0.7686 - val_loss: 0.5967 - val_accuracy: 0.6877 - val_auc: 0.7465\n",
      "Epoch 451/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5753 - accuracy: 0.6969 - auc: 0.7696 - val_loss: 0.5977 - val_accuracy: 0.6909 - val_auc: 0.7452\n",
      "Epoch 452/700\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 0.5716 - accuracy: 0.7019 - auc: 0.7741 - val_loss: 0.5983 - val_accuracy: 0.6845 - val_auc: 0.7438\n",
      "Epoch 453/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5769 - accuracy: 0.6953 - auc: 0.7653 - val_loss: 0.5977 - val_accuracy: 0.6958 - val_auc: 0.7452\n",
      "Epoch 454/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5786 - accuracy: 0.6953 - auc: 0.7656 - val_loss: 0.5973 - val_accuracy: 0.6942 - val_auc: 0.7457\n",
      "Epoch 455/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5732 - accuracy: 0.7029 - auc: 0.7736 - val_loss: 0.5968 - val_accuracy: 0.6877 - val_auc: 0.7469\n",
      "Epoch 456/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5691 - accuracy: 0.6984 - auc: 0.7757 - val_loss: 0.5967 - val_accuracy: 0.6926 - val_auc: 0.7467\n",
      "Epoch 457/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5754 - accuracy: 0.6974 - auc: 0.7682 - val_loss: 0.5965 - val_accuracy: 0.6926 - val_auc: 0.7468\n",
      "Epoch 458/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5749 - accuracy: 0.6979 - auc: 0.7693 - val_loss: 0.5976 - val_accuracy: 0.6926 - val_auc: 0.7452\n",
      "Epoch 459/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5692 - accuracy: 0.7034 - auc: 0.7752 - val_loss: 0.5969 - val_accuracy: 0.6942 - val_auc: 0.7457\n",
      "Epoch 460/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5797 - accuracy: 0.7009 - auc: 0.7667 - val_loss: 0.5973 - val_accuracy: 0.6942 - val_auc: 0.7449\n",
      "Epoch 461/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5731 - accuracy: 0.7065 - auc: 0.7751 - val_loss: 0.5973 - val_accuracy: 0.6974 - val_auc: 0.7455\n",
      "Epoch 462/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5734 - accuracy: 0.6974 - auc: 0.7711 - val_loss: 0.5971 - val_accuracy: 0.6926 - val_auc: 0.7450\n",
      "Epoch 463/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5688 - accuracy: 0.7009 - auc: 0.7744 - val_loss: 0.5972 - val_accuracy: 0.6909 - val_auc: 0.7453\n",
      "Epoch 464/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5709 - accuracy: 0.7080 - auc: 0.7745 - val_loss: 0.5963 - val_accuracy: 0.6926 - val_auc: 0.7471\n",
      "Epoch 465/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5680 - accuracy: 0.6979 - auc: 0.7760 - val_loss: 0.5958 - val_accuracy: 0.6942 - val_auc: 0.7476\n",
      "Epoch 466/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5718 - accuracy: 0.7024 - auc: 0.7734 - val_loss: 0.5956 - val_accuracy: 0.6926 - val_auc: 0.7479\n",
      "Epoch 467/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5700 - accuracy: 0.7080 - auc: 0.7736 - val_loss: 0.5965 - val_accuracy: 0.6909 - val_auc: 0.7471\n",
      "Epoch 468/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5729 - accuracy: 0.7039 - auc: 0.7726 - val_loss: 0.5967 - val_accuracy: 0.6909 - val_auc: 0.7465\n",
      "Epoch 469/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5745 - accuracy: 0.7034 - auc: 0.7707 - val_loss: 0.5977 - val_accuracy: 0.6877 - val_auc: 0.7449\n",
      "Epoch 470/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5753 - accuracy: 0.6959 - auc: 0.7676 - val_loss: 0.5962 - val_accuracy: 0.6926 - val_auc: 0.7473\n",
      "Epoch 471/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5725 - accuracy: 0.7060 - auc: 0.7748 - val_loss: 0.5973 - val_accuracy: 0.6926 - val_auc: 0.7454\n",
      "Epoch 472/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5702 - accuracy: 0.6994 - auc: 0.7736 - val_loss: 0.5970 - val_accuracy: 0.6958 - val_auc: 0.7461\n",
      "Epoch 473/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5742 - accuracy: 0.7070 - auc: 0.7722 - val_loss: 0.5963 - val_accuracy: 0.6958 - val_auc: 0.7464\n",
      "Epoch 474/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5777 - accuracy: 0.7014 - auc: 0.7661 - val_loss: 0.5963 - val_accuracy: 0.6942 - val_auc: 0.7470\n",
      "Epoch 475/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5774 - accuracy: 0.7039 - auc: 0.7678 - val_loss: 0.5959 - val_accuracy: 0.6909 - val_auc: 0.7474\n",
      "Epoch 476/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5741 - accuracy: 0.7045 - auc: 0.7706 - val_loss: 0.5956 - val_accuracy: 0.6926 - val_auc: 0.7480\n",
      "Epoch 477/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5752 - accuracy: 0.7080 - auc: 0.7707 - val_loss: 0.5967 - val_accuracy: 0.6958 - val_auc: 0.7463\n",
      "Epoch 478/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5734 - accuracy: 0.7039 - auc: 0.7711 - val_loss: 0.5976 - val_accuracy: 0.6893 - val_auc: 0.7447\n",
      "Epoch 479/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5756 - accuracy: 0.6969 - auc: 0.7684 - val_loss: 0.5970 - val_accuracy: 0.6877 - val_auc: 0.7456\n",
      "Epoch 480/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5739 - accuracy: 0.7039 - auc: 0.7699 - val_loss: 0.5969 - val_accuracy: 0.6942 - val_auc: 0.7461\n",
      "Epoch 481/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5745 - accuracy: 0.7004 - auc: 0.7688 - val_loss: 0.5957 - val_accuracy: 0.6893 - val_auc: 0.7483\n",
      "Epoch 482/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5711 - accuracy: 0.7095 - auc: 0.7740 - val_loss: 0.5967 - val_accuracy: 0.6942 - val_auc: 0.7461\n",
      "Epoch 483/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5758 - accuracy: 0.7065 - auc: 0.7699 - val_loss: 0.5960 - val_accuracy: 0.6926 - val_auc: 0.7474\n",
      "Epoch 484/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5717 - accuracy: 0.7039 - auc: 0.7736 - val_loss: 0.5960 - val_accuracy: 0.6926 - val_auc: 0.7472\n",
      "Epoch 485/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5723 - accuracy: 0.7095 - auc: 0.7738 - val_loss: 0.5956 - val_accuracy: 0.6909 - val_auc: 0.7477\n",
      "Epoch 486/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5695 - accuracy: 0.7009 - auc: 0.7741 - val_loss: 0.5963 - val_accuracy: 0.6909 - val_auc: 0.7470\n",
      "Epoch 487/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5734 - accuracy: 0.6959 - auc: 0.7691 - val_loss: 0.5961 - val_accuracy: 0.6909 - val_auc: 0.7474\n",
      "Epoch 488/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5680 - accuracy: 0.7105 - auc: 0.7782 - val_loss: 0.5966 - val_accuracy: 0.6942 - val_auc: 0.7468\n",
      "Epoch 489/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5716 - accuracy: 0.7070 - auc: 0.7735 - val_loss: 0.5958 - val_accuracy: 0.6926 - val_auc: 0.7479\n",
      "Epoch 490/700\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.5758 - accuracy: 0.6933 - auc: 0.7662 - val_loss: 0.5951 - val_accuracy: 0.6909 - val_auc: 0.7490\n",
      "Epoch 491/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5731 - accuracy: 0.7009 - auc: 0.7723 - val_loss: 0.5958 - val_accuracy: 0.6926 - val_auc: 0.7473\n",
      "Epoch 492/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5727 - accuracy: 0.6999 - auc: 0.7730 - val_loss: 0.5949 - val_accuracy: 0.6909 - val_auc: 0.7491\n",
      "Epoch 493/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5754 - accuracy: 0.7039 - auc: 0.7700 - val_loss: 0.5948 - val_accuracy: 0.6909 - val_auc: 0.7491\n",
      "Epoch 494/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5713 - accuracy: 0.7029 - auc: 0.7747 - val_loss: 0.5947 - val_accuracy: 0.6909 - val_auc: 0.7495\n",
      "Epoch 495/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5706 - accuracy: 0.6984 - auc: 0.7727 - val_loss: 0.5950 - val_accuracy: 0.6909 - val_auc: 0.7486\n",
      "Epoch 496/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5704 - accuracy: 0.6923 - auc: 0.7740 - val_loss: 0.5950 - val_accuracy: 0.6909 - val_auc: 0.7487\n",
      "Epoch 497/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5706 - accuracy: 0.7014 - auc: 0.7762 - val_loss: 0.5947 - val_accuracy: 0.6893 - val_auc: 0.7492\n",
      "Epoch 498/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5688 - accuracy: 0.7065 - auc: 0.7785 - val_loss: 0.5953 - val_accuracy: 0.6926 - val_auc: 0.7481\n",
      "Epoch 499/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5768 - accuracy: 0.6928 - auc: 0.7653 - val_loss: 0.5950 - val_accuracy: 0.6926 - val_auc: 0.7483\n",
      "Epoch 500/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5718 - accuracy: 0.7060 - auc: 0.7719 - val_loss: 0.5953 - val_accuracy: 0.6861 - val_auc: 0.7483\n",
      "Epoch 501/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5704 - accuracy: 0.7034 - auc: 0.7753 - val_loss: 0.5949 - val_accuracy: 0.6877 - val_auc: 0.7484\n",
      "Epoch 502/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5702 - accuracy: 0.7115 - auc: 0.7767 - val_loss: 0.5948 - val_accuracy: 0.6861 - val_auc: 0.7487\n",
      "Epoch 503/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5719 - accuracy: 0.7029 - auc: 0.7710 - val_loss: 0.5953 - val_accuracy: 0.6845 - val_auc: 0.7477\n",
      "Epoch 504/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5710 - accuracy: 0.6984 - auc: 0.7737 - val_loss: 0.5950 - val_accuracy: 0.6893 - val_auc: 0.7484\n",
      "Epoch 505/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5667 - accuracy: 0.7045 - auc: 0.7776 - val_loss: 0.5951 - val_accuracy: 0.6877 - val_auc: 0.7480\n",
      "Epoch 506/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5686 - accuracy: 0.7024 - auc: 0.7751 - val_loss: 0.5946 - val_accuracy: 0.6909 - val_auc: 0.7490\n",
      "Epoch 507/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5685 - accuracy: 0.7131 - auc: 0.7799 - val_loss: 0.5947 - val_accuracy: 0.6909 - val_auc: 0.7485\n",
      "Epoch 508/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5793 - accuracy: 0.6953 - auc: 0.7640 - val_loss: 0.5940 - val_accuracy: 0.6877 - val_auc: 0.7496\n",
      "Epoch 509/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5674 - accuracy: 0.7070 - auc: 0.7775 - val_loss: 0.5937 - val_accuracy: 0.6893 - val_auc: 0.7503\n",
      "Epoch 510/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5661 - accuracy: 0.7131 - auc: 0.7809 - val_loss: 0.5932 - val_accuracy: 0.6877 - val_auc: 0.7507\n",
      "Epoch 511/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5733 - accuracy: 0.7050 - auc: 0.7715 - val_loss: 0.5929 - val_accuracy: 0.6909 - val_auc: 0.7514\n",
      "Epoch 512/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5718 - accuracy: 0.7029 - auc: 0.7729 - val_loss: 0.5925 - val_accuracy: 0.6942 - val_auc: 0.7522\n",
      "Epoch 513/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5708 - accuracy: 0.7055 - auc: 0.7750 - val_loss: 0.5936 - val_accuracy: 0.6893 - val_auc: 0.7502\n",
      "Epoch 514/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5731 - accuracy: 0.7029 - auc: 0.7716 - val_loss: 0.5935 - val_accuracy: 0.6893 - val_auc: 0.7504\n",
      "Epoch 515/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5749 - accuracy: 0.6999 - auc: 0.7687 - val_loss: 0.5936 - val_accuracy: 0.6893 - val_auc: 0.7501\n",
      "Epoch 516/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5702 - accuracy: 0.7070 - auc: 0.7734 - val_loss: 0.5946 - val_accuracy: 0.6861 - val_auc: 0.7487\n",
      "Epoch 517/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5655 - accuracy: 0.7090 - auc: 0.7797 - val_loss: 0.5937 - val_accuracy: 0.6909 - val_auc: 0.7503\n",
      "Epoch 518/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5760 - accuracy: 0.6928 - auc: 0.7653 - val_loss: 0.5931 - val_accuracy: 0.6909 - val_auc: 0.7509\n",
      "Epoch 519/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5735 - accuracy: 0.7024 - auc: 0.7699 - val_loss: 0.5934 - val_accuracy: 0.6909 - val_auc: 0.7509\n",
      "Epoch 520/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5703 - accuracy: 0.7055 - auc: 0.7743 - val_loss: 0.5931 - val_accuracy: 0.6893 - val_auc: 0.7511\n",
      "Epoch 521/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5767 - accuracy: 0.6994 - auc: 0.7668 - val_loss: 0.5945 - val_accuracy: 0.6909 - val_auc: 0.7491\n",
      "Epoch 522/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5679 - accuracy: 0.7090 - auc: 0.7782 - val_loss: 0.5937 - val_accuracy: 0.6909 - val_auc: 0.7505\n",
      "Epoch 523/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5656 - accuracy: 0.7019 - auc: 0.7771 - val_loss: 0.5934 - val_accuracy: 0.6909 - val_auc: 0.7508\n",
      "Epoch 524/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5724 - accuracy: 0.7115 - auc: 0.7723 - val_loss: 0.5938 - val_accuracy: 0.6893 - val_auc: 0.7507\n",
      "Epoch 525/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5700 - accuracy: 0.7100 - auc: 0.7748 - val_loss: 0.5929 - val_accuracy: 0.6909 - val_auc: 0.7513\n",
      "Epoch 526/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5735 - accuracy: 0.6989 - auc: 0.7698 - val_loss: 0.5924 - val_accuracy: 0.6909 - val_auc: 0.7521\n",
      "Epoch 527/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5649 - accuracy: 0.7120 - auc: 0.7803 - val_loss: 0.5924 - val_accuracy: 0.6877 - val_auc: 0.7519\n",
      "Epoch 528/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5707 - accuracy: 0.7019 - auc: 0.7739 - val_loss: 0.5931 - val_accuracy: 0.6877 - val_auc: 0.7510\n",
      "Epoch 529/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5645 - accuracy: 0.7186 - auc: 0.7827 - val_loss: 0.5946 - val_accuracy: 0.6877 - val_auc: 0.7483\n",
      "Epoch 530/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5663 - accuracy: 0.7045 - auc: 0.7776 - val_loss: 0.5941 - val_accuracy: 0.6861 - val_auc: 0.7493\n",
      "Epoch 531/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5723 - accuracy: 0.7100 - auc: 0.7726 - val_loss: 0.5931 - val_accuracy: 0.6893 - val_auc: 0.7510\n",
      "Epoch 532/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5644 - accuracy: 0.7019 - auc: 0.7794 - val_loss: 0.5940 - val_accuracy: 0.6909 - val_auc: 0.7496\n",
      "Epoch 533/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5645 - accuracy: 0.7131 - auc: 0.7811 - val_loss: 0.5937 - val_accuracy: 0.6909 - val_auc: 0.7505\n",
      "Epoch 534/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5662 - accuracy: 0.7034 - auc: 0.7768 - val_loss: 0.5934 - val_accuracy: 0.6942 - val_auc: 0.7509\n",
      "Epoch 535/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5700 - accuracy: 0.7034 - auc: 0.7754 - val_loss: 0.5931 - val_accuracy: 0.6909 - val_auc: 0.7513\n",
      "Epoch 536/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5669 - accuracy: 0.7019 - auc: 0.7753 - val_loss: 0.5939 - val_accuracy: 0.6926 - val_auc: 0.7499\n",
      "Epoch 537/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5659 - accuracy: 0.7090 - auc: 0.7795 - val_loss: 0.5930 - val_accuracy: 0.6926 - val_auc: 0.7515\n",
      "Epoch 538/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5635 - accuracy: 0.7110 - auc: 0.7818 - val_loss: 0.5930 - val_accuracy: 0.6974 - val_auc: 0.7519\n",
      "Epoch 539/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5713 - accuracy: 0.7090 - auc: 0.7736 - val_loss: 0.5928 - val_accuracy: 0.6926 - val_auc: 0.7519\n",
      "Epoch 540/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5703 - accuracy: 0.7019 - auc: 0.7764 - val_loss: 0.5933 - val_accuracy: 0.6877 - val_auc: 0.7511\n",
      "Epoch 541/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5713 - accuracy: 0.6974 - auc: 0.7719 - val_loss: 0.5929 - val_accuracy: 0.6909 - val_auc: 0.7519\n",
      "Epoch 542/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5707 - accuracy: 0.7024 - auc: 0.7754 - val_loss: 0.5939 - val_accuracy: 0.6877 - val_auc: 0.7504\n",
      "Epoch 543/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5683 - accuracy: 0.7100 - auc: 0.7780 - val_loss: 0.5926 - val_accuracy: 0.6909 - val_auc: 0.7521\n",
      "Epoch 544/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5681 - accuracy: 0.7110 - auc: 0.7778 - val_loss: 0.5933 - val_accuracy: 0.6909 - val_auc: 0.7508\n",
      "Epoch 545/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5725 - accuracy: 0.7055 - auc: 0.7729 - val_loss: 0.5929 - val_accuracy: 0.6909 - val_auc: 0.7516\n",
      "Epoch 546/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5678 - accuracy: 0.7100 - auc: 0.7778 - val_loss: 0.5937 - val_accuracy: 0.6909 - val_auc: 0.7505\n",
      "Epoch 547/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5670 - accuracy: 0.7095 - auc: 0.7769 - val_loss: 0.5927 - val_accuracy: 0.6942 - val_auc: 0.7522\n",
      "Epoch 548/700\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.5624 - accuracy: 0.7095 - auc: 0.7842 - val_loss: 0.5918 - val_accuracy: 0.6958 - val_auc: 0.7530\n",
      "Epoch 549/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5666 - accuracy: 0.7171 - auc: 0.7818 - val_loss: 0.5921 - val_accuracy: 0.6942 - val_auc: 0.7525\n",
      "Epoch 550/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5691 - accuracy: 0.6994 - auc: 0.7748 - val_loss: 0.5916 - val_accuracy: 0.6958 - val_auc: 0.7531\n",
      "Epoch 551/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5706 - accuracy: 0.7009 - auc: 0.7720 - val_loss: 0.5914 - val_accuracy: 0.6942 - val_auc: 0.7541\n",
      "Epoch 552/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5576 - accuracy: 0.7075 - auc: 0.7871 - val_loss: 0.5918 - val_accuracy: 0.6926 - val_auc: 0.7536\n",
      "Epoch 553/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5647 - accuracy: 0.7060 - auc: 0.7789 - val_loss: 0.5918 - val_accuracy: 0.6942 - val_auc: 0.7532\n",
      "Epoch 554/700\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 0.5679 - accuracy: 0.7050 - auc: 0.7783 - val_loss: 0.5911 - val_accuracy: 0.6958 - val_auc: 0.7545\n",
      "Epoch 555/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5789 - accuracy: 0.7014 - auc: 0.7672 - val_loss: 0.5912 - val_accuracy: 0.6974 - val_auc: 0.7546\n",
      "Epoch 556/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5676 - accuracy: 0.7039 - auc: 0.7759 - val_loss: 0.5911 - val_accuracy: 0.6958 - val_auc: 0.7546\n",
      "Epoch 557/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5674 - accuracy: 0.7019 - auc: 0.7768 - val_loss: 0.5911 - val_accuracy: 0.6942 - val_auc: 0.7540\n",
      "Epoch 558/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5616 - accuracy: 0.7019 - auc: 0.7827 - val_loss: 0.5915 - val_accuracy: 0.6942 - val_auc: 0.7535\n",
      "Epoch 559/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5652 - accuracy: 0.7105 - auc: 0.7801 - val_loss: 0.5914 - val_accuracy: 0.6974 - val_auc: 0.7533\n",
      "Epoch 560/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5688 - accuracy: 0.6994 - auc: 0.7755 - val_loss: 0.5917 - val_accuracy: 0.6942 - val_auc: 0.7529\n",
      "Epoch 561/700\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 0.5610 - accuracy: 0.7131 - auc: 0.7858 - val_loss: 0.5901 - val_accuracy: 0.6958 - val_auc: 0.7553\n",
      "Epoch 562/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5646 - accuracy: 0.7120 - auc: 0.7800 - val_loss: 0.5902 - val_accuracy: 0.6958 - val_auc: 0.7550\n",
      "Epoch 563/700\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 0.5712 - accuracy: 0.7126 - auc: 0.7734 - val_loss: 0.5897 - val_accuracy: 0.7006 - val_auc: 0.7564\n",
      "Epoch 564/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5721 - accuracy: 0.7045 - auc: 0.7709 - val_loss: 0.5901 - val_accuracy: 0.6958 - val_auc: 0.7554\n",
      "Epoch 565/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5716 - accuracy: 0.7070 - auc: 0.7734 - val_loss: 0.5912 - val_accuracy: 0.6958 - val_auc: 0.7539\n",
      "Epoch 566/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5685 - accuracy: 0.7110 - auc: 0.7782 - val_loss: 0.5900 - val_accuracy: 0.6958 - val_auc: 0.7553\n",
      "Epoch 567/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5698 - accuracy: 0.7004 - auc: 0.7757 - val_loss: 0.5904 - val_accuracy: 0.6958 - val_auc: 0.7548\n",
      "Epoch 568/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5689 - accuracy: 0.6979 - auc: 0.7763 - val_loss: 0.5908 - val_accuracy: 0.6942 - val_auc: 0.7545\n",
      "Epoch 569/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5700 - accuracy: 0.7075 - auc: 0.7763 - val_loss: 0.5906 - val_accuracy: 0.6958 - val_auc: 0.7547\n",
      "Epoch 570/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5690 - accuracy: 0.7039 - auc: 0.7767 - val_loss: 0.5909 - val_accuracy: 0.6958 - val_auc: 0.7542\n",
      "Epoch 571/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5724 - accuracy: 0.7039 - auc: 0.7725 - val_loss: 0.5909 - val_accuracy: 0.6958 - val_auc: 0.7544\n",
      "Epoch 572/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5677 - accuracy: 0.7126 - auc: 0.7765 - val_loss: 0.5917 - val_accuracy: 0.6926 - val_auc: 0.7532\n",
      "Epoch 573/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5594 - accuracy: 0.7131 - auc: 0.7870 - val_loss: 0.5917 - val_accuracy: 0.6926 - val_auc: 0.7531\n",
      "Epoch 574/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5693 - accuracy: 0.7034 - auc: 0.7753 - val_loss: 0.5915 - val_accuracy: 0.6926 - val_auc: 0.7535\n",
      "Epoch 575/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5687 - accuracy: 0.7131 - auc: 0.7764 - val_loss: 0.5917 - val_accuracy: 0.6926 - val_auc: 0.7532\n",
      "Epoch 576/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5653 - accuracy: 0.7055 - auc: 0.7789 - val_loss: 0.5915 - val_accuracy: 0.6926 - val_auc: 0.7531\n",
      "Epoch 577/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5654 - accuracy: 0.7105 - auc: 0.7786 - val_loss: 0.5903 - val_accuracy: 0.6958 - val_auc: 0.7554\n",
      "Epoch 578/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5627 - accuracy: 0.7085 - auc: 0.7825 - val_loss: 0.5917 - val_accuracy: 0.6926 - val_auc: 0.7531\n",
      "Epoch 579/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5677 - accuracy: 0.7196 - auc: 0.7796 - val_loss: 0.5918 - val_accuracy: 0.6926 - val_auc: 0.7523\n",
      "Epoch 580/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5602 - accuracy: 0.7100 - auc: 0.7865 - val_loss: 0.5922 - val_accuracy: 0.6942 - val_auc: 0.7519\n",
      "Epoch 581/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5674 - accuracy: 0.7019 - auc: 0.7741 - val_loss: 0.5913 - val_accuracy: 0.6926 - val_auc: 0.7533\n",
      "Epoch 582/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5641 - accuracy: 0.7090 - auc: 0.7804 - val_loss: 0.5906 - val_accuracy: 0.6958 - val_auc: 0.7541\n",
      "Epoch 583/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5715 - accuracy: 0.7146 - auc: 0.7756 - val_loss: 0.5906 - val_accuracy: 0.6974 - val_auc: 0.7546\n",
      "Epoch 584/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5714 - accuracy: 0.7055 - auc: 0.7727 - val_loss: 0.5912 - val_accuracy: 0.6942 - val_auc: 0.7537\n",
      "Epoch 585/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5677 - accuracy: 0.7156 - auc: 0.7776 - val_loss: 0.5905 - val_accuracy: 0.6958 - val_auc: 0.7548\n",
      "Epoch 586/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5697 - accuracy: 0.7045 - auc: 0.7736 - val_loss: 0.5909 - val_accuracy: 0.6926 - val_auc: 0.7535\n",
      "Epoch 587/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5671 - accuracy: 0.7029 - auc: 0.7767 - val_loss: 0.5917 - val_accuracy: 0.6909 - val_auc: 0.7530\n",
      "Epoch 588/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5643 - accuracy: 0.7136 - auc: 0.7811 - val_loss: 0.5902 - val_accuracy: 0.6942 - val_auc: 0.7550\n",
      "Epoch 589/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5632 - accuracy: 0.7105 - auc: 0.7813 - val_loss: 0.5898 - val_accuracy: 0.6942 - val_auc: 0.7554\n",
      "Epoch 590/700\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.5684 - accuracy: 0.7115 - auc: 0.7776 - val_loss: 0.5896 - val_accuracy: 0.6942 - val_auc: 0.7557\n",
      "Epoch 591/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5663 - accuracy: 0.7004 - auc: 0.7771 - val_loss: 0.5899 - val_accuracy: 0.6926 - val_auc: 0.7551\n",
      "Epoch 592/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5647 - accuracy: 0.7060 - auc: 0.7807 - val_loss: 0.5900 - val_accuracy: 0.6942 - val_auc: 0.7550\n",
      "Epoch 593/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5681 - accuracy: 0.7166 - auc: 0.7780 - val_loss: 0.5897 - val_accuracy: 0.6942 - val_auc: 0.7553\n",
      "Epoch 594/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5639 - accuracy: 0.7176 - auc: 0.7820 - val_loss: 0.5896 - val_accuracy: 0.6942 - val_auc: 0.7556\n",
      "Epoch 595/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5645 - accuracy: 0.7136 - auc: 0.7822 - val_loss: 0.5900 - val_accuracy: 0.6942 - val_auc: 0.7550\n",
      "Epoch 596/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5651 - accuracy: 0.7126 - auc: 0.7795 - val_loss: 0.5896 - val_accuracy: 0.6958 - val_auc: 0.7554\n",
      "Epoch 597/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5655 - accuracy: 0.7055 - auc: 0.7808 - val_loss: 0.5891 - val_accuracy: 0.6974 - val_auc: 0.7567\n",
      "Epoch 598/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5680 - accuracy: 0.7080 - auc: 0.7777 - val_loss: 0.5895 - val_accuracy: 0.6958 - val_auc: 0.7561\n",
      "Epoch 599/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5667 - accuracy: 0.6984 - auc: 0.7757 - val_loss: 0.5890 - val_accuracy: 0.6990 - val_auc: 0.7569\n",
      "Epoch 600/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5652 - accuracy: 0.7045 - auc: 0.7774 - val_loss: 0.5900 - val_accuracy: 0.6958 - val_auc: 0.7554\n",
      "Epoch 601/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5630 - accuracy: 0.7105 - auc: 0.7817 - val_loss: 0.5905 - val_accuracy: 0.6942 - val_auc: 0.7544\n",
      "Epoch 602/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5604 - accuracy: 0.7090 - auc: 0.7847 - val_loss: 0.5907 - val_accuracy: 0.6942 - val_auc: 0.7538\n",
      "Epoch 603/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5656 - accuracy: 0.7070 - auc: 0.7780 - val_loss: 0.5906 - val_accuracy: 0.6958 - val_auc: 0.7541\n",
      "Epoch 604/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5644 - accuracy: 0.7085 - auc: 0.7816 - val_loss: 0.5891 - val_accuracy: 0.6958 - val_auc: 0.7563\n",
      "Epoch 605/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5713 - accuracy: 0.6918 - auc: 0.7720 - val_loss: 0.5884 - val_accuracy: 0.6974 - val_auc: 0.7575\n",
      "Epoch 606/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5679 - accuracy: 0.7075 - auc: 0.7791 - val_loss: 0.5890 - val_accuracy: 0.6958 - val_auc: 0.7563\n",
      "Epoch 607/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5675 - accuracy: 0.7024 - auc: 0.7766 - val_loss: 0.5897 - val_accuracy: 0.6958 - val_auc: 0.7551\n",
      "Epoch 608/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5673 - accuracy: 0.7039 - auc: 0.7773 - val_loss: 0.5892 - val_accuracy: 0.6958 - val_auc: 0.7560\n",
      "Epoch 609/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5623 - accuracy: 0.7075 - auc: 0.7823 - val_loss: 0.5889 - val_accuracy: 0.6958 - val_auc: 0.7563\n",
      "Epoch 610/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5638 - accuracy: 0.7009 - auc: 0.7794 - val_loss: 0.5889 - val_accuracy: 0.6942 - val_auc: 0.7569\n",
      "Epoch 611/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5629 - accuracy: 0.7110 - auc: 0.7804 - val_loss: 0.5886 - val_accuracy: 0.6958 - val_auc: 0.7569\n",
      "Epoch 612/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5673 - accuracy: 0.7080 - auc: 0.7768 - val_loss: 0.5885 - val_accuracy: 0.6990 - val_auc: 0.7573\n",
      "Epoch 613/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5640 - accuracy: 0.7039 - auc: 0.7789 - val_loss: 0.5881 - val_accuracy: 0.6990 - val_auc: 0.7580\n",
      "Epoch 614/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5627 - accuracy: 0.7115 - auc: 0.7842 - val_loss: 0.5887 - val_accuracy: 0.6958 - val_auc: 0.7566\n",
      "Epoch 615/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5668 - accuracy: 0.7100 - auc: 0.7769 - val_loss: 0.5876 - val_accuracy: 0.6974 - val_auc: 0.7581\n",
      "Epoch 616/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5629 - accuracy: 0.7080 - auc: 0.7817 - val_loss: 0.5882 - val_accuracy: 0.6974 - val_auc: 0.7571\n",
      "Epoch 617/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5682 - accuracy: 0.6984 - auc: 0.7747 - val_loss: 0.5883 - val_accuracy: 0.6958 - val_auc: 0.7571\n",
      "Epoch 618/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5678 - accuracy: 0.7004 - auc: 0.7763 - val_loss: 0.5885 - val_accuracy: 0.6958 - val_auc: 0.7569\n",
      "Epoch 619/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5606 - accuracy: 0.7075 - auc: 0.7833 - val_loss: 0.5886 - val_accuracy: 0.6974 - val_auc: 0.7566\n",
      "Epoch 620/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5627 - accuracy: 0.7039 - auc: 0.7797 - val_loss: 0.5878 - val_accuracy: 0.6974 - val_auc: 0.7582\n",
      "Epoch 621/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5713 - accuracy: 0.7080 - auc: 0.7728 - val_loss: 0.5878 - val_accuracy: 0.6958 - val_auc: 0.7583\n",
      "Epoch 622/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5588 - accuracy: 0.7136 - auc: 0.7853 - val_loss: 0.5883 - val_accuracy: 0.6974 - val_auc: 0.7575\n",
      "Epoch 623/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5620 - accuracy: 0.7151 - auc: 0.7824 - val_loss: 0.5887 - val_accuracy: 0.6958 - val_auc: 0.7567\n",
      "Epoch 624/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5646 - accuracy: 0.7060 - auc: 0.7818 - val_loss: 0.5882 - val_accuracy: 0.6958 - val_auc: 0.7579\n",
      "Epoch 625/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5673 - accuracy: 0.7131 - auc: 0.7774 - val_loss: 0.5883 - val_accuracy: 0.6958 - val_auc: 0.7573\n",
      "Epoch 626/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5657 - accuracy: 0.7060 - auc: 0.7768 - val_loss: 0.5875 - val_accuracy: 0.6974 - val_auc: 0.7587\n",
      "Epoch 627/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5614 - accuracy: 0.7131 - auc: 0.7836 - val_loss: 0.5876 - val_accuracy: 0.6958 - val_auc: 0.7585\n",
      "Epoch 628/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5634 - accuracy: 0.7181 - auc: 0.7841 - val_loss: 0.5872 - val_accuracy: 0.7006 - val_auc: 0.7588\n",
      "Epoch 629/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5642 - accuracy: 0.7050 - auc: 0.7794 - val_loss: 0.5881 - val_accuracy: 0.6958 - val_auc: 0.7575\n",
      "Epoch 630/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5618 - accuracy: 0.7136 - auc: 0.7845 - val_loss: 0.5877 - val_accuracy: 0.7006 - val_auc: 0.7584\n",
      "Epoch 631/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5649 - accuracy: 0.7019 - auc: 0.7797 - val_loss: 0.5880 - val_accuracy: 0.6990 - val_auc: 0.7581\n",
      "Epoch 632/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5685 - accuracy: 0.7060 - auc: 0.7756 - val_loss: 0.5894 - val_accuracy: 0.6926 - val_auc: 0.7553\n",
      "Epoch 633/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5637 - accuracy: 0.7055 - auc: 0.7815 - val_loss: 0.5886 - val_accuracy: 0.6926 - val_auc: 0.7565\n",
      "Epoch 634/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5627 - accuracy: 0.7065 - auc: 0.7807 - val_loss: 0.5880 - val_accuracy: 0.6958 - val_auc: 0.7573\n",
      "Epoch 635/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5634 - accuracy: 0.7166 - auc: 0.7808 - val_loss: 0.5874 - val_accuracy: 0.6958 - val_auc: 0.7584\n",
      "Epoch 636/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5678 - accuracy: 0.7014 - auc: 0.7750 - val_loss: 0.5874 - val_accuracy: 0.6958 - val_auc: 0.7585\n",
      "Epoch 637/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5617 - accuracy: 0.7055 - auc: 0.7822 - val_loss: 0.5878 - val_accuracy: 0.6974 - val_auc: 0.7578\n",
      "Epoch 638/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5656 - accuracy: 0.7151 - auc: 0.7822 - val_loss: 0.5885 - val_accuracy: 0.6974 - val_auc: 0.7567\n",
      "Epoch 639/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5638 - accuracy: 0.7126 - auc: 0.7812 - val_loss: 0.5875 - val_accuracy: 0.6990 - val_auc: 0.7582\n",
      "Epoch 640/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5678 - accuracy: 0.7019 - auc: 0.7752 - val_loss: 0.5876 - val_accuracy: 0.6974 - val_auc: 0.7578\n",
      "Epoch 641/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5632 - accuracy: 0.7136 - auc: 0.7804 - val_loss: 0.5877 - val_accuracy: 0.6974 - val_auc: 0.7577\n",
      "Epoch 642/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5606 - accuracy: 0.7110 - auc: 0.7829 - val_loss: 0.5876 - val_accuracy: 0.6958 - val_auc: 0.7577\n",
      "Epoch 643/700\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.5623 - accuracy: 0.7171 - auc: 0.7828 - val_loss: 0.5871 - val_accuracy: 0.6974 - val_auc: 0.7586\n",
      "Epoch 644/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5604 - accuracy: 0.7146 - auc: 0.7863 - val_loss: 0.5872 - val_accuracy: 0.6990 - val_auc: 0.7588\n",
      "Epoch 645/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5681 - accuracy: 0.7055 - auc: 0.7763 - val_loss: 0.5874 - val_accuracy: 0.6958 - val_auc: 0.7579\n",
      "Epoch 646/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5634 - accuracy: 0.7065 - auc: 0.7808 - val_loss: 0.5869 - val_accuracy: 0.6990 - val_auc: 0.7591\n",
      "Epoch 647/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5673 - accuracy: 0.7115 - auc: 0.7786 - val_loss: 0.5880 - val_accuracy: 0.6926 - val_auc: 0.7574\n",
      "Epoch 648/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5674 - accuracy: 0.7070 - auc: 0.7779 - val_loss: 0.5870 - val_accuracy: 0.6990 - val_auc: 0.7588\n",
      "Epoch 649/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5627 - accuracy: 0.7090 - auc: 0.7815 - val_loss: 0.5867 - val_accuracy: 0.6990 - val_auc: 0.7594\n",
      "Epoch 650/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5698 - accuracy: 0.7004 - auc: 0.7750 - val_loss: 0.5869 - val_accuracy: 0.6958 - val_auc: 0.7592\n",
      "Epoch 651/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5635 - accuracy: 0.7090 - auc: 0.7811 - val_loss: 0.5875 - val_accuracy: 0.6926 - val_auc: 0.7583\n",
      "Epoch 652/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5696 - accuracy: 0.7045 - auc: 0.7758 - val_loss: 0.5869 - val_accuracy: 0.6958 - val_auc: 0.7590\n",
      "Epoch 653/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5634 - accuracy: 0.7115 - auc: 0.7824 - val_loss: 0.5863 - val_accuracy: 0.6990 - val_auc: 0.7600\n",
      "Epoch 654/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5648 - accuracy: 0.7070 - auc: 0.7799 - val_loss: 0.5868 - val_accuracy: 0.6974 - val_auc: 0.7590\n",
      "Epoch 655/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5627 - accuracy: 0.7090 - auc: 0.7833 - val_loss: 0.5864 - val_accuracy: 0.6990 - val_auc: 0.7601\n",
      "Epoch 656/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5634 - accuracy: 0.6984 - auc: 0.7792 - val_loss: 0.5868 - val_accuracy: 0.6990 - val_auc: 0.7592\n",
      "Epoch 657/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5611 - accuracy: 0.6964 - auc: 0.7815 - val_loss: 0.5867 - val_accuracy: 0.6974 - val_auc: 0.7595\n",
      "Epoch 658/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5624 - accuracy: 0.7176 - auc: 0.7816 - val_loss: 0.5872 - val_accuracy: 0.6926 - val_auc: 0.7584\n",
      "Epoch 659/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5561 - accuracy: 0.7151 - auc: 0.7892 - val_loss: 0.5870 - val_accuracy: 0.6958 - val_auc: 0.7590\n",
      "Epoch 660/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5610 - accuracy: 0.7014 - auc: 0.7826 - val_loss: 0.5873 - val_accuracy: 0.6942 - val_auc: 0.7580\n",
      "Epoch 661/700\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5629 - accuracy: 0.7115 - auc: 0.7806 - val_loss: 0.5874 - val_accuracy: 0.6974 - val_auc: 0.7581\n",
      "Epoch 662/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5652 - accuracy: 0.7024 - auc: 0.7763 - val_loss: 0.5874 - val_accuracy: 0.6974 - val_auc: 0.7584\n",
      "Epoch 663/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5689 - accuracy: 0.7095 - auc: 0.7760 - val_loss: 0.5859 - val_accuracy: 0.7006 - val_auc: 0.7611\n",
      "Epoch 664/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5597 - accuracy: 0.7146 - auc: 0.7863 - val_loss: 0.5880 - val_accuracy: 0.6974 - val_auc: 0.7574\n",
      "Epoch 665/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5661 - accuracy: 0.7065 - auc: 0.7777 - val_loss: 0.5867 - val_accuracy: 0.6974 - val_auc: 0.7594\n",
      "Epoch 666/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5633 - accuracy: 0.7055 - auc: 0.7817 - val_loss: 0.5857 - val_accuracy: 0.6990 - val_auc: 0.7611\n",
      "Epoch 667/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5620 - accuracy: 0.7126 - auc: 0.7821 - val_loss: 0.5863 - val_accuracy: 0.6990 - val_auc: 0.7605\n",
      "Epoch 668/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5618 - accuracy: 0.7176 - auc: 0.7845 - val_loss: 0.5882 - val_accuracy: 0.6942 - val_auc: 0.7570\n",
      "Epoch 669/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5642 - accuracy: 0.7029 - auc: 0.7800 - val_loss: 0.5864 - val_accuracy: 0.6990 - val_auc: 0.7600\n",
      "Epoch 670/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5635 - accuracy: 0.7181 - auc: 0.7813 - val_loss: 0.5870 - val_accuracy: 0.6942 - val_auc: 0.7586\n",
      "Epoch 671/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5568 - accuracy: 0.7085 - auc: 0.7877 - val_loss: 0.5853 - val_accuracy: 0.7006 - val_auc: 0.7616\n",
      "Epoch 672/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5613 - accuracy: 0.7120 - auc: 0.7855 - val_loss: 0.5854 - val_accuracy: 0.6974 - val_auc: 0.7610\n",
      "Epoch 673/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5668 - accuracy: 0.7075 - auc: 0.7763 - val_loss: 0.5854 - val_accuracy: 0.6974 - val_auc: 0.7608\n",
      "Epoch 674/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5619 - accuracy: 0.7105 - auc: 0.7817 - val_loss: 0.5860 - val_accuracy: 0.6942 - val_auc: 0.7599\n",
      "Epoch 675/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5617 - accuracy: 0.7161 - auc: 0.7838 - val_loss: 0.5859 - val_accuracy: 0.6974 - val_auc: 0.7600\n",
      "Epoch 676/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5623 - accuracy: 0.7100 - auc: 0.7809 - val_loss: 0.5857 - val_accuracy: 0.6958 - val_auc: 0.7606\n",
      "Epoch 677/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5614 - accuracy: 0.7206 - auc: 0.7858 - val_loss: 0.5860 - val_accuracy: 0.6958 - val_auc: 0.7600\n",
      "Epoch 678/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5632 - accuracy: 0.7105 - auc: 0.7819 - val_loss: 0.5846 - val_accuracy: 0.7006 - val_auc: 0.7626\n",
      "Epoch 679/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5615 - accuracy: 0.7146 - auc: 0.7830 - val_loss: 0.5863 - val_accuracy: 0.6942 - val_auc: 0.7596\n",
      "Epoch 680/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5575 - accuracy: 0.7090 - auc: 0.7867 - val_loss: 0.5854 - val_accuracy: 0.6958 - val_auc: 0.7607\n",
      "Epoch 681/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5616 - accuracy: 0.7131 - auc: 0.7841 - val_loss: 0.5845 - val_accuracy: 0.7006 - val_auc: 0.7624\n",
      "Epoch 682/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5597 - accuracy: 0.7050 - auc: 0.7836 - val_loss: 0.5845 - val_accuracy: 0.7006 - val_auc: 0.7627\n",
      "Epoch 683/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5611 - accuracy: 0.7161 - auc: 0.7840 - val_loss: 0.5851 - val_accuracy: 0.6990 - val_auc: 0.7615\n",
      "Epoch 684/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5594 - accuracy: 0.7100 - auc: 0.7844 - val_loss: 0.5855 - val_accuracy: 0.6958 - val_auc: 0.7606\n",
      "Epoch 685/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5654 - accuracy: 0.7060 - auc: 0.7798 - val_loss: 0.5849 - val_accuracy: 0.7006 - val_auc: 0.7621\n",
      "Epoch 686/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5604 - accuracy: 0.7029 - auc: 0.7833 - val_loss: 0.5855 - val_accuracy: 0.6958 - val_auc: 0.7604\n",
      "Epoch 687/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5595 - accuracy: 0.7120 - auc: 0.7853 - val_loss: 0.5845 - val_accuracy: 0.7006 - val_auc: 0.7624\n",
      "Epoch 688/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5582 - accuracy: 0.7171 - auc: 0.7893 - val_loss: 0.5860 - val_accuracy: 0.6942 - val_auc: 0.7601\n",
      "Epoch 689/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5659 - accuracy: 0.7024 - auc: 0.7772 - val_loss: 0.5857 - val_accuracy: 0.6958 - val_auc: 0.7603\n",
      "Epoch 690/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5649 - accuracy: 0.7196 - auc: 0.7808 - val_loss: 0.5861 - val_accuracy: 0.6942 - val_auc: 0.7600\n",
      "Epoch 691/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5657 - accuracy: 0.7100 - auc: 0.7780 - val_loss: 0.5859 - val_accuracy: 0.6958 - val_auc: 0.7600\n",
      "Epoch 692/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5591 - accuracy: 0.7146 - auc: 0.7852 - val_loss: 0.5853 - val_accuracy: 0.6974 - val_auc: 0.7607\n",
      "Epoch 693/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5657 - accuracy: 0.7070 - auc: 0.7797 - val_loss: 0.5845 - val_accuracy: 0.6990 - val_auc: 0.7623\n",
      "Epoch 694/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5581 - accuracy: 0.7141 - auc: 0.7873 - val_loss: 0.5849 - val_accuracy: 0.6958 - val_auc: 0.7612\n",
      "Epoch 695/700\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.5641 - accuracy: 0.7141 - auc: 0.7815 - val_loss: 0.5837 - val_accuracy: 0.7006 - val_auc: 0.7633\n",
      "Epoch 696/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5596 - accuracy: 0.7156 - auc: 0.7865 - val_loss: 0.5838 - val_accuracy: 0.6974 - val_auc: 0.7631\n",
      "Epoch 697/700\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.5676 - accuracy: 0.7141 - auc: 0.7794 - val_loss: 0.5829 - val_accuracy: 0.7006 - val_auc: 0.7648\n",
      "Epoch 698/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5589 - accuracy: 0.7120 - auc: 0.7870 - val_loss: 0.5833 - val_accuracy: 0.6974 - val_auc: 0.7640\n",
      "Epoch 699/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5634 - accuracy: 0.7136 - auc: 0.7806 - val_loss: 0.5846 - val_accuracy: 0.6990 - val_auc: 0.7618\n",
      "Epoch 700/700\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5621 - accuracy: 0.7166 - auc: 0.7845 - val_loss: 0.5849 - val_accuracy: 0.6958 - val_auc: 0.7617\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('surprised_ravdess_meld.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1596315545011,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1516,
     "status": "ok",
     "timestamp": 1596315556817,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "7df3f762-ec3f-4d71-d71b-3ff1ffbd4692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5829474925994873\n",
      "accuracy :  0.700647234916687\n",
      "auc :  0.7647947669029236\n",
      "\n",
      "(True Negatives):  298\n",
      "(False Positives):  111\n",
      "(False Negatives):  74\n",
      "(True Positives):  135\n",
      "Total emotions_happy:  209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76       409\n",
      "           1       0.55      0.65      0.59       209\n",
      "\n",
      "    accuracy                           0.70       618\n",
      "   macro avg       0.67      0.69      0.68       618\n",
      "weighted avg       0.72      0.70      0.71       618\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('surprised_ravdess_meld.hdf5')\n",
    "test_predictions_baseline = model.predict(X_test)\n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1521,
     "status": "ok",
     "timestamp": 1596315571814,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "f3af1fc9-6bfe-4d50-cb77-08f729f2c19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5716212391853333\n",
      "accuracy :  0.7186234593391418\n",
      "auc :  0.7717835903167725\n",
      "\n",
      "(True Negatives):  234\n",
      "(False Positives):  88\n",
      "(False Negatives):  51\n",
      "(True Positives):  121\n",
      "Total emotions_happy:  172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       322\n",
      "           1       0.58      0.70      0.64       172\n",
      "\n",
      "    accuracy                           0.72       494\n",
      "   macro avg       0.70      0.72      0.70       494\n",
      "weighted avg       0.74      0.72      0.72       494\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAFNCAYAAAB1+2ZJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxd873/8dc7CZHEGMI1BNEmIfrTRFGlNGqoqU2pKVw1By3a0lbRa6re6q1eFNVGjVUx1KwETUtMcQUpIpHBUBlEJIgMIsn5/P5Y3xM7xxn22dn77LPPej891iNrfdfw/e59nM/5Dmt9lyICM7M861TtApiZVZsDoZnlngOhmeWeA6GZ5Z4DoZnlngOhmeWeA6GZ5Z4DYTskqZuk+yV9KOmOlbjOEZIeKWfZqkXSLpJeq3Y5rGNyIFwJkg6XNFbSfEkzJT0k6atluPRBwAbAuhFxcKkXiYi/RMReZShPRUkKSZ9v7piIeCIi+q9kPnulPzDvSJot6UlJx0rq1OC4npLulrRA0luSDm/mmudLWpL+H6hftijYP1DS85IWpn8HrsxnsMpwICyRpNOBy4D/JgtamwK/B4aU4fKbAZMiYmkZrlXzJHUpwzX+h+xn9SdgS+A/gFOArwMPSOpacPhVwCdkP9cjgKslbd3M5W+LiNULltdTnqsC9wI3A+sANwL3pnRrTyLCSysXYC1gPnBwM8d0JQuUM9JyGdA17RsMTAPOAN4FZgLHpH0XkP0SLkl5HAecD9xccO3NgQC6pO2jgdeBj4A3gCMK0p8sOG8n4Dngw/TvTgX7HgN+ATyVrvMIsF4Tn62+/D8tKP+3gX2BScBc4OyC43cAngE+SMdeCaya9o1On2VB+ryHFlz/TOAd4M/1aemcz6U8tk3bGwGzgcFNlPe76fN0bWL/b4Bz03qP9P33K9j/Z+DiJs5d4WfTYN9ewHRABWn/Bvau9v/DXhr8rKpdgFpcgL2BpfWBqIljLgTGAOsDvYCngV+kfYPT+RcCq6QAshBYJ+1vGPiaDITpF3ce0D/t2xDYOq0vD4RAT+B94Mh03tC0vW7a/xgwFegHdEvbTf3y15f/3FT+E1IgugVYA9gaWAT0Scd/Cdgx5bs5MAH4YcH1Avh8I9f/NdkflG6FgTAdcwLwKtAdeBi4pJmfxWSgd1r/NVlwfQG4NH0f3YCpaf8gYGGD838M3N/Etc8n+8MyFxgPnFyw70fAQw2OfwA4o9r/D3tZcXHTuDTrAu9F803XI4ALI+LdiJhNVtM7smD/krR/SUQ8SFYbKrUPrA74gqRuETEzIsY3csx+wOSI+HNELI2IEcBE4JsFx1wfEZMiYhFwO9Bcf9YS4JcRsQS4FVgPuDwiPkr5vwp8ESAino+IMSnfN4E/Al8r4jOdFxGLU3lWEBHXAFOAZ8mC/zmNXST1Pc6IiLcl7QPsA2xD9sdsd6Bzuv5cSesBq5P9YSn0IVmAb8ztwFZkf+xOAM6VNDTtWz2dW+y1rEocCEszB1ivhb6rjYC3CrbfSmnLr9EgkC4k+8VplYhYQNacPAmYKelvkrYsojz1Zdq4YPudVpRnTkQsS+v1gWpWwf5F9edL6ifpgTRIMY+sr269Zq4NMDsiPm7hmGuALwBXRMTiJo5Zn6x5CvD/gJHpj9O7wMhUvk5kfXhzyf4grdngGmuSdRd8RkS8GhEzImJZRDwNXE422EVrr2XV40BYmmeAxWT9Yk2ZQTboUW/TlFaKBWRNwHr/UbgzIh6OiD3JakYTyQJES+WpL9P0Ro4tt6vJytU3ItYEzgbUwjnNzg8naXWyftdrgfMl9Wzi0PfIvheAl4FvSFpf0vpktcIewK+AByOijqyPs4ukvgXX+CJZs7cYwaefbTywjaTCz7pNK65lbcSBsAQR8SFZ/9hVkr4tqbukVSTtk0YnAUYAP5fUKzW5ziUbPSzFOGBXSZtKWgs4q36HpA0kDZHUgyw4zydrVjb0INAv3fLTRdKhwACyPqtKW4OsuTk/1VZPbrB/FrDFZ85q3uXA2Ig4Hvgb8IfGDoqISUBvSRtGxENktcB/AfeRDdScTFZD+3E6fgFwF3ChpB6Sdia7E+DPjV0/fffrKLMDcBrZSDFk/azLgNMkdZV0Skr/Rys/q1VatTspa3kh6wccS1Zje4fsF3KntG814Hdko6Qz0/pqad9gCjr+U9qbwB5p/XwajESS3dLxAVm/2Al8OliyIfA4Wd/TB2S/fAPSOUez4qjxV4Hn07HPA18t2PcYcHzB9grnNijLCuVP5Qhg84K0J4H/TOu7ktUI5wNPkA0SFZbrpPQdfQAc0sT3szyNLDBNB3qm7dXT93JEE+Udln42nxncaiKtJ3BP+rn+Gzi8YN8uwPyC7RFkXSXz02c8rcG1BqXvehHZAM2gav9/6+Wzi9IPy6xDk3QlWRP3XLKujU5kt7dcBOwXEQ37Ty1HHAgtNyQdAHyfNJpNdkvTryMb5LAccyA0s9zzYImZ5Z4DoZnl3ko/zF4pS9573W32GnXgtqdVuwi2Eu7/9wMt3ePZqFJ/Z1dZb4uS8isn1wjNLPfabY3QzGpM3bKWj2mnHAjNrDyisQeaaoMDoZmVR50DoZnlXLhGaGa55xqhmeWea4RmlnseNTaz3KvhGqFvqDaz8qirK21pgaTekv4p6VVJ4yX9IKX/RtJESS+l91CvndI3l7RI0ri0NDppbyHXCM2sLCo4aryU7M1/L0haA3he0qPAo8BZEbFU0q/JZm4/M50zNSKae/nYChwIzaw8KjRqHBH1s7wTER9JmgBsHBGPFBw2hk9fmtVqbhqbWXlEXUmLpGGSxhYsw5rKQtLmZK8/eLbBrmOBhwq2+0h6UdLjknZpqeiuEZpZeZQ4ahwRw4HhLR2X3lx4J/DDiJhXkH4OWfP5LylpJrBpRMyR9CXgHklbF57TkAOhmZVHBUeNJa1CFgT/EhF3FaQfDewP7B5puv3I3nG9OK0/L2kq0I/sRWuNciA0s/KoUB9hei/0tcCEiPjfgvS9gZ8CX4uIhQXpvYC5EbFM0hZAX+D15vJwIDSz8qhcjXBn4EjgZUnjUtrZZK/I7Qo8msVKxkTESWSvj71Q0hKyd3yfFBFzm8vAgdDM2rWIeBJobBbrB5s4/k6yZnTRHAjNrDw86YKZ5V2EnzU2s7yr4WeNHQjNrDzcNDaz3HON0Mxyz/MRmlnuuUZoZrnnPkIzyz3XCM0s91wjNLPccyA0s7zzkyVmZq4RmlnuebDEzHLPNUIzy70arhH6LXZmlnuuEZpZebhpbGa5V8NNYwdCMysP1wjNLPccCM0s99w0NrPcc43QzHLPNUIzyz3XCM0s91wjNLPcc43QzHKvhgOhnzU2s/KIKG1pgaTekv4p6VVJ4yX9IKX3lPSopMnp33VSuiT9TtIUSS9J2ralPBwIzaw86upKW1q2FDgjIgYAOwLflzQA+BkwKiL6AqPSNsA+QN+0DAOubikDB0IzK48KBcKImBkRL6T1j4AJwMbAEODGdNiNwLfT+hDgpsiMAdaWtGFzeTgQmll5RF1Ji6RhksYWLMOaykLS5sAg4Flgg4iYmXa9A2yQ1jcG3i44bVpKa5IHS8ysPEocLImI4cDwlo6TtDpwJ/DDiJgnqfAaIanlDscmuEZoZu2epFXIguBfIuKulDyrvsmb/n03pU8HehecvklKa5IDoZmVR+VGjQVcC0yIiP8t2HUfcFRaPwq4tyD9u2n0eEfgw4ImdKPcNDaz8qjcfYQ7A0cCL0sal9LOBi4Gbpd0HPAWcEja9yCwLzAFWAgc01IGDoRmVh4VCoQR8SSgJnbv3sjxAXy/NXk4EJpZefhZYzPLu6gredC26hwIzaw8avhZYwdCMysPN43NLPfcNDaz3HPT2Mxyz4HQCs2cNZuzf3EJc95/HyEOGrIPRx7yba4YfhP/ePIZOqkTPddZi1+ecwbr91p3+XkvT3iN/zzxdH5zwc/Ya7ddqvgJrNCQ44aw19C9iIA3J77J5T++jK22G8CxZx+DOnXi44WLuOz0y5j5VrMPL3R8RTwl0l45EFZAl86d+cmpJzCg/+dZsGAhhxx3GjttP4hjjvgOpw77LgA333EvV19/C+f99FQAli1bxqW/v56dtm9xDklrQz03WJdvHvNNvrf79/hk8Sec+fsz2fWbu3LwKYdw0fG/YNqUaex75L4cetqhXHbGZdUubnW5RvhZkrYkmxesfvqb6cB9ETGhUnm2F73W60mv9XoC0KNHd7bYrDezZs/hc302W37MokUfUzB5Brf89T72HLwzr0yY1NbFtRZ06tKZVVdblaVLl9K1W1fmzppLRNB99e4AdF+zB3Nmza1yKdsBD5asSNKZwFDgVuD/UvImwAhJt0bExZXItz2aPnMWEyZPZZut+wNw+R9v4L6Ro1ijRw+uuyL7GmbNfo9Ro5/muit+7UDYzsydNYe7h9/NdWOu55OPP+HF0S/y4hMvcsWZV3DejefzycefsHD+Qn485IxqF7X6avj2mUrNPnMcsH1EXBwRN6flYmCHtC8XFi5cxI/OuYgzTzuR1Xv0AOAHJx7NqLv/zH577cYtd94PwK8v/yM/OvlYOnXyZEDtTY+1evDlPb/M8Tsfx1Hbf5fVundl8AGDGXLcEC446nyO+fLR/P32v3P8fx1f7aJWX12UtrQDlfrNqwM2aiR9w7SvUYUz1f7pphEVKlrbWLJ0KT885yL222s39hy882f277/Xbvz9sacAGD9xMj8572L2+s5RPPLYk1x0yVWMGv10WxfZGjHwqwOZ9fYs5s2dx7Kly3h65DNstd0A+gzow6RxWe39yfufYMvttqpySasv6upKWtqDSvUR/hAYJWkyn06ZvSnweeCUpk4qnKl2yXuvt48/FSWICM791WVssVlvjjrswOXpb709nc16Z12m/3jiGfpstgkAD//1huXHnHPRb/nazjuw+647tWmZrXGzp89my23703W1riz+eDFf3PmLTHlpMl/db2c26rMRM96YwcBdBjJt8tstX8zarYoEwogYKakfWVO4cLDkuYhYVok825MXXxrP/SNH0fdzm/Odo7LZgH5w4lHc9cAjvPnvaaiT2Og/1ufcn5xa5ZJaSyaNm8RTDz7FZQ9exrJldbw+fiojbxnJezPncNYfzybqgvkfzufyn+R8xBjaTTO3FIp2eu9PLdcI8+7AbU+rdhFsJdz/7weamvuvWQsu+s+Sfmd7/PzmkvIrJ99HaGblUcM1QgdCMyuPdjLwUQoHQjMrD9cIzSz3aviGagdCMysP1wjNLO/ay83RpXAgNLPycI3QzHLPgdDMcs+DJWaWe64Rmlne+QXvZmYOhGaWexW6fUbSdcD+wLsR8YWUdhvQPx2yNvBBRAyUtDkwAXgt7RsTESe1lIcDoZmVR+VqhDcAVwI31SdExKH165J+C3xYcPzUiBjYmgwcCM2sPCoUCCNidKrpfYYkAYcAX1+ZPPySDDOrZbsAsyJickFaH0kvSnpcUlEvCHeN0MzKotRJniUNA4YVJA1Pr+0oxlCg8AVHM4FNI2KOpC8B90jaOiLmNXcRB0IzK48Sm8aF7ypqDUldgAOBLxVcazGwOK0/L2kq0A8Y29y1HAjNrDza/vaZPYCJETGtPkFSL2BuRCyTtAXQF3i9pQu5j9DMyiLqoqSlJZJGAM8A/SVNk1T/bvTDWLFZDLAr8JKkccBfgZMiYm5LebhGaGblUblR46FNpB/dSNqdwJ2tzcOB0MzKo3bnXHAgNLPy8LPGZmYOhGaWe24am1neuWlsZuYaoZnlnWuEZmauEZpZ3tXwu5scCM2sTBwIzSzvarlG6EkXzCz3XCM0s/Ko4RqhA6GZlUUtN40dCM2sLBwIzSz3OmQglPQRUH+ruNK/kdYjItascNnMrJaEWj6mnWoyEEbEGm1ZEDOrbR2yRlhI0leBvhFxvaT1gDUi4o3KFs3MaknUdcAaYT1J5wHbAf2B64FVgZuBnStbNDOrJR29RngAMAh4ASAiZkhys9nMVhAdsY+wwCcREZICQFKPCpfJzGpQR68R3i7pj8Dakk4AjgWuqWyxzKzWdOg+woi4RNKewDygH3BuRDxa8ZKZWU2J2p2Xtegbql8GupHdR/hy5YpjZrWqlmuELc4+I+l44P+AA4GDgDGSjq10wcystkSdSlrag2JqhD8BBkXEHABJ6wJPA9dVsmBmVls6etN4DvBRwfZHKc3MbLn2UrsrRZNNY0mnSzodmAI8K+n8dHP1GGBSWxXQzPJN0nWS3pX0SkHa+ZKmSxqXln0L9p0laYqk1yR9o5g8mqsR1t80PTUt9e5tzYcws3yo4A3VNwBXAjc1SL80Ii4pTJA0ADgM2BrYCPi7pH4Rsay5DJqbdOGCUkpsZvlUqRuqI2K0pM2LPHwIcGtELAbekDQF2AF4prmTinnWuBfwU7IIu1pB4b5eZMHMLAfq2v4Ru1MkfRcYC5wREe8DG5N139WbltKaVczLm/4CTAT6ABcAbwLPtbLAZtbBRaikRdIwSWMLlmFFZHc18DlgIDAT+O3KlL2YUeN1I+JaST+IiMeBxyU5EJrZCkodNY6I4cDwVp4zq35d0jXAA2lzOtC74NBNUlqziqkRLkn/zpS0n6RBQM/iimtmeRFR2lIKSRsWbB4A1I8o3wccJqmrpD5AX7IHQppVTI3wIklrAWcAVwBrAj9qVanNrMOr1H2EkkYAg4H1JE0DzgMGSxpI9tjvm8CJABExXtLtwKvAUuD7LY0YQ3GTLtRXOT8Edmv9xzCzPKjUYElEDG0k+dpmjv8l8MvW5NHcy5uu4NOXNzWW2WmtycjMOraOOjHr2DYrhZnVvA75rHFE3NiWBTGz2laF+wjLxi94N7Oy6KhNYzOzonXIpnG1ddtol2oXwUp01fq+uSCPOmTT2KPGZtYaHbVp7FFjMytah6wRetTYzPKi2Gm4zgQG4Gm4zKwJNTxWUvQ0XBPwNFxm1oy6UElLe1BMIFw3Iq4FlkTE4xFxLODaoJmtoNT5CNuDYm6fWWEaLmAGnobLzBqo0Ez9bcLTcJlZWQTto3ZXCk/DZWZlUVfDoyXFjBpfTyMDQqmv0MwMgLqOXCPk03cBQHb7zAFk/YRmZst19KbxnYXbadrsJytWIjOrSR19sKShvsD65S6ImdW2Dl0jlPQRK/YRvkP2pImZ2XIdukYYEWu0RUHMrLbVciBs8ckSSaOKSTOzfAtU0tIeNDcf4WpAd7J3ia4Dy0u8JrBxG5TNzGpIhV5r3CaaaxqfCPwQ2Ah4nk8D4TzgygqXy8xqTIe8jzAiLgcul3RqRFzRhmUysxpUww+WFDX7TJ2ktes3JK0j6XsVLJOZWZsqJhCeEBEf1G9ExPvACZUrkpnVoroSl/agmBuqO0tSRPayPkmdgVUrWywzqzV1qt0+wmJqhCOB2yTtLml3YERKMzNbLkpcWiLpOknvSnqlIO03kiZKeknS3fXdd5I2l7RI0ri0/KGYshcTCM8E/gGcnJZRwE+KubiZ5UcFm8Y3AHs3SHsU+EJEbANMAs4q2Dc1Igam5aRiMmgxEEZEXUT8ISIOioiDgFfJJmg1M1uuTqUtLYmI0cDcBmmPRMTStDkG2GRlyl5MjRBJgyT9j6Q3gQuBiSuTqZl1PHWopKUMjgUeKtjuI+lFSY9L2qWYCzT3ZEk/YGha3gNuAxQRnqXazD6j1PsIJQ0DhhUkDY+I4UWeew6wlOxtmwAzgU0jYo6kLwH3SNo6IuY1d53mRo0nAk8A+0fElJSp31ViZo0q9RG7FPSKCnyFJB0N7A/sXn9XS0QsBhan9eclTQX6AWObu1ZzTeMDyaLrPyVdk0aMa3d83Mwqqi3vI5S0N/BT4FsRsbAgvVe6xQ9JW5DNn/p6S9drMhBGxD0RcRiwJfBPsueO15d0taS9Siy/mXVQFbx9ZgTwDNBf0jRJx5HNd7AG8GiD22R2BV6SNA74K3BSRMxt9MIFipmPcAFwC3BLmoXmYLJbah4p4jOYWU5UavaZiBjaSPK1TRx7J3BnY/uaU9SocUEm70fE8IjYvbUZmVnH1tEfsTMza1F7CWqlcCA0s7KIGh5KdSA0s7JwjdDMcs+B0Mxyr6PPUG1m1qG5RmhmZdFR32JnZlY09xGaWe45EJpZ7tXyYIkDoZmVhfsIzSz33DQ2s9xz09jMcq+uhkOhA6GZlYWbxmaWe7VbH3QgNLMycY3QzHLPt8+YWe55sMTMcq92w6ADoZmVifsIzSz3arlp7IlZzSz3XCM0s7Ko3fqgA6GZlYn7CM0s92q5j9CB0MzKonbDoAdLzKxM6kpcWiLpOknvSnqlIK2npEclTU7/rpPSJel3kqZIeknStsWU3YHQzMoiSvyvCDcAezdI+xkwKiL6AqPSNsA+QN+0DAOuLiYDB0IzK4tK1QgjYjQwt0HyEODGtH4j8O2C9JsiMwZYW9KGLeXhPkIzK4s2HizZICJmpvV3gA3S+sbA2wXHTUtpM2mGA2EbmDJpDB/Nn8+yZXUsXbqUHb+yL9/5zv6c+1+ns9WWffnKTvvx/AsvVbuYlnztkhPYbI+BLHpvHnfscRYAO/58KJvuMYi6JUuZ99a7PHb6cD6Zt5Cua6/OnsNPY/0vbsFrd4zmqZ/fVOXSV0+pYVDSMLJmbL3hETG86HwjQtJKRWEHwjayx54HM2fO+8u3x4+fyMGHnMDVV11cxVJZYybdMZrxNzzKbpeduDxt2uiXefZXtxHL6vjy2Ycy6JRv8ux/38ayxUsY+5u/sk7/Tei55SZVLHX1lVojTEGv6MCXzJK0YUTMTE3fd1P6dKB3wXGbpLRmuY+wSiZOnMKkSVOrXQxrxMxnX+PjD+avkDZt9CvEsqxHa9YLU+mxYU8Ali5azDvPTWLZ4iVtXs72plJ9hE24DzgqrR8F3FuQ/t00erwj8GFBE7pJbR4IJR3T1nlWW0Tw0IMjeHbMQxx/3BHVLo6tpC0P3ZW3/+mujIYqNWosaQTwDNBf0jRJxwEXA3tKmgzskbYBHgReB6YA1wDfK6bs1WgaXwBcX4V8q+Zrux3AjBnv0KvXuox86FZee20KTzz5bLWLZSUYdOq3qFtWx+S7nqp2UdqdSj1iFxFDm9i1eyPHBvD91uZRkUAoqak/l+LT0Z3GzlveaarOa9GpU48KlK7tzZjxDgCzZ8/h3nsfYvvtBzoQ1qB+B+/CZnsM4oFDf1XtorRLRd4T2C5Vqka4AfAN4P0G6QKebuqkwk7TLqtuXLvfaoHu3bvRqVMn5s9fQPfu3dhzj69x0S8vrXaxrJV6D96GgSfvz30HXcTSjz+pdnHaJU+68FkPAKtHxLiGOyQ9VqE826UNNujFX++4FoAuXTpz66338PAjjzFkyN5cfulF9OrVk/vuvYl//Ws8++7v/sP2YPcrv8+GX9mK1XquzhHP/Y6xv72TQad8i86rdmG/EdkDDO++MIUnzsp6eA5/5lJWWaMbnVfpwubf2I6/HX4xH0yeUc2PUBV1Ubt1F0U7LXxHqRHm0VXr71btIthKOHHazSW9j+7IzQ4s6Xf2z2/dVfX33/k+QjMri1quuTgQmllZeD5CM8s9jxqbWe551NjMcs9NYzPLPTeNzSz33DQ2s9xrr/ckF8OB0MzKwn2EZpZ7bhqbWe55sMTMcs9NYzPLPQ+WmFnuuY/QzHLPfYRmlnu13Efo13maWe65RmhmZeHBEjPLvVpuGjsQmllZeLDEzHKvlt9i50BoZmVRu2HQgdDMysR9hGaWew6EZpZ7lbp9RlJ/4LaCpC2Ac4G1gROA2Sn97Ih4sJQ8HAjNrCwqVSOMiNeAgQCSOgPTgbuBY4BLI+KSlc3DgdDMyqKNbp/ZHZgaEW9JKttF/YidmZVFRJS0tNJhwIiC7VMkvSTpOknrlFp2B0IzK4s6oqRF0jBJYwuWYY1dX9KqwLeAO1LS1cDnyJrNM4Hfllp2N43NrCxKHSyJiOHA8CIO3Qd4ISJmpfNm1e+QdA3wQEkFwIHQzMqkDW6fGUpBs1jShhExM20eALxS6oUdCM2sLCo5WCKpB7AncGJB8v9IGkj2UMubDfa1igOhmZVFJZ81jogFwLoN0o4s1/U9WGJmuecaoZmVhafhMrPc8zRcZpZ7rhGaWe65RmhmuecaoZnlnmuEZpZ7rhGaWe5F1FW7CCVzIDSzsvBU/WaWe5Waqr8tOBCaWVm4RmhmuecaoZnlnm+fMbPc8+0zZpZ7bhqbWe55sMTMcq+Wa4SeodrMcs81QjMrC48am1nu1XLT2IHQzMrCgyVmlnuuEZpZ7rmP0Mxyz0+WmFnuuUZoZrnnPkIzyz03jc0s91wjNLPccyA0s9yr3TAIquUoXsskDYuI4dUuh5XGP7+OxbPPVM+wahfAVop/fh2IA6GZ5Z4DoZnlngNh9bh/qbb559eBeLDEzHLPNUIzyz0HwiqQtLek1yRNkfSzapfHiifpOknvSnql2mWx8nEgbGOSOgNXAfsAA4ChkgZUt1TWCjcAe1e7EFZeDoRtbwdgSkS8HhGfALcCQ6pcJitSRIwG5la7HFZeDoRtb2Pg7YLtaSnNzKrEgdDMcs+BsO1NB3oXbG+S0sysShwI295zQF9JfSStChwG3FflMpnlmgNhG4uIpcApwMPABOD2iBhf3VJZsSSNAJ4B+kuaJum4apfJVp6fLDGz3HON0Mxyz4HQzHLPgdDMcs+B0Mxyz4HQzHLPgbCDkLRM0jhJr0i6Q1L3lbjWDZIOSut/am5SCEmDJe1UQh5vSlqv2PQGx8xvZV7nS/pxa8to+eFA2HEsioiBEfEF4BPgpMKdkkp6dWtEHB8RrzZzyGCg1YHQrD1xIOyYngA+n2prT0i6D3hVUmdJv5H0nKSXJJ0IoMyVaY7EvwPr119I0mOStkvre0t6QdK/JI2StDlZwP1Rqo3uIqmXpDtTHs9J2jmdu66kRySNl/QnQC19CEn3SHo+nTOswb5LU/ooSb1S2uckjUznPCFpy3J8mdbx+QXvHUyq+e0DjExJ2wJfiIg3UjD5MCK2l9QVeErSI8AgoD/Z/IgbAK8C1zW4bi/gGmDXdK2eETFX0h+A+RFxSTruFuDSiAmLosAAAAHiSURBVHhS0qZkT9BsBZwHPBkRF0raDyjmiYxjUx7dgOck3RkRc4AewNiI+JGkc9O1TyF7j8hJETFZ0peB3wNfL+FrtJxxIOw4ukkal9afAK4la7L+X0S8kdL3Arap7/8D1gL6ArsCIyJiGTBD0j8auf6OwOj6a0VEU3Py7QEMkJZX+NaUtHrK48B07t8kvV/EZzpN0gFpvXcq6xygDrgtpd8M3JXy2Am4oyDvrkXkYeZA2IEsioiBhQkpICwoTAJOjYiHGxy3bxnL0QnYMSI+bqQsRZM0mCyofiUiFkp6DFiticMj5ftBw+/ArBjuI8yXh4GTJa0CIKmfpB7AaODQ1Ie4IbBbI+eOAXaV1Ced2zOlfwSsUXDcI8Cp9RuS6gPTaODwlLYPsE4LZV0LeD8FwS3JaqT1OgH1tdrDyZrc84A3JB2c8pCkL7aQhxngQJg3fyLr/3shvXzoj2StgruByWnfTWSzq6wgImYDw8iaof/i06bp/cAB9YMlwGnAdmkw5lU+Hb2+gCyQjidrIv+7hbKOBLpImgBcTBaI6y0Adkif4evAhSn9COC4VL7x+BUIViTPPmNmuecaoZnlngOhmeWeA6GZ5Z4DoZnlngOhmeWeA6GZ5Z4DoZnlngOhmeXe/wegh6+WLaUb0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_predictions_baseline = model.predict(X_val)\n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM1Oc4y9c+Hcj+WsvPV9TDF",
   "collapsed_sections": [],
   "name": "deep_surprised_RAVDESS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
