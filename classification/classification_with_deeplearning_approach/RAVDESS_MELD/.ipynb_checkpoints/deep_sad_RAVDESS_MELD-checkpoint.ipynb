{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6581,
     "status": "ok",
     "timestamp": 1596193160538,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ymHSlukhKIF9",
    "outputId": "f99d3680-73c3-43da-9077-c81ee6339a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.7.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 5.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (2.1.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.18.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.16.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (4.4.2)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.15.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.48.0)\n",
      "Collecting soundfile>=0.9.0\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (49.1.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.14.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)\n",
      "Building wheels for collected packages: librosa\n",
      "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for librosa: filename=librosa-0.7.2-cp36-none-any.whl size=1612885 sha256=55e3f87ab8ab71bb7247399c33f3e916254052145aed3a430cadd4f28281bd3f\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/6e/d7/bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
      "Successfully built librosa\n",
      "Installing collected packages: soundfile, librosa\n",
      "  Found existing installation: librosa 0.6.3\n",
      "    Uninstalling librosa-0.6.3:\n",
      "      Successfully uninstalled librosa-0.6.3\n",
      "Successfully installed librosa-0.7.2 soundfile-0.10.3.post1\n"
     ]
    }
   ],
   "source": [
    "pip install librosa==0.7.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10002,
     "status": "ok",
     "timestamp": 1596026935548,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "sXnDmXR7RDr2",
    "outputId": "3b9dff36-3699-413b-8a0a-75f3af305685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10711,
     "status": "ok",
     "timestamp": 1596026954464,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Y04m-jvKRDsJ",
    "outputId": "ce46bb70-bae2-4985-8f6b-ee3fece0cc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
      "CPU (s):\n",
      "2.876127255\n",
      "GPU (s):\n",
      "0.1083209219999901\n",
      "GPU speedup over CPU: 26x\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()https://support.mozilla.org/fr/kb/comment-vider-le-cache-de-firefox\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24162,
     "status": "ok",
     "timestamp": 1596193268534,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l9EbbgJpzQDD",
    "outputId": "ffd7cfd2-833b-41ff-dda1-9e15272f289f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5427,
     "status": "ok",
     "timestamp": 1596193327425,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ltf4WKPCeyVR",
    "outputId": "b7b2b9af-10ee-47dd-e949-ec4f6def91a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praat-parselmouth\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7b/9fa1172a63b6277603d27bb5613559b5a8888f58e68c1698017b87b0061d/praat_parselmouth-0.3.3-cp36-cp36m-manylinux1_x86_64.whl (9.0MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0MB 4.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from praat-parselmouth) (1.18.5)\n",
      "Installing collected packages: praat-parselmouth\n",
      "Successfully installed praat-parselmouth-0.3.3\n"
     ]
    }
   ],
   "source": [
    "pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5475,
     "status": "ok",
     "timestamp": 1596193348936,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PNwtWyMXe_Qb",
    "outputId": "31a5df32-ac0a-4a91-c96b-bfc492d6dee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting essentia\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/cf/3c776d02b63fed7b0958bef2ce57b900870e2ac3f1fd8ffbb63f22d0e69e/essentia-2.1b6.dev234-cp36-cp36m-manylinux1_x86_64.whl (11.7MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7MB 4.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from essentia) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from essentia) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from essentia) (3.13)\n",
      "Installing collected packages: essentia\n",
      "Successfully installed essentia-2.1b6.dev234\n"
     ]
    }
   ],
   "source": [
    "pip install essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5892,
     "status": "ok",
     "timestamp": 1596193377578,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "B9TmOS9AFg61",
    "outputId": "1168fddd-76cf-4e5c-cb3f-285e248cc3a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "#Spafe for audio\n",
    "#import spafe\n",
    "import scipy.io.wavfile\n",
    "#import spafe.utils.vis as vis\n",
    "#from spafe.features.mfcc import mfcc, imfcc\n",
    "#from spafe.features.gfcc import gfcc\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1596193454324,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "QAD42F-CgYli",
    "outputId": "72dd7ea4-d9e0-4504-e8d4-ed5eb87a0007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "cd drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20224,
     "status": "ok",
     "timestamp": 1596193506067,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "eb472746-244c-407b-a743-106a035df9cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surprised/suprised_03-01-08-01-01-02-21_norm_o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy/happy_03-01-03-01-01-01-09_norm_outNoise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surprised/suprised_03-01-08-01-01-02-15_norm_o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry/angry_03-01-05-01-01-02-13_norm_outNoise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry/angry_03-01-05-02-01-01-14_norm_outNoise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio label\n",
       "0  surprised/suprised_03-01-08-01-01-02-21_norm_o...     0\n",
       "1  happy/happy_03-01-03-01-01-01-09_norm_outNoise...     0\n",
       "2  surprised/suprised_03-01-08-01-01-02-15_norm_o...     0\n",
       "3  angry/angry_03-01-05-01-01-02-13_norm_outNoise...     0\n",
       "4  angry/angry_03-01-05-02-01-01-14_norm_outNoise...     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"fusion_data\"\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i.startswith(\"sad\"):\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) # here at df defined, with the columns we add the values:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1596193551631,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "cb08e280-8dbd-4eb5-bd78-4598c5bd697b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1992\n",
      "1     296\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1596193628040,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1596194110762,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "AjNAMwsfG2C8"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    fs, sig = scipy.io.wavfile.read(audio_path) \n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    spec =  fram_window(audio_path) \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)\n",
    "            \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "               \n",
    "    #gfccs = gfcc(sig= spec, fs=fs, num_ceps=13)    \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    #features.append(np.mean(gfccs))\n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4527029,
     "status": "ok",
     "timestamp": 1596198712084,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "folder ='fusion_data'\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(folder+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1596198832188,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "db152c1a-515c-4a42-8324-770d7a3d0b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1596198853714,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1596198871865,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1596198895428,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "1a3faf77-7790-4e2c-e8a3-11cbf5e16231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 1162\n",
      "After OverSampling, counts of label '0': 1992\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \" [1, 3, 4, 8, 15, 17]    \" are deleted 997 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48360,
     "status": "ok",
     "timestamp": 1596198969254,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "3593d270-4b44-4749-f5e4-673be737d1ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 4, 8, 15, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 3, 4, 8, 15, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 3, 4, 8, 15, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 3, 4, 8, 15, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 3, 4, 8, 15, 17]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration             X_removed\n",
       "0         1  [1, 3, 4, 8, 15, 17]\n",
       "1         2  [1, 3, 4, 8, 15, 17]\n",
       "2         3  [1, 3, 4, 8, 15, 17]\n",
       "3         4  [1, 3, 4, 8, 15, 17]\n",
       "4         5  [1, 3, 4, 8, 15, 17]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 8, 15, 17]    997\n",
       "[1, 3, 4, 8]              3\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1596199449768,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6sTQj5wDWdev"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0], X[i][2], X[i][5], X[i][6], X[i][7], X[i][9], X[i][10],\n",
    "               X[i][11], X[i][12], X[i][13], X[i][14], X[i][16], X[i][18],\n",
    "                X[i][19], X[i][20], X[i][21]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1596199467230,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "edf95f56-41e1-4fd6-819f-0d76e0939c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "631\n",
      "505\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2272,
     "status": "ok",
     "timestamp": 1596199493305,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "TWis1PUVfK_4",
    "outputId": "f4da3300-07fa-4718-d13f-85aab3e5fe86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Plot imports ###\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "### Warning ###\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1596199511481,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 427,
     "status": "ok",
     "timestamp": 1596199522621,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "ad710fe9-1c10-4e5b-9d4b-bc63fafdbafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2018, 16, 1)\n",
      "(631, 16, 1)\n",
      "(505, 16, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1596199542405,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "9a582a4f-36c3-40be-be45-5cb2fdd32415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2018, 2)\n",
      "(631, 2)\n",
      "(505, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1596199614361,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1596199617405,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "55148bd3-d7e0-402d-9d0e-4cf3d7eca0b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 1)]           0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 16, 128)           768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 16, 128)           512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 16, 128)           82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 87,434\n",
      "Trainable params: 87,174\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## First LFLB (local feature learning block)\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1596199651709,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 567742,
     "status": "ok",
     "timestamp": 1596201188397,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "8bbeca87-6045-490a-a55d-3e7efc9425e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.5544 - accuracy: 0.7157 - auc: 0.7967 - val_loss: 0.5292 - val_accuracy: 0.7496 - val_auc: 0.8207\n",
      "Epoch 2/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5616 - accuracy: 0.7116 - auc: 0.7810 - val_loss: 0.5294 - val_accuracy: 0.7544 - val_auc: 0.8208\n",
      "Epoch 3/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5579 - accuracy: 0.7061 - auc: 0.7838 - val_loss: 0.5301 - val_accuracy: 0.7528 - val_auc: 0.8199\n",
      "Epoch 4/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5527 - accuracy: 0.7071 - auc: 0.7901 - val_loss: 0.5300 - val_accuracy: 0.7575 - val_auc: 0.8202\n",
      "Epoch 5/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5516 - accuracy: 0.7086 - auc: 0.7924 - val_loss: 0.5294 - val_accuracy: 0.7559 - val_auc: 0.8208\n",
      "Epoch 6/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5473 - accuracy: 0.7185 - auc: 0.7967 - val_loss: 0.5297 - val_accuracy: 0.7512 - val_auc: 0.8202\n",
      "Epoch 7/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5534 - accuracy: 0.7230 - auc: 0.7907 - val_loss: 0.5307 - val_accuracy: 0.7559 - val_auc: 0.8196\n",
      "Epoch 8/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5618 - accuracy: 0.7205 - auc: 0.7839 - val_loss: 0.5302 - val_accuracy: 0.7512 - val_auc: 0.8196\n",
      "Epoch 9/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5521 - accuracy: 0.7170 - auc: 0.7926 - val_loss: 0.5305 - val_accuracy: 0.7512 - val_auc: 0.8194\n",
      "Epoch 10/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5504 - accuracy: 0.7136 - auc: 0.7931 - val_loss: 0.5302 - val_accuracy: 0.7496 - val_auc: 0.8197\n",
      "Epoch 11/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5521 - accuracy: 0.7156 - auc: 0.7923 - val_loss: 0.5299 - val_accuracy: 0.7512 - val_auc: 0.8198\n",
      "Epoch 12/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5556 - accuracy: 0.7146 - auc: 0.7909 - val_loss: 0.5299 - val_accuracy: 0.7512 - val_auc: 0.8203\n",
      "Epoch 13/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5534 - accuracy: 0.7180 - auc: 0.7931 - val_loss: 0.5299 - val_accuracy: 0.7528 - val_auc: 0.8205\n",
      "Epoch 14/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5576 - accuracy: 0.7131 - auc: 0.7870 - val_loss: 0.5294 - val_accuracy: 0.7575 - val_auc: 0.8212\n",
      "Epoch 15/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5467 - accuracy: 0.7161 - auc: 0.7947 - val_loss: 0.5300 - val_accuracy: 0.7496 - val_auc: 0.8207\n",
      "Epoch 16/700\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5484 - accuracy: 0.7185 - auc: 0.7944 - val_loss: 0.5285 - val_accuracy: 0.7559 - val_auc: 0.8218\n",
      "Epoch 17/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5411 - accuracy: 0.7180 - auc: 0.8025 - val_loss: 0.5286 - val_accuracy: 0.7575 - val_auc: 0.8219\n",
      "Epoch 18/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5522 - accuracy: 0.7210 - auc: 0.7937 - val_loss: 0.5285 - val_accuracy: 0.7544 - val_auc: 0.8211\n",
      "Epoch 19/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5605 - accuracy: 0.7037 - auc: 0.7811 - val_loss: 0.5282 - val_accuracy: 0.7528 - val_auc: 0.8210\n",
      "Epoch 20/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5567 - accuracy: 0.7175 - auc: 0.7876 - val_loss: 0.5282 - val_accuracy: 0.7496 - val_auc: 0.8211\n",
      "Epoch 21/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5554 - accuracy: 0.7106 - auc: 0.7871 - val_loss: 0.5285 - val_accuracy: 0.7559 - val_auc: 0.8213\n",
      "Epoch 22/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5516 - accuracy: 0.7190 - auc: 0.7906 - val_loss: 0.5288 - val_accuracy: 0.7559 - val_auc: 0.8210\n",
      "Epoch 23/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5549 - accuracy: 0.7151 - auc: 0.7879 - val_loss: 0.5289 - val_accuracy: 0.7528 - val_auc: 0.8207\n",
      "Epoch 24/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5468 - accuracy: 0.7250 - auc: 0.7970 - val_loss: 0.5293 - val_accuracy: 0.7528 - val_auc: 0.8206\n",
      "Epoch 25/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5518 - accuracy: 0.7205 - auc: 0.7925 - val_loss: 0.5288 - val_accuracy: 0.7544 - val_auc: 0.8212\n",
      "Epoch 26/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5560 - accuracy: 0.7121 - auc: 0.7883 - val_loss: 0.5285 - val_accuracy: 0.7512 - val_auc: 0.8218\n",
      "Epoch 27/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5549 - accuracy: 0.7121 - auc: 0.7889 - val_loss: 0.5287 - val_accuracy: 0.7512 - val_auc: 0.8207\n",
      "Epoch 28/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5494 - accuracy: 0.7161 - auc: 0.7920 - val_loss: 0.5288 - val_accuracy: 0.7528 - val_auc: 0.8209\n",
      "Epoch 29/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5547 - accuracy: 0.7126 - auc: 0.7875 - val_loss: 0.5290 - val_accuracy: 0.7528 - val_auc: 0.8210\n",
      "Epoch 30/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5468 - accuracy: 0.7166 - auc: 0.7966 - val_loss: 0.5291 - val_accuracy: 0.7544 - val_auc: 0.8208\n",
      "Epoch 31/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5586 - accuracy: 0.7086 - auc: 0.7855 - val_loss: 0.5292 - val_accuracy: 0.7544 - val_auc: 0.8203\n",
      "Epoch 32/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5570 - accuracy: 0.7146 - auc: 0.7866 - val_loss: 0.5293 - val_accuracy: 0.7528 - val_auc: 0.8207\n",
      "Epoch 33/700\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5494 - accuracy: 0.7170 - auc: 0.7931 - val_loss: 0.5280 - val_accuracy: 0.7559 - val_auc: 0.8220\n",
      "Epoch 34/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5515 - accuracy: 0.7220 - auc: 0.7938 - val_loss: 0.5281 - val_accuracy: 0.7544 - val_auc: 0.8220\n",
      "Epoch 35/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5598 - accuracy: 0.7007 - auc: 0.7814 - val_loss: 0.5278 - val_accuracy: 0.7575 - val_auc: 0.8216\n",
      "Epoch 36/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5561 - accuracy: 0.7032 - auc: 0.7866 - val_loss: 0.5277 - val_accuracy: 0.7559 - val_auc: 0.8213\n",
      "Epoch 37/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5611 - accuracy: 0.7081 - auc: 0.7824 - val_loss: 0.5284 - val_accuracy: 0.7544 - val_auc: 0.8209\n",
      "Epoch 38/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5479 - accuracy: 0.7136 - auc: 0.7954 - val_loss: 0.5286 - val_accuracy: 0.7528 - val_auc: 0.8208\n",
      "Epoch 39/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5517 - accuracy: 0.7175 - auc: 0.7895 - val_loss: 0.5280 - val_accuracy: 0.7559 - val_auc: 0.8213\n",
      "Epoch 40/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5568 - accuracy: 0.7022 - auc: 0.7857 - val_loss: 0.5275 - val_accuracy: 0.7528 - val_auc: 0.8219\n",
      "Epoch 41/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5560 - accuracy: 0.7027 - auc: 0.7846 - val_loss: 0.5275 - val_accuracy: 0.7496 - val_auc: 0.8218\n",
      "Epoch 42/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5566 - accuracy: 0.7052 - auc: 0.7837 - val_loss: 0.5274 - val_accuracy: 0.7528 - val_auc: 0.8218\n",
      "Epoch 43/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5532 - accuracy: 0.7141 - auc: 0.7898 - val_loss: 0.5276 - val_accuracy: 0.7528 - val_auc: 0.8217\n",
      "Epoch 44/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5493 - accuracy: 0.7190 - auc: 0.7936 - val_loss: 0.5269 - val_accuracy: 0.7544 - val_auc: 0.8224\n",
      "Epoch 45/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5524 - accuracy: 0.7161 - auc: 0.7910 - val_loss: 0.5275 - val_accuracy: 0.7559 - val_auc: 0.8219\n",
      "Epoch 46/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5627 - accuracy: 0.7081 - auc: 0.7808 - val_loss: 0.5277 - val_accuracy: 0.7496 - val_auc: 0.8214\n",
      "Epoch 47/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5521 - accuracy: 0.7141 - auc: 0.7917 - val_loss: 0.5277 - val_accuracy: 0.7591 - val_auc: 0.8222\n",
      "Epoch 48/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5496 - accuracy: 0.7230 - auc: 0.7942 - val_loss: 0.5272 - val_accuracy: 0.7528 - val_auc: 0.8225\n",
      "Epoch 49/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5552 - accuracy: 0.7180 - auc: 0.7870 - val_loss: 0.5281 - val_accuracy: 0.7544 - val_auc: 0.8217\n",
      "Epoch 50/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5479 - accuracy: 0.7017 - auc: 0.7909 - val_loss: 0.5276 - val_accuracy: 0.7544 - val_auc: 0.8224\n",
      "Epoch 51/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5584 - accuracy: 0.7081 - auc: 0.7854 - val_loss: 0.5270 - val_accuracy: 0.7575 - val_auc: 0.8232\n",
      "Epoch 52/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5556 - accuracy: 0.7205 - auc: 0.7875 - val_loss: 0.5276 - val_accuracy: 0.7575 - val_auc: 0.8224\n",
      "Epoch 53/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5483 - accuracy: 0.7126 - auc: 0.7935 - val_loss: 0.5270 - val_accuracy: 0.7544 - val_auc: 0.8231\n",
      "Epoch 54/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5521 - accuracy: 0.7052 - auc: 0.7895 - val_loss: 0.5264 - val_accuracy: 0.7544 - val_auc: 0.8237\n",
      "Epoch 55/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5536 - accuracy: 0.7161 - auc: 0.7875 - val_loss: 0.5272 - val_accuracy: 0.7575 - val_auc: 0.8226\n",
      "Epoch 56/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5499 - accuracy: 0.7270 - auc: 0.7976 - val_loss: 0.5269 - val_accuracy: 0.7544 - val_auc: 0.8227\n",
      "Epoch 57/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5486 - accuracy: 0.7175 - auc: 0.7934 - val_loss: 0.5269 - val_accuracy: 0.7559 - val_auc: 0.8235\n",
      "Epoch 58/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5475 - accuracy: 0.7156 - auc: 0.7958 - val_loss: 0.5266 - val_accuracy: 0.7591 - val_auc: 0.8238\n",
      "Epoch 59/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5587 - accuracy: 0.7052 - auc: 0.7837 - val_loss: 0.5271 - val_accuracy: 0.7591 - val_auc: 0.8233\n",
      "Epoch 60/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5489 - accuracy: 0.7096 - auc: 0.7935 - val_loss: 0.5268 - val_accuracy: 0.7528 - val_auc: 0.8231\n",
      "Epoch 61/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5552 - accuracy: 0.7200 - auc: 0.7890 - val_loss: 0.5269 - val_accuracy: 0.7528 - val_auc: 0.8230\n",
      "Epoch 62/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5535 - accuracy: 0.7101 - auc: 0.7880 - val_loss: 0.5278 - val_accuracy: 0.7591 - val_auc: 0.8228\n",
      "Epoch 63/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5531 - accuracy: 0.7156 - auc: 0.7907 - val_loss: 0.5272 - val_accuracy: 0.7528 - val_auc: 0.8229\n",
      "Epoch 64/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5524 - accuracy: 0.7255 - auc: 0.7932 - val_loss: 0.5277 - val_accuracy: 0.7544 - val_auc: 0.8224\n",
      "Epoch 65/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5504 - accuracy: 0.7086 - auc: 0.7922 - val_loss: 0.5269 - val_accuracy: 0.7512 - val_auc: 0.8229\n",
      "Epoch 66/700\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.5570 - accuracy: 0.7240 - auc: 0.7873 - val_loss: 0.5263 - val_accuracy: 0.7528 - val_auc: 0.8232\n",
      "Epoch 67/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5512 - accuracy: 0.7151 - auc: 0.7919 - val_loss: 0.5260 - val_accuracy: 0.7544 - val_auc: 0.8236\n",
      "Epoch 68/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5455 - accuracy: 0.7200 - auc: 0.7984 - val_loss: 0.5256 - val_accuracy: 0.7512 - val_auc: 0.8232\n",
      "Epoch 69/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5512 - accuracy: 0.7056 - auc: 0.7908 - val_loss: 0.5257 - val_accuracy: 0.7544 - val_auc: 0.8232\n",
      "Epoch 70/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5481 - accuracy: 0.7166 - auc: 0.7973 - val_loss: 0.5265 - val_accuracy: 0.7528 - val_auc: 0.8229\n",
      "Epoch 71/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5426 - accuracy: 0.7190 - auc: 0.8010 - val_loss: 0.5260 - val_accuracy: 0.7528 - val_auc: 0.8236\n",
      "Epoch 72/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5539 - accuracy: 0.7146 - auc: 0.7886 - val_loss: 0.5254 - val_accuracy: 0.7512 - val_auc: 0.8240\n",
      "Epoch 73/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5449 - accuracy: 0.7141 - auc: 0.7974 - val_loss: 0.5260 - val_accuracy: 0.7559 - val_auc: 0.8234\n",
      "Epoch 74/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5563 - accuracy: 0.7066 - auc: 0.7848 - val_loss: 0.5254 - val_accuracy: 0.7528 - val_auc: 0.8238\n",
      "Epoch 75/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5478 - accuracy: 0.7161 - auc: 0.7962 - val_loss: 0.5255 - val_accuracy: 0.7559 - val_auc: 0.8237\n",
      "Epoch 76/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5464 - accuracy: 0.7121 - auc: 0.7965 - val_loss: 0.5257 - val_accuracy: 0.7544 - val_auc: 0.8235\n",
      "Epoch 77/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5470 - accuracy: 0.7294 - auc: 0.7979 - val_loss: 0.5261 - val_accuracy: 0.7544 - val_auc: 0.8231\n",
      "Epoch 78/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5483 - accuracy: 0.7151 - auc: 0.7946 - val_loss: 0.5260 - val_accuracy: 0.7480 - val_auc: 0.8232\n",
      "Epoch 79/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5465 - accuracy: 0.7210 - auc: 0.7959 - val_loss: 0.5259 - val_accuracy: 0.7512 - val_auc: 0.8233\n",
      "Epoch 80/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5499 - accuracy: 0.7205 - auc: 0.7921 - val_loss: 0.5256 - val_accuracy: 0.7528 - val_auc: 0.8237\n",
      "Epoch 81/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5570 - accuracy: 0.7066 - auc: 0.7878 - val_loss: 0.5260 - val_accuracy: 0.7528 - val_auc: 0.8234\n",
      "Epoch 82/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5483 - accuracy: 0.7225 - auc: 0.7950 - val_loss: 0.5267 - val_accuracy: 0.7512 - val_auc: 0.8227\n",
      "Epoch 83/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5469 - accuracy: 0.7284 - auc: 0.7968 - val_loss: 0.5263 - val_accuracy: 0.7512 - val_auc: 0.8231\n",
      "Epoch 84/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5496 - accuracy: 0.7255 - auc: 0.7941 - val_loss: 0.5263 - val_accuracy: 0.7512 - val_auc: 0.8224\n",
      "Epoch 85/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5556 - accuracy: 0.7101 - auc: 0.7875 - val_loss: 0.5259 - val_accuracy: 0.7575 - val_auc: 0.8224\n",
      "Epoch 86/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5565 - accuracy: 0.7215 - auc: 0.7875 - val_loss: 0.5258 - val_accuracy: 0.7528 - val_auc: 0.8229\n",
      "Epoch 87/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5567 - accuracy: 0.7175 - auc: 0.7885 - val_loss: 0.5256 - val_accuracy: 0.7528 - val_auc: 0.8226\n",
      "Epoch 88/700\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.5490 - accuracy: 0.7299 - auc: 0.7960 - val_loss: 0.5252 - val_accuracy: 0.7528 - val_auc: 0.8230\n",
      "Epoch 89/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5499 - accuracy: 0.7215 - auc: 0.7947 - val_loss: 0.5260 - val_accuracy: 0.7512 - val_auc: 0.8231\n",
      "Epoch 90/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5515 - accuracy: 0.7220 - auc: 0.7916 - val_loss: 0.5264 - val_accuracy: 0.7496 - val_auc: 0.8225\n",
      "Epoch 91/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5501 - accuracy: 0.7230 - auc: 0.7919 - val_loss: 0.5268 - val_accuracy: 0.7575 - val_auc: 0.8223\n",
      "Epoch 92/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5550 - accuracy: 0.7042 - auc: 0.7882 - val_loss: 0.5272 - val_accuracy: 0.7496 - val_auc: 0.8222\n",
      "Epoch 93/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5509 - accuracy: 0.7245 - auc: 0.7913 - val_loss: 0.5270 - val_accuracy: 0.7528 - val_auc: 0.8223\n",
      "Epoch 94/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5475 - accuracy: 0.7156 - auc: 0.7949 - val_loss: 0.5266 - val_accuracy: 0.7575 - val_auc: 0.8229\n",
      "Epoch 95/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5401 - accuracy: 0.7289 - auc: 0.8038 - val_loss: 0.5257 - val_accuracy: 0.7591 - val_auc: 0.8236\n",
      "Epoch 96/700\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.5480 - accuracy: 0.7166 - auc: 0.7946 - val_loss: 0.5250 - val_accuracy: 0.7591 - val_auc: 0.8236\n",
      "Epoch 97/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5513 - accuracy: 0.7175 - auc: 0.7915 - val_loss: 0.5252 - val_accuracy: 0.7575 - val_auc: 0.8242\n",
      "Epoch 98/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5480 - accuracy: 0.7235 - auc: 0.7973 - val_loss: 0.5255 - val_accuracy: 0.7528 - val_auc: 0.8239\n",
      "Epoch 99/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5496 - accuracy: 0.7205 - auc: 0.7951 - val_loss: 0.5253 - val_accuracy: 0.7528 - val_auc: 0.8241\n",
      "Epoch 100/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5564 - accuracy: 0.7166 - auc: 0.7887 - val_loss: 0.5256 - val_accuracy: 0.7512 - val_auc: 0.8236\n",
      "Epoch 101/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5534 - accuracy: 0.7106 - auc: 0.7897 - val_loss: 0.5255 - val_accuracy: 0.7528 - val_auc: 0.8235\n",
      "Epoch 102/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5510 - accuracy: 0.7111 - auc: 0.7907 - val_loss: 0.5252 - val_accuracy: 0.7528 - val_auc: 0.8236\n",
      "Epoch 103/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5484 - accuracy: 0.7235 - auc: 0.7937 - val_loss: 0.5249 - val_accuracy: 0.7528 - val_auc: 0.8243\n",
      "Epoch 104/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5488 - accuracy: 0.7141 - auc: 0.7940 - val_loss: 0.5252 - val_accuracy: 0.7512 - val_auc: 0.8240\n",
      "Epoch 105/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5412 - accuracy: 0.7245 - auc: 0.8030 - val_loss: 0.5251 - val_accuracy: 0.7544 - val_auc: 0.8246\n",
      "Epoch 106/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5530 - accuracy: 0.7131 - auc: 0.7891 - val_loss: 0.5245 - val_accuracy: 0.7544 - val_auc: 0.8248\n",
      "Epoch 107/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5485 - accuracy: 0.7032 - auc: 0.7933 - val_loss: 0.5251 - val_accuracy: 0.7559 - val_auc: 0.8245\n",
      "Epoch 108/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5509 - accuracy: 0.7260 - auc: 0.7917 - val_loss: 0.5252 - val_accuracy: 0.7559 - val_auc: 0.8240\n",
      "Epoch 109/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5455 - accuracy: 0.7131 - auc: 0.7974 - val_loss: 0.5254 - val_accuracy: 0.7528 - val_auc: 0.8239\n",
      "Epoch 110/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5507 - accuracy: 0.7175 - auc: 0.7951 - val_loss: 0.5258 - val_accuracy: 0.7559 - val_auc: 0.8234\n",
      "Epoch 111/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5530 - accuracy: 0.7161 - auc: 0.7911 - val_loss: 0.5256 - val_accuracy: 0.7544 - val_auc: 0.8234\n",
      "Epoch 112/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5560 - accuracy: 0.7111 - auc: 0.7886 - val_loss: 0.5259 - val_accuracy: 0.7544 - val_auc: 0.8232\n",
      "Epoch 113/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5489 - accuracy: 0.7170 - auc: 0.7964 - val_loss: 0.5253 - val_accuracy: 0.7528 - val_auc: 0.8236\n",
      "Epoch 114/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5468 - accuracy: 0.7116 - auc: 0.7934 - val_loss: 0.5259 - val_accuracy: 0.7528 - val_auc: 0.8231\n",
      "Epoch 115/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5499 - accuracy: 0.7141 - auc: 0.7920 - val_loss: 0.5260 - val_accuracy: 0.7528 - val_auc: 0.8225\n",
      "Epoch 116/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5405 - accuracy: 0.7289 - auc: 0.8025 - val_loss: 0.5257 - val_accuracy: 0.7544 - val_auc: 0.8236\n",
      "Epoch 117/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5543 - accuracy: 0.7081 - auc: 0.7874 - val_loss: 0.5257 - val_accuracy: 0.7528 - val_auc: 0.8237\n",
      "Epoch 118/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5452 - accuracy: 0.7185 - auc: 0.7952 - val_loss: 0.5255 - val_accuracy: 0.7528 - val_auc: 0.8236\n",
      "Epoch 119/700\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.5487 - accuracy: 0.7210 - auc: 0.7953 - val_loss: 0.5244 - val_accuracy: 0.7559 - val_auc: 0.8247\n",
      "Epoch 120/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5511 - accuracy: 0.7126 - auc: 0.7924 - val_loss: 0.5245 - val_accuracy: 0.7544 - val_auc: 0.8239\n",
      "Epoch 121/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5471 - accuracy: 0.7225 - auc: 0.7967 - val_loss: 0.5245 - val_accuracy: 0.7559 - val_auc: 0.8244\n",
      "Epoch 122/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5467 - accuracy: 0.7180 - auc: 0.7966 - val_loss: 0.5249 - val_accuracy: 0.7575 - val_auc: 0.8237\n",
      "Epoch 123/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5614 - accuracy: 0.7156 - auc: 0.7835 - val_loss: 0.5250 - val_accuracy: 0.7559 - val_auc: 0.8242\n",
      "Epoch 124/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5507 - accuracy: 0.7161 - auc: 0.7933 - val_loss: 0.5244 - val_accuracy: 0.7591 - val_auc: 0.8246\n",
      "Epoch 125/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5526 - accuracy: 0.7195 - auc: 0.7909 - val_loss: 0.5248 - val_accuracy: 0.7559 - val_auc: 0.8245\n",
      "Epoch 126/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5488 - accuracy: 0.7141 - auc: 0.7940 - val_loss: 0.5249 - val_accuracy: 0.7544 - val_auc: 0.8246\n",
      "Epoch 127/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5539 - accuracy: 0.7136 - auc: 0.7886 - val_loss: 0.5252 - val_accuracy: 0.7528 - val_auc: 0.8244\n",
      "Epoch 128/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5551 - accuracy: 0.7052 - auc: 0.7860 - val_loss: 0.5250 - val_accuracy: 0.7528 - val_auc: 0.8245\n",
      "Epoch 129/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5496 - accuracy: 0.7156 - auc: 0.7915 - val_loss: 0.5243 - val_accuracy: 0.7544 - val_auc: 0.8253\n",
      "Epoch 130/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5431 - accuracy: 0.7284 - auc: 0.8008 - val_loss: 0.5243 - val_accuracy: 0.7512 - val_auc: 0.8251\n",
      "Epoch 131/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5491 - accuracy: 0.7076 - auc: 0.7945 - val_loss: 0.5241 - val_accuracy: 0.7480 - val_auc: 0.8250\n",
      "Epoch 132/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5477 - accuracy: 0.7250 - auc: 0.7977 - val_loss: 0.5238 - val_accuracy: 0.7575 - val_auc: 0.8254\n",
      "Epoch 133/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5450 - accuracy: 0.7121 - auc: 0.7966 - val_loss: 0.5236 - val_accuracy: 0.7591 - val_auc: 0.8252\n",
      "Epoch 134/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5540 - accuracy: 0.7151 - auc: 0.7903 - val_loss: 0.5240 - val_accuracy: 0.7544 - val_auc: 0.8253\n",
      "Epoch 135/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5637 - accuracy: 0.6972 - auc: 0.7791 - val_loss: 0.5236 - val_accuracy: 0.7512 - val_auc: 0.8253\n",
      "Epoch 136/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5464 - accuracy: 0.7240 - auc: 0.7971 - val_loss: 0.5238 - val_accuracy: 0.7512 - val_auc: 0.8246\n",
      "Epoch 137/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5452 - accuracy: 0.7210 - auc: 0.7967 - val_loss: 0.5227 - val_accuracy: 0.7559 - val_auc: 0.8252\n",
      "Epoch 138/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5559 - accuracy: 0.7161 - auc: 0.7890 - val_loss: 0.5231 - val_accuracy: 0.7591 - val_auc: 0.8251\n",
      "Epoch 139/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5532 - accuracy: 0.7225 - auc: 0.7917 - val_loss: 0.5229 - val_accuracy: 0.7559 - val_auc: 0.8254\n",
      "Epoch 140/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5412 - accuracy: 0.7131 - auc: 0.7997 - val_loss: 0.5232 - val_accuracy: 0.7575 - val_auc: 0.8251\n",
      "Epoch 141/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5466 - accuracy: 0.7156 - auc: 0.7948 - val_loss: 0.5234 - val_accuracy: 0.7528 - val_auc: 0.8252\n",
      "Epoch 142/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5430 - accuracy: 0.7235 - auc: 0.8006 - val_loss: 0.5238 - val_accuracy: 0.7512 - val_auc: 0.8249\n",
      "Epoch 143/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5433 - accuracy: 0.7260 - auc: 0.8011 - val_loss: 0.5232 - val_accuracy: 0.7544 - val_auc: 0.8256\n",
      "Epoch 144/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5463 - accuracy: 0.7265 - auc: 0.7990 - val_loss: 0.5233 - val_accuracy: 0.7575 - val_auc: 0.8252\n",
      "Epoch 145/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5478 - accuracy: 0.7175 - auc: 0.7965 - val_loss: 0.5234 - val_accuracy: 0.7544 - val_auc: 0.8258\n",
      "Epoch 146/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5452 - accuracy: 0.7230 - auc: 0.7971 - val_loss: 0.5232 - val_accuracy: 0.7559 - val_auc: 0.8254\n",
      "Epoch 147/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5450 - accuracy: 0.7235 - auc: 0.7986 - val_loss: 0.5237 - val_accuracy: 0.7496 - val_auc: 0.8250\n",
      "Epoch 148/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5501 - accuracy: 0.7166 - auc: 0.7931 - val_loss: 0.5234 - val_accuracy: 0.7512 - val_auc: 0.8251\n",
      "Epoch 149/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5474 - accuracy: 0.7136 - auc: 0.7950 - val_loss: 0.5234 - val_accuracy: 0.7528 - val_auc: 0.8252\n",
      "Epoch 150/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5474 - accuracy: 0.7081 - auc: 0.7929 - val_loss: 0.5232 - val_accuracy: 0.7496 - val_auc: 0.8255\n",
      "Epoch 151/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5424 - accuracy: 0.7235 - auc: 0.8013 - val_loss: 0.5235 - val_accuracy: 0.7528 - val_auc: 0.8253\n",
      "Epoch 152/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5496 - accuracy: 0.7136 - auc: 0.7934 - val_loss: 0.5228 - val_accuracy: 0.7559 - val_auc: 0.8259\n",
      "Epoch 153/700\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.5500 - accuracy: 0.7220 - auc: 0.7936 - val_loss: 0.5224 - val_accuracy: 0.7575 - val_auc: 0.8259\n",
      "Epoch 154/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5513 - accuracy: 0.7126 - auc: 0.7916 - val_loss: 0.5216 - val_accuracy: 0.7623 - val_auc: 0.8269\n",
      "Epoch 155/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5482 - accuracy: 0.7096 - auc: 0.7923 - val_loss: 0.5222 - val_accuracy: 0.7591 - val_auc: 0.8268\n",
      "Epoch 156/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5437 - accuracy: 0.7190 - auc: 0.7992 - val_loss: 0.5226 - val_accuracy: 0.7575 - val_auc: 0.8268\n",
      "Epoch 157/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5459 - accuracy: 0.7215 - auc: 0.7975 - val_loss: 0.5220 - val_accuracy: 0.7544 - val_auc: 0.8265\n",
      "Epoch 158/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5466 - accuracy: 0.7215 - auc: 0.7953 - val_loss: 0.5221 - val_accuracy: 0.7591 - val_auc: 0.8269\n",
      "Epoch 159/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5454 - accuracy: 0.7136 - auc: 0.7938 - val_loss: 0.5226 - val_accuracy: 0.7607 - val_auc: 0.8265\n",
      "Epoch 160/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5511 - accuracy: 0.7111 - auc: 0.7901 - val_loss: 0.5222 - val_accuracy: 0.7639 - val_auc: 0.8266\n",
      "Epoch 161/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5497 - accuracy: 0.7136 - auc: 0.7910 - val_loss: 0.5219 - val_accuracy: 0.7639 - val_auc: 0.8266\n",
      "Epoch 162/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5608 - accuracy: 0.6962 - auc: 0.7814 - val_loss: 0.5222 - val_accuracy: 0.7591 - val_auc: 0.8260\n",
      "Epoch 163/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5436 - accuracy: 0.7180 - auc: 0.8003 - val_loss: 0.5214 - val_accuracy: 0.7623 - val_auc: 0.8267\n",
      "Epoch 164/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5412 - accuracy: 0.7309 - auc: 0.8018 - val_loss: 0.5212 - val_accuracy: 0.7655 - val_auc: 0.8275\n",
      "Epoch 165/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5404 - accuracy: 0.7255 - auc: 0.8035 - val_loss: 0.5223 - val_accuracy: 0.7559 - val_auc: 0.8262\n",
      "Epoch 166/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5560 - accuracy: 0.7170 - auc: 0.7876 - val_loss: 0.5223 - val_accuracy: 0.7575 - val_auc: 0.8259\n",
      "Epoch 167/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5476 - accuracy: 0.7180 - auc: 0.7982 - val_loss: 0.5231 - val_accuracy: 0.7559 - val_auc: 0.8257\n",
      "Epoch 168/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5412 - accuracy: 0.7289 - auc: 0.8032 - val_loss: 0.5223 - val_accuracy: 0.7591 - val_auc: 0.8260\n",
      "Epoch 169/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5481 - accuracy: 0.7175 - auc: 0.7939 - val_loss: 0.5228 - val_accuracy: 0.7575 - val_auc: 0.8265\n",
      "Epoch 170/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5425 - accuracy: 0.7195 - auc: 0.8011 - val_loss: 0.5222 - val_accuracy: 0.7575 - val_auc: 0.8264\n",
      "Epoch 171/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5392 - accuracy: 0.7047 - auc: 0.8005 - val_loss: 0.5225 - val_accuracy: 0.7559 - val_auc: 0.8262\n",
      "Epoch 172/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5491 - accuracy: 0.7185 - auc: 0.7934 - val_loss: 0.5222 - val_accuracy: 0.7544 - val_auc: 0.8262\n",
      "Epoch 173/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5557 - accuracy: 0.7116 - auc: 0.7865 - val_loss: 0.5230 - val_accuracy: 0.7559 - val_auc: 0.8257\n",
      "Epoch 174/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5415 - accuracy: 0.7240 - auc: 0.7980 - val_loss: 0.5226 - val_accuracy: 0.7544 - val_auc: 0.8267\n",
      "Epoch 175/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5463 - accuracy: 0.7170 - auc: 0.7971 - val_loss: 0.5216 - val_accuracy: 0.7607 - val_auc: 0.8268\n",
      "Epoch 176/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5410 - accuracy: 0.7250 - auc: 0.8006 - val_loss: 0.5214 - val_accuracy: 0.7575 - val_auc: 0.8267\n",
      "Epoch 177/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5445 - accuracy: 0.7151 - auc: 0.7974 - val_loss: 0.5214 - val_accuracy: 0.7544 - val_auc: 0.8266\n",
      "Epoch 178/700\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.5399 - accuracy: 0.7131 - auc: 0.7995 - val_loss: 0.5211 - val_accuracy: 0.7607 - val_auc: 0.8272\n",
      "Epoch 179/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5508 - accuracy: 0.7185 - auc: 0.7925 - val_loss: 0.5214 - val_accuracy: 0.7575 - val_auc: 0.8265\n",
      "Epoch 180/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5457 - accuracy: 0.7245 - auc: 0.7990 - val_loss: 0.5215 - val_accuracy: 0.7575 - val_auc: 0.8267\n",
      "Epoch 181/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5435 - accuracy: 0.7279 - auc: 0.8007 - val_loss: 0.5208 - val_accuracy: 0.7607 - val_auc: 0.8271\n",
      "Epoch 182/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5439 - accuracy: 0.7245 - auc: 0.7975 - val_loss: 0.5206 - val_accuracy: 0.7639 - val_auc: 0.8276\n",
      "Epoch 183/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5390 - accuracy: 0.7190 - auc: 0.8035 - val_loss: 0.5211 - val_accuracy: 0.7544 - val_auc: 0.8264\n",
      "Epoch 184/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5481 - accuracy: 0.7230 - auc: 0.7939 - val_loss: 0.5215 - val_accuracy: 0.7544 - val_auc: 0.8266\n",
      "Epoch 185/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5440 - accuracy: 0.7136 - auc: 0.7988 - val_loss: 0.5208 - val_accuracy: 0.7639 - val_auc: 0.8275\n",
      "Epoch 186/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5525 - accuracy: 0.7066 - auc: 0.7882 - val_loss: 0.5206 - val_accuracy: 0.7607 - val_auc: 0.8277\n",
      "Epoch 187/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5430 - accuracy: 0.7245 - auc: 0.8008 - val_loss: 0.5205 - val_accuracy: 0.7623 - val_auc: 0.8279\n",
      "Epoch 188/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5484 - accuracy: 0.7170 - auc: 0.7945 - val_loss: 0.5202 - val_accuracy: 0.7623 - val_auc: 0.8283\n",
      "Epoch 189/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5393 - accuracy: 0.7250 - auc: 0.8022 - val_loss: 0.5199 - val_accuracy: 0.7607 - val_auc: 0.8282\n",
      "Epoch 190/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5428 - accuracy: 0.7185 - auc: 0.7983 - val_loss: 0.5198 - val_accuracy: 0.7575 - val_auc: 0.8284\n",
      "Epoch 191/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5446 - accuracy: 0.7180 - auc: 0.7969 - val_loss: 0.5200 - val_accuracy: 0.7591 - val_auc: 0.8279\n",
      "Epoch 192/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5520 - accuracy: 0.7126 - auc: 0.7899 - val_loss: 0.5204 - val_accuracy: 0.7623 - val_auc: 0.8274\n",
      "Epoch 193/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5438 - accuracy: 0.7225 - auc: 0.7986 - val_loss: 0.5206 - val_accuracy: 0.7575 - val_auc: 0.8272\n",
      "Epoch 194/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5413 - accuracy: 0.7180 - auc: 0.8018 - val_loss: 0.5207 - val_accuracy: 0.7575 - val_auc: 0.8274\n",
      "Epoch 195/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5487 - accuracy: 0.7205 - auc: 0.7935 - val_loss: 0.5204 - val_accuracy: 0.7607 - val_auc: 0.8277\n",
      "Epoch 196/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5520 - accuracy: 0.7230 - auc: 0.7938 - val_loss: 0.5198 - val_accuracy: 0.7607 - val_auc: 0.8280\n",
      "Epoch 197/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5573 - accuracy: 0.7096 - auc: 0.7851 - val_loss: 0.5199 - val_accuracy: 0.7591 - val_auc: 0.8272\n",
      "Epoch 198/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5493 - accuracy: 0.7185 - auc: 0.7941 - val_loss: 0.5200 - val_accuracy: 0.7575 - val_auc: 0.8268\n",
      "Epoch 199/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5411 - accuracy: 0.7284 - auc: 0.8012 - val_loss: 0.5203 - val_accuracy: 0.7575 - val_auc: 0.8269\n",
      "Epoch 200/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5532 - accuracy: 0.7166 - auc: 0.7891 - val_loss: 0.5199 - val_accuracy: 0.7559 - val_auc: 0.8272\n",
      "Epoch 201/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5418 - accuracy: 0.7279 - auc: 0.8003 - val_loss: 0.5202 - val_accuracy: 0.7591 - val_auc: 0.8271\n",
      "Epoch 202/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5437 - accuracy: 0.7265 - auc: 0.7978 - val_loss: 0.5201 - val_accuracy: 0.7607 - val_auc: 0.8279\n",
      "Epoch 203/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5441 - accuracy: 0.7166 - auc: 0.7966 - val_loss: 0.5207 - val_accuracy: 0.7544 - val_auc: 0.8276\n",
      "Epoch 204/700\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.5418 - accuracy: 0.7190 - auc: 0.8001 - val_loss: 0.5196 - val_accuracy: 0.7623 - val_auc: 0.8285\n",
      "Epoch 205/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5464 - accuracy: 0.7175 - auc: 0.7974 - val_loss: 0.5198 - val_accuracy: 0.7591 - val_auc: 0.8281\n",
      "Epoch 206/700\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.5448 - accuracy: 0.7091 - auc: 0.7954 - val_loss: 0.5192 - val_accuracy: 0.7591 - val_auc: 0.8279\n",
      "Epoch 207/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5463 - accuracy: 0.7151 - auc: 0.7965 - val_loss: 0.5195 - val_accuracy: 0.7591 - val_auc: 0.8276\n",
      "Epoch 208/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5440 - accuracy: 0.7245 - auc: 0.7976 - val_loss: 0.5200 - val_accuracy: 0.7559 - val_auc: 0.8278\n",
      "Epoch 209/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5372 - accuracy: 0.7250 - auc: 0.8055 - val_loss: 0.5196 - val_accuracy: 0.7607 - val_auc: 0.8276\n",
      "Epoch 210/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5493 - accuracy: 0.7225 - auc: 0.7933 - val_loss: 0.5196 - val_accuracy: 0.7639 - val_auc: 0.8279\n",
      "Epoch 211/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5401 - accuracy: 0.7255 - auc: 0.8039 - val_loss: 0.5199 - val_accuracy: 0.7591 - val_auc: 0.8280\n",
      "Epoch 212/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5541 - accuracy: 0.7156 - auc: 0.7904 - val_loss: 0.5202 - val_accuracy: 0.7528 - val_auc: 0.8271\n",
      "Epoch 213/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5531 - accuracy: 0.7161 - auc: 0.7898 - val_loss: 0.5192 - val_accuracy: 0.7591 - val_auc: 0.8284\n",
      "Epoch 214/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5454 - accuracy: 0.7225 - auc: 0.7978 - val_loss: 0.5195 - val_accuracy: 0.7575 - val_auc: 0.8283\n",
      "Epoch 215/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5478 - accuracy: 0.7205 - auc: 0.7982 - val_loss: 0.5197 - val_accuracy: 0.7544 - val_auc: 0.8279\n",
      "Epoch 216/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5485 - accuracy: 0.7141 - auc: 0.7940 - val_loss: 0.5198 - val_accuracy: 0.7575 - val_auc: 0.8273\n",
      "Epoch 217/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5468 - accuracy: 0.7126 - auc: 0.7943 - val_loss: 0.5195 - val_accuracy: 0.7559 - val_auc: 0.8282\n",
      "Epoch 218/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5390 - accuracy: 0.7185 - auc: 0.7999 - val_loss: 0.5197 - val_accuracy: 0.7528 - val_auc: 0.8276\n",
      "Epoch 219/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5542 - accuracy: 0.7141 - auc: 0.7893 - val_loss: 0.5207 - val_accuracy: 0.7544 - val_auc: 0.8271\n",
      "Epoch 220/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5416 - accuracy: 0.7250 - auc: 0.8016 - val_loss: 0.5199 - val_accuracy: 0.7544 - val_auc: 0.8271\n",
      "Epoch 221/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5470 - accuracy: 0.7275 - auc: 0.7958 - val_loss: 0.5191 - val_accuracy: 0.7559 - val_auc: 0.8281\n",
      "Epoch 222/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5430 - accuracy: 0.7190 - auc: 0.8000 - val_loss: 0.5197 - val_accuracy: 0.7575 - val_auc: 0.8278\n",
      "Epoch 223/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5492 - accuracy: 0.7200 - auc: 0.7941 - val_loss: 0.5193 - val_accuracy: 0.7559 - val_auc: 0.8284\n",
      "Epoch 224/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5489 - accuracy: 0.7047 - auc: 0.7910 - val_loss: 0.5191 - val_accuracy: 0.7607 - val_auc: 0.8284\n",
      "Epoch 225/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5438 - accuracy: 0.7215 - auc: 0.7998 - val_loss: 0.5191 - val_accuracy: 0.7575 - val_auc: 0.8279\n",
      "Epoch 226/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5446 - accuracy: 0.7146 - auc: 0.7965 - val_loss: 0.5196 - val_accuracy: 0.7528 - val_auc: 0.8281\n",
      "Epoch 227/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5410 - accuracy: 0.7289 - auc: 0.8044 - val_loss: 0.5191 - val_accuracy: 0.7512 - val_auc: 0.8281\n",
      "Epoch 228/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5440 - accuracy: 0.7235 - auc: 0.7992 - val_loss: 0.5191 - val_accuracy: 0.7575 - val_auc: 0.8282\n",
      "Epoch 229/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5416 - accuracy: 0.7190 - auc: 0.8000 - val_loss: 0.5197 - val_accuracy: 0.7575 - val_auc: 0.8279\n",
      "Epoch 230/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5416 - accuracy: 0.7205 - auc: 0.7997 - val_loss: 0.5196 - val_accuracy: 0.7575 - val_auc: 0.8280\n",
      "Epoch 231/700\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5512 - accuracy: 0.6957 - auc: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7623 - val_auc: 0.8280\n",
      "Epoch 232/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5521 - accuracy: 0.7116 - auc: 0.7897 - val_loss: 0.5190 - val_accuracy: 0.7591 - val_auc: 0.8283\n",
      "Epoch 233/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5453 - accuracy: 0.7170 - auc: 0.7971 - val_loss: 0.5195 - val_accuracy: 0.7607 - val_auc: 0.8278\n",
      "Epoch 234/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5445 - accuracy: 0.7220 - auc: 0.7993 - val_loss: 0.5200 - val_accuracy: 0.7559 - val_auc: 0.8278\n",
      "Epoch 235/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5454 - accuracy: 0.7225 - auc: 0.7972 - val_loss: 0.5196 - val_accuracy: 0.7591 - val_auc: 0.8283\n",
      "Epoch 236/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5495 - accuracy: 0.7180 - auc: 0.7929 - val_loss: 0.5185 - val_accuracy: 0.7623 - val_auc: 0.8286\n",
      "Epoch 237/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5413 - accuracy: 0.7245 - auc: 0.8028 - val_loss: 0.5183 - val_accuracy: 0.7639 - val_auc: 0.8290\n",
      "Epoch 238/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5405 - accuracy: 0.7151 - auc: 0.7993 - val_loss: 0.5184 - val_accuracy: 0.7623 - val_auc: 0.8291\n",
      "Epoch 239/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5400 - accuracy: 0.7240 - auc: 0.8032 - val_loss: 0.5185 - val_accuracy: 0.7607 - val_auc: 0.8290\n",
      "Epoch 240/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5485 - accuracy: 0.7195 - auc: 0.7951 - val_loss: 0.5185 - val_accuracy: 0.7559 - val_auc: 0.8283\n",
      "Epoch 241/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5502 - accuracy: 0.7200 - auc: 0.7940 - val_loss: 0.5183 - val_accuracy: 0.7607 - val_auc: 0.8288\n",
      "Epoch 242/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5465 - accuracy: 0.7210 - auc: 0.7971 - val_loss: 0.5187 - val_accuracy: 0.7544 - val_auc: 0.8284\n",
      "Epoch 243/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5465 - accuracy: 0.7250 - auc: 0.7976 - val_loss: 0.5186 - val_accuracy: 0.7528 - val_auc: 0.8283\n",
      "Epoch 244/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5391 - accuracy: 0.7225 - auc: 0.8030 - val_loss: 0.5181 - val_accuracy: 0.7591 - val_auc: 0.8288\n",
      "Epoch 245/700\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5375 - accuracy: 0.7240 - auc: 0.8057 - val_loss: 0.5183 - val_accuracy: 0.7528 - val_auc: 0.8286\n",
      "Epoch 246/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5472 - accuracy: 0.7156 - auc: 0.7946 - val_loss: 0.5186 - val_accuracy: 0.7512 - val_auc: 0.8285\n",
      "Epoch 247/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5431 - accuracy: 0.7096 - auc: 0.7984 - val_loss: 0.5183 - val_accuracy: 0.7591 - val_auc: 0.8285\n",
      "Epoch 248/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5478 - accuracy: 0.7047 - auc: 0.7922 - val_loss: 0.5181 - val_accuracy: 0.7591 - val_auc: 0.8288\n",
      "Epoch 249/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5459 - accuracy: 0.7190 - auc: 0.7976 - val_loss: 0.5188 - val_accuracy: 0.7528 - val_auc: 0.8284\n",
      "Epoch 250/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5439 - accuracy: 0.7275 - auc: 0.8007 - val_loss: 0.5182 - val_accuracy: 0.7591 - val_auc: 0.8291\n",
      "Epoch 251/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5384 - accuracy: 0.7215 - auc: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7559 - val_auc: 0.8297\n",
      "Epoch 252/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5530 - accuracy: 0.7121 - auc: 0.7884 - val_loss: 0.5180 - val_accuracy: 0.7639 - val_auc: 0.8290\n",
      "Epoch 253/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5457 - accuracy: 0.7141 - auc: 0.7942 - val_loss: 0.5176 - val_accuracy: 0.7591 - val_auc: 0.8297\n",
      "Epoch 254/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5462 - accuracy: 0.7101 - auc: 0.7938 - val_loss: 0.5181 - val_accuracy: 0.7559 - val_auc: 0.8290\n",
      "Epoch 255/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5400 - accuracy: 0.7185 - auc: 0.8009 - val_loss: 0.5181 - val_accuracy: 0.7559 - val_auc: 0.8292\n",
      "Epoch 256/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5403 - accuracy: 0.7245 - auc: 0.8027 - val_loss: 0.5174 - val_accuracy: 0.7575 - val_auc: 0.8296\n",
      "Epoch 257/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5470 - accuracy: 0.7141 - auc: 0.7946 - val_loss: 0.5174 - val_accuracy: 0.7575 - val_auc: 0.8298\n",
      "Epoch 258/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5484 - accuracy: 0.7170 - auc: 0.7949 - val_loss: 0.5178 - val_accuracy: 0.7575 - val_auc: 0.8293\n",
      "Epoch 259/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5503 - accuracy: 0.7166 - auc: 0.7920 - val_loss: 0.5177 - val_accuracy: 0.7575 - val_auc: 0.8292\n",
      "Epoch 260/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5446 - accuracy: 0.7141 - auc: 0.7967 - val_loss: 0.5177 - val_accuracy: 0.7623 - val_auc: 0.8295\n",
      "Epoch 261/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5469 - accuracy: 0.7250 - auc: 0.7940 - val_loss: 0.5183 - val_accuracy: 0.7575 - val_auc: 0.8289\n",
      "Epoch 262/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5332 - accuracy: 0.7354 - auc: 0.8112 - val_loss: 0.5184 - val_accuracy: 0.7544 - val_auc: 0.8290\n",
      "Epoch 263/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5491 - accuracy: 0.7156 - auc: 0.7926 - val_loss: 0.5185 - val_accuracy: 0.7559 - val_auc: 0.8288\n",
      "Epoch 264/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5419 - accuracy: 0.7260 - auc: 0.8024 - val_loss: 0.5182 - val_accuracy: 0.7559 - val_auc: 0.8287\n",
      "Epoch 265/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5387 - accuracy: 0.7250 - auc: 0.8053 - val_loss: 0.5185 - val_accuracy: 0.7575 - val_auc: 0.8290\n",
      "Epoch 266/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5501 - accuracy: 0.7170 - auc: 0.7936 - val_loss: 0.5182 - val_accuracy: 0.7544 - val_auc: 0.8287\n",
      "Epoch 267/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5451 - accuracy: 0.7289 - auc: 0.8005 - val_loss: 0.5183 - val_accuracy: 0.7559 - val_auc: 0.8291\n",
      "Epoch 268/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5446 - accuracy: 0.7175 - auc: 0.7984 - val_loss: 0.5188 - val_accuracy: 0.7544 - val_auc: 0.8283\n",
      "Epoch 269/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5420 - accuracy: 0.7255 - auc: 0.8017 - val_loss: 0.5181 - val_accuracy: 0.7591 - val_auc: 0.8289\n",
      "Epoch 270/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5520 - accuracy: 0.7185 - auc: 0.7909 - val_loss: 0.5176 - val_accuracy: 0.7544 - val_auc: 0.8291\n",
      "Epoch 271/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5409 - accuracy: 0.7166 - auc: 0.8000 - val_loss: 0.5176 - val_accuracy: 0.7607 - val_auc: 0.8294\n",
      "Epoch 272/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5452 - accuracy: 0.7180 - auc: 0.7984 - val_loss: 0.5176 - val_accuracy: 0.7559 - val_auc: 0.8296\n",
      "Epoch 273/700\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.5472 - accuracy: 0.7111 - auc: 0.7923 - val_loss: 0.5169 - val_accuracy: 0.7623 - val_auc: 0.8304\n",
      "Epoch 274/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5515 - accuracy: 0.7111 - auc: 0.7905 - val_loss: 0.5168 - val_accuracy: 0.7639 - val_auc: 0.8299\n",
      "Epoch 275/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5480 - accuracy: 0.7096 - auc: 0.7928 - val_loss: 0.5174 - val_accuracy: 0.7623 - val_auc: 0.8298\n",
      "Epoch 276/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5456 - accuracy: 0.7225 - auc: 0.7973 - val_loss: 0.5170 - val_accuracy: 0.7623 - val_auc: 0.8296\n",
      "Epoch 277/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5476 - accuracy: 0.7245 - auc: 0.7956 - val_loss: 0.5176 - val_accuracy: 0.7528 - val_auc: 0.8291\n",
      "Epoch 278/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5459 - accuracy: 0.7275 - auc: 0.7986 - val_loss: 0.5178 - val_accuracy: 0.7528 - val_auc: 0.8289\n",
      "Epoch 279/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5329 - accuracy: 0.7220 - auc: 0.8069 - val_loss: 0.5181 - val_accuracy: 0.7528 - val_auc: 0.8291\n",
      "Epoch 280/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5450 - accuracy: 0.7131 - auc: 0.7943 - val_loss: 0.5173 - val_accuracy: 0.7623 - val_auc: 0.8301\n",
      "Epoch 281/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5384 - accuracy: 0.7304 - auc: 0.8039 - val_loss: 0.5166 - val_accuracy: 0.7544 - val_auc: 0.8308\n",
      "Epoch 282/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5439 - accuracy: 0.7136 - auc: 0.7964 - val_loss: 0.5168 - val_accuracy: 0.7591 - val_auc: 0.8302\n",
      "Epoch 283/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5462 - accuracy: 0.7230 - auc: 0.7945 - val_loss: 0.5174 - val_accuracy: 0.7591 - val_auc: 0.8291\n",
      "Epoch 284/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5468 - accuracy: 0.7235 - auc: 0.7963 - val_loss: 0.5176 - val_accuracy: 0.7607 - val_auc: 0.8292\n",
      "Epoch 285/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5398 - accuracy: 0.7265 - auc: 0.8017 - val_loss: 0.5176 - val_accuracy: 0.7575 - val_auc: 0.8290\n",
      "Epoch 286/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5388 - accuracy: 0.7230 - auc: 0.8015 - val_loss: 0.5170 - val_accuracy: 0.7575 - val_auc: 0.8303\n",
      "Epoch 287/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5387 - accuracy: 0.7284 - auc: 0.8026 - val_loss: 0.5160 - val_accuracy: 0.7639 - val_auc: 0.8310\n",
      "Epoch 288/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5474 - accuracy: 0.7156 - auc: 0.7953 - val_loss: 0.5162 - val_accuracy: 0.7639 - val_auc: 0.8313\n",
      "Epoch 289/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5471 - accuracy: 0.7220 - auc: 0.7954 - val_loss: 0.5167 - val_accuracy: 0.7623 - val_auc: 0.8305\n",
      "Epoch 290/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5446 - accuracy: 0.7166 - auc: 0.7991 - val_loss: 0.5170 - val_accuracy: 0.7575 - val_auc: 0.8304\n",
      "Epoch 291/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5385 - accuracy: 0.7289 - auc: 0.8038 - val_loss: 0.5167 - val_accuracy: 0.7623 - val_auc: 0.8305\n",
      "Epoch 292/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5506 - accuracy: 0.7076 - auc: 0.7916 - val_loss: 0.5163 - val_accuracy: 0.7623 - val_auc: 0.8301\n",
      "Epoch 293/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5429 - accuracy: 0.7195 - auc: 0.7997 - val_loss: 0.5163 - val_accuracy: 0.7623 - val_auc: 0.8306\n",
      "Epoch 294/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5393 - accuracy: 0.7265 - auc: 0.8052 - val_loss: 0.5169 - val_accuracy: 0.7591 - val_auc: 0.8306\n",
      "Epoch 295/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5459 - accuracy: 0.7166 - auc: 0.7943 - val_loss: 0.5167 - val_accuracy: 0.7591 - val_auc: 0.8302\n",
      "Epoch 296/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5441 - accuracy: 0.7185 - auc: 0.7982 - val_loss: 0.5159 - val_accuracy: 0.7639 - val_auc: 0.8305\n",
      "Epoch 297/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5409 - accuracy: 0.7210 - auc: 0.8017 - val_loss: 0.5163 - val_accuracy: 0.7623 - val_auc: 0.8309\n",
      "Epoch 298/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5417 - accuracy: 0.7146 - auc: 0.8006 - val_loss: 0.5166 - val_accuracy: 0.7655 - val_auc: 0.8300\n",
      "Epoch 299/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5410 - accuracy: 0.7175 - auc: 0.8013 - val_loss: 0.5166 - val_accuracy: 0.7575 - val_auc: 0.8302\n",
      "Epoch 300/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5353 - accuracy: 0.7369 - auc: 0.8073 - val_loss: 0.5161 - val_accuracy: 0.7591 - val_auc: 0.8303\n",
      "Epoch 301/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5448 - accuracy: 0.7215 - auc: 0.7997 - val_loss: 0.5164 - val_accuracy: 0.7575 - val_auc: 0.8306\n",
      "Epoch 302/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5381 - accuracy: 0.7180 - auc: 0.8010 - val_loss: 0.5158 - val_accuracy: 0.7607 - val_auc: 0.8319\n",
      "Epoch 303/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5387 - accuracy: 0.7166 - auc: 0.8033 - val_loss: 0.5159 - val_accuracy: 0.7607 - val_auc: 0.8311\n",
      "Epoch 304/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5396 - accuracy: 0.7265 - auc: 0.8039 - val_loss: 0.5162 - val_accuracy: 0.7575 - val_auc: 0.8308\n",
      "Epoch 305/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5361 - accuracy: 0.7284 - auc: 0.8057 - val_loss: 0.5165 - val_accuracy: 0.7575 - val_auc: 0.8311\n",
      "Epoch 306/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5490 - accuracy: 0.7170 - auc: 0.7932 - val_loss: 0.5163 - val_accuracy: 0.7591 - val_auc: 0.8311\n",
      "Epoch 307/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5505 - accuracy: 0.7121 - auc: 0.7941 - val_loss: 0.5163 - val_accuracy: 0.7575 - val_auc: 0.8307\n",
      "Epoch 308/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5504 - accuracy: 0.7170 - auc: 0.7924 - val_loss: 0.5158 - val_accuracy: 0.7575 - val_auc: 0.8307\n",
      "Epoch 309/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5424 - accuracy: 0.7220 - auc: 0.8004 - val_loss: 0.5161 - val_accuracy: 0.7623 - val_auc: 0.8311\n",
      "Epoch 310/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.7180 - auc: 0.8018 - val_loss: 0.5160 - val_accuracy: 0.7639 - val_auc: 0.8314\n",
      "Epoch 311/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5432 - accuracy: 0.7210 - auc: 0.7980 - val_loss: 0.5160 - val_accuracy: 0.7623 - val_auc: 0.8305\n",
      "Epoch 312/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5373 - accuracy: 0.7319 - auc: 0.8050 - val_loss: 0.5160 - val_accuracy: 0.7591 - val_auc: 0.8302\n",
      "Epoch 313/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5423 - accuracy: 0.7151 - auc: 0.7973 - val_loss: 0.5165 - val_accuracy: 0.7591 - val_auc: 0.8299\n",
      "Epoch 314/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5412 - accuracy: 0.7205 - auc: 0.7984 - val_loss: 0.5169 - val_accuracy: 0.7575 - val_auc: 0.8299\n",
      "Epoch 315/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5353 - accuracy: 0.7175 - auc: 0.8056 - val_loss: 0.5167 - val_accuracy: 0.7544 - val_auc: 0.8302\n",
      "Epoch 316/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5453 - accuracy: 0.7156 - auc: 0.7963 - val_loss: 0.5168 - val_accuracy: 0.7512 - val_auc: 0.8300\n",
      "Epoch 317/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5392 - accuracy: 0.7324 - auc: 0.8039 - val_loss: 0.5160 - val_accuracy: 0.7623 - val_auc: 0.8300\n",
      "Epoch 318/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5410 - accuracy: 0.7190 - auc: 0.8005 - val_loss: 0.5161 - val_accuracy: 0.7639 - val_auc: 0.8307\n",
      "Epoch 319/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5368 - accuracy: 0.7126 - auc: 0.8040 - val_loss: 0.5161 - val_accuracy: 0.7591 - val_auc: 0.8307\n",
      "Epoch 320/700\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5389 - accuracy: 0.7205 - auc: 0.8006 - val_loss: 0.5157 - val_accuracy: 0.7623 - val_auc: 0.8307\n",
      "Epoch 321/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5454 - accuracy: 0.7195 - auc: 0.7966 - val_loss: 0.5162 - val_accuracy: 0.7591 - val_auc: 0.8304\n",
      "Epoch 322/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5441 - accuracy: 0.7220 - auc: 0.7989 - val_loss: 0.5158 - val_accuracy: 0.7607 - val_auc: 0.8307\n",
      "Epoch 323/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5464 - accuracy: 0.7170 - auc: 0.7968 - val_loss: 0.5155 - val_accuracy: 0.7623 - val_auc: 0.8304\n",
      "Epoch 324/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5450 - accuracy: 0.7215 - auc: 0.7977 - val_loss: 0.5154 - val_accuracy: 0.7607 - val_auc: 0.8309\n",
      "Epoch 325/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5458 - accuracy: 0.7289 - auc: 0.7984 - val_loss: 0.5162 - val_accuracy: 0.7639 - val_auc: 0.8300\n",
      "Epoch 326/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5429 - accuracy: 0.7175 - auc: 0.7994 - val_loss: 0.5162 - val_accuracy: 0.7607 - val_auc: 0.8303\n",
      "Epoch 327/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5426 - accuracy: 0.7275 - auc: 0.7999 - val_loss: 0.5157 - val_accuracy: 0.7639 - val_auc: 0.8310\n",
      "Epoch 328/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5387 - accuracy: 0.7195 - auc: 0.8010 - val_loss: 0.5153 - val_accuracy: 0.7623 - val_auc: 0.8314\n",
      "Epoch 329/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5459 - accuracy: 0.7260 - auc: 0.7959 - val_loss: 0.5152 - val_accuracy: 0.7607 - val_auc: 0.8311\n",
      "Epoch 330/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5467 - accuracy: 0.7170 - auc: 0.7957 - val_loss: 0.5155 - val_accuracy: 0.7575 - val_auc: 0.8312\n",
      "Epoch 331/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5391 - accuracy: 0.7131 - auc: 0.8014 - val_loss: 0.5152 - val_accuracy: 0.7639 - val_auc: 0.8311\n",
      "Epoch 332/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5410 - accuracy: 0.7260 - auc: 0.8019 - val_loss: 0.5149 - val_accuracy: 0.7655 - val_auc: 0.8312\n",
      "Epoch 333/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5435 - accuracy: 0.7220 - auc: 0.7996 - val_loss: 0.5154 - val_accuracy: 0.7623 - val_auc: 0.8306\n",
      "Epoch 334/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.7096 - auc: 0.7961 - val_loss: 0.5154 - val_accuracy: 0.7544 - val_auc: 0.8307\n",
      "Epoch 335/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5379 - accuracy: 0.7215 - auc: 0.8027 - val_loss: 0.5152 - val_accuracy: 0.7544 - val_auc: 0.8309\n",
      "Epoch 336/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5396 - accuracy: 0.7289 - auc: 0.8028 - val_loss: 0.5151 - val_accuracy: 0.7559 - val_auc: 0.8310\n",
      "Epoch 337/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5382 - accuracy: 0.7245 - auc: 0.8014 - val_loss: 0.5146 - val_accuracy: 0.7607 - val_auc: 0.8309\n",
      "Epoch 338/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5451 - accuracy: 0.7210 - auc: 0.7988 - val_loss: 0.5151 - val_accuracy: 0.7591 - val_auc: 0.8307\n",
      "Epoch 339/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5445 - accuracy: 0.7205 - auc: 0.7996 - val_loss: 0.5151 - val_accuracy: 0.7559 - val_auc: 0.8305\n",
      "Epoch 340/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5436 - accuracy: 0.7175 - auc: 0.7983 - val_loss: 0.5147 - val_accuracy: 0.7591 - val_auc: 0.8311\n",
      "Epoch 341/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5441 - accuracy: 0.7230 - auc: 0.7978 - val_loss: 0.5153 - val_accuracy: 0.7544 - val_auc: 0.8308\n",
      "Epoch 342/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5428 - accuracy: 0.7121 - auc: 0.8003 - val_loss: 0.5155 - val_accuracy: 0.7575 - val_auc: 0.8311\n",
      "Epoch 343/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5397 - accuracy: 0.7284 - auc: 0.8027 - val_loss: 0.5150 - val_accuracy: 0.7607 - val_auc: 0.8309\n",
      "Epoch 344/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5416 - accuracy: 0.7240 - auc: 0.8004 - val_loss: 0.5150 - val_accuracy: 0.7639 - val_auc: 0.8311\n",
      "Epoch 345/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5365 - accuracy: 0.7245 - auc: 0.8056 - val_loss: 0.5156 - val_accuracy: 0.7544 - val_auc: 0.8302\n",
      "Epoch 346/700\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5429 - accuracy: 0.7166 - auc: 0.7971 - val_loss: 0.5151 - val_accuracy: 0.7607 - val_auc: 0.8307\n",
      "Epoch 347/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.5409 - accuracy: 0.7314 - auc: 0.8012 - val_loss: 0.5149 - val_accuracy: 0.7591 - val_auc: 0.8318\n",
      "Epoch 348/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.5428 - accuracy: 0.7151 - auc: 0.7988 - val_loss: 0.5152 - val_accuracy: 0.7655 - val_auc: 0.8315\n",
      "Epoch 349/700\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.5411 - accuracy: 0.7190 - auc: 0.7992 - val_loss: 0.5160 - val_accuracy: 0.7591 - val_auc: 0.8306\n",
      "Epoch 350/700\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.5461 - accuracy: 0.7136 - auc: 0.7965 - val_loss: 0.5153 - val_accuracy: 0.7623 - val_auc: 0.8308\n",
      "Epoch 351/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5400 - accuracy: 0.7200 - auc: 0.7999 - val_loss: 0.5158 - val_accuracy: 0.7623 - val_auc: 0.8307\n",
      "Epoch 352/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5441 - accuracy: 0.7166 - auc: 0.7984 - val_loss: 0.5160 - val_accuracy: 0.7575 - val_auc: 0.8307\n",
      "Epoch 353/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5416 - accuracy: 0.7265 - auc: 0.7994 - val_loss: 0.5155 - val_accuracy: 0.7575 - val_auc: 0.8308\n",
      "Epoch 354/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5446 - accuracy: 0.7175 - auc: 0.7985 - val_loss: 0.5161 - val_accuracy: 0.7575 - val_auc: 0.8298\n",
      "Epoch 355/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5390 - accuracy: 0.7255 - auc: 0.8020 - val_loss: 0.5155 - val_accuracy: 0.7591 - val_auc: 0.8310\n",
      "Epoch 356/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5475 - accuracy: 0.7225 - auc: 0.7991 - val_loss: 0.5161 - val_accuracy: 0.7591 - val_auc: 0.8300\n",
      "Epoch 357/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5380 - accuracy: 0.7146 - auc: 0.8023 - val_loss: 0.5159 - val_accuracy: 0.7575 - val_auc: 0.8304\n",
      "Epoch 358/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5447 - accuracy: 0.7166 - auc: 0.7962 - val_loss: 0.5153 - val_accuracy: 0.7623 - val_auc: 0.8311\n",
      "Epoch 359/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5379 - accuracy: 0.7284 - auc: 0.8043 - val_loss: 0.5152 - val_accuracy: 0.7623 - val_auc: 0.8311\n",
      "Epoch 360/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5465 - accuracy: 0.7175 - auc: 0.7947 - val_loss: 0.5159 - val_accuracy: 0.7575 - val_auc: 0.8311\n",
      "Epoch 361/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5400 - accuracy: 0.7195 - auc: 0.8007 - val_loss: 0.5151 - val_accuracy: 0.7575 - val_auc: 0.8317\n",
      "Epoch 362/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5360 - accuracy: 0.7195 - auc: 0.8037 - val_loss: 0.5151 - val_accuracy: 0.7575 - val_auc: 0.8314\n",
      "Epoch 363/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5355 - accuracy: 0.7359 - auc: 0.8075 - val_loss: 0.5153 - val_accuracy: 0.7575 - val_auc: 0.8316\n",
      "Epoch 364/700\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.5454 - accuracy: 0.7220 - auc: 0.7964 - val_loss: 0.5145 - val_accuracy: 0.7591 - val_auc: 0.8319\n",
      "Epoch 365/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5411 - accuracy: 0.7215 - auc: 0.7995 - val_loss: 0.5149 - val_accuracy: 0.7575 - val_auc: 0.8311\n",
      "Epoch 366/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5471 - accuracy: 0.7141 - auc: 0.7935 - val_loss: 0.5147 - val_accuracy: 0.7591 - val_auc: 0.8311\n",
      "Epoch 367/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5502 - accuracy: 0.7265 - auc: 0.7925 - val_loss: 0.5145 - val_accuracy: 0.7591 - val_auc: 0.8322\n",
      "Epoch 368/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5422 - accuracy: 0.7240 - auc: 0.8013 - val_loss: 0.5151 - val_accuracy: 0.7559 - val_auc: 0.8309\n",
      "Epoch 369/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5514 - accuracy: 0.7086 - auc: 0.7901 - val_loss: 0.5148 - val_accuracy: 0.7623 - val_auc: 0.8311\n",
      "Epoch 370/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5409 - accuracy: 0.7275 - auc: 0.8022 - val_loss: 0.5154 - val_accuracy: 0.7575 - val_auc: 0.8311\n",
      "Epoch 371/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5333 - accuracy: 0.7270 - auc: 0.8090 - val_loss: 0.5152 - val_accuracy: 0.7623 - val_auc: 0.8317\n",
      "Epoch 372/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5456 - accuracy: 0.7255 - auc: 0.7969 - val_loss: 0.5147 - val_accuracy: 0.7623 - val_auc: 0.8322\n",
      "Epoch 373/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5411 - accuracy: 0.7210 - auc: 0.8003 - val_loss: 0.5148 - val_accuracy: 0.7639 - val_auc: 0.8313\n",
      "Epoch 374/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5453 - accuracy: 0.7185 - auc: 0.7965 - val_loss: 0.5146 - val_accuracy: 0.7655 - val_auc: 0.8313\n",
      "Epoch 375/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5395 - accuracy: 0.7289 - auc: 0.8043 - val_loss: 0.5152 - val_accuracy: 0.7639 - val_auc: 0.8314\n",
      "Epoch 376/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5367 - accuracy: 0.7220 - auc: 0.8043 - val_loss: 0.5149 - val_accuracy: 0.7639 - val_auc: 0.8317\n",
      "Epoch 377/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5386 - accuracy: 0.7185 - auc: 0.8020 - val_loss: 0.5146 - val_accuracy: 0.7623 - val_auc: 0.8321\n",
      "Epoch 378/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5393 - accuracy: 0.7294 - auc: 0.8048 - val_loss: 0.5150 - val_accuracy: 0.7544 - val_auc: 0.8316\n",
      "Epoch 379/700\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.5402 - accuracy: 0.7245 - auc: 0.8009 - val_loss: 0.5142 - val_accuracy: 0.7639 - val_auc: 0.8322\n",
      "Epoch 380/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5382 - accuracy: 0.7205 - auc: 0.8037 - val_loss: 0.5145 - val_accuracy: 0.7623 - val_auc: 0.8316\n",
      "Epoch 381/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5422 - accuracy: 0.7250 - auc: 0.8007 - val_loss: 0.5146 - val_accuracy: 0.7607 - val_auc: 0.8320\n",
      "Epoch 382/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5405 - accuracy: 0.7185 - auc: 0.8007 - val_loss: 0.5142 - val_accuracy: 0.7639 - val_auc: 0.8326\n",
      "Epoch 383/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5454 - accuracy: 0.7156 - auc: 0.7962 - val_loss: 0.5141 - val_accuracy: 0.7607 - val_auc: 0.8320\n",
      "Epoch 384/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5389 - accuracy: 0.7230 - auc: 0.8022 - val_loss: 0.5140 - val_accuracy: 0.7623 - val_auc: 0.8326\n",
      "Epoch 385/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5467 - accuracy: 0.7131 - auc: 0.7942 - val_loss: 0.5139 - val_accuracy: 0.7655 - val_auc: 0.8327\n",
      "Epoch 386/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5395 - accuracy: 0.7116 - auc: 0.8023 - val_loss: 0.5143 - val_accuracy: 0.7623 - val_auc: 0.8320\n",
      "Epoch 387/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5481 - accuracy: 0.7166 - auc: 0.7950 - val_loss: 0.5142 - val_accuracy: 0.7623 - val_auc: 0.8320\n",
      "Epoch 388/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5455 - accuracy: 0.7240 - auc: 0.7959 - val_loss: 0.5148 - val_accuracy: 0.7655 - val_auc: 0.8314\n",
      "Epoch 389/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5416 - accuracy: 0.7279 - auc: 0.8030 - val_loss: 0.5142 - val_accuracy: 0.7607 - val_auc: 0.8319\n",
      "Epoch 390/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5374 - accuracy: 0.7299 - auc: 0.8041 - val_loss: 0.5142 - val_accuracy: 0.7623 - val_auc: 0.8317\n",
      "Epoch 391/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5413 - accuracy: 0.7141 - auc: 0.7978 - val_loss: 0.5139 - val_accuracy: 0.7655 - val_auc: 0.8321\n",
      "Epoch 392/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5392 - accuracy: 0.7111 - auc: 0.7995 - val_loss: 0.5147 - val_accuracy: 0.7623 - val_auc: 0.8315\n",
      "Epoch 393/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5362 - accuracy: 0.7260 - auc: 0.8052 - val_loss: 0.5144 - val_accuracy: 0.7639 - val_auc: 0.8316\n",
      "Epoch 394/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5346 - accuracy: 0.7265 - auc: 0.8053 - val_loss: 0.5142 - val_accuracy: 0.7607 - val_auc: 0.8320\n",
      "Epoch 395/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5365 - accuracy: 0.7349 - auc: 0.8062 - val_loss: 0.5146 - val_accuracy: 0.7575 - val_auc: 0.8321\n",
      "Epoch 396/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5260 - accuracy: 0.7374 - auc: 0.8152 - val_loss: 0.5148 - val_accuracy: 0.7559 - val_auc: 0.8318\n",
      "Epoch 397/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5351 - accuracy: 0.7299 - auc: 0.8068 - val_loss: 0.5141 - val_accuracy: 0.7655 - val_auc: 0.8320\n",
      "Epoch 398/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5390 - accuracy: 0.7156 - auc: 0.8008 - val_loss: 0.5140 - val_accuracy: 0.7607 - val_auc: 0.8321\n",
      "Epoch 399/700\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.5444 - accuracy: 0.7210 - auc: 0.7987 - val_loss: 0.5137 - val_accuracy: 0.7639 - val_auc: 0.8323\n",
      "Epoch 400/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5374 - accuracy: 0.7220 - auc: 0.8037 - val_loss: 0.5135 - val_accuracy: 0.7591 - val_auc: 0.8322\n",
      "Epoch 401/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5410 - accuracy: 0.7131 - auc: 0.7992 - val_loss: 0.5136 - val_accuracy: 0.7623 - val_auc: 0.8316\n",
      "Epoch 402/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5360 - accuracy: 0.7215 - auc: 0.8044 - val_loss: 0.5134 - val_accuracy: 0.7623 - val_auc: 0.8317\n",
      "Epoch 403/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5540 - accuracy: 0.7151 - auc: 0.7877 - val_loss: 0.5140 - val_accuracy: 0.7559 - val_auc: 0.8316\n",
      "Epoch 404/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5309 - accuracy: 0.7225 - auc: 0.8089 - val_loss: 0.5138 - val_accuracy: 0.7575 - val_auc: 0.8319\n",
      "Epoch 405/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5448 - accuracy: 0.7121 - auc: 0.7949 - val_loss: 0.5139 - val_accuracy: 0.7591 - val_auc: 0.8315\n",
      "Epoch 406/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5445 - accuracy: 0.7245 - auc: 0.7990 - val_loss: 0.5138 - val_accuracy: 0.7591 - val_auc: 0.8315\n",
      "Epoch 407/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5365 - accuracy: 0.7175 - auc: 0.8019 - val_loss: 0.5142 - val_accuracy: 0.7607 - val_auc: 0.8318\n",
      "Epoch 408/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5408 - accuracy: 0.7146 - auc: 0.7990 - val_loss: 0.5148 - val_accuracy: 0.7496 - val_auc: 0.8315\n",
      "Epoch 409/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5424 - accuracy: 0.7210 - auc: 0.7984 - val_loss: 0.5145 - val_accuracy: 0.7575 - val_auc: 0.8314\n",
      "Epoch 410/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5412 - accuracy: 0.7250 - auc: 0.8010 - val_loss: 0.5148 - val_accuracy: 0.7559 - val_auc: 0.8311\n",
      "Epoch 411/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5381 - accuracy: 0.7284 - auc: 0.8035 - val_loss: 0.5145 - val_accuracy: 0.7528 - val_auc: 0.8314\n",
      "Epoch 412/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5387 - accuracy: 0.7255 - auc: 0.8041 - val_loss: 0.5137 - val_accuracy: 0.7591 - val_auc: 0.8321\n",
      "Epoch 413/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5418 - accuracy: 0.7210 - auc: 0.8015 - val_loss: 0.5138 - val_accuracy: 0.7544 - val_auc: 0.8323\n",
      "Epoch 414/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5364 - accuracy: 0.7265 - auc: 0.8041 - val_loss: 0.5136 - val_accuracy: 0.7544 - val_auc: 0.8321\n",
      "Epoch 415/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5329 - accuracy: 0.7349 - auc: 0.8108 - val_loss: 0.5138 - val_accuracy: 0.7512 - val_auc: 0.8325\n",
      "Epoch 416/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5277 - accuracy: 0.7359 - auc: 0.8156 - val_loss: 0.5138 - val_accuracy: 0.7559 - val_auc: 0.8325\n",
      "Epoch 417/700\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.5395 - accuracy: 0.7210 - auc: 0.8034 - val_loss: 0.5129 - val_accuracy: 0.7623 - val_auc: 0.8332\n",
      "Epoch 418/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5334 - accuracy: 0.7235 - auc: 0.8076 - val_loss: 0.5132 - val_accuracy: 0.7575 - val_auc: 0.8327\n",
      "Epoch 419/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5379 - accuracy: 0.7240 - auc: 0.8025 - val_loss: 0.5132 - val_accuracy: 0.7623 - val_auc: 0.8327\n",
      "Epoch 420/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5371 - accuracy: 0.7220 - auc: 0.8040 - val_loss: 0.5131 - val_accuracy: 0.7575 - val_auc: 0.8323\n",
      "Epoch 421/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5423 - accuracy: 0.7215 - auc: 0.7979 - val_loss: 0.5123 - val_accuracy: 0.7607 - val_auc: 0.8330\n",
      "Epoch 422/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5368 - accuracy: 0.7250 - auc: 0.8045 - val_loss: 0.5123 - val_accuracy: 0.7623 - val_auc: 0.8327\n",
      "Epoch 423/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5437 - accuracy: 0.7225 - auc: 0.7984 - val_loss: 0.5128 - val_accuracy: 0.7575 - val_auc: 0.8325\n",
      "Epoch 424/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5376 - accuracy: 0.7151 - auc: 0.8019 - val_loss: 0.5127 - val_accuracy: 0.7591 - val_auc: 0.8322\n",
      "Epoch 425/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5379 - accuracy: 0.7384 - auc: 0.8071 - val_loss: 0.5124 - val_accuracy: 0.7607 - val_auc: 0.8328\n",
      "Epoch 426/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5480 - accuracy: 0.7106 - auc: 0.7939 - val_loss: 0.5134 - val_accuracy: 0.7528 - val_auc: 0.8322\n",
      "Epoch 427/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5458 - accuracy: 0.7136 - auc: 0.7950 - val_loss: 0.5126 - val_accuracy: 0.7575 - val_auc: 0.8331\n",
      "Epoch 428/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5482 - accuracy: 0.7220 - auc: 0.7979 - val_loss: 0.5125 - val_accuracy: 0.7591 - val_auc: 0.8332\n",
      "Epoch 429/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5458 - accuracy: 0.7230 - auc: 0.7985 - val_loss: 0.5125 - val_accuracy: 0.7591 - val_auc: 0.8329\n",
      "Epoch 430/700\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.5398 - accuracy: 0.7240 - auc: 0.8013 - val_loss: 0.5123 - val_accuracy: 0.7591 - val_auc: 0.8335\n",
      "Epoch 431/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5368 - accuracy: 0.7096 - auc: 0.8035 - val_loss: 0.5124 - val_accuracy: 0.7575 - val_auc: 0.8333\n",
      "Epoch 432/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5357 - accuracy: 0.7279 - auc: 0.8060 - val_loss: 0.5121 - val_accuracy: 0.7591 - val_auc: 0.8337\n",
      "Epoch 433/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5404 - accuracy: 0.7284 - auc: 0.8029 - val_loss: 0.5119 - val_accuracy: 0.7575 - val_auc: 0.8334\n",
      "Epoch 434/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5354 - accuracy: 0.7180 - auc: 0.8047 - val_loss: 0.5120 - val_accuracy: 0.7623 - val_auc: 0.8332\n",
      "Epoch 435/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5340 - accuracy: 0.7289 - auc: 0.8067 - val_loss: 0.5123 - val_accuracy: 0.7559 - val_auc: 0.8339\n",
      "Epoch 436/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5462 - accuracy: 0.7230 - auc: 0.7955 - val_loss: 0.5127 - val_accuracy: 0.7559 - val_auc: 0.8332\n",
      "Epoch 437/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5381 - accuracy: 0.7235 - auc: 0.8027 - val_loss: 0.5123 - val_accuracy: 0.7528 - val_auc: 0.8333\n",
      "Epoch 438/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5355 - accuracy: 0.7166 - auc: 0.8061 - val_loss: 0.5122 - val_accuracy: 0.7607 - val_auc: 0.8333\n",
      "Epoch 439/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5385 - accuracy: 0.7180 - auc: 0.8019 - val_loss: 0.5122 - val_accuracy: 0.7607 - val_auc: 0.8333\n",
      "Epoch 440/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5412 - accuracy: 0.7289 - auc: 0.8008 - val_loss: 0.5120 - val_accuracy: 0.7639 - val_auc: 0.8334\n",
      "Epoch 441/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5361 - accuracy: 0.7329 - auc: 0.8073 - val_loss: 0.5120 - val_accuracy: 0.7623 - val_auc: 0.8333\n",
      "Epoch 442/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5467 - accuracy: 0.7166 - auc: 0.7964 - val_loss: 0.5124 - val_accuracy: 0.7544 - val_auc: 0.8326\n",
      "Epoch 443/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5367 - accuracy: 0.7284 - auc: 0.8050 - val_loss: 0.5124 - val_accuracy: 0.7607 - val_auc: 0.8331\n",
      "Epoch 444/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5350 - accuracy: 0.7265 - auc: 0.8073 - val_loss: 0.5125 - val_accuracy: 0.7575 - val_auc: 0.8327\n",
      "Epoch 445/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5386 - accuracy: 0.7265 - auc: 0.8020 - val_loss: 0.5135 - val_accuracy: 0.7559 - val_auc: 0.8315\n",
      "Epoch 446/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5403 - accuracy: 0.7101 - auc: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7559 - val_auc: 0.8324\n",
      "Epoch 447/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5338 - accuracy: 0.7205 - auc: 0.8069 - val_loss: 0.5124 - val_accuracy: 0.7623 - val_auc: 0.8332\n",
      "Epoch 448/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5396 - accuracy: 0.7250 - auc: 0.8024 - val_loss: 0.5122 - val_accuracy: 0.7639 - val_auc: 0.8328\n",
      "Epoch 449/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5347 - accuracy: 0.7369 - auc: 0.8071 - val_loss: 0.5119 - val_accuracy: 0.7575 - val_auc: 0.8336\n",
      "Epoch 450/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5431 - accuracy: 0.7329 - auc: 0.7991 - val_loss: 0.5127 - val_accuracy: 0.7512 - val_auc: 0.8331\n",
      "Epoch 451/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5384 - accuracy: 0.7349 - auc: 0.8047 - val_loss: 0.5121 - val_accuracy: 0.7591 - val_auc: 0.8338\n",
      "Epoch 452/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5350 - accuracy: 0.7156 - auc: 0.8033 - val_loss: 0.5123 - val_accuracy: 0.7591 - val_auc: 0.8329\n",
      "Epoch 453/700\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5327 - accuracy: 0.7314 - auc: 0.8079 - val_loss: 0.5118 - val_accuracy: 0.7655 - val_auc: 0.8332\n",
      "Epoch 454/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5333 - accuracy: 0.7255 - auc: 0.8090 - val_loss: 0.5124 - val_accuracy: 0.7591 - val_auc: 0.8327\n",
      "Epoch 455/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5386 - accuracy: 0.7284 - auc: 0.8030 - val_loss: 0.5117 - val_accuracy: 0.7623 - val_auc: 0.8331\n",
      "Epoch 456/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5289 - accuracy: 0.7339 - auc: 0.8108 - val_loss: 0.5116 - val_accuracy: 0.7591 - val_auc: 0.8335\n",
      "Epoch 457/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5388 - accuracy: 0.7126 - auc: 0.7987 - val_loss: 0.5121 - val_accuracy: 0.7575 - val_auc: 0.8333\n",
      "Epoch 458/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5365 - accuracy: 0.7260 - auc: 0.8068 - val_loss: 0.5118 - val_accuracy: 0.7639 - val_auc: 0.8336\n",
      "Epoch 459/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5327 - accuracy: 0.7170 - auc: 0.8052 - val_loss: 0.5117 - val_accuracy: 0.7607 - val_auc: 0.8338\n",
      "Epoch 460/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5409 - accuracy: 0.7146 - auc: 0.8000 - val_loss: 0.5114 - val_accuracy: 0.7639 - val_auc: 0.8335\n",
      "Epoch 461/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5386 - accuracy: 0.7230 - auc: 0.8016 - val_loss: 0.5113 - val_accuracy: 0.7623 - val_auc: 0.8337\n",
      "Epoch 462/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5382 - accuracy: 0.7230 - auc: 0.8031 - val_loss: 0.5122 - val_accuracy: 0.7575 - val_auc: 0.8332\n",
      "Epoch 463/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5448 - accuracy: 0.7170 - auc: 0.7950 - val_loss: 0.5116 - val_accuracy: 0.7575 - val_auc: 0.8335\n",
      "Epoch 464/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5446 - accuracy: 0.7225 - auc: 0.7980 - val_loss: 0.5114 - val_accuracy: 0.7607 - val_auc: 0.8332\n",
      "Epoch 465/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5411 - accuracy: 0.7195 - auc: 0.8017 - val_loss: 0.5112 - val_accuracy: 0.7559 - val_auc: 0.8335\n",
      "Epoch 466/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5445 - accuracy: 0.7200 - auc: 0.7955 - val_loss: 0.5115 - val_accuracy: 0.7623 - val_auc: 0.8329\n",
      "Epoch 467/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5374 - accuracy: 0.7215 - auc: 0.8020 - val_loss: 0.5118 - val_accuracy: 0.7639 - val_auc: 0.8324\n",
      "Epoch 468/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5409 - accuracy: 0.7230 - auc: 0.8011 - val_loss: 0.5122 - val_accuracy: 0.7655 - val_auc: 0.8326\n",
      "Epoch 469/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5454 - accuracy: 0.7166 - auc: 0.7970 - val_loss: 0.5124 - val_accuracy: 0.7607 - val_auc: 0.8325\n",
      "Epoch 470/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5412 - accuracy: 0.7215 - auc: 0.7999 - val_loss: 0.5126 - val_accuracy: 0.7607 - val_auc: 0.8328\n",
      "Epoch 471/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5395 - accuracy: 0.7166 - auc: 0.8001 - val_loss: 0.5116 - val_accuracy: 0.7639 - val_auc: 0.8333\n",
      "Epoch 472/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5459 - accuracy: 0.7190 - auc: 0.7971 - val_loss: 0.5115 - val_accuracy: 0.7623 - val_auc: 0.8334\n",
      "Epoch 473/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5348 - accuracy: 0.7265 - auc: 0.8060 - val_loss: 0.5118 - val_accuracy: 0.7607 - val_auc: 0.8333\n",
      "Epoch 474/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5490 - accuracy: 0.7141 - auc: 0.7910 - val_loss: 0.5120 - val_accuracy: 0.7559 - val_auc: 0.8332\n",
      "Epoch 475/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5410 - accuracy: 0.7180 - auc: 0.7978 - val_loss: 0.5120 - val_accuracy: 0.7623 - val_auc: 0.8334\n",
      "Epoch 476/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5331 - accuracy: 0.7334 - auc: 0.8114 - val_loss: 0.5113 - val_accuracy: 0.7655 - val_auc: 0.8341\n",
      "Epoch 477/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5431 - accuracy: 0.7200 - auc: 0.7972 - val_loss: 0.5116 - val_accuracy: 0.7591 - val_auc: 0.8340\n",
      "Epoch 478/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5448 - accuracy: 0.7195 - auc: 0.7969 - val_loss: 0.5116 - val_accuracy: 0.7607 - val_auc: 0.8339\n",
      "Epoch 479/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5415 - accuracy: 0.7230 - auc: 0.7988 - val_loss: 0.5114 - val_accuracy: 0.7591 - val_auc: 0.8341\n",
      "Epoch 480/700\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.5293 - accuracy: 0.7255 - auc: 0.8125 - val_loss: 0.5107 - val_accuracy: 0.7559 - val_auc: 0.8347\n",
      "Epoch 481/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5331 - accuracy: 0.7235 - auc: 0.8086 - val_loss: 0.5114 - val_accuracy: 0.7591 - val_auc: 0.8341\n",
      "Epoch 482/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5385 - accuracy: 0.7255 - auc: 0.8025 - val_loss: 0.5115 - val_accuracy: 0.7559 - val_auc: 0.8339\n",
      "Epoch 483/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5272 - accuracy: 0.7374 - auc: 0.8146 - val_loss: 0.5115 - val_accuracy: 0.7528 - val_auc: 0.8338\n",
      "Epoch 484/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5446 - accuracy: 0.7210 - auc: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7607 - val_auc: 0.8339\n",
      "Epoch 485/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5388 - accuracy: 0.7195 - auc: 0.8027 - val_loss: 0.5112 - val_accuracy: 0.7623 - val_auc: 0.8337\n",
      "Epoch 486/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5356 - accuracy: 0.7279 - auc: 0.8065 - val_loss: 0.5119 - val_accuracy: 0.7591 - val_auc: 0.8332\n",
      "Epoch 487/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5345 - accuracy: 0.7294 - auc: 0.8085 - val_loss: 0.5118 - val_accuracy: 0.7623 - val_auc: 0.8335\n",
      "Epoch 488/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5418 - accuracy: 0.7230 - auc: 0.8017 - val_loss: 0.5121 - val_accuracy: 0.7591 - val_auc: 0.8334\n",
      "Epoch 489/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5384 - accuracy: 0.7349 - auc: 0.8039 - val_loss: 0.5114 - val_accuracy: 0.7655 - val_auc: 0.8337\n",
      "Epoch 490/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5342 - accuracy: 0.7344 - auc: 0.8078 - val_loss: 0.5113 - val_accuracy: 0.7607 - val_auc: 0.8338\n",
      "Epoch 491/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5374 - accuracy: 0.7245 - auc: 0.8029 - val_loss: 0.5116 - val_accuracy: 0.7544 - val_auc: 0.8338\n",
      "Epoch 492/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5358 - accuracy: 0.7289 - auc: 0.8045 - val_loss: 0.5111 - val_accuracy: 0.7591 - val_auc: 0.8343\n",
      "Epoch 493/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5450 - accuracy: 0.7205 - auc: 0.7975 - val_loss: 0.5108 - val_accuracy: 0.7559 - val_auc: 0.8340\n",
      "Epoch 494/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5384 - accuracy: 0.7215 - auc: 0.8026 - val_loss: 0.5109 - val_accuracy: 0.7639 - val_auc: 0.8338\n",
      "Epoch 495/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5399 - accuracy: 0.7200 - auc: 0.8006 - val_loss: 0.5112 - val_accuracy: 0.7575 - val_auc: 0.8332\n",
      "Epoch 496/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5370 - accuracy: 0.7294 - auc: 0.8046 - val_loss: 0.5110 - val_accuracy: 0.7591 - val_auc: 0.8336\n",
      "Epoch 497/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5357 - accuracy: 0.7284 - auc: 0.8047 - val_loss: 0.5111 - val_accuracy: 0.7607 - val_auc: 0.8336\n",
      "Epoch 498/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5313 - accuracy: 0.7215 - auc: 0.8073 - val_loss: 0.5110 - val_accuracy: 0.7607 - val_auc: 0.8333\n",
      "Epoch 499/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5406 - accuracy: 0.7279 - auc: 0.8002 - val_loss: 0.5108 - val_accuracy: 0.7544 - val_auc: 0.8335\n",
      "Epoch 500/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5428 - accuracy: 0.7215 - auc: 0.7994 - val_loss: 0.5117 - val_accuracy: 0.7512 - val_auc: 0.8333\n",
      "Epoch 501/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5393 - accuracy: 0.7245 - auc: 0.8013 - val_loss: 0.5112 - val_accuracy: 0.7512 - val_auc: 0.8338\n",
      "Epoch 502/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5337 - accuracy: 0.7255 - auc: 0.8077 - val_loss: 0.5108 - val_accuracy: 0.7480 - val_auc: 0.8339\n",
      "Epoch 503/700\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.5329 - accuracy: 0.7220 - auc: 0.8050 - val_loss: 0.5107 - val_accuracy: 0.7528 - val_auc: 0.8339\n",
      "Epoch 504/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5360 - accuracy: 0.7190 - auc: 0.8051 - val_loss: 0.5113 - val_accuracy: 0.7544 - val_auc: 0.8335\n",
      "Epoch 505/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5387 - accuracy: 0.7354 - auc: 0.8040 - val_loss: 0.5118 - val_accuracy: 0.7544 - val_auc: 0.8332\n",
      "Epoch 506/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5414 - accuracy: 0.7265 - auc: 0.8012 - val_loss: 0.5107 - val_accuracy: 0.7559 - val_auc: 0.8343\n",
      "Epoch 507/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5399 - accuracy: 0.7220 - auc: 0.7999 - val_loss: 0.5112 - val_accuracy: 0.7544 - val_auc: 0.8335\n",
      "Epoch 508/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5415 - accuracy: 0.7121 - auc: 0.7973 - val_loss: 0.5104 - val_accuracy: 0.7575 - val_auc: 0.8339\n",
      "Epoch 509/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5443 - accuracy: 0.7230 - auc: 0.7990 - val_loss: 0.5108 - val_accuracy: 0.7544 - val_auc: 0.8334\n",
      "Epoch 510/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5245 - accuracy: 0.7294 - auc: 0.8142 - val_loss: 0.5111 - val_accuracy: 0.7559 - val_auc: 0.8338\n",
      "Epoch 511/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5278 - accuracy: 0.7314 - auc: 0.8124 - val_loss: 0.5112 - val_accuracy: 0.7607 - val_auc: 0.8335\n",
      "Epoch 512/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5419 - accuracy: 0.7161 - auc: 0.7991 - val_loss: 0.5105 - val_accuracy: 0.7575 - val_auc: 0.8344\n",
      "Epoch 513/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5355 - accuracy: 0.7294 - auc: 0.8056 - val_loss: 0.5102 - val_accuracy: 0.7591 - val_auc: 0.8341\n",
      "Epoch 514/700\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5355 - accuracy: 0.7141 - auc: 0.8028 - val_loss: 0.5102 - val_accuracy: 0.7623 - val_auc: 0.8346\n",
      "Epoch 515/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5378 - accuracy: 0.7166 - auc: 0.8012 - val_loss: 0.5101 - val_accuracy: 0.7623 - val_auc: 0.8342\n",
      "Epoch 516/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5365 - accuracy: 0.7359 - auc: 0.8058 - val_loss: 0.5102 - val_accuracy: 0.7575 - val_auc: 0.8347\n",
      "Epoch 517/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5315 - accuracy: 0.7354 - auc: 0.8103 - val_loss: 0.5099 - val_accuracy: 0.7639 - val_auc: 0.8348\n",
      "Epoch 518/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5339 - accuracy: 0.7294 - auc: 0.8079 - val_loss: 0.5102 - val_accuracy: 0.7575 - val_auc: 0.8343\n",
      "Epoch 519/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5450 - accuracy: 0.7240 - auc: 0.7971 - val_loss: 0.5098 - val_accuracy: 0.7607 - val_auc: 0.8346\n",
      "Epoch 520/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5330 - accuracy: 0.7299 - auc: 0.8087 - val_loss: 0.5098 - val_accuracy: 0.7607 - val_auc: 0.8347\n",
      "Epoch 521/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5341 - accuracy: 0.7284 - auc: 0.8058 - val_loss: 0.5106 - val_accuracy: 0.7559 - val_auc: 0.8344\n",
      "Epoch 522/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5418 - accuracy: 0.7190 - auc: 0.7995 - val_loss: 0.5107 - val_accuracy: 0.7591 - val_auc: 0.8336\n",
      "Epoch 523/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5443 - accuracy: 0.7175 - auc: 0.7961 - val_loss: 0.5104 - val_accuracy: 0.7607 - val_auc: 0.8339\n",
      "Epoch 524/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5372 - accuracy: 0.7195 - auc: 0.8028 - val_loss: 0.5112 - val_accuracy: 0.7528 - val_auc: 0.8338\n",
      "Epoch 525/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5329 - accuracy: 0.7185 - auc: 0.8072 - val_loss: 0.5106 - val_accuracy: 0.7544 - val_auc: 0.8342\n",
      "Epoch 526/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5352 - accuracy: 0.7190 - auc: 0.8053 - val_loss: 0.5105 - val_accuracy: 0.7591 - val_auc: 0.8343\n",
      "Epoch 527/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5403 - accuracy: 0.7200 - auc: 0.8001 - val_loss: 0.5105 - val_accuracy: 0.7607 - val_auc: 0.8343\n",
      "Epoch 528/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5451 - accuracy: 0.7230 - auc: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7591 - val_auc: 0.8341\n",
      "Epoch 529/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5423 - accuracy: 0.7215 - auc: 0.7977 - val_loss: 0.5108 - val_accuracy: 0.7559 - val_auc: 0.8341\n",
      "Epoch 530/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5384 - accuracy: 0.7255 - auc: 0.8043 - val_loss: 0.5107 - val_accuracy: 0.7591 - val_auc: 0.8347\n",
      "Epoch 531/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5433 - accuracy: 0.7151 - auc: 0.7985 - val_loss: 0.5108 - val_accuracy: 0.7591 - val_auc: 0.8343\n",
      "Epoch 532/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5361 - accuracy: 0.7299 - auc: 0.8044 - val_loss: 0.5111 - val_accuracy: 0.7559 - val_auc: 0.8338\n",
      "Epoch 533/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5368 - accuracy: 0.7141 - auc: 0.8019 - val_loss: 0.5101 - val_accuracy: 0.7575 - val_auc: 0.8342\n",
      "Epoch 534/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5417 - accuracy: 0.7175 - auc: 0.7992 - val_loss: 0.5109 - val_accuracy: 0.7575 - val_auc: 0.8332\n",
      "Epoch 535/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5403 - accuracy: 0.7230 - auc: 0.8010 - val_loss: 0.5112 - val_accuracy: 0.7575 - val_auc: 0.8327\n",
      "Epoch 536/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5324 - accuracy: 0.7141 - auc: 0.8061 - val_loss: 0.5107 - val_accuracy: 0.7575 - val_auc: 0.8332\n",
      "Epoch 537/700\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5354 - accuracy: 0.7284 - auc: 0.8043 - val_loss: 0.5096 - val_accuracy: 0.7591 - val_auc: 0.8346\n",
      "Epoch 538/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5442 - accuracy: 0.7185 - auc: 0.7990 - val_loss: 0.5099 - val_accuracy: 0.7575 - val_auc: 0.8345\n",
      "Epoch 539/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5354 - accuracy: 0.7309 - auc: 0.8077 - val_loss: 0.5100 - val_accuracy: 0.7607 - val_auc: 0.8346\n",
      "Epoch 540/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5376 - accuracy: 0.7260 - auc: 0.8052 - val_loss: 0.5108 - val_accuracy: 0.7575 - val_auc: 0.8340\n",
      "Epoch 541/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5428 - accuracy: 0.7091 - auc: 0.7957 - val_loss: 0.5099 - val_accuracy: 0.7559 - val_auc: 0.8346\n",
      "Epoch 542/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5375 - accuracy: 0.7284 - auc: 0.8044 - val_loss: 0.5098 - val_accuracy: 0.7591 - val_auc: 0.8345\n",
      "Epoch 543/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5398 - accuracy: 0.7289 - auc: 0.8016 - val_loss: 0.5099 - val_accuracy: 0.7591 - val_auc: 0.8336\n",
      "Epoch 544/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5334 - accuracy: 0.7279 - auc: 0.8071 - val_loss: 0.5100 - val_accuracy: 0.7559 - val_auc: 0.8341\n",
      "Epoch 545/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5474 - accuracy: 0.7205 - auc: 0.7945 - val_loss: 0.5107 - val_accuracy: 0.7559 - val_auc: 0.8338\n",
      "Epoch 546/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5418 - accuracy: 0.7175 - auc: 0.7988 - val_loss: 0.5105 - val_accuracy: 0.7575 - val_auc: 0.8339\n",
      "Epoch 547/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5317 - accuracy: 0.7319 - auc: 0.8106 - val_loss: 0.5107 - val_accuracy: 0.7591 - val_auc: 0.8339\n",
      "Epoch 548/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5327 - accuracy: 0.7230 - auc: 0.8079 - val_loss: 0.5104 - val_accuracy: 0.7544 - val_auc: 0.8342\n",
      "Epoch 549/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5359 - accuracy: 0.7304 - auc: 0.8061 - val_loss: 0.5106 - val_accuracy: 0.7544 - val_auc: 0.8341\n",
      "Epoch 550/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5495 - accuracy: 0.7156 - auc: 0.7936 - val_loss: 0.5109 - val_accuracy: 0.7575 - val_auc: 0.8336\n",
      "Epoch 551/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5328 - accuracy: 0.7334 - auc: 0.8087 - val_loss: 0.5100 - val_accuracy: 0.7528 - val_auc: 0.8345\n",
      "Epoch 552/700\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.5370 - accuracy: 0.7319 - auc: 0.8044 - val_loss: 0.5095 - val_accuracy: 0.7512 - val_auc: 0.8352\n",
      "Epoch 553/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5395 - accuracy: 0.7245 - auc: 0.8005 - val_loss: 0.5094 - val_accuracy: 0.7575 - val_auc: 0.8348\n",
      "Epoch 554/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5321 - accuracy: 0.7324 - auc: 0.8087 - val_loss: 0.5105 - val_accuracy: 0.7512 - val_auc: 0.8342\n",
      "Epoch 555/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5387 - accuracy: 0.7156 - auc: 0.8012 - val_loss: 0.5098 - val_accuracy: 0.7512 - val_auc: 0.8344\n",
      "Epoch 556/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5332 - accuracy: 0.7195 - auc: 0.8082 - val_loss: 0.5112 - val_accuracy: 0.7544 - val_auc: 0.8337\n",
      "Epoch 557/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5333 - accuracy: 0.7299 - auc: 0.8058 - val_loss: 0.5100 - val_accuracy: 0.7559 - val_auc: 0.8343\n",
      "Epoch 558/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5315 - accuracy: 0.7334 - auc: 0.8089 - val_loss: 0.5101 - val_accuracy: 0.7544 - val_auc: 0.8344\n",
      "Epoch 559/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5316 - accuracy: 0.7250 - auc: 0.8062 - val_loss: 0.5100 - val_accuracy: 0.7528 - val_auc: 0.8343\n",
      "Epoch 560/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5421 - accuracy: 0.7270 - auc: 0.7982 - val_loss: 0.5107 - val_accuracy: 0.7559 - val_auc: 0.8340\n",
      "Epoch 561/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5424 - accuracy: 0.7230 - auc: 0.7999 - val_loss: 0.5103 - val_accuracy: 0.7591 - val_auc: 0.8339\n",
      "Epoch 562/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5371 - accuracy: 0.7141 - auc: 0.8016 - val_loss: 0.5105 - val_accuracy: 0.7559 - val_auc: 0.8339\n",
      "Epoch 563/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5372 - accuracy: 0.7349 - auc: 0.8037 - val_loss: 0.5100 - val_accuracy: 0.7639 - val_auc: 0.8346\n",
      "Epoch 564/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5449 - accuracy: 0.7136 - auc: 0.7959 - val_loss: 0.5103 - val_accuracy: 0.7575 - val_auc: 0.8343\n",
      "Epoch 565/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5416 - accuracy: 0.7096 - auc: 0.7987 - val_loss: 0.5103 - val_accuracy: 0.7575 - val_auc: 0.8343\n",
      "Epoch 566/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5309 - accuracy: 0.7309 - auc: 0.8097 - val_loss: 0.5103 - val_accuracy: 0.7655 - val_auc: 0.8338\n",
      "Epoch 567/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5309 - accuracy: 0.7289 - auc: 0.8110 - val_loss: 0.5103 - val_accuracy: 0.7607 - val_auc: 0.8339\n",
      "Epoch 568/700\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.5324 - accuracy: 0.7235 - auc: 0.8061 - val_loss: 0.5092 - val_accuracy: 0.7607 - val_auc: 0.8346\n",
      "Epoch 569/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5372 - accuracy: 0.7225 - auc: 0.8058 - val_loss: 0.5097 - val_accuracy: 0.7528 - val_auc: 0.8350\n",
      "Epoch 570/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5340 - accuracy: 0.7304 - auc: 0.8062 - val_loss: 0.5097 - val_accuracy: 0.7559 - val_auc: 0.8350\n",
      "Epoch 571/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5368 - accuracy: 0.7220 - auc: 0.8057 - val_loss: 0.5096 - val_accuracy: 0.7607 - val_auc: 0.8347\n",
      "Epoch 572/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5397 - accuracy: 0.7086 - auc: 0.7999 - val_loss: 0.5092 - val_accuracy: 0.7559 - val_auc: 0.8347\n",
      "Epoch 573/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5317 - accuracy: 0.7334 - auc: 0.8114 - val_loss: 0.5097 - val_accuracy: 0.7575 - val_auc: 0.8342\n",
      "Epoch 574/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5413 - accuracy: 0.7210 - auc: 0.7994 - val_loss: 0.5091 - val_accuracy: 0.7591 - val_auc: 0.8346\n",
      "Epoch 575/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5305 - accuracy: 0.7349 - auc: 0.8089 - val_loss: 0.5099 - val_accuracy: 0.7559 - val_auc: 0.8345\n",
      "Epoch 576/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5420 - accuracy: 0.7161 - auc: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7528 - val_auc: 0.8347\n",
      "Epoch 577/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5310 - accuracy: 0.7403 - auc: 0.8095 - val_loss: 0.5094 - val_accuracy: 0.7544 - val_auc: 0.8352\n",
      "Epoch 578/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5374 - accuracy: 0.7225 - auc: 0.8037 - val_loss: 0.5108 - val_accuracy: 0.7559 - val_auc: 0.8345\n",
      "Epoch 579/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5339 - accuracy: 0.7190 - auc: 0.8053 - val_loss: 0.5098 - val_accuracy: 0.7496 - val_auc: 0.8348\n",
      "Epoch 580/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5371 - accuracy: 0.7086 - auc: 0.7995 - val_loss: 0.5097 - val_accuracy: 0.7512 - val_auc: 0.8350\n",
      "Epoch 581/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5367 - accuracy: 0.7170 - auc: 0.8035 - val_loss: 0.5096 - val_accuracy: 0.7496 - val_auc: 0.8353\n",
      "Epoch 582/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5359 - accuracy: 0.7200 - auc: 0.8039 - val_loss: 0.5094 - val_accuracy: 0.7512 - val_auc: 0.8353\n",
      "Epoch 583/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5341 - accuracy: 0.7265 - auc: 0.8065 - val_loss: 0.5096 - val_accuracy: 0.7544 - val_auc: 0.8345\n",
      "Epoch 584/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5319 - accuracy: 0.7329 - auc: 0.8098 - val_loss: 0.5095 - val_accuracy: 0.7559 - val_auc: 0.8345\n",
      "Epoch 585/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5296 - accuracy: 0.7393 - auc: 0.8107 - val_loss: 0.5093 - val_accuracy: 0.7544 - val_auc: 0.8345\n",
      "Epoch 586/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5349 - accuracy: 0.7329 - auc: 0.8069 - val_loss: 0.5095 - val_accuracy: 0.7575 - val_auc: 0.8347\n",
      "Epoch 587/700\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.5342 - accuracy: 0.7279 - auc: 0.8076 - val_loss: 0.5091 - val_accuracy: 0.7544 - val_auc: 0.8350\n",
      "Epoch 588/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5314 - accuracy: 0.7339 - auc: 0.8080 - val_loss: 0.5095 - val_accuracy: 0.7559 - val_auc: 0.8345\n",
      "Epoch 589/700\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5401 - accuracy: 0.7260 - auc: 0.8002 - val_loss: 0.5086 - val_accuracy: 0.7544 - val_auc: 0.8357\n",
      "Epoch 590/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5387 - accuracy: 0.7240 - auc: 0.8036 - val_loss: 0.5083 - val_accuracy: 0.7512 - val_auc: 0.8358\n",
      "Epoch 591/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5340 - accuracy: 0.7235 - auc: 0.8080 - val_loss: 0.5088 - val_accuracy: 0.7544 - val_auc: 0.8355\n",
      "Epoch 592/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5412 - accuracy: 0.7146 - auc: 0.7986 - val_loss: 0.5086 - val_accuracy: 0.7512 - val_auc: 0.8356\n",
      "Epoch 593/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5392 - accuracy: 0.7265 - auc: 0.8025 - val_loss: 0.5088 - val_accuracy: 0.7544 - val_auc: 0.8350\n",
      "Epoch 594/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5338 - accuracy: 0.7275 - auc: 0.8075 - val_loss: 0.5093 - val_accuracy: 0.7591 - val_auc: 0.8349\n",
      "Epoch 595/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5369 - accuracy: 0.7210 - auc: 0.8048 - val_loss: 0.5088 - val_accuracy: 0.7591 - val_auc: 0.8348\n",
      "Epoch 596/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5237 - accuracy: 0.7279 - auc: 0.8143 - val_loss: 0.5081 - val_accuracy: 0.7528 - val_auc: 0.8354\n",
      "Epoch 597/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5333 - accuracy: 0.7151 - auc: 0.8050 - val_loss: 0.5086 - val_accuracy: 0.7591 - val_auc: 0.8350\n",
      "Epoch 598/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5483 - accuracy: 0.7101 - auc: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7528 - val_auc: 0.8352\n",
      "Epoch 599/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5388 - accuracy: 0.7131 - auc: 0.7999 - val_loss: 0.5083 - val_accuracy: 0.7591 - val_auc: 0.8351\n",
      "Epoch 600/700\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5334 - accuracy: 0.7299 - auc: 0.8077 - val_loss: 0.5083 - val_accuracy: 0.7559 - val_auc: 0.8355\n",
      "Epoch 601/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5284 - accuracy: 0.7294 - auc: 0.8105 - val_loss: 0.5086 - val_accuracy: 0.7512 - val_auc: 0.8353\n",
      "Epoch 602/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5356 - accuracy: 0.7324 - auc: 0.8045 - val_loss: 0.5082 - val_accuracy: 0.7496 - val_auc: 0.8354\n",
      "Epoch 603/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5381 - accuracy: 0.7086 - auc: 0.7988 - val_loss: 0.5087 - val_accuracy: 0.7528 - val_auc: 0.8352\n",
      "Epoch 604/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5367 - accuracy: 0.7260 - auc: 0.8047 - val_loss: 0.5083 - val_accuracy: 0.7528 - val_auc: 0.8357\n",
      "Epoch 605/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5360 - accuracy: 0.7265 - auc: 0.8046 - val_loss: 0.5084 - val_accuracy: 0.7496 - val_auc: 0.8357\n",
      "Epoch 606/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5332 - accuracy: 0.7240 - auc: 0.8068 - val_loss: 0.5087 - val_accuracy: 0.7512 - val_auc: 0.8356\n",
      "Epoch 607/700\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5386 - accuracy: 0.7180 - auc: 0.8028 - val_loss: 0.5079 - val_accuracy: 0.7512 - val_auc: 0.8357\n",
      "Epoch 608/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5321 - accuracy: 0.7304 - auc: 0.8089 - val_loss: 0.5085 - val_accuracy: 0.7559 - val_auc: 0.8354\n",
      "Epoch 609/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5299 - accuracy: 0.7294 - auc: 0.8111 - val_loss: 0.5085 - val_accuracy: 0.7544 - val_auc: 0.8352\n",
      "Epoch 610/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5367 - accuracy: 0.7235 - auc: 0.8042 - val_loss: 0.5081 - val_accuracy: 0.7544 - val_auc: 0.8358\n",
      "Epoch 611/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5428 - accuracy: 0.7146 - auc: 0.7959 - val_loss: 0.5079 - val_accuracy: 0.7480 - val_auc: 0.8352\n",
      "Epoch 612/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5333 - accuracy: 0.7294 - auc: 0.8092 - val_loss: 0.5074 - val_accuracy: 0.7544 - val_auc: 0.8358\n",
      "Epoch 613/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5385 - accuracy: 0.7245 - auc: 0.8035 - val_loss: 0.5083 - val_accuracy: 0.7544 - val_auc: 0.8350\n",
      "Epoch 614/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5392 - accuracy: 0.7245 - auc: 0.8019 - val_loss: 0.5085 - val_accuracy: 0.7575 - val_auc: 0.8349\n",
      "Epoch 615/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5424 - accuracy: 0.7175 - auc: 0.7975 - val_loss: 0.5083 - val_accuracy: 0.7559 - val_auc: 0.8353\n",
      "Epoch 616/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5382 - accuracy: 0.7225 - auc: 0.8034 - val_loss: 0.5086 - val_accuracy: 0.7575 - val_auc: 0.8351\n",
      "Epoch 617/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5313 - accuracy: 0.7255 - auc: 0.8066 - val_loss: 0.5077 - val_accuracy: 0.7607 - val_auc: 0.8360\n",
      "Epoch 618/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5333 - accuracy: 0.7240 - auc: 0.8074 - val_loss: 0.5082 - val_accuracy: 0.7528 - val_auc: 0.8358\n",
      "Epoch 619/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5439 - accuracy: 0.7170 - auc: 0.7982 - val_loss: 0.5076 - val_accuracy: 0.7528 - val_auc: 0.8364\n",
      "Epoch 620/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5333 - accuracy: 0.7235 - auc: 0.8052 - val_loss: 0.5077 - val_accuracy: 0.7512 - val_auc: 0.8365\n",
      "Epoch 621/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5417 - accuracy: 0.7260 - auc: 0.8025 - val_loss: 0.5076 - val_accuracy: 0.7544 - val_auc: 0.8362\n",
      "Epoch 622/700\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5428 - accuracy: 0.7126 - auc: 0.7963 - val_loss: 0.5070 - val_accuracy: 0.7591 - val_auc: 0.8361\n",
      "Epoch 623/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5257 - accuracy: 0.7374 - auc: 0.8142 - val_loss: 0.5076 - val_accuracy: 0.7575 - val_auc: 0.8360\n",
      "Epoch 624/700\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5371 - accuracy: 0.7220 - auc: 0.8042 - val_loss: 0.5076 - val_accuracy: 0.7607 - val_auc: 0.8358\n",
      "Epoch 625/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5358 - accuracy: 0.7230 - auc: 0.8044 - val_loss: 0.5077 - val_accuracy: 0.7607 - val_auc: 0.8357\n",
      "Epoch 626/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5284 - accuracy: 0.7334 - auc: 0.8107 - val_loss: 0.5079 - val_accuracy: 0.7639 - val_auc: 0.8355\n",
      "Epoch 627/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5381 - accuracy: 0.7319 - auc: 0.8048 - val_loss: 0.5076 - val_accuracy: 0.7591 - val_auc: 0.8357\n",
      "Epoch 628/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5388 - accuracy: 0.7260 - auc: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7591 - val_auc: 0.8357\n",
      "Epoch 629/700\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.5334 - accuracy: 0.7403 - auc: 0.8078 - val_loss: 0.5067 - val_accuracy: 0.7575 - val_auc: 0.8364\n",
      "Epoch 630/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5367 - accuracy: 0.7185 - auc: 0.8018 - val_loss: 0.5067 - val_accuracy: 0.7544 - val_auc: 0.8365\n",
      "Epoch 631/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5426 - accuracy: 0.7185 - auc: 0.7987 - val_loss: 0.5071 - val_accuracy: 0.7575 - val_auc: 0.8358\n",
      "Epoch 632/700\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5387 - accuracy: 0.7245 - auc: 0.8013 - val_loss: 0.5066 - val_accuracy: 0.7575 - val_auc: 0.8366\n",
      "Epoch 633/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5385 - accuracy: 0.7260 - auc: 0.8015 - val_loss: 0.5068 - val_accuracy: 0.7575 - val_auc: 0.8365\n",
      "Epoch 634/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5280 - accuracy: 0.7270 - auc: 0.8124 - val_loss: 0.5075 - val_accuracy: 0.7544 - val_auc: 0.8361\n",
      "Epoch 635/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5372 - accuracy: 0.7284 - auc: 0.8056 - val_loss: 0.5076 - val_accuracy: 0.7544 - val_auc: 0.8357\n",
      "Epoch 636/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5419 - accuracy: 0.7205 - auc: 0.8009 - val_loss: 0.5075 - val_accuracy: 0.7559 - val_auc: 0.8357\n",
      "Epoch 637/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5416 - accuracy: 0.7260 - auc: 0.8000 - val_loss: 0.5071 - val_accuracy: 0.7512 - val_auc: 0.8362\n",
      "Epoch 638/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5300 - accuracy: 0.7289 - auc: 0.8097 - val_loss: 0.5073 - val_accuracy: 0.7512 - val_auc: 0.8362\n",
      "Epoch 639/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5468 - accuracy: 0.7175 - auc: 0.7950 - val_loss: 0.5081 - val_accuracy: 0.7544 - val_auc: 0.8361\n",
      "Epoch 640/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5345 - accuracy: 0.7240 - auc: 0.8048 - val_loss: 0.5076 - val_accuracy: 0.7544 - val_auc: 0.8364\n",
      "Epoch 641/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5373 - accuracy: 0.7235 - auc: 0.8022 - val_loss: 0.5076 - val_accuracy: 0.7607 - val_auc: 0.8361\n",
      "Epoch 642/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5346 - accuracy: 0.7195 - auc: 0.8055 - val_loss: 0.5069 - val_accuracy: 0.7575 - val_auc: 0.8366\n",
      "Epoch 643/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5316 - accuracy: 0.7275 - auc: 0.8071 - val_loss: 0.5073 - val_accuracy: 0.7544 - val_auc: 0.8363\n",
      "Epoch 644/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5338 - accuracy: 0.7304 - auc: 0.8066 - val_loss: 0.5071 - val_accuracy: 0.7575 - val_auc: 0.8365\n",
      "Epoch 645/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5434 - accuracy: 0.7339 - auc: 0.8022 - val_loss: 0.5075 - val_accuracy: 0.7575 - val_auc: 0.8363\n",
      "Epoch 646/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5298 - accuracy: 0.7334 - auc: 0.8133 - val_loss: 0.5071 - val_accuracy: 0.7528 - val_auc: 0.8367\n",
      "Epoch 647/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5332 - accuracy: 0.7260 - auc: 0.8064 - val_loss: 0.5072 - val_accuracy: 0.7559 - val_auc: 0.8366\n",
      "Epoch 648/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5353 - accuracy: 0.7284 - auc: 0.8078 - val_loss: 0.5078 - val_accuracy: 0.7559 - val_auc: 0.8366\n",
      "Epoch 649/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5356 - accuracy: 0.7250 - auc: 0.8038 - val_loss: 0.5068 - val_accuracy: 0.7607 - val_auc: 0.8369\n",
      "Epoch 650/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5400 - accuracy: 0.7245 - auc: 0.7998 - val_loss: 0.5074 - val_accuracy: 0.7591 - val_auc: 0.8370\n",
      "Epoch 651/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5337 - accuracy: 0.7304 - auc: 0.8103 - val_loss: 0.5080 - val_accuracy: 0.7544 - val_auc: 0.8362\n",
      "Epoch 652/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5352 - accuracy: 0.7235 - auc: 0.8062 - val_loss: 0.5076 - val_accuracy: 0.7528 - val_auc: 0.8364\n",
      "Epoch 653/700\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5351 - accuracy: 0.7299 - auc: 0.8059 - val_loss: 0.5078 - val_accuracy: 0.7559 - val_auc: 0.8359\n",
      "Epoch 654/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5325 - accuracy: 0.7284 - auc: 0.8094 - val_loss: 0.5075 - val_accuracy: 0.7528 - val_auc: 0.8360\n",
      "Epoch 655/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5301 - accuracy: 0.7359 - auc: 0.8120 - val_loss: 0.5077 - val_accuracy: 0.7559 - val_auc: 0.8356\n",
      "Epoch 656/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5357 - accuracy: 0.7275 - auc: 0.8041 - val_loss: 0.5081 - val_accuracy: 0.7575 - val_auc: 0.8360\n",
      "Epoch 657/700\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5410 - accuracy: 0.7275 - auc: 0.8010 - val_loss: 0.5076 - val_accuracy: 0.7575 - val_auc: 0.8360\n",
      "Epoch 658/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5346 - accuracy: 0.7250 - auc: 0.8041 - val_loss: 0.5078 - val_accuracy: 0.7559 - val_auc: 0.8362\n",
      "Epoch 659/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5281 - accuracy: 0.7314 - auc: 0.8118 - val_loss: 0.5077 - val_accuracy: 0.7559 - val_auc: 0.8363\n",
      "Epoch 660/700\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.5326 - accuracy: 0.7314 - auc: 0.8085 - val_loss: 0.5077 - val_accuracy: 0.7591 - val_auc: 0.8366\n",
      "Epoch 661/700\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5345 - accuracy: 0.7314 - auc: 0.8079 - val_loss: 0.5083 - val_accuracy: 0.7575 - val_auc: 0.8363\n",
      "Epoch 662/700\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5322 - accuracy: 0.7250 - auc: 0.8078 - val_loss: 0.5081 - val_accuracy: 0.7559 - val_auc: 0.8359\n",
      "Epoch 00662: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('sad_ravdess_meld.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1596201573556,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ddcJYxjpRmou"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('sad_ravdess_meld.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1596201607881,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "w4snlhBmRqz8"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_predictions_baseline = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1596201610320,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1596201613342,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "a8d30e2a-88e3-42e0-d717-ad16463270f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5065837502479553\n",
      "accuracy :  0.7575277090072632\n",
      "auc :  0.8366439938545227\n",
      "\n",
      "(True Negatives):  353\n",
      "(False Positives):  58\n",
      "(False Negatives):  95\n",
      "(True Positives):  125\n",
      "Total emotions_happy:  220\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       411\n",
      "           1       0.68      0.57      0.62       220\n",
      "\n",
      "    accuracy                           0.76       631\n",
      "   macro avg       0.74      0.71      0.72       631\n",
      "weighted avg       0.75      0.76      0.75       631\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1596201616994,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "GJk2L3O8ImIn"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 964,
     "status": "ok",
     "timestamp": 1596201620008,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "51a1d607-7bb6-460c-9a82-929ad3f48ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5445708632469177\n",
      "accuracy :  0.7287128567695618\n",
      "auc :  0.7985079884529114\n",
      "\n",
      "(True Negatives):  273\n",
      "(False Positives):  66\n",
      "(False Negatives):  71\n",
      "(True Positives):  95\n",
      "Total emotions_happy:  166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       339\n",
      "           1       0.59      0.57      0.58       166\n",
      "\n",
      "    accuracy                           0.73       505\n",
      "   macro avg       0.69      0.69      0.69       505\n",
      "weighted avg       0.73      0.73      0.73       505\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMH8llOXbtHjTn+8NuMkTQf",
   "name": "deep_sad_RAVDESS_MELD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
