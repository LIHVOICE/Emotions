{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13244,
     "status": "ok",
     "timestamp": 1596310413387,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ymHSlukhKIF9",
    "outputId": "d8d51ca4-31fe-45b8-e10b-327262cb5a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.7.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 2.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (2.1.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.18.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.16.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (4.4.2)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.15.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.48.0)\n",
      "Collecting soundfile>=0.9.0\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (49.2.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.14.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)\n",
      "Building wheels for collected packages: librosa\n",
      "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for librosa: filename=librosa-0.7.2-cp36-none-any.whl size=1612885 sha256=e9c15a781451854710a2718893faea09522a5057d69e2d574e87cce9b8f29cef\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/6e/d7/bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
      "Successfully built librosa\n",
      "Installing collected packages: soundfile, librosa\n",
      "  Found existing installation: librosa 0.6.3\n",
      "    Uninstalling librosa-0.6.3:\n",
      "      Successfully uninstalled librosa-0.6.3\n",
      "Successfully installed librosa-0.7.2 soundfile-0.10.3.post1\n"
     ]
    }
   ],
   "source": [
    "pip install librosa==0.7.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10002,
     "status": "ok",
     "timestamp": 1596026935548,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "sXnDmXR7RDr2",
    "outputId": "3b9dff36-3699-413b-8a0a-75f3af305685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10711,
     "status": "ok",
     "timestamp": 1596026954464,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Y04m-jvKRDsJ",
    "outputId": "ce46bb70-bae2-4985-8f6b-ee3fece0cc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
      "CPU (s):\n",
      "2.876127255\n",
      "GPU (s):\n",
      "0.1083209219999901\n",
      "GPU speedup over CPU: 26x\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()https://support.mozilla.org/fr/kb/comment-vider-le-cache-de-firefox\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121357,
     "status": "ok",
     "timestamp": 1596310572075,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l9EbbgJpzQDD",
    "outputId": "20fbcbfd-e11b-4f71-f4d4-c2e6cd8ff05c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8717,
     "status": "ok",
     "timestamp": 1596310604639,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ltf4WKPCeyVR",
    "outputId": "c2fb00f1-84d1-48d8-9e8f-8592fc9d5dd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praat-parselmouth\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7b/9fa1172a63b6277603d27bb5613559b5a8888f58e68c1698017b87b0061d/praat_parselmouth-0.3.3-cp36-cp36m-manylinux1_x86_64.whl (9.0MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0MB 2.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from praat-parselmouth) (1.18.5)\n",
      "Installing collected packages: praat-parselmouth\n",
      "Successfully installed praat-parselmouth-0.3.3\n"
     ]
    }
   ],
   "source": [
    "pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9541,
     "status": "ok",
     "timestamp": 1596310625309,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PNwtWyMXe_Qb",
    "outputId": "cee107da-102a-4df2-c45c-193a6dbaffa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting essentia\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/cf/3c776d02b63fed7b0958bef2ce57b900870e2ac3f1fd8ffbb63f22d0e69e/essentia-2.1b6.dev234-cp36-cp36m-manylinux1_x86_64.whl (11.7MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7MB 359kB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from essentia) (3.13)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from essentia) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from essentia) (1.18.5)\n",
      "Installing collected packages: essentia\n",
      "Successfully installed essentia-2.1b6.dev234\n"
     ]
    }
   ],
   "source": [
    "pip install essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6719,
     "status": "ok",
     "timestamp": 1596310646166,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "B9TmOS9AFg61",
    "outputId": "b08d8c96-0d28-45d4-e7f8-aa509a6b4999"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "#Spafe for audio\n",
    "#import spafe\n",
    "import scipy.io.wavfile\n",
    "#import spafe.utils.vis as vis\n",
    "#from spafe.features.mfcc import mfcc, imfcc\n",
    "#from spafe.features.gfcc import gfcc\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2011,
     "status": "ok",
     "timestamp": 1596310686585,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "QAD42F-CgYli",
    "outputId": "c1201328-a8cf-4090-d8e1-105300860c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "cd drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20780,
     "status": "ok",
     "timestamp": 1596310750890,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "3786fb25-5d34-48d0-f7e2-4ff230b6dc90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disgust/disgust_03-01-07-02-01-02-23_norm_outN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral/neutral_dia11_utt1_norm_outNoise.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust/disgust_03-01-07-01-01-01-18_norm_outN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprised/suprised_03-01-08-01-01-01-15_norm_o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fearfull/fearfull_03-01-06-02-02-02-08_norm_ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio label\n",
       "0  disgust/disgust_03-01-07-02-01-02-23_norm_outN...     0\n",
       "1       neutral/neutral_dia11_utt1_norm_outNoise.wav     1\n",
       "2  disgust/disgust_03-01-07-01-01-01-18_norm_outN...     0\n",
       "3  surprised/suprised_03-01-08-01-01-01-15_norm_o...     0\n",
       "4  fearfull/fearfull_03-01-06-02-02-02-08_norm_ou...     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"fusion_data\"\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i.startswith(\"neutral\"):\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) # here at df defined, with the columns we add the values:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1596310773848,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "374c3f5f-eda0-43ff-f485-540a9f1dd873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1753\n",
      "1     535\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjNAMwsfG2C8"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    fs, sig = scipy.io.wavfile.read(audio_path) \n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    spec =  fram_window(audio_path) \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)\n",
    "            \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "               \n",
    "    #gfccs = gfcc(sig= spec, fs=fs, num_ceps=13)    \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    #features.append(np.mean(gfccs))\n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "folder ='fusion_data'\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(folder+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1596289585023,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "91401075-dcb2-4a8a-afb9-ffdc8056f7d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1596289677023,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "f7df9cd8-b416-49a9-eb51-f4072744455f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 1243\n",
      "After OverSampling, counts of label '0': 2075\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HmCSFrX3uO-"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGH8xzEd3zMo"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPUcXA6f4DcQ"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3QCHMyl4HVw"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1596316494368,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VkaD0N1w4JxN",
    "outputId": "8c5f65d6-6ab5-4c29-fcd1-f52684757cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 1037\n",
      "After OverSampling, counts of label '0': 1753\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \" [1, 3, 4, 6, 9, 12, 13, 14, 18, 19, 21]   \" are deleted 276 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 85775,
     "status": "ok",
     "timestamp": 1596316621831,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "f95b3e72-3c23-47b3-ebc0-e64dee0bd3d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 4, 6, 9, 12, 13, 14, 18, 19, 20, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 3, 4, 6, 9, 12, 13, 14, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 3, 4, 6, 9, 12, 13, 14, 18, 19, 20, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 3, 4, 6, 9, 13, 14, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 3, 4, 6, 8, 9, 12, 13, 14, 18, 19, 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration                                    X_removed\n",
       "0         1  [1, 3, 4, 6, 9, 12, 13, 14, 18, 19, 20, 21]\n",
       "1         2      [1, 3, 4, 6, 9, 12, 13, 14, 18, 19, 21]\n",
       "2         3  [1, 3, 4, 6, 9, 12, 13, 14, 18, 19, 20, 21]\n",
       "3         4          [1, 3, 4, 6, 9, 13, 14, 18, 19, 21]\n",
       "4         5   [1, 3, 4, 6, 8, 9, 12, 13, 14, 18, 19, 21]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 6, 9, 12, 13, 14, 18, 19, 21]                   276\n",
       "[1, 3, 4, 6, 9, 13, 14, 18, 19, 21]                       172\n",
       "[1, 3, 4, 6, 9, 12, 13, 18, 19, 21]                        90\n",
       "[1, 3, 4, 6, 9, 13, 18, 19, 21]                            65\n",
       "[1, 3, 4, 6, 8, 9, 12, 13, 14, 18, 19, 21]                 57\n",
       "[1, 3, 4, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 21]         43\n",
       "[1, 3, 4, 6, 8, 9, 13, 14, 18, 19, 21]                     35\n",
       "[1, 3, 4, 6, 8, 9, 13, 18, 19, 21]                         33\n",
       "[1, 3, 4, 6, 8, 9, 12, 13, 18, 19, 21]                     31\n",
       "[1, 3, 4, 6, 9, 12, 13, 14, 15, 17, 18, 19, 21]            30\n",
       "[1, 3, 4, 6, 8, 9, 13, 14, 15, 17, 18, 19, 21]             28\n",
       "[1, 3, 4, 6, 9, 13, 14, 15, 17, 18, 19, 21]                20\n",
       "[1, 3, 4, 6, 8, 9, 12, 13, 15, 17, 18, 19, 21]             20\n",
       "[1, 3, 4, 6, 9, 12, 13, 14, 18, 19, 20, 21]                17\n",
       "[1, 3, 4, 6, 8, 9, 13, 15, 17, 18, 19, 21]                 16\n",
       "[1, 3, 4, 6, 9, 13, 15, 17, 18, 19, 21]                    16\n",
       "[1, 3, 4, 6, 9, 12, 13, 15, 17, 18, 19, 21]                12\n",
       "[1, 3, 4, 6, 9, 13, 14, 18, 19, 20, 21]                     5\n",
       "[1, 3, 4, 6, 9, 12, 13, 18, 19, 20, 21]                     5\n",
       "[1, 3, 4, 6, 9, 12, 13, 14, 15, 17, 18, 19, 20, 21]         5\n",
       "[1, 3, 4, 6, 13, 18, 19, 21]                                3\n",
       "[1, 3, 4, 6, 8, 9, 12, 13, 18, 19, 20, 21]                  3\n",
       "[1, 3, 4, 6, 9, 13, 18, 19, 20, 21]                         3\n",
       "[1, 3, 4, 6, 9, 13, 15, 17, 18, 19, 20, 21]                 2\n",
       "[1, 3, 4, 6, 12, 13, 14, 18, 19, 21]                        2\n",
       "[1, 3, 4, 6, 8, 9, 13, 14, 18, 19, 20, 21]                  1\n",
       "[1, 3, 4, 6, 12, 13, 15, 17, 18, 19, 21]                    1\n",
       "[1, 3, 4, 6, 13, 14, 18, 19, 21]                            1\n",
       "[1, 3, 4, 6, 12, 13, 14, 15, 17, 18, 19, 21]                1\n",
       "[1, 3, 4, 6, 8, 9, 13, 14, 15, 17, 18, 19, 20, 21]          1\n",
       "[1, 3, 4, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 20, 21]      1\n",
       "[1, 3, 4, 6, 8, 12, 13, 14, 15, 17, 18, 19, 21]             1\n",
       "[1, 3, 4, 6, 9, 13, 14, 15, 17, 18, 19, 20, 21]             1\n",
       "[1, 3, 4, 6, 8, 9, 12, 13, 14, 18, 19, 20, 21]              1\n",
       "[1, 3, 4, 6, 12, 13, 18, 19, 21]                            1\n",
       "[1, 3, 4, 6, 8, 13, 14, 15, 17, 18, 19, 21]                 1\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sTQj5wDWdev"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0],  X[i][2],  X[i][5],   X[i][7],\n",
    "             X[i][8] ,  X[i][10], X[i][11],  X[i][15], X[i][16], \n",
    "                X[i][17], X[i][20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1257,
     "status": "ok",
     "timestamp": 1596316752086,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "79a38d49-91b7-444f-c29f-193ffdfb671e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1785\n",
      "558\n",
      "447\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2828,
     "status": "ok",
     "timestamp": 1596316799680,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "TWis1PUVfK_4",
    "outputId": "caebfc1a-65b6-4c63-d918-58be5c73685c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Plot imports ###\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "### Warning ###\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1239,
     "status": "ok",
     "timestamp": 1596316835550,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "9111817c-4a08-47e4-9407-722f07c2d814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1785, 11, 1)\n",
      "(558, 11, 1)\n",
      "(447, 11, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1552,
     "status": "ok",
     "timestamp": 1596316862268,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "33849981-0c67-4f47-89d9-ce3f6b6e71f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1785, 2)\n",
      "(558, 2)\n",
      "(447, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (11,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2214,
     "status": "ok",
     "timestamp": 1596317044694,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "2f3d2cec-d311-43eb-9a7e-ed8d44172123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 11, 1)]           0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 11, 128)           768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 11, 128)           512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 11, 128)           82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2818      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 86,154\n",
      "Trainable params: 85,894\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## First LFLB (local feature learning block)\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28674,
     "status": "ok",
     "timestamp": 1596317084412,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "343fdb1e-491e-473e-c837-5afc64bb9e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 0.7342 - accuracy: 0.5630 - auc: 0.5715 - val_loss: 0.6639 - val_accuracy: 0.6846 - val_auc: 0.7365\n",
      "Epoch 2/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.6604 - accuracy: 0.6403 - auc: 0.6808 - val_loss: 0.6496 - val_accuracy: 0.6649 - val_auc: 0.7500\n",
      "Epoch 3/700\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.6286 - accuracy: 0.6678 - auc: 0.7148 - val_loss: 0.6396 - val_accuracy: 0.6613 - val_auc: 0.7458\n",
      "Epoch 4/700\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.6317 - accuracy: 0.6751 - auc: 0.7159 - val_loss: 0.6320 - val_accuracy: 0.6577 - val_auc: 0.7457\n",
      "Epoch 5/700\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.6143 - accuracy: 0.6790 - auc: 0.7324 - val_loss: 0.6263 - val_accuracy: 0.6667 - val_auc: 0.7454\n",
      "Epoch 6/700\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.5990 - accuracy: 0.6958 - auc: 0.7460 - val_loss: 0.6222 - val_accuracy: 0.6756 - val_auc: 0.7445\n",
      "Epoch 7/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.6031 - accuracy: 0.6936 - auc: 0.7433 - val_loss: 0.6192 - val_accuracy: 0.6685 - val_auc: 0.7417\n",
      "Epoch 8/700\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.5935 - accuracy: 0.6913 - auc: 0.7516 - val_loss: 0.6173 - val_accuracy: 0.6703 - val_auc: 0.7380\n",
      "Epoch 9/700\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.6000 - accuracy: 0.6930 - auc: 0.7483 - val_loss: 0.6145 - val_accuracy: 0.6828 - val_auc: 0.7352\n",
      "Epoch 10/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5943 - accuracy: 0.6913 - auc: 0.7524 - val_loss: 0.6122 - val_accuracy: 0.6774 - val_auc: 0.7324\n",
      "Epoch 11/700\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.5854 - accuracy: 0.7042 - auc: 0.7610 - val_loss: 0.6115 - val_accuracy: 0.6703 - val_auc: 0.7293\n",
      "Epoch 12/700\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.5854 - accuracy: 0.7064 - auc: 0.7628 - val_loss: 0.6112 - val_accuracy: 0.6685 - val_auc: 0.7272\n",
      "Epoch 13/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5853 - accuracy: 0.6964 - auc: 0.7616 - val_loss: 0.6119 - val_accuracy: 0.6649 - val_auc: 0.7236\n",
      "Epoch 14/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5822 - accuracy: 0.6958 - auc: 0.7621 - val_loss: 0.6125 - val_accuracy: 0.6631 - val_auc: 0.7215\n",
      "Epoch 15/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5836 - accuracy: 0.7020 - auc: 0.7607 - val_loss: 0.6137 - val_accuracy: 0.6667 - val_auc: 0.7199\n",
      "Epoch 16/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5906 - accuracy: 0.7048 - auc: 0.7558 - val_loss: 0.6153 - val_accuracy: 0.6667 - val_auc: 0.7172\n",
      "Epoch 17/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5874 - accuracy: 0.7020 - auc: 0.7605 - val_loss: 0.6162 - val_accuracy: 0.6649 - val_auc: 0.7167\n",
      "Epoch 18/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5787 - accuracy: 0.7048 - auc: 0.7674 - val_loss: 0.6174 - val_accuracy: 0.6685 - val_auc: 0.7164\n",
      "Epoch 19/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5814 - accuracy: 0.7087 - auc: 0.7648 - val_loss: 0.6197 - val_accuracy: 0.6595 - val_auc: 0.7140\n",
      "Epoch 20/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5821 - accuracy: 0.6997 - auc: 0.7634 - val_loss: 0.6216 - val_accuracy: 0.6577 - val_auc: 0.7131\n",
      "Epoch 21/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5880 - accuracy: 0.7031 - auc: 0.7604 - val_loss: 0.6242 - val_accuracy: 0.6577 - val_auc: 0.7117\n",
      "Epoch 22/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5810 - accuracy: 0.7087 - auc: 0.7631 - val_loss: 0.6237 - val_accuracy: 0.6541 - val_auc: 0.7125\n",
      "Epoch 23/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5897 - accuracy: 0.6947 - auc: 0.7567 - val_loss: 0.6244 - val_accuracy: 0.6595 - val_auc: 0.7121\n",
      "Epoch 24/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5844 - accuracy: 0.6975 - auc: 0.7604 - val_loss: 0.6249 - val_accuracy: 0.6631 - val_auc: 0.7128\n",
      "Epoch 25/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5848 - accuracy: 0.7020 - auc: 0.7604 - val_loss: 0.6263 - val_accuracy: 0.6577 - val_auc: 0.7116\n",
      "Epoch 26/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5884 - accuracy: 0.7031 - auc: 0.7574 - val_loss: 0.6256 - val_accuracy: 0.6559 - val_auc: 0.7125\n",
      "Epoch 27/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5764 - accuracy: 0.7148 - auc: 0.7687 - val_loss: 0.6257 - val_accuracy: 0.6559 - val_auc: 0.7120\n",
      "Epoch 28/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5737 - accuracy: 0.7104 - auc: 0.7707 - val_loss: 0.6268 - val_accuracy: 0.6577 - val_auc: 0.7118\n",
      "Epoch 29/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5798 - accuracy: 0.7048 - auc: 0.7644 - val_loss: 0.6281 - val_accuracy: 0.6559 - val_auc: 0.7112\n",
      "Epoch 30/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5749 - accuracy: 0.7087 - auc: 0.7705 - val_loss: 0.6272 - val_accuracy: 0.6541 - val_auc: 0.7113\n",
      "Epoch 31/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5798 - accuracy: 0.7053 - auc: 0.7645 - val_loss: 0.6275 - val_accuracy: 0.6559 - val_auc: 0.7116\n",
      "Epoch 32/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5832 - accuracy: 0.7036 - auc: 0.7616 - val_loss: 0.6269 - val_accuracy: 0.6577 - val_auc: 0.7120\n",
      "Epoch 33/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5822 - accuracy: 0.6997 - auc: 0.7624 - val_loss: 0.6281 - val_accuracy: 0.6577 - val_auc: 0.7111\n",
      "Epoch 34/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5810 - accuracy: 0.7092 - auc: 0.7649 - val_loss: 0.6286 - val_accuracy: 0.6577 - val_auc: 0.7105\n",
      "Epoch 35/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5772 - accuracy: 0.7036 - auc: 0.7675 - val_loss: 0.6284 - val_accuracy: 0.6595 - val_auc: 0.7109\n",
      "Epoch 36/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5746 - accuracy: 0.7031 - auc: 0.7688 - val_loss: 0.6280 - val_accuracy: 0.6577 - val_auc: 0.7112\n",
      "Epoch 37/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5771 - accuracy: 0.7087 - auc: 0.7669 - val_loss: 0.6274 - val_accuracy: 0.6577 - val_auc: 0.7117\n",
      "Epoch 38/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5704 - accuracy: 0.7053 - auc: 0.7749 - val_loss: 0.6262 - val_accuracy: 0.6541 - val_auc: 0.7128\n",
      "Epoch 39/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5636 - accuracy: 0.7137 - auc: 0.7810 - val_loss: 0.6261 - val_accuracy: 0.6595 - val_auc: 0.7132\n",
      "Epoch 40/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5735 - accuracy: 0.7020 - auc: 0.7704 - val_loss: 0.6276 - val_accuracy: 0.6541 - val_auc: 0.7120\n",
      "Epoch 41/700\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5718 - accuracy: 0.7092 - auc: 0.7728 - val_loss: 0.6279 - val_accuracy: 0.6577 - val_auc: 0.7117\n",
      "Epoch 42/700\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5755 - accuracy: 0.7053 - auc: 0.7684 - val_loss: 0.6277 - val_accuracy: 0.6595 - val_auc: 0.7118\n",
      "Epoch 00042: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('neutral_ravdess_meld.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddcJYxjpRmou"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('neutral_ravdess_meld.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w4snlhBmRqz8"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_predictions_baseline = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2754,
     "status": "ok",
     "timestamp": 1596317422469,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "ca0b9174-4c3f-4e41-f34e-bea45d7c159a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.6111550331115723\n",
      "accuracy :  0.6684587597846985\n",
      "auc :  0.7272195816040039\n",
      "\n",
      "(True Negatives):  232\n",
      "(False Positives):  121\n",
      "(False Negatives):  64\n",
      "(True Positives):  141\n",
      "Total emotions_happy:  205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.71       353\n",
      "           1       0.54      0.69      0.60       205\n",
      "\n",
      "    accuracy                           0.67       558\n",
      "   macro avg       0.66      0.67      0.66       558\n",
      "weighted avg       0.69      0.67      0.67       558\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJk2L3O8ImIn"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1996,
     "status": "ok",
     "timestamp": 1596317435096,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "772127be-a750-45d7-f421-d802b6757087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5654510855674744\n",
      "accuracy :  0.7114093899726868\n",
      "auc :  0.8073009252548218\n",
      "\n",
      "(True Negatives):  208\n",
      "(False Positives):  89\n",
      "(False Negatives):  40\n",
      "(True Positives):  110\n",
      "Total emotions_happy:  150\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76       297\n",
      "           1       0.55      0.73      0.63       150\n",
      "\n",
      "    accuracy                           0.71       447\n",
      "   macro avg       0.70      0.72      0.70       447\n",
      "weighted avg       0.74      0.71      0.72       447\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPCNMB9wIZM/sp6Ac4jGE6F",
   "collapsed_sections": [],
   "name": "deep_neutral_RAVDESS_MELD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
