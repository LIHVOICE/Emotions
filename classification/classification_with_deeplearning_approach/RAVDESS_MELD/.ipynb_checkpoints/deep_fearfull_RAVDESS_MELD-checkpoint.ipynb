{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5058,
     "status": "ok",
     "timestamp": 1596281123013,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ymHSlukhKIF9",
    "outputId": "d768807e-b71b-4775-e9a5-a4502af66acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa==0.7.2 in /usr/local/lib/python3.6/dist-packages (0.7.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.16.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.2.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (4.4.2)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (2.1.8)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.22.2.post1)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.10.3.post1)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.15.0)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.48.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.14.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (49.2.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)\n"
     ]
    }
   ],
   "source": [
    "pip install librosa==0.7.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10002,
     "status": "ok",
     "timestamp": 1596026935548,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "sXnDmXR7RDr2",
    "outputId": "3b9dff36-3699-413b-8a0a-75f3af305685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10711,
     "status": "ok",
     "timestamp": 1596026954464,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Y04m-jvKRDsJ",
    "outputId": "ce46bb70-bae2-4985-8f6b-ee3fece0cc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
      "CPU (s):\n",
      "2.876127255\n",
      "GPU (s):\n",
      "0.1083209219999901\n",
      "GPU speedup over CPU: 26x\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()https://support.mozilla.org/fr/kb/comment-vider-le-cache-de-firefox\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76917,
     "status": "ok",
     "timestamp": 1596281258084,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l9EbbgJpzQDD",
    "outputId": "9d28148f-7d92-4118-e57c-89a462113686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6100,
     "status": "ok",
     "timestamp": 1596281295353,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ltf4WKPCeyVR",
    "outputId": "7a43a8b6-d281-44a8-ee4a-466f1174f6c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praat-parselmouth\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7b/9fa1172a63b6277603d27bb5613559b5a8888f58e68c1698017b87b0061d/praat_parselmouth-0.3.3-cp36-cp36m-manylinux1_x86_64.whl (9.0MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0MB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from praat-parselmouth) (1.18.5)\n",
      "Installing collected packages: praat-parselmouth\n",
      "Successfully installed praat-parselmouth-0.3.3\n"
     ]
    }
   ],
   "source": [
    "pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6526,
     "status": "ok",
     "timestamp": 1596281319632,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PNwtWyMXe_Qb",
    "outputId": "fa91bbd4-ee16-4e76-8e3a-f5bf58fcbcdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting essentia\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/cf/3c776d02b63fed7b0958bef2ce57b900870e2ac3f1fd8ffbb63f22d0e69e/essentia-2.1b6.dev234-cp36-cp36m-manylinux1_x86_64.whl (11.7MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7MB 301kB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from essentia) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from essentia) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from essentia) (3.13)\n",
      "Installing collected packages: essentia\n",
      "Successfully installed essentia-2.1b6.dev234\n"
     ]
    }
   ],
   "source": [
    "pip install essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6120,
     "status": "ok",
     "timestamp": 1596281339533,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "B9TmOS9AFg61",
    "outputId": "3853efed-e570-466d-80c1-aeeb06a36975"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Numpy, pandas ans os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "#Spafe for audio\n",
    "#import spafe\n",
    "import scipy.io.wavfile\n",
    "#import spafe.utils.vis as vis\n",
    "#from spafe.features.mfcc import mfcc, imfcc\n",
    "#from spafe.features.gfcc import gfcc\n",
    "\n",
    "#parselmouth for audio\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n",
    "#essentia\n",
    "\n",
    "import essentia.standard\n",
    "import essentia.streaming\n",
    "from essentia.standard import *\n",
    "\n",
    "\n",
    "#librairies for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "#for warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category= ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKH47UdIodVo"
   },
   "source": [
    "Dataframe to match audio with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1596281372877,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "QAD42F-CgYli",
    "outputId": "79d8b81f-52b0-479c-fd11-b22d53cf3794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "cd drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18150,
     "status": "ok",
     "timestamp": 1596281447136,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6IAO4Lt4pfBi",
    "outputId": "f41c39c5-973a-4135-d51c-6cb954fdbc67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fearfull/fearfull_03-01-06-02-01-01-20_norm_ou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fearfull/fearfull_03-01-06-02-01-01-18_norm_ou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surprised/suprised_03-01-08-02-02-01-08_norm_o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry/angry_03-01-05-01-01-02-16_norm_outNoise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sad/sad_03-01-04-01-02-02-24_norm_outNoise.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio label\n",
       "0  fearfull/fearfull_03-01-06-02-01-01-20_norm_ou...     1\n",
       "1  fearfull/fearfull_03-01-06-02-01-01-18_norm_ou...     1\n",
       "2  surprised/suprised_03-01-08-02-02-01-08_norm_o...     0\n",
       "3  angry/angry_03-01-05-01-01-02-16_norm_outNoise...     0\n",
       "4     sad/sad_03-01-04-01-02-02-24_norm_outNoise.wav     0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_dir = \"fusion_data\"\n",
    "def prepare_datadf(parent_dir): # a function whose parameter is the audio folder\n",
    "    df = pd.DataFrame(columns = ['audio', 'label']) #dataframe columns\n",
    "    \n",
    "    for  fichier_audio in os.listdir(parent_dir): # for each element in the audio folder\n",
    "        folder_path = os.path.join(parent_dir, fichier_audio) # path of each item  in the audio folder\n",
    "        \n",
    "       \n",
    "        \n",
    "        if(os.path.isdir(folder_path)): \n",
    "            audios = os.listdir(folder_path) #content of each emotional file\n",
    "            for i in audios:\n",
    "                emotion = None\n",
    "                if i.endswith('outNoise.wav'):\n",
    "                    if i.startswith(\"fearfull\"):\n",
    "                        emotion = 1\n",
    "                    \n",
    "                    else:\n",
    "                        emotion = 0\n",
    "                    df = df.append(pd.DataFrame({'audio':[os.path.join(fichier_audio, i)], 'label':[emotion]}), \n",
    "                           ignore_index=True) # here at df defined, with the columns we add the values:\n",
    "                                            #the audio column will take the audios_path, \n",
    "                                            #and the emotion column will take the corresponding emotion, ie the name of the folder\n",
    "    #Shuffling for randomness\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    return df\n",
    "datadf = prepare_datadf(parent_dir) #function call\n",
    "display(datadf.head()) #dataframe display\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr4_HGmdH_hY"
   },
   "source": [
    "Number of labels 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1596281473363,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "3_Rz5am4IBEV",
    "outputId": "6ce09201-d70d-427b-976d-b92d9b3447c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2061\n",
      "1     227\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "array=datadf.values\n",
    "audios=array[:,0]\n",
    "emotions=array[:,1]\n",
    "print(datadf.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM9Dsr6nGdQK"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWiD09QxGpVJ"
   },
   "source": [
    "Function for framing and windowing the audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1596281526644,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PhgtSddTGvNT"
   },
   "outputs": [],
   "source": [
    "def fram_window(audio_path):\n",
    "    loader = essentia.standard.MonoLoader(filename= audio_path)\n",
    "\n",
    "    # and then we actually perform the loading:\n",
    "    audio = loader()\n",
    "\n",
    "    w = Windowing(type = 'hann')\n",
    "    spectrum = Spectrum() \n",
    "    #default parameter (hopsize and framesize)\n",
    "    hopSize = 512\n",
    "    frameSize = 1024 \n",
    "    for frame in FrameGenerator(audio, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "        spect = spectrum(w(frame))\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5G6NwKlG8JW"
   },
   "source": [
    "function for features extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1596281568313,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "AjNAMwsfG2C8"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    #Load audios with the different libraries\n",
    "      \n",
    "    y,sr = librosa.load(audio_path)\n",
    "    sound = parselmouth.Sound(audio_path)\n",
    "    fs, sig = scipy.io.wavfile.read(audio_path) \n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    spec =  fram_window(audio_path) \n",
    "    duration = librosa.get_duration(y= spec, sr=sr)\n",
    "    energy = np.sum(spec ** 2) / np.float64(len(spec))\n",
    "            \n",
    "    lpc = librosa.core.lpc(spec,16)\n",
    "            \n",
    "    zcr = librosa.feature.zero_crossing_rate(spec)\n",
    "               \n",
    "    #gfccs = gfcc(sig= spec, fs=fs, num_ceps=13)    \n",
    "    mfcc = librosa.feature.mfcc(y= spec, sr=sr, n_mfcc = 13)\n",
    "        \n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    HNR = call(harmonicity, \"Get mean\", 0, 0)\n",
    "                \n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 100)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "        \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    \n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "\n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)   \n",
    "            \n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    features.append(mean_pitch)\n",
    "    features.append(duration)\n",
    "    features.append(energy)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.mean(lpc))\n",
    "    \n",
    "        \n",
    "    features.append(np.mean(mfcc))\n",
    "    \n",
    "    #features.append(np.mean(gfccs))\n",
    "    features.append(HNR)\n",
    "    \n",
    "    features.append(localJitter)\n",
    "    features.append(np.mean(localabsoluteJitter))\n",
    "    \n",
    "    features.append(localShimmer)\n",
    "    features.append(localdbShimmer)\n",
    "    features.append(f1_mean)   \n",
    "    features.append(f2_mean)\n",
    "    features.append(f3_mean)\n",
    "    features.append(f4_mean)\n",
    "        \n",
    "    features.append(rapJitter)\n",
    "    features.append(ppq5Jitter)\n",
    "    features.append(ddpJitter)\n",
    "    \n",
    "    features.append(apq3Shimmer)\n",
    "    features.append(aqpq5Shimmer)\n",
    "    features.append(apq11Shimmer)\n",
    "    features.append(ddaShimmer)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqLDut92HWAf"
   },
   "source": [
    "Application of features extraction function on all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4469831,
     "status": "ok",
     "timestamp": 1596286081143,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "i4HYtF5eHXRr"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "folder ='fusion_data'\n",
    "for audio_file in array[:,0]:\n",
    "    if audio_file.endswith('.wav'):\n",
    "        \n",
    "        features = extract_features(folder+'/'+audio_file)\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1596286476079,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "x8PZZgEyUeYX",
    "outputId": "fc54d37d-2722-4218-9c8a-557675e3ecf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288\n"
     ]
    }
   ],
   "source": [
    "print(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvIDRVAUpD3"
   },
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1596286511348,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "oDxfO5SJUss2"
   },
   "outputs": [],
   "source": [
    "encod = preprocessing.LabelEncoder()\n",
    "emotions = array[:,1]\n",
    "encod.fit(emotions)\n",
    "list(encod.classes_)\n",
    "labels=encod.transform(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atpDw444U3tg"
   },
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 655,
     "status": "ok",
     "timestamp": 1596286547442,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "FAI6k0k1U5I6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "X_scaler = scaler.transform(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hENmg0CTVBrQ"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1596286580307,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "OpQA2jnHVC3M",
    "outputId": "9d03600a-7e88-468b-9a92-f0d3d5809afd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 1278\n",
      "After OverSampling, counts of label '0': 2061\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy = 0.6)\n",
    "X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dy5_XTIhVSpm"
   },
   "source": [
    "Process to select features after oversampling with ADASYN : the code first takes in a list the position of the features that are deleted, during the 1000 iterations, then uses a dataframe to count them. we notice that the features \" [1, 3, 8, 9, 12, 13, 14, 15, 17, 19] \" are deleted 432 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43197,
     "status": "ok",
     "timestamp": 1596286663376,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NtMPEzopVUKN",
    "outputId": "6dccb8c7-5743-4da9-d5cd-745a5837a24c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>X_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 8, 9, 10, 12, 13, 14, 15, 17, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 3, 8, 9, 10, 12, 13, 14, 15, 17, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 3, 8, 9, 12, 13, 14, 15, 17, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 3, 8, 9, 12, 13, 14, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 3, 8, 9, 12, 13, 14, 15, 17, 19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iteration                                 X_removed\n",
       "0         1  [1, 3, 8, 9, 10, 12, 13, 14, 15, 17, 19]\n",
       "1         2  [1, 3, 8, 9, 10, 12, 13, 14, 15, 17, 19]\n",
       "2         3      [1, 3, 8, 9, 12, 13, 14, 15, 17, 19]\n",
       "3         4              [1, 3, 8, 9, 12, 13, 14, 19]\n",
       "4         5      [1, 3, 8, 9, 12, 13, 14, 15, 17, 19]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of features that are removed :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 8, 9, 12, 13, 14, 15, 17, 19]            432\n",
       "[1, 3, 8, 9, 10, 12, 13, 14, 15, 17, 19]        192\n",
       "[1, 3, 8, 9, 12, 13, 14, 19]                    127\n",
       "[1, 3, 8, 9, 10, 12, 13, 14, 19]                 86\n",
       "[1, 3, 8, 9, 13, 14, 15, 17, 19]                 66\n",
       "[1, 3, 8, 9, 10, 13, 14, 15, 17, 19]             30\n",
       "[1, 3, 8, 9, 12, 13, 14, 15, 17, 19, 20]         21\n",
       "[1, 3, 8, 9, 13, 14, 19]                         11\n",
       "[1, 3, 8, 9, 12, 13, 14, 19, 20]                 10\n",
       "[1, 3, 8, 9, 10, 13, 14, 19]                     10\n",
       "[1, 3, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20]      6\n",
       "[1, 3, 8, 9, 13, 14, 15, 17, 19, 20]              5\n",
       "[1, 3, 8, 9, 13, 14, 19, 20]                      2\n",
       "[1, 3, 8, 9, 10, 12, 13, 14, 19, 20]              1\n",
       "[1, 3, 8, 9, 10, 14, 19]                          1\n",
       "Name: X_removed, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compt=0\n",
    "df = pd.DataFrame(columns = ['iteration', 'X_removed'])\n",
    "while compt < 1000:\n",
    "    ada = ADASYN(sampling_strategy = 0.6)\n",
    "    \n",
    "    X, y = ada.fit_sample(X_scaler, labels.ravel())\n",
    "    X = np.asarray(X)\n",
    "    Kbest = SelectKBest(k=\"all\")\n",
    "    selec_features = Kbest.fit(X, y)\n",
    "    alpha = 0.01\n",
    "    #remove non_signifiant features selection\n",
    "    X_selec = X[:,np.where(selec_features.pvalues_ < alpha)[0]]\n",
    "    \n",
    "    pos_removed = []    \n",
    "    for i in range(len(X[0])):\n",
    "   \n",
    "        if X[0][i] not in X_selec[0]:\n",
    "            #print(i)\n",
    "            pos_removed.append(i)\n",
    "            str_pos_removed = str(pos_removed)\n",
    "    #print(pos_removed)\n",
    "    \n",
    "    compt = compt + 1\n",
    "    df= df.append(pd.DataFrame({'iteration':[compt], 'X_removed':[str_pos_removed]}), ignore_index=True)\n",
    "display(df.head())\n",
    "\n",
    "print(\"Number of occurrences of features that are removed :\")\n",
    "df[\"X_removed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1596287254504,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "6sTQj5wDWdev"
   },
   "outputs": [],
   "source": [
    "#manually feature selection\n",
    "X_selected = []\n",
    "for i in range(len(X)):\n",
    "    #print(w[i][0])\n",
    "    X_selected.append([X[i][0],  X[i][2], X[i][4], X[i][5], X[i][6],  X[i][7],\n",
    "              X[i][10],  X[i][11],  X[i][16], \n",
    "                X[i][18],  X[i][20], X[i][21]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch2KlT914uA9"
   },
   "source": [
    "Split dataset to Train, Test and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1596287332259,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "VYsXl_cV4vbq",
    "outputId": "da263fb7-48e8-426a-9f8d-a840849d979d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2136\n",
      "668\n",
      "535\n"
     ]
    }
   ],
   "source": [
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aN6WjeKMa8Y"
   },
   "source": [
    "Reshape Labels and features for deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2465,
     "status": "ok",
     "timestamp": 1596287371648,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "TWis1PUVfK_4",
    "outputId": "83ef9f7b-e352-4d4f-e349-bfbeb50d4a85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Plot imports ###\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Time Distributed ConvNet imports ###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "### Warning ###\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFUFXgkLUQZp"
   },
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1596287403361,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "PaaJCOWhTjcU"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "X_val = np.asarray(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1596287419768,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "NbPd-wZjTBNq",
    "outputId": "4f782117-b800-4426-e603-085386a0ea4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2136, 12, 1)\n",
      "(668, 12, 1)\n",
      "(535, 12, 1)\n"
     ]
    }
   ],
   "source": [
    " X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    " X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    " X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unzcOMlUSc6"
   },
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1596287457904,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "5dXesYt5KsyA",
    "outputId": "5b292da0-157d-41f6-b66f-7cfa2a7e4388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2136, 2)\n",
      "(668, 2)\n",
      "(535, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8U62d8rGqo9"
   },
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XcJ-s24okEk"
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1596287496275,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "goTNTktzg0L8"
   },
   "outputs": [],
   "source": [
    "input_y = Input(shape= (12,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1596287504475,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "objpwMFrPH6y",
    "outputId": "735d9ee7-3025-4712-c018-6b9c35ed9d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 12, 1)]           0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv1D)              (None, 12, 128)           768       \n",
      "_________________________________________________________________\n",
      "BatchNorm_3 (BatchNormalizat (None, 12, 128)           512       \n",
      "_________________________________________________________________\n",
      "Activ_5 (Activation)         (None, 12, 128)           0         \n",
      "_________________________________________________________________\n",
      "Drop_2 (Dropout)             (None, 12, 128)           0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv1D)              (None, 12, 128)           82048     \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "Drop_3 (Dropout)             (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 3074      \n",
      "_________________________________________________________________\n",
      "BatchNorm_4 (BatchNormalizat (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "Activ_6 (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 86,410\n",
      "Trainable params: 86,150\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## First LFLB (local feature learning block)\n",
    "y = Conv1D(256, kernel_size=5, strides= 1,  name='Conv_1', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_1')(y)\n",
    "y = Activation('elu', name='Activ_1')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_2', padding = 'same')(input_y)\n",
    "y = Activation('elu', name='Activ_2')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_1')(y)\n",
    "y = BatchNormalization( name='BatchNorm_2')(y)\n",
    "y = MaxPooling1D(pool_size=8, name = 'maxpooling', padding = 'same') (y) \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_3', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_3')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_4', padding = 'same')(y)\n",
    "y = Activation('elu', name='Activ_4')(y)\n",
    "\n",
    "y = Conv1D(128, kernel_size=5, strides= 1,  name='Conv_5', padding = 'same')(input_y)\n",
    "y = BatchNormalization( name='BatchNorm_3')(y)\n",
    "y = Activation('elu', name='Activ_5')(y)\n",
    "\n",
    "y = Dropout(0.2, name='Drop_2')(y)     \n",
    "\n",
    "y = Conv1D(128, kernel_size= 5, strides= 1,  name='Conv_6', padding = 'same')(y)\n",
    "\n",
    "y = Flatten(name='Flat')(y)\n",
    "y = Dropout(0.2, name='Drop_3')(y)  \n",
    "\n",
    "y = Dense(y_train.shape[1],  name='dense')(y)\n",
    "\n",
    "y = BatchNormalization(name='BatchNorm_4')(y)\n",
    "\n",
    "y = Activation('softmax', name='Activ_6')(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build final model\n",
    "model = Model(inputs=input_y, outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1596287513603,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "Fl2GZEzYQBC0"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "METRICS = [\n",
    "      \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      \n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 521528,
     "status": "ok",
     "timestamp": 1596288056040,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "zHXRXbVTQEqd",
    "outputId": "56e0c484-ed28-4f5e-f816-2ae4f463fae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.8326 - accuracy: 0.5033 - auc: 0.5175 - val_loss: 0.6879 - val_accuracy: 0.5284 - val_auc: 0.5420\n",
      "Epoch 2/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.7474 - accuracy: 0.5552 - auc: 0.5806 - val_loss: 0.6788 - val_accuracy: 0.5479 - val_auc: 0.5920\n",
      "Epoch 3/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6997 - accuracy: 0.5838 - auc: 0.6320 - val_loss: 0.6716 - val_accuracy: 0.5719 - val_auc: 0.6179\n",
      "Epoch 4/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.6823 - accuracy: 0.6091 - auc: 0.6522 - val_loss: 0.6641 - val_accuracy: 0.5913 - val_auc: 0.6394\n",
      "Epoch 5/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6687 - accuracy: 0.6217 - auc: 0.6658 - val_loss: 0.6573 - val_accuracy: 0.5928 - val_auc: 0.6545\n",
      "Epoch 6/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6515 - accuracy: 0.6325 - auc: 0.6802 - val_loss: 0.6499 - val_accuracy: 0.6078 - val_auc: 0.6692\n",
      "Epoch 7/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6425 - accuracy: 0.6306 - auc: 0.6908 - val_loss: 0.6437 - val_accuracy: 0.6168 - val_auc: 0.6786\n",
      "Epoch 8/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6383 - accuracy: 0.6287 - auc: 0.6925 - val_loss: 0.6364 - val_accuracy: 0.6347 - val_auc: 0.6894\n",
      "Epoch 9/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6360 - accuracy: 0.6503 - auc: 0.7005 - val_loss: 0.6305 - val_accuracy: 0.6392 - val_auc: 0.6985\n",
      "Epoch 10/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6317 - accuracy: 0.6498 - auc: 0.7046 - val_loss: 0.6227 - val_accuracy: 0.6497 - val_auc: 0.7092\n",
      "Epoch 11/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.6167 - accuracy: 0.6596 - auc: 0.7181 - val_loss: 0.6169 - val_accuracy: 0.6497 - val_auc: 0.7165\n",
      "Epoch 12/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6196 - accuracy: 0.6554 - auc: 0.7148 - val_loss: 0.6118 - val_accuracy: 0.6557 - val_auc: 0.7226\n",
      "Epoch 13/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6241 - accuracy: 0.6470 - auc: 0.7077 - val_loss: 0.6078 - val_accuracy: 0.6662 - val_auc: 0.7273\n",
      "Epoch 14/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6179 - accuracy: 0.6573 - auc: 0.7161 - val_loss: 0.6042 - val_accuracy: 0.6647 - val_auc: 0.7305\n",
      "Epoch 15/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.6159 - accuracy: 0.6582 - auc: 0.7170 - val_loss: 0.6003 - val_accuracy: 0.6707 - val_auc: 0.7354\n",
      "Epoch 16/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6172 - accuracy: 0.6479 - auc: 0.7184 - val_loss: 0.5977 - val_accuracy: 0.6692 - val_auc: 0.7384\n",
      "Epoch 17/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.6194 - accuracy: 0.6564 - auc: 0.7152 - val_loss: 0.5958 - val_accuracy: 0.6722 - val_auc: 0.7407\n",
      "Epoch 18/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.6186 - accuracy: 0.6573 - auc: 0.7153 - val_loss: 0.5943 - val_accuracy: 0.6737 - val_auc: 0.7433\n",
      "Epoch 19/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6121 - accuracy: 0.6699 - auc: 0.7250 - val_loss: 0.5942 - val_accuracy: 0.6751 - val_auc: 0.7424\n",
      "Epoch 20/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6152 - accuracy: 0.6606 - auc: 0.7227 - val_loss: 0.5928 - val_accuracy: 0.6707 - val_auc: 0.7442\n",
      "Epoch 21/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.6099 - accuracy: 0.6657 - auc: 0.7259 - val_loss: 0.5916 - val_accuracy: 0.6707 - val_auc: 0.7451\n",
      "Epoch 22/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.6158 - accuracy: 0.6559 - auc: 0.7164 - val_loss: 0.5920 - val_accuracy: 0.6737 - val_auc: 0.7444\n",
      "Epoch 23/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.6153 - accuracy: 0.6639 - auc: 0.7216 - val_loss: 0.5921 - val_accuracy: 0.6722 - val_auc: 0.7441\n",
      "Epoch 24/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6065 - accuracy: 0.6732 - auc: 0.7286 - val_loss: 0.5934 - val_accuracy: 0.6707 - val_auc: 0.7427\n",
      "Epoch 25/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6115 - accuracy: 0.6718 - auc: 0.7254 - val_loss: 0.5907 - val_accuracy: 0.6751 - val_auc: 0.7461\n",
      "Epoch 26/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6117 - accuracy: 0.6653 - auc: 0.7240 - val_loss: 0.5903 - val_accuracy: 0.6781 - val_auc: 0.7466\n",
      "Epoch 27/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6117 - accuracy: 0.6634 - auc: 0.7232 - val_loss: 0.5897 - val_accuracy: 0.6781 - val_auc: 0.7475\n",
      "Epoch 28/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6104 - accuracy: 0.6704 - auc: 0.7260 - val_loss: 0.5896 - val_accuracy: 0.6796 - val_auc: 0.7476\n",
      "Epoch 29/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.6035 - accuracy: 0.6746 - auc: 0.7353 - val_loss: 0.5904 - val_accuracy: 0.6781 - val_auc: 0.7470\n",
      "Epoch 30/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.6071 - accuracy: 0.6695 - auc: 0.7302 - val_loss: 0.5908 - val_accuracy: 0.6751 - val_auc: 0.7463\n",
      "Epoch 31/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.6039 - accuracy: 0.6662 - auc: 0.7315 - val_loss: 0.5901 - val_accuracy: 0.6781 - val_auc: 0.7476\n",
      "Epoch 32/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6004 - accuracy: 0.6760 - auc: 0.7378 - val_loss: 0.5897 - val_accuracy: 0.6796 - val_auc: 0.7480\n",
      "Epoch 33/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6018 - accuracy: 0.6770 - auc: 0.7374 - val_loss: 0.5894 - val_accuracy: 0.6751 - val_auc: 0.7480\n",
      "Epoch 34/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.6008 - accuracy: 0.6676 - auc: 0.7367 - val_loss: 0.5879 - val_accuracy: 0.6781 - val_auc: 0.7500\n",
      "Epoch 35/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6095 - accuracy: 0.6685 - auc: 0.7293 - val_loss: 0.5878 - val_accuracy: 0.6796 - val_auc: 0.7505\n",
      "Epoch 36/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5999 - accuracy: 0.6807 - auc: 0.7405 - val_loss: 0.5879 - val_accuracy: 0.6781 - val_auc: 0.7501\n",
      "Epoch 37/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6067 - accuracy: 0.6690 - auc: 0.7283 - val_loss: 0.5875 - val_accuracy: 0.6796 - val_auc: 0.7504\n",
      "Epoch 38/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6013 - accuracy: 0.6807 - auc: 0.7371 - val_loss: 0.5873 - val_accuracy: 0.6766 - val_auc: 0.7511\n",
      "Epoch 39/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5996 - accuracy: 0.6854 - auc: 0.7398 - val_loss: 0.5878 - val_accuracy: 0.6796 - val_auc: 0.7506\n",
      "Epoch 40/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5998 - accuracy: 0.6779 - auc: 0.7379 - val_loss: 0.5880 - val_accuracy: 0.6781 - val_auc: 0.7501\n",
      "Epoch 41/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5900 - accuracy: 0.6840 - auc: 0.7489 - val_loss: 0.5874 - val_accuracy: 0.6751 - val_auc: 0.7509\n",
      "Epoch 42/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5990 - accuracy: 0.6896 - auc: 0.7410 - val_loss: 0.5879 - val_accuracy: 0.6737 - val_auc: 0.7503\n",
      "Epoch 43/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.6004 - accuracy: 0.6784 - auc: 0.7403 - val_loss: 0.5867 - val_accuracy: 0.6751 - val_auc: 0.7518\n",
      "Epoch 44/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5952 - accuracy: 0.6831 - auc: 0.7435 - val_loss: 0.5863 - val_accuracy: 0.6781 - val_auc: 0.7525\n",
      "Epoch 45/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5990 - accuracy: 0.6751 - auc: 0.7373 - val_loss: 0.5866 - val_accuracy: 0.6796 - val_auc: 0.7523\n",
      "Epoch 46/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5983 - accuracy: 0.6816 - auc: 0.7407 - val_loss: 0.5864 - val_accuracy: 0.6751 - val_auc: 0.7523\n",
      "Epoch 47/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5972 - accuracy: 0.6821 - auc: 0.7413 - val_loss: 0.5861 - val_accuracy: 0.6766 - val_auc: 0.7530\n",
      "Epoch 48/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5992 - accuracy: 0.6737 - auc: 0.7407 - val_loss: 0.5862 - val_accuracy: 0.6751 - val_auc: 0.7528\n",
      "Epoch 49/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5948 - accuracy: 0.6760 - auc: 0.7423 - val_loss: 0.5858 - val_accuracy: 0.6737 - val_auc: 0.7530\n",
      "Epoch 50/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5974 - accuracy: 0.6915 - auc: 0.7425 - val_loss: 0.5857 - val_accuracy: 0.6737 - val_auc: 0.7531\n",
      "Epoch 51/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5922 - accuracy: 0.6835 - auc: 0.7477 - val_loss: 0.5857 - val_accuracy: 0.6766 - val_auc: 0.7532\n",
      "Epoch 52/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5933 - accuracy: 0.6854 - auc: 0.7447 - val_loss: 0.5857 - val_accuracy: 0.6751 - val_auc: 0.7533\n",
      "Epoch 53/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5968 - accuracy: 0.6821 - auc: 0.7408 - val_loss: 0.5851 - val_accuracy: 0.6766 - val_auc: 0.7539\n",
      "Epoch 54/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5989 - accuracy: 0.6868 - auc: 0.7415 - val_loss: 0.5850 - val_accuracy: 0.6811 - val_auc: 0.7543\n",
      "Epoch 55/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5938 - accuracy: 0.6849 - auc: 0.7452 - val_loss: 0.5853 - val_accuracy: 0.6811 - val_auc: 0.7541\n",
      "Epoch 56/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5959 - accuracy: 0.6821 - auc: 0.7451 - val_loss: 0.5848 - val_accuracy: 0.6811 - val_auc: 0.7548\n",
      "Epoch 57/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.6002 - accuracy: 0.6732 - auc: 0.7383 - val_loss: 0.5842 - val_accuracy: 0.6796 - val_auc: 0.7551\n",
      "Epoch 58/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5922 - accuracy: 0.6854 - auc: 0.7477 - val_loss: 0.5842 - val_accuracy: 0.6781 - val_auc: 0.7555\n",
      "Epoch 59/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5932 - accuracy: 0.6891 - auc: 0.7470 - val_loss: 0.5842 - val_accuracy: 0.6841 - val_auc: 0.7556\n",
      "Epoch 60/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5922 - accuracy: 0.6948 - auc: 0.7487 - val_loss: 0.5844 - val_accuracy: 0.6811 - val_auc: 0.7549\n",
      "Epoch 61/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5900 - accuracy: 0.6793 - auc: 0.7491 - val_loss: 0.5846 - val_accuracy: 0.6811 - val_auc: 0.7551\n",
      "Epoch 62/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5918 - accuracy: 0.6845 - auc: 0.7479 - val_loss: 0.5844 - val_accuracy: 0.6766 - val_auc: 0.7556\n",
      "Epoch 63/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5904 - accuracy: 0.6971 - auc: 0.7499 - val_loss: 0.5839 - val_accuracy: 0.6811 - val_auc: 0.7560\n",
      "Epoch 64/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5905 - accuracy: 0.6831 - auc: 0.7492 - val_loss: 0.5839 - val_accuracy: 0.6796 - val_auc: 0.7556\n",
      "Epoch 65/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5943 - accuracy: 0.6784 - auc: 0.7443 - val_loss: 0.5840 - val_accuracy: 0.6811 - val_auc: 0.7561\n",
      "Epoch 66/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5944 - accuracy: 0.6873 - auc: 0.7477 - val_loss: 0.5838 - val_accuracy: 0.6841 - val_auc: 0.7559\n",
      "Epoch 67/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5900 - accuracy: 0.6952 - auc: 0.7512 - val_loss: 0.5827 - val_accuracy: 0.6856 - val_auc: 0.7574\n",
      "Epoch 68/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5958 - accuracy: 0.6934 - auc: 0.7457 - val_loss: 0.5839 - val_accuracy: 0.6856 - val_auc: 0.7562\n",
      "Epoch 69/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5879 - accuracy: 0.6854 - auc: 0.7506 - val_loss: 0.5842 - val_accuracy: 0.6826 - val_auc: 0.7553\n",
      "Epoch 70/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5893 - accuracy: 0.6863 - auc: 0.7500 - val_loss: 0.5824 - val_accuracy: 0.6871 - val_auc: 0.7579\n",
      "Epoch 71/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5883 - accuracy: 0.6812 - auc: 0.7531 - val_loss: 0.5819 - val_accuracy: 0.6871 - val_auc: 0.7584\n",
      "Epoch 72/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5915 - accuracy: 0.6765 - auc: 0.7470 - val_loss: 0.5816 - val_accuracy: 0.6841 - val_auc: 0.7587\n",
      "Epoch 73/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5899 - accuracy: 0.6910 - auc: 0.7515 - val_loss: 0.5814 - val_accuracy: 0.6871 - val_auc: 0.7589\n",
      "Epoch 74/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5929 - accuracy: 0.6821 - auc: 0.7462 - val_loss: 0.5815 - val_accuracy: 0.6901 - val_auc: 0.7588\n",
      "Epoch 75/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5895 - accuracy: 0.6882 - auc: 0.7504 - val_loss: 0.5813 - val_accuracy: 0.6856 - val_auc: 0.7591\n",
      "Epoch 76/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5878 - accuracy: 0.6873 - auc: 0.7525 - val_loss: 0.5812 - val_accuracy: 0.6856 - val_auc: 0.7593\n",
      "Epoch 77/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5882 - accuracy: 0.6999 - auc: 0.7546 - val_loss: 0.5815 - val_accuracy: 0.6871 - val_auc: 0.7593\n",
      "Epoch 78/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5869 - accuracy: 0.6919 - auc: 0.7523 - val_loss: 0.5815 - val_accuracy: 0.6886 - val_auc: 0.7590\n",
      "Epoch 79/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5863 - accuracy: 0.6877 - auc: 0.7536 - val_loss: 0.5817 - val_accuracy: 0.6901 - val_auc: 0.7590\n",
      "Epoch 80/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5922 - accuracy: 0.6919 - auc: 0.7492 - val_loss: 0.5819 - val_accuracy: 0.6886 - val_auc: 0.7584\n",
      "Epoch 81/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5834 - accuracy: 0.6971 - auc: 0.7560 - val_loss: 0.5815 - val_accuracy: 0.6901 - val_auc: 0.7590\n",
      "Epoch 82/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5931 - accuracy: 0.6863 - auc: 0.7485 - val_loss: 0.5806 - val_accuracy: 0.6901 - val_auc: 0.7602\n",
      "Epoch 83/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5881 - accuracy: 0.6873 - auc: 0.7524 - val_loss: 0.5805 - val_accuracy: 0.6901 - val_auc: 0.7605\n",
      "Epoch 84/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5894 - accuracy: 0.6835 - auc: 0.7507 - val_loss: 0.5808 - val_accuracy: 0.6871 - val_auc: 0.7607\n",
      "Epoch 85/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5857 - accuracy: 0.6877 - auc: 0.7552 - val_loss: 0.5816 - val_accuracy: 0.6886 - val_auc: 0.7595\n",
      "Epoch 86/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5853 - accuracy: 0.6971 - auc: 0.7566 - val_loss: 0.5805 - val_accuracy: 0.6886 - val_auc: 0.7606\n",
      "Epoch 87/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5862 - accuracy: 0.6957 - auc: 0.7556 - val_loss: 0.5799 - val_accuracy: 0.6916 - val_auc: 0.7612\n",
      "Epoch 88/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5855 - accuracy: 0.6882 - auc: 0.7553 - val_loss: 0.5790 - val_accuracy: 0.6916 - val_auc: 0.7625\n",
      "Epoch 89/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5865 - accuracy: 0.6896 - auc: 0.7550 - val_loss: 0.5791 - val_accuracy: 0.6916 - val_auc: 0.7620\n",
      "Epoch 90/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5864 - accuracy: 0.6859 - auc: 0.7556 - val_loss: 0.5798 - val_accuracy: 0.6901 - val_auc: 0.7610\n",
      "Epoch 91/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5806 - accuracy: 0.6948 - auc: 0.7633 - val_loss: 0.5795 - val_accuracy: 0.6901 - val_auc: 0.7609\n",
      "Epoch 92/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5875 - accuracy: 0.6962 - auc: 0.7544 - val_loss: 0.5791 - val_accuracy: 0.6901 - val_auc: 0.7617\n",
      "Epoch 93/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5857 - accuracy: 0.6934 - auc: 0.7542 - val_loss: 0.5787 - val_accuracy: 0.6916 - val_auc: 0.7623\n",
      "Epoch 94/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5899 - accuracy: 0.6859 - auc: 0.7492 - val_loss: 0.5789 - val_accuracy: 0.6886 - val_auc: 0.7622\n",
      "Epoch 95/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5877 - accuracy: 0.6971 - auc: 0.7538 - val_loss: 0.5788 - val_accuracy: 0.6901 - val_auc: 0.7623\n",
      "Epoch 96/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5849 - accuracy: 0.6980 - auc: 0.7566 - val_loss: 0.5786 - val_accuracy: 0.6886 - val_auc: 0.7628\n",
      "Epoch 97/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5869 - accuracy: 0.7013 - auc: 0.7551 - val_loss: 0.5783 - val_accuracy: 0.6916 - val_auc: 0.7631\n",
      "Epoch 98/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5836 - accuracy: 0.6994 - auc: 0.7575 - val_loss: 0.5788 - val_accuracy: 0.6931 - val_auc: 0.7622\n",
      "Epoch 99/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5764 - accuracy: 0.6999 - auc: 0.7666 - val_loss: 0.5785 - val_accuracy: 0.6916 - val_auc: 0.7625\n",
      "Epoch 100/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5837 - accuracy: 0.6896 - auc: 0.7549 - val_loss: 0.5790 - val_accuracy: 0.6916 - val_auc: 0.7618\n",
      "Epoch 101/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5810 - accuracy: 0.6901 - auc: 0.7607 - val_loss: 0.5787 - val_accuracy: 0.6916 - val_auc: 0.7627\n",
      "Epoch 102/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5802 - accuracy: 0.7018 - auc: 0.7626 - val_loss: 0.5778 - val_accuracy: 0.6946 - val_auc: 0.7636\n",
      "Epoch 103/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5801 - accuracy: 0.6957 - auc: 0.7598 - val_loss: 0.5776 - val_accuracy: 0.6946 - val_auc: 0.7642\n",
      "Epoch 104/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5880 - accuracy: 0.6784 - auc: 0.7508 - val_loss: 0.5771 - val_accuracy: 0.6976 - val_auc: 0.7647\n",
      "Epoch 105/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5794 - accuracy: 0.7037 - auc: 0.7629 - val_loss: 0.5779 - val_accuracy: 0.6946 - val_auc: 0.7637\n",
      "Epoch 106/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5787 - accuracy: 0.6994 - auc: 0.7631 - val_loss: 0.5768 - val_accuracy: 0.6976 - val_auc: 0.7647\n",
      "Epoch 107/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5800 - accuracy: 0.6980 - auc: 0.7630 - val_loss: 0.5764 - val_accuracy: 0.6976 - val_auc: 0.7653\n",
      "Epoch 108/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5791 - accuracy: 0.6994 - auc: 0.7624 - val_loss: 0.5757 - val_accuracy: 0.6991 - val_auc: 0.7662\n",
      "Epoch 109/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5824 - accuracy: 0.7018 - auc: 0.7606 - val_loss: 0.5753 - val_accuracy: 0.7006 - val_auc: 0.7664\n",
      "Epoch 110/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5827 - accuracy: 0.7013 - auc: 0.7582 - val_loss: 0.5752 - val_accuracy: 0.6976 - val_auc: 0.7667\n",
      "Epoch 111/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5815 - accuracy: 0.6891 - auc: 0.7598 - val_loss: 0.5750 - val_accuracy: 0.7006 - val_auc: 0.7671\n",
      "Epoch 112/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5810 - accuracy: 0.6976 - auc: 0.7603 - val_loss: 0.5744 - val_accuracy: 0.6991 - val_auc: 0.7678\n",
      "Epoch 113/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5800 - accuracy: 0.6990 - auc: 0.7614 - val_loss: 0.5738 - val_accuracy: 0.7006 - val_auc: 0.7683\n",
      "Epoch 114/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5851 - accuracy: 0.7013 - auc: 0.7574 - val_loss: 0.5733 - val_accuracy: 0.6976 - val_auc: 0.7690\n",
      "Epoch 115/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5812 - accuracy: 0.6934 - auc: 0.7599 - val_loss: 0.5732 - val_accuracy: 0.7021 - val_auc: 0.7691\n",
      "Epoch 116/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5765 - accuracy: 0.6985 - auc: 0.7662 - val_loss: 0.5731 - val_accuracy: 0.7021 - val_auc: 0.7694\n",
      "Epoch 117/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5847 - accuracy: 0.6943 - auc: 0.7564 - val_loss: 0.5737 - val_accuracy: 0.7021 - val_auc: 0.7686\n",
      "Epoch 118/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5835 - accuracy: 0.6980 - auc: 0.7581 - val_loss: 0.5741 - val_accuracy: 0.7006 - val_auc: 0.7682\n",
      "Epoch 119/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5716 - accuracy: 0.7013 - auc: 0.7717 - val_loss: 0.5745 - val_accuracy: 0.7021 - val_auc: 0.7678\n",
      "Epoch 120/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5771 - accuracy: 0.7041 - auc: 0.7654 - val_loss: 0.5741 - val_accuracy: 0.7006 - val_auc: 0.7685\n",
      "Epoch 121/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5819 - accuracy: 0.7022 - auc: 0.7610 - val_loss: 0.5739 - val_accuracy: 0.7021 - val_auc: 0.7685\n",
      "Epoch 122/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5822 - accuracy: 0.6905 - auc: 0.7583 - val_loss: 0.5734 - val_accuracy: 0.6991 - val_auc: 0.7692\n",
      "Epoch 123/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5826 - accuracy: 0.6938 - auc: 0.7588 - val_loss: 0.5740 - val_accuracy: 0.6991 - val_auc: 0.7682\n",
      "Epoch 124/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5827 - accuracy: 0.6938 - auc: 0.7583 - val_loss: 0.5734 - val_accuracy: 0.7021 - val_auc: 0.7687\n",
      "Epoch 125/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5794 - accuracy: 0.7051 - auc: 0.7626 - val_loss: 0.5740 - val_accuracy: 0.7006 - val_auc: 0.7683\n",
      "Epoch 126/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5814 - accuracy: 0.7041 - auc: 0.7640 - val_loss: 0.5732 - val_accuracy: 0.7021 - val_auc: 0.7690\n",
      "Epoch 127/700\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5765 - accuracy: 0.7051 - auc: 0.7661 - val_loss: 0.5729 - val_accuracy: 0.7021 - val_auc: 0.7696\n",
      "Epoch 128/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5827 - accuracy: 0.7027 - auc: 0.7605 - val_loss: 0.5724 - val_accuracy: 0.7036 - val_auc: 0.7702\n",
      "Epoch 129/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5752 - accuracy: 0.7032 - auc: 0.7678 - val_loss: 0.5719 - val_accuracy: 0.7036 - val_auc: 0.7707\n",
      "Epoch 130/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5776 - accuracy: 0.7041 - auc: 0.7647 - val_loss: 0.5717 - val_accuracy: 0.7021 - val_auc: 0.7710\n",
      "Epoch 131/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5750 - accuracy: 0.6929 - auc: 0.7671 - val_loss: 0.5713 - val_accuracy: 0.7036 - val_auc: 0.7716\n",
      "Epoch 132/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5750 - accuracy: 0.6994 - auc: 0.7669 - val_loss: 0.5714 - val_accuracy: 0.7036 - val_auc: 0.7713\n",
      "Epoch 133/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5798 - accuracy: 0.6976 - auc: 0.7625 - val_loss: 0.5717 - val_accuracy: 0.7021 - val_auc: 0.7708\n",
      "Epoch 134/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5800 - accuracy: 0.7013 - auc: 0.7639 - val_loss: 0.5713 - val_accuracy: 0.7036 - val_auc: 0.7716\n",
      "Epoch 135/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5776 - accuracy: 0.6966 - auc: 0.7643 - val_loss: 0.5713 - val_accuracy: 0.7036 - val_auc: 0.7717\n",
      "Epoch 136/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5772 - accuracy: 0.7008 - auc: 0.7651 - val_loss: 0.5711 - val_accuracy: 0.7036 - val_auc: 0.7720\n",
      "Epoch 137/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5791 - accuracy: 0.7069 - auc: 0.7646 - val_loss: 0.5712 - val_accuracy: 0.7051 - val_auc: 0.7718\n",
      "Epoch 138/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5722 - accuracy: 0.7074 - auc: 0.7702 - val_loss: 0.5710 - val_accuracy: 0.7051 - val_auc: 0.7720\n",
      "Epoch 139/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5767 - accuracy: 0.7018 - auc: 0.7645 - val_loss: 0.5709 - val_accuracy: 0.7051 - val_auc: 0.7719\n",
      "Epoch 140/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5812 - accuracy: 0.6962 - auc: 0.7602 - val_loss: 0.5711 - val_accuracy: 0.7066 - val_auc: 0.7720\n",
      "Epoch 141/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5757 - accuracy: 0.6868 - auc: 0.7638 - val_loss: 0.5716 - val_accuracy: 0.7036 - val_auc: 0.7711\n",
      "Epoch 142/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5761 - accuracy: 0.7116 - auc: 0.7668 - val_loss: 0.5713 - val_accuracy: 0.7036 - val_auc: 0.7718\n",
      "Epoch 143/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5732 - accuracy: 0.7022 - auc: 0.7697 - val_loss: 0.5706 - val_accuracy: 0.7066 - val_auc: 0.7719\n",
      "Epoch 144/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5727 - accuracy: 0.7111 - auc: 0.7713 - val_loss: 0.5702 - val_accuracy: 0.7051 - val_auc: 0.7727\n",
      "Epoch 145/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5752 - accuracy: 0.7004 - auc: 0.7668 - val_loss: 0.5693 - val_accuracy: 0.7051 - val_auc: 0.7738\n",
      "Epoch 146/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5791 - accuracy: 0.7041 - auc: 0.7643 - val_loss: 0.5693 - val_accuracy: 0.7066 - val_auc: 0.7739\n",
      "Epoch 147/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5711 - accuracy: 0.7022 - auc: 0.7701 - val_loss: 0.5676 - val_accuracy: 0.7096 - val_auc: 0.7760\n",
      "Epoch 148/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5723 - accuracy: 0.7037 - auc: 0.7700 - val_loss: 0.5685 - val_accuracy: 0.7066 - val_auc: 0.7749\n",
      "Epoch 149/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5704 - accuracy: 0.7074 - auc: 0.7733 - val_loss: 0.5680 - val_accuracy: 0.7081 - val_auc: 0.7754\n",
      "Epoch 150/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5723 - accuracy: 0.6999 - auc: 0.7696 - val_loss: 0.5690 - val_accuracy: 0.7051 - val_auc: 0.7743\n",
      "Epoch 151/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5729 - accuracy: 0.7074 - auc: 0.7709 - val_loss: 0.5685 - val_accuracy: 0.7051 - val_auc: 0.7746\n",
      "Epoch 152/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5692 - accuracy: 0.7154 - auc: 0.7741 - val_loss: 0.5686 - val_accuracy: 0.7066 - val_auc: 0.7747\n",
      "Epoch 153/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5758 - accuracy: 0.7065 - auc: 0.7659 - val_loss: 0.5676 - val_accuracy: 0.7081 - val_auc: 0.7761\n",
      "Epoch 154/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5762 - accuracy: 0.7037 - auc: 0.7659 - val_loss: 0.5672 - val_accuracy: 0.7111 - val_auc: 0.7764\n",
      "Epoch 155/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5830 - accuracy: 0.6901 - auc: 0.7585 - val_loss: 0.5670 - val_accuracy: 0.7096 - val_auc: 0.7765\n",
      "Epoch 156/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5678 - accuracy: 0.7074 - auc: 0.7771 - val_loss: 0.5672 - val_accuracy: 0.7066 - val_auc: 0.7763\n",
      "Epoch 157/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5751 - accuracy: 0.7018 - auc: 0.7671 - val_loss: 0.5663 - val_accuracy: 0.7096 - val_auc: 0.7773\n",
      "Epoch 158/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5773 - accuracy: 0.7051 - auc: 0.7680 - val_loss: 0.5665 - val_accuracy: 0.7081 - val_auc: 0.7771\n",
      "Epoch 159/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5712 - accuracy: 0.7093 - auc: 0.7713 - val_loss: 0.5675 - val_accuracy: 0.7066 - val_auc: 0.7761\n",
      "Epoch 160/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5730 - accuracy: 0.7051 - auc: 0.7681 - val_loss: 0.5675 - val_accuracy: 0.7081 - val_auc: 0.7759\n",
      "Epoch 161/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5722 - accuracy: 0.7093 - auc: 0.7731 - val_loss: 0.5661 - val_accuracy: 0.7051 - val_auc: 0.7775\n",
      "Epoch 162/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5686 - accuracy: 0.7168 - auc: 0.7733 - val_loss: 0.5659 - val_accuracy: 0.7066 - val_auc: 0.7781\n",
      "Epoch 163/700\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5715 - accuracy: 0.7032 - auc: 0.7709 - val_loss: 0.5657 - val_accuracy: 0.7081 - val_auc: 0.7784\n",
      "Epoch 164/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5762 - accuracy: 0.6938 - auc: 0.7651 - val_loss: 0.5666 - val_accuracy: 0.7051 - val_auc: 0.7772\n",
      "Epoch 165/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5730 - accuracy: 0.6971 - auc: 0.7674 - val_loss: 0.5662 - val_accuracy: 0.7051 - val_auc: 0.7778\n",
      "Epoch 166/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5702 - accuracy: 0.7041 - auc: 0.7737 - val_loss: 0.5672 - val_accuracy: 0.7051 - val_auc: 0.7765\n",
      "Epoch 167/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5735 - accuracy: 0.6976 - auc: 0.7673 - val_loss: 0.5667 - val_accuracy: 0.7036 - val_auc: 0.7773\n",
      "Epoch 168/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5736 - accuracy: 0.7093 - auc: 0.7710 - val_loss: 0.5659 - val_accuracy: 0.7036 - val_auc: 0.7784\n",
      "Epoch 169/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5737 - accuracy: 0.7037 - auc: 0.7710 - val_loss: 0.5654 - val_accuracy: 0.7051 - val_auc: 0.7786\n",
      "Epoch 170/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5673 - accuracy: 0.7205 - auc: 0.7765 - val_loss: 0.5650 - val_accuracy: 0.7051 - val_auc: 0.7791\n",
      "Epoch 171/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5781 - accuracy: 0.7041 - auc: 0.7649 - val_loss: 0.5647 - val_accuracy: 0.7096 - val_auc: 0.7797\n",
      "Epoch 172/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5682 - accuracy: 0.7022 - auc: 0.7746 - val_loss: 0.5639 - val_accuracy: 0.7081 - val_auc: 0.7808\n",
      "Epoch 173/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5658 - accuracy: 0.7069 - auc: 0.7771 - val_loss: 0.5648 - val_accuracy: 0.7066 - val_auc: 0.7796\n",
      "Epoch 174/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5724 - accuracy: 0.7065 - auc: 0.7710 - val_loss: 0.5636 - val_accuracy: 0.7066 - val_auc: 0.7804\n",
      "Epoch 175/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5678 - accuracy: 0.7097 - auc: 0.7754 - val_loss: 0.5637 - val_accuracy: 0.7066 - val_auc: 0.7805\n",
      "Epoch 176/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5649 - accuracy: 0.7079 - auc: 0.7768 - val_loss: 0.5632 - val_accuracy: 0.7096 - val_auc: 0.7812\n",
      "Epoch 177/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5729 - accuracy: 0.7018 - auc: 0.7687 - val_loss: 0.5638 - val_accuracy: 0.7081 - val_auc: 0.7800\n",
      "Epoch 178/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5688 - accuracy: 0.7055 - auc: 0.7738 - val_loss: 0.5627 - val_accuracy: 0.7111 - val_auc: 0.7816\n",
      "Epoch 179/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5683 - accuracy: 0.7079 - auc: 0.7750 - val_loss: 0.5628 - val_accuracy: 0.7096 - val_auc: 0.7813\n",
      "Epoch 180/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5717 - accuracy: 0.7008 - auc: 0.7705 - val_loss: 0.5628 - val_accuracy: 0.7096 - val_auc: 0.7814\n",
      "Epoch 181/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5653 - accuracy: 0.7116 - auc: 0.7771 - val_loss: 0.5631 - val_accuracy: 0.7096 - val_auc: 0.7811\n",
      "Epoch 182/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5697 - accuracy: 0.7055 - auc: 0.7731 - val_loss: 0.5627 - val_accuracy: 0.7096 - val_auc: 0.7818\n",
      "Epoch 183/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5646 - accuracy: 0.7154 - auc: 0.7779 - val_loss: 0.5627 - val_accuracy: 0.7081 - val_auc: 0.7814\n",
      "Epoch 184/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5689 - accuracy: 0.6957 - auc: 0.7716 - val_loss: 0.5625 - val_accuracy: 0.7096 - val_auc: 0.7817\n",
      "Epoch 185/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5728 - accuracy: 0.7149 - auc: 0.7737 - val_loss: 0.5623 - val_accuracy: 0.7096 - val_auc: 0.7819\n",
      "Epoch 186/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5662 - accuracy: 0.6962 - auc: 0.7746 - val_loss: 0.5627 - val_accuracy: 0.7066 - val_auc: 0.7817\n",
      "Epoch 187/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5659 - accuracy: 0.7107 - auc: 0.7792 - val_loss: 0.5631 - val_accuracy: 0.7066 - val_auc: 0.7812\n",
      "Epoch 188/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5645 - accuracy: 0.7060 - auc: 0.7782 - val_loss: 0.5626 - val_accuracy: 0.7081 - val_auc: 0.7815\n",
      "Epoch 189/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5717 - accuracy: 0.7055 - auc: 0.7709 - val_loss: 0.5611 - val_accuracy: 0.7096 - val_auc: 0.7834\n",
      "Epoch 190/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5638 - accuracy: 0.7107 - auc: 0.7811 - val_loss: 0.5616 - val_accuracy: 0.7051 - val_auc: 0.7826\n",
      "Epoch 191/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5649 - accuracy: 0.7065 - auc: 0.7782 - val_loss: 0.5624 - val_accuracy: 0.7066 - val_auc: 0.7816\n",
      "Epoch 192/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5694 - accuracy: 0.7074 - auc: 0.7728 - val_loss: 0.5615 - val_accuracy: 0.7111 - val_auc: 0.7826\n",
      "Epoch 193/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5681 - accuracy: 0.7027 - auc: 0.7745 - val_loss: 0.5606 - val_accuracy: 0.7096 - val_auc: 0.7838\n",
      "Epoch 194/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5728 - accuracy: 0.7022 - auc: 0.7704 - val_loss: 0.5607 - val_accuracy: 0.7141 - val_auc: 0.7839\n",
      "Epoch 195/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5670 - accuracy: 0.7121 - auc: 0.7739 - val_loss: 0.5610 - val_accuracy: 0.7171 - val_auc: 0.7835\n",
      "Epoch 196/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5646 - accuracy: 0.7154 - auc: 0.7802 - val_loss: 0.5609 - val_accuracy: 0.7156 - val_auc: 0.7836\n",
      "Epoch 197/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5668 - accuracy: 0.7130 - auc: 0.7773 - val_loss: 0.5603 - val_accuracy: 0.7171 - val_auc: 0.7841\n",
      "Epoch 198/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5629 - accuracy: 0.7060 - auc: 0.7788 - val_loss: 0.5604 - val_accuracy: 0.7201 - val_auc: 0.7841\n",
      "Epoch 199/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5655 - accuracy: 0.7102 - auc: 0.7777 - val_loss: 0.5604 - val_accuracy: 0.7156 - val_auc: 0.7838\n",
      "Epoch 200/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5698 - accuracy: 0.7074 - auc: 0.7721 - val_loss: 0.5605 - val_accuracy: 0.7156 - val_auc: 0.7836\n",
      "Epoch 201/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5668 - accuracy: 0.7177 - auc: 0.7781 - val_loss: 0.5606 - val_accuracy: 0.7156 - val_auc: 0.7836\n",
      "Epoch 202/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5632 - accuracy: 0.7116 - auc: 0.7808 - val_loss: 0.5594 - val_accuracy: 0.7156 - val_auc: 0.7849\n",
      "Epoch 203/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5618 - accuracy: 0.7210 - auc: 0.7817 - val_loss: 0.5598 - val_accuracy: 0.7141 - val_auc: 0.7845\n",
      "Epoch 204/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5604 - accuracy: 0.7051 - auc: 0.7828 - val_loss: 0.5596 - val_accuracy: 0.7126 - val_auc: 0.7844\n",
      "Epoch 205/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5649 - accuracy: 0.6999 - auc: 0.7771 - val_loss: 0.5597 - val_accuracy: 0.7141 - val_auc: 0.7846\n",
      "Epoch 206/700\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.5747 - accuracy: 0.6999 - auc: 0.7668 - val_loss: 0.5598 - val_accuracy: 0.7111 - val_auc: 0.7846\n",
      "Epoch 207/700\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.5628 - accuracy: 0.7130 - auc: 0.7798 - val_loss: 0.5589 - val_accuracy: 0.7156 - val_auc: 0.7858\n",
      "Epoch 208/700\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.5618 - accuracy: 0.7116 - auc: 0.7800 - val_loss: 0.5575 - val_accuracy: 0.7171 - val_auc: 0.7873\n",
      "Epoch 209/700\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.5650 - accuracy: 0.7107 - auc: 0.7789 - val_loss: 0.5580 - val_accuracy: 0.7081 - val_auc: 0.7865\n",
      "Epoch 210/700\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.5628 - accuracy: 0.7116 - auc: 0.7806 - val_loss: 0.5571 - val_accuracy: 0.7111 - val_auc: 0.7875\n",
      "Epoch 211/700\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5588 - accuracy: 0.7135 - auc: 0.7836 - val_loss: 0.5574 - val_accuracy: 0.7111 - val_auc: 0.7872\n",
      "Epoch 212/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5621 - accuracy: 0.7149 - auc: 0.7819 - val_loss: 0.5590 - val_accuracy: 0.7141 - val_auc: 0.7851\n",
      "Epoch 213/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5725 - accuracy: 0.7013 - auc: 0.7698 - val_loss: 0.5581 - val_accuracy: 0.7156 - val_auc: 0.7864\n",
      "Epoch 214/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5577 - accuracy: 0.7051 - auc: 0.7831 - val_loss: 0.5582 - val_accuracy: 0.7156 - val_auc: 0.7859\n",
      "Epoch 215/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5608 - accuracy: 0.7130 - auc: 0.7813 - val_loss: 0.5584 - val_accuracy: 0.7126 - val_auc: 0.7861\n",
      "Epoch 216/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5584 - accuracy: 0.7130 - auc: 0.7849 - val_loss: 0.5580 - val_accuracy: 0.7141 - val_auc: 0.7863\n",
      "Epoch 217/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5639 - accuracy: 0.7130 - auc: 0.7803 - val_loss: 0.5579 - val_accuracy: 0.7126 - val_auc: 0.7863\n",
      "Epoch 218/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5669 - accuracy: 0.7093 - auc: 0.7753 - val_loss: 0.5575 - val_accuracy: 0.7126 - val_auc: 0.7866\n",
      "Epoch 219/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5636 - accuracy: 0.7214 - auc: 0.7799 - val_loss: 0.5574 - val_accuracy: 0.7141 - val_auc: 0.7868\n",
      "Epoch 220/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5648 - accuracy: 0.7083 - auc: 0.7766 - val_loss: 0.5573 - val_accuracy: 0.7096 - val_auc: 0.7870\n",
      "Epoch 221/700\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5645 - accuracy: 0.7074 - auc: 0.7780 - val_loss: 0.5569 - val_accuracy: 0.7126 - val_auc: 0.7875\n",
      "Epoch 222/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5622 - accuracy: 0.7135 - auc: 0.7801 - val_loss: 0.5564 - val_accuracy: 0.7126 - val_auc: 0.7882\n",
      "Epoch 223/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5653 - accuracy: 0.7093 - auc: 0.7780 - val_loss: 0.5564 - val_accuracy: 0.7096 - val_auc: 0.7879\n",
      "Epoch 224/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5641 - accuracy: 0.7107 - auc: 0.7781 - val_loss: 0.5568 - val_accuracy: 0.7126 - val_auc: 0.7872\n",
      "Epoch 225/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5627 - accuracy: 0.7140 - auc: 0.7813 - val_loss: 0.5558 - val_accuracy: 0.7126 - val_auc: 0.7884\n",
      "Epoch 226/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5626 - accuracy: 0.7121 - auc: 0.7800 - val_loss: 0.5562 - val_accuracy: 0.7231 - val_auc: 0.7885\n",
      "Epoch 227/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5683 - accuracy: 0.7013 - auc: 0.7735 - val_loss: 0.5573 - val_accuracy: 0.7186 - val_auc: 0.7868\n",
      "Epoch 228/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5664 - accuracy: 0.7055 - auc: 0.7752 - val_loss: 0.5572 - val_accuracy: 0.7201 - val_auc: 0.7870\n",
      "Epoch 229/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5632 - accuracy: 0.7111 - auc: 0.7811 - val_loss: 0.5569 - val_accuracy: 0.7231 - val_auc: 0.7872\n",
      "Epoch 230/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5627 - accuracy: 0.7154 - auc: 0.7806 - val_loss: 0.5571 - val_accuracy: 0.7171 - val_auc: 0.7869\n",
      "Epoch 231/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5620 - accuracy: 0.7102 - auc: 0.7797 - val_loss: 0.5574 - val_accuracy: 0.7171 - val_auc: 0.7866\n",
      "Epoch 232/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5636 - accuracy: 0.7158 - auc: 0.7788 - val_loss: 0.5560 - val_accuracy: 0.7156 - val_auc: 0.7885\n",
      "Epoch 233/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5589 - accuracy: 0.7247 - auc: 0.7851 - val_loss: 0.5558 - val_accuracy: 0.7216 - val_auc: 0.7886\n",
      "Epoch 234/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5652 - accuracy: 0.7065 - auc: 0.7770 - val_loss: 0.5560 - val_accuracy: 0.7216 - val_auc: 0.7884\n",
      "Epoch 235/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5642 - accuracy: 0.7140 - auc: 0.7778 - val_loss: 0.5550 - val_accuracy: 0.7186 - val_auc: 0.7894\n",
      "Epoch 236/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5685 - accuracy: 0.7111 - auc: 0.7743 - val_loss: 0.5545 - val_accuracy: 0.7231 - val_auc: 0.7901\n",
      "Epoch 237/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5621 - accuracy: 0.7065 - auc: 0.7808 - val_loss: 0.5545 - val_accuracy: 0.7246 - val_auc: 0.7899\n",
      "Epoch 238/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5592 - accuracy: 0.7205 - auc: 0.7834 - val_loss: 0.5550 - val_accuracy: 0.7216 - val_auc: 0.7895\n",
      "Epoch 239/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5636 - accuracy: 0.7032 - auc: 0.7801 - val_loss: 0.5544 - val_accuracy: 0.7216 - val_auc: 0.7897\n",
      "Epoch 240/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5568 - accuracy: 0.7168 - auc: 0.7858 - val_loss: 0.5543 - val_accuracy: 0.7201 - val_auc: 0.7898\n",
      "Epoch 241/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5547 - accuracy: 0.7191 - auc: 0.7878 - val_loss: 0.5545 - val_accuracy: 0.7246 - val_auc: 0.7895\n",
      "Epoch 242/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5625 - accuracy: 0.7125 - auc: 0.7795 - val_loss: 0.5547 - val_accuracy: 0.7216 - val_auc: 0.7895\n",
      "Epoch 243/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5538 - accuracy: 0.7243 - auc: 0.7901 - val_loss: 0.5546 - val_accuracy: 0.7186 - val_auc: 0.7894\n",
      "Epoch 244/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5546 - accuracy: 0.7093 - auc: 0.7878 - val_loss: 0.5550 - val_accuracy: 0.7156 - val_auc: 0.7890\n",
      "Epoch 245/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5628 - accuracy: 0.7093 - auc: 0.7803 - val_loss: 0.5540 - val_accuracy: 0.7186 - val_auc: 0.7901\n",
      "Epoch 246/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5597 - accuracy: 0.7154 - auc: 0.7832 - val_loss: 0.5539 - val_accuracy: 0.7216 - val_auc: 0.7903\n",
      "Epoch 247/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5607 - accuracy: 0.7125 - auc: 0.7831 - val_loss: 0.5528 - val_accuracy: 0.7186 - val_auc: 0.7917\n",
      "Epoch 248/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5587 - accuracy: 0.7177 - auc: 0.7841 - val_loss: 0.5527 - val_accuracy: 0.7201 - val_auc: 0.7918\n",
      "Epoch 249/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5591 - accuracy: 0.7088 - auc: 0.7819 - val_loss: 0.5531 - val_accuracy: 0.7201 - val_auc: 0.7910\n",
      "Epoch 250/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5576 - accuracy: 0.7191 - auc: 0.7837 - val_loss: 0.5523 - val_accuracy: 0.7186 - val_auc: 0.7921\n",
      "Epoch 251/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5576 - accuracy: 0.7191 - auc: 0.7859 - val_loss: 0.5524 - val_accuracy: 0.7156 - val_auc: 0.7917\n",
      "Epoch 252/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5616 - accuracy: 0.7102 - auc: 0.7816 - val_loss: 0.5514 - val_accuracy: 0.7216 - val_auc: 0.7933\n",
      "Epoch 253/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5616 - accuracy: 0.7163 - auc: 0.7817 - val_loss: 0.5525 - val_accuracy: 0.7201 - val_auc: 0.7920\n",
      "Epoch 254/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5517 - accuracy: 0.7219 - auc: 0.7900 - val_loss: 0.5530 - val_accuracy: 0.7216 - val_auc: 0.7915\n",
      "Epoch 255/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5585 - accuracy: 0.7135 - auc: 0.7842 - val_loss: 0.5533 - val_accuracy: 0.7201 - val_auc: 0.7914\n",
      "Epoch 256/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5612 - accuracy: 0.7172 - auc: 0.7808 - val_loss: 0.5534 - val_accuracy: 0.7216 - val_auc: 0.7909\n",
      "Epoch 257/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5560 - accuracy: 0.7210 - auc: 0.7881 - val_loss: 0.5532 - val_accuracy: 0.7201 - val_auc: 0.7907\n",
      "Epoch 258/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5590 - accuracy: 0.7158 - auc: 0.7834 - val_loss: 0.5528 - val_accuracy: 0.7231 - val_auc: 0.7917\n",
      "Epoch 259/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5646 - accuracy: 0.7097 - auc: 0.7786 - val_loss: 0.5525 - val_accuracy: 0.7246 - val_auc: 0.7922\n",
      "Epoch 260/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5652 - accuracy: 0.7074 - auc: 0.7783 - val_loss: 0.5526 - val_accuracy: 0.7231 - val_auc: 0.7920\n",
      "Epoch 261/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5611 - accuracy: 0.7088 - auc: 0.7801 - val_loss: 0.5527 - val_accuracy: 0.7186 - val_auc: 0.7918\n",
      "Epoch 262/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5621 - accuracy: 0.7093 - auc: 0.7799 - val_loss: 0.5520 - val_accuracy: 0.7216 - val_auc: 0.7926\n",
      "Epoch 263/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5546 - accuracy: 0.7210 - auc: 0.7882 - val_loss: 0.5526 - val_accuracy: 0.7186 - val_auc: 0.7919\n",
      "Epoch 264/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5598 - accuracy: 0.7107 - auc: 0.7824 - val_loss: 0.5530 - val_accuracy: 0.7201 - val_auc: 0.7911\n",
      "Epoch 265/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5549 - accuracy: 0.7130 - auc: 0.7868 - val_loss: 0.5528 - val_accuracy: 0.7201 - val_auc: 0.7915\n",
      "Epoch 266/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5637 - accuracy: 0.7135 - auc: 0.7793 - val_loss: 0.5521 - val_accuracy: 0.7201 - val_auc: 0.7922\n",
      "Epoch 267/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5568 - accuracy: 0.7130 - auc: 0.7847 - val_loss: 0.5516 - val_accuracy: 0.7156 - val_auc: 0.7929\n",
      "Epoch 268/700\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5539 - accuracy: 0.7158 - auc: 0.7881 - val_loss: 0.5513 - val_accuracy: 0.7186 - val_auc: 0.7930\n",
      "Epoch 269/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5631 - accuracy: 0.7041 - auc: 0.7787 - val_loss: 0.5511 - val_accuracy: 0.7171 - val_auc: 0.7931\n",
      "Epoch 270/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5519 - accuracy: 0.7186 - auc: 0.7895 - val_loss: 0.5515 - val_accuracy: 0.7186 - val_auc: 0.7927\n",
      "Epoch 271/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5575 - accuracy: 0.7111 - auc: 0.7865 - val_loss: 0.5507 - val_accuracy: 0.7171 - val_auc: 0.7935\n",
      "Epoch 272/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5546 - accuracy: 0.7243 - auc: 0.7881 - val_loss: 0.5523 - val_accuracy: 0.7231 - val_auc: 0.7918\n",
      "Epoch 273/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5620 - accuracy: 0.7097 - auc: 0.7797 - val_loss: 0.5509 - val_accuracy: 0.7275 - val_auc: 0.7935\n",
      "Epoch 274/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5528 - accuracy: 0.7196 - auc: 0.7882 - val_loss: 0.5514 - val_accuracy: 0.7186 - val_auc: 0.7929\n",
      "Epoch 275/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5524 - accuracy: 0.7172 - auc: 0.7893 - val_loss: 0.5510 - val_accuracy: 0.7186 - val_auc: 0.7933\n",
      "Epoch 276/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5594 - accuracy: 0.7205 - auc: 0.7838 - val_loss: 0.5522 - val_accuracy: 0.7201 - val_auc: 0.7920\n",
      "Epoch 277/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5557 - accuracy: 0.7252 - auc: 0.7875 - val_loss: 0.5519 - val_accuracy: 0.7231 - val_auc: 0.7920\n",
      "Epoch 278/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5494 - accuracy: 0.7252 - auc: 0.7951 - val_loss: 0.5509 - val_accuracy: 0.7260 - val_auc: 0.7930\n",
      "Epoch 279/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5609 - accuracy: 0.7008 - auc: 0.7802 - val_loss: 0.5502 - val_accuracy: 0.7260 - val_auc: 0.7935\n",
      "Epoch 280/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5571 - accuracy: 0.7182 - auc: 0.7856 - val_loss: 0.5492 - val_accuracy: 0.7216 - val_auc: 0.7944\n",
      "Epoch 281/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5495 - accuracy: 0.7210 - auc: 0.7941 - val_loss: 0.5491 - val_accuracy: 0.7201 - val_auc: 0.7950\n",
      "Epoch 282/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5535 - accuracy: 0.7121 - auc: 0.7884 - val_loss: 0.5488 - val_accuracy: 0.7216 - val_auc: 0.7959\n",
      "Epoch 283/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5551 - accuracy: 0.7243 - auc: 0.7880 - val_loss: 0.5480 - val_accuracy: 0.7201 - val_auc: 0.7965\n",
      "Epoch 284/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5637 - accuracy: 0.7093 - auc: 0.7815 - val_loss: 0.5487 - val_accuracy: 0.7231 - val_auc: 0.7957\n",
      "Epoch 285/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5538 - accuracy: 0.7074 - auc: 0.7891 - val_loss: 0.5492 - val_accuracy: 0.7186 - val_auc: 0.7947\n",
      "Epoch 286/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5439 - accuracy: 0.7285 - auc: 0.7997 - val_loss: 0.5491 - val_accuracy: 0.7186 - val_auc: 0.7950\n",
      "Epoch 287/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5494 - accuracy: 0.7275 - auc: 0.7938 - val_loss: 0.5486 - val_accuracy: 0.7216 - val_auc: 0.7954\n",
      "Epoch 288/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5574 - accuracy: 0.7205 - auc: 0.7859 - val_loss: 0.5480 - val_accuracy: 0.7186 - val_auc: 0.7962\n",
      "Epoch 289/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5512 - accuracy: 0.7266 - auc: 0.7917 - val_loss: 0.5478 - val_accuracy: 0.7201 - val_auc: 0.7965\n",
      "Epoch 290/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5549 - accuracy: 0.7144 - auc: 0.7891 - val_loss: 0.5474 - val_accuracy: 0.7216 - val_auc: 0.7968\n",
      "Epoch 291/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5487 - accuracy: 0.7214 - auc: 0.7928 - val_loss: 0.5481 - val_accuracy: 0.7216 - val_auc: 0.7959\n",
      "Epoch 292/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5511 - accuracy: 0.7163 - auc: 0.7907 - val_loss: 0.5479 - val_accuracy: 0.7216 - val_auc: 0.7962\n",
      "Epoch 293/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5583 - accuracy: 0.7168 - auc: 0.7846 - val_loss: 0.5483 - val_accuracy: 0.7231 - val_auc: 0.7958\n",
      "Epoch 294/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5557 - accuracy: 0.7158 - auc: 0.7863 - val_loss: 0.5481 - val_accuracy: 0.7231 - val_auc: 0.7962\n",
      "Epoch 295/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5590 - accuracy: 0.7074 - auc: 0.7828 - val_loss: 0.5479 - val_accuracy: 0.7216 - val_auc: 0.7963\n",
      "Epoch 296/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5525 - accuracy: 0.7200 - auc: 0.7896 - val_loss: 0.5486 - val_accuracy: 0.7231 - val_auc: 0.7954\n",
      "Epoch 297/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5537 - accuracy: 0.7233 - auc: 0.7887 - val_loss: 0.5482 - val_accuracy: 0.7231 - val_auc: 0.7955\n",
      "Epoch 298/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5531 - accuracy: 0.7168 - auc: 0.7904 - val_loss: 0.5479 - val_accuracy: 0.7231 - val_auc: 0.7958\n",
      "Epoch 299/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5536 - accuracy: 0.7191 - auc: 0.7888 - val_loss: 0.5484 - val_accuracy: 0.7246 - val_auc: 0.7957\n",
      "Epoch 300/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5522 - accuracy: 0.7224 - auc: 0.7914 - val_loss: 0.5477 - val_accuracy: 0.7305 - val_auc: 0.7964\n",
      "Epoch 301/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5536 - accuracy: 0.7172 - auc: 0.7890 - val_loss: 0.5482 - val_accuracy: 0.7231 - val_auc: 0.7958\n",
      "Epoch 302/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5530 - accuracy: 0.7154 - auc: 0.7881 - val_loss: 0.5474 - val_accuracy: 0.7290 - val_auc: 0.7965\n",
      "Epoch 303/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5554 - accuracy: 0.7205 - auc: 0.7865 - val_loss: 0.5475 - val_accuracy: 0.7290 - val_auc: 0.7964\n",
      "Epoch 304/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5543 - accuracy: 0.7144 - auc: 0.7858 - val_loss: 0.5478 - val_accuracy: 0.7246 - val_auc: 0.7961\n",
      "Epoch 305/700\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5571 - accuracy: 0.7191 - auc: 0.7850 - val_loss: 0.5474 - val_accuracy: 0.7260 - val_auc: 0.7963\n",
      "Epoch 306/700\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.5525 - accuracy: 0.7205 - auc: 0.7892 - val_loss: 0.5482 - val_accuracy: 0.7275 - val_auc: 0.7952\n",
      "Epoch 307/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5565 - accuracy: 0.7135 - auc: 0.7859 - val_loss: 0.5482 - val_accuracy: 0.7275 - val_auc: 0.7956\n",
      "Epoch 308/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5533 - accuracy: 0.7252 - auc: 0.7898 - val_loss: 0.5475 - val_accuracy: 0.7260 - val_auc: 0.7962\n",
      "Epoch 309/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5502 - accuracy: 0.7210 - auc: 0.7918 - val_loss: 0.5471 - val_accuracy: 0.7231 - val_auc: 0.7969\n",
      "Epoch 310/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5550 - accuracy: 0.7196 - auc: 0.7862 - val_loss: 0.5470 - val_accuracy: 0.7260 - val_auc: 0.7970\n",
      "Epoch 311/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5498 - accuracy: 0.7289 - auc: 0.7933 - val_loss: 0.5467 - val_accuracy: 0.7231 - val_auc: 0.7973\n",
      "Epoch 312/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5483 - accuracy: 0.7196 - auc: 0.7926 - val_loss: 0.5475 - val_accuracy: 0.7260 - val_auc: 0.7962\n",
      "Epoch 313/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5519 - accuracy: 0.7271 - auc: 0.7900 - val_loss: 0.5464 - val_accuracy: 0.7216 - val_auc: 0.7977\n",
      "Epoch 314/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5586 - accuracy: 0.7168 - auc: 0.7854 - val_loss: 0.5462 - val_accuracy: 0.7231 - val_auc: 0.7978\n",
      "Epoch 315/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5546 - accuracy: 0.7186 - auc: 0.7877 - val_loss: 0.5466 - val_accuracy: 0.7246 - val_auc: 0.7973\n",
      "Epoch 316/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5580 - accuracy: 0.7210 - auc: 0.7837 - val_loss: 0.5466 - val_accuracy: 0.7246 - val_auc: 0.7971\n",
      "Epoch 317/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5492 - accuracy: 0.7168 - auc: 0.7930 - val_loss: 0.5468 - val_accuracy: 0.7231 - val_auc: 0.7969\n",
      "Epoch 318/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5522 - accuracy: 0.7168 - auc: 0.7884 - val_loss: 0.5461 - val_accuracy: 0.7201 - val_auc: 0.7978\n",
      "Epoch 319/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5495 - accuracy: 0.7285 - auc: 0.7946 - val_loss: 0.5456 - val_accuracy: 0.7216 - val_auc: 0.7987\n",
      "Epoch 320/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5511 - accuracy: 0.7214 - auc: 0.7910 - val_loss: 0.5455 - val_accuracy: 0.7231 - val_auc: 0.7990\n",
      "Epoch 321/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5549 - accuracy: 0.7186 - auc: 0.7885 - val_loss: 0.5453 - val_accuracy: 0.7216 - val_auc: 0.7990\n",
      "Epoch 322/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5535 - accuracy: 0.7243 - auc: 0.7902 - val_loss: 0.5452 - val_accuracy: 0.7260 - val_auc: 0.7986\n",
      "Epoch 323/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5501 - accuracy: 0.7140 - auc: 0.7908 - val_loss: 0.5460 - val_accuracy: 0.7260 - val_auc: 0.7979\n",
      "Epoch 324/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5555 - accuracy: 0.7140 - auc: 0.7856 - val_loss: 0.5457 - val_accuracy: 0.7260 - val_auc: 0.7984\n",
      "Epoch 325/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5502 - accuracy: 0.7233 - auc: 0.7919 - val_loss: 0.5457 - val_accuracy: 0.7231 - val_auc: 0.7983\n",
      "Epoch 326/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5416 - accuracy: 0.7303 - auc: 0.8008 - val_loss: 0.5451 - val_accuracy: 0.7246 - val_auc: 0.7987\n",
      "Epoch 327/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5531 - accuracy: 0.7177 - auc: 0.7896 - val_loss: 0.5443 - val_accuracy: 0.7216 - val_auc: 0.7998\n",
      "Epoch 328/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5504 - accuracy: 0.7299 - auc: 0.7926 - val_loss: 0.5445 - val_accuracy: 0.7201 - val_auc: 0.7994\n",
      "Epoch 329/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5518 - accuracy: 0.7149 - auc: 0.7883 - val_loss: 0.5447 - val_accuracy: 0.7246 - val_auc: 0.7990\n",
      "Epoch 330/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5540 - accuracy: 0.7144 - auc: 0.7871 - val_loss: 0.5441 - val_accuracy: 0.7231 - val_auc: 0.7995\n",
      "Epoch 331/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5503 - accuracy: 0.7205 - auc: 0.7919 - val_loss: 0.5433 - val_accuracy: 0.7216 - val_auc: 0.8005\n",
      "Epoch 332/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5491 - accuracy: 0.7233 - auc: 0.7939 - val_loss: 0.5435 - val_accuracy: 0.7216 - val_auc: 0.8000\n",
      "Epoch 333/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5543 - accuracy: 0.7219 - auc: 0.7891 - val_loss: 0.5430 - val_accuracy: 0.7246 - val_auc: 0.8007\n",
      "Epoch 334/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5469 - accuracy: 0.7228 - auc: 0.7947 - val_loss: 0.5440 - val_accuracy: 0.7231 - val_auc: 0.7998\n",
      "Epoch 335/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5481 - accuracy: 0.7233 - auc: 0.7952 - val_loss: 0.5434 - val_accuracy: 0.7231 - val_auc: 0.8004\n",
      "Epoch 336/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5492 - accuracy: 0.7172 - auc: 0.7940 - val_loss: 0.5441 - val_accuracy: 0.7231 - val_auc: 0.7999\n",
      "Epoch 337/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5464 - accuracy: 0.7266 - auc: 0.7960 - val_loss: 0.5434 - val_accuracy: 0.7246 - val_auc: 0.8008\n",
      "Epoch 338/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5532 - accuracy: 0.7191 - auc: 0.7888 - val_loss: 0.5432 - val_accuracy: 0.7246 - val_auc: 0.8005\n",
      "Epoch 339/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5483 - accuracy: 0.7191 - auc: 0.7931 - val_loss: 0.5439 - val_accuracy: 0.7216 - val_auc: 0.7996\n",
      "Epoch 340/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5453 - accuracy: 0.7322 - auc: 0.7970 - val_loss: 0.5445 - val_accuracy: 0.7246 - val_auc: 0.7988\n",
      "Epoch 341/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5532 - accuracy: 0.7191 - auc: 0.7892 - val_loss: 0.5445 - val_accuracy: 0.7216 - val_auc: 0.7989\n",
      "Epoch 342/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5467 - accuracy: 0.7238 - auc: 0.7941 - val_loss: 0.5446 - val_accuracy: 0.7231 - val_auc: 0.7986\n",
      "Epoch 343/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5532 - accuracy: 0.7093 - auc: 0.7872 - val_loss: 0.5440 - val_accuracy: 0.7260 - val_auc: 0.7998\n",
      "Epoch 344/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5557 - accuracy: 0.7135 - auc: 0.7869 - val_loss: 0.5435 - val_accuracy: 0.7246 - val_auc: 0.7998\n",
      "Epoch 345/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5497 - accuracy: 0.7182 - auc: 0.7930 - val_loss: 0.5431 - val_accuracy: 0.7246 - val_auc: 0.8004\n",
      "Epoch 346/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5466 - accuracy: 0.7233 - auc: 0.7948 - val_loss: 0.5437 - val_accuracy: 0.7231 - val_auc: 0.7997\n",
      "Epoch 347/700\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5486 - accuracy: 0.7168 - auc: 0.7942 - val_loss: 0.5429 - val_accuracy: 0.7231 - val_auc: 0.8006\n",
      "Epoch 348/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5505 - accuracy: 0.7172 - auc: 0.7913 - val_loss: 0.5438 - val_accuracy: 0.7231 - val_auc: 0.7996\n",
      "Epoch 349/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5495 - accuracy: 0.7135 - auc: 0.7921 - val_loss: 0.5436 - val_accuracy: 0.7231 - val_auc: 0.7999\n",
      "Epoch 350/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5483 - accuracy: 0.7196 - auc: 0.7947 - val_loss: 0.5441 - val_accuracy: 0.7231 - val_auc: 0.7990\n",
      "Epoch 351/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5454 - accuracy: 0.7257 - auc: 0.7963 - val_loss: 0.5440 - val_accuracy: 0.7231 - val_auc: 0.7992\n",
      "Epoch 352/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5496 - accuracy: 0.7275 - auc: 0.7940 - val_loss: 0.5429 - val_accuracy: 0.7246 - val_auc: 0.8003\n",
      "Epoch 353/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5440 - accuracy: 0.7271 - auc: 0.7990 - val_loss: 0.5430 - val_accuracy: 0.7246 - val_auc: 0.8003\n",
      "Epoch 354/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5491 - accuracy: 0.7219 - auc: 0.7938 - val_loss: 0.5425 - val_accuracy: 0.7231 - val_auc: 0.8007\n",
      "Epoch 355/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5464 - accuracy: 0.7200 - auc: 0.7964 - val_loss: 0.5433 - val_accuracy: 0.7231 - val_auc: 0.7995\n",
      "Epoch 356/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5487 - accuracy: 0.7200 - auc: 0.7918 - val_loss: 0.5430 - val_accuracy: 0.7246 - val_auc: 0.8000\n",
      "Epoch 357/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5502 - accuracy: 0.7158 - auc: 0.7910 - val_loss: 0.5423 - val_accuracy: 0.7216 - val_auc: 0.8011\n",
      "Epoch 358/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5467 - accuracy: 0.7233 - auc: 0.7957 - val_loss: 0.5419 - val_accuracy: 0.7246 - val_auc: 0.8013\n",
      "Epoch 359/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5448 - accuracy: 0.7196 - auc: 0.7957 - val_loss: 0.5414 - val_accuracy: 0.7216 - val_auc: 0.8022\n",
      "Epoch 360/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5442 - accuracy: 0.7252 - auc: 0.7963 - val_loss: 0.5408 - val_accuracy: 0.7231 - val_auc: 0.8028\n",
      "Epoch 361/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5438 - accuracy: 0.7313 - auc: 0.7995 - val_loss: 0.5418 - val_accuracy: 0.7216 - val_auc: 0.8022\n",
      "Epoch 362/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5488 - accuracy: 0.7158 - auc: 0.7918 - val_loss: 0.5417 - val_accuracy: 0.7246 - val_auc: 0.8019\n",
      "Epoch 363/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5498 - accuracy: 0.7238 - auc: 0.7920 - val_loss: 0.5417 - val_accuracy: 0.7231 - val_auc: 0.8018\n",
      "Epoch 364/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5467 - accuracy: 0.7294 - auc: 0.7955 - val_loss: 0.5414 - val_accuracy: 0.7231 - val_auc: 0.8022\n",
      "Epoch 365/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5520 - accuracy: 0.7233 - auc: 0.7912 - val_loss: 0.5413 - val_accuracy: 0.7246 - val_auc: 0.8021\n",
      "Epoch 366/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5451 - accuracy: 0.7261 - auc: 0.7972 - val_loss: 0.5419 - val_accuracy: 0.7275 - val_auc: 0.8012\n",
      "Epoch 367/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5503 - accuracy: 0.7196 - auc: 0.7925 - val_loss: 0.5421 - val_accuracy: 0.7290 - val_auc: 0.8013\n",
      "Epoch 368/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5498 - accuracy: 0.7107 - auc: 0.7905 - val_loss: 0.5418 - val_accuracy: 0.7260 - val_auc: 0.8014\n",
      "Epoch 369/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5497 - accuracy: 0.7186 - auc: 0.7915 - val_loss: 0.5419 - val_accuracy: 0.7246 - val_auc: 0.8013\n",
      "Epoch 370/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5471 - accuracy: 0.7214 - auc: 0.7959 - val_loss: 0.5409 - val_accuracy: 0.7231 - val_auc: 0.8025\n",
      "Epoch 371/700\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5488 - accuracy: 0.7196 - auc: 0.7940 - val_loss: 0.5406 - val_accuracy: 0.7260 - val_auc: 0.8028\n",
      "Epoch 372/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5450 - accuracy: 0.7172 - auc: 0.7948 - val_loss: 0.5403 - val_accuracy: 0.7231 - val_auc: 0.8032\n",
      "Epoch 373/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5486 - accuracy: 0.7158 - auc: 0.7940 - val_loss: 0.5397 - val_accuracy: 0.7275 - val_auc: 0.8040\n",
      "Epoch 374/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5569 - accuracy: 0.7205 - auc: 0.7860 - val_loss: 0.5389 - val_accuracy: 0.7246 - val_auc: 0.8045\n",
      "Epoch 375/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5470 - accuracy: 0.7214 - auc: 0.7964 - val_loss: 0.5394 - val_accuracy: 0.7231 - val_auc: 0.8039\n",
      "Epoch 376/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5484 - accuracy: 0.7285 - auc: 0.7952 - val_loss: 0.5405 - val_accuracy: 0.7260 - val_auc: 0.8030\n",
      "Epoch 377/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5449 - accuracy: 0.7224 - auc: 0.7983 - val_loss: 0.5398 - val_accuracy: 0.7246 - val_auc: 0.8035\n",
      "Epoch 378/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5477 - accuracy: 0.7252 - auc: 0.7941 - val_loss: 0.5397 - val_accuracy: 0.7231 - val_auc: 0.8040\n",
      "Epoch 379/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5437 - accuracy: 0.7252 - auc: 0.7985 - val_loss: 0.5396 - val_accuracy: 0.7246 - val_auc: 0.8040\n",
      "Epoch 380/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5503 - accuracy: 0.7196 - auc: 0.7911 - val_loss: 0.5396 - val_accuracy: 0.7260 - val_auc: 0.8041\n",
      "Epoch 381/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5450 - accuracy: 0.7331 - auc: 0.7971 - val_loss: 0.5385 - val_accuracy: 0.7275 - val_auc: 0.8052\n",
      "Epoch 382/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5455 - accuracy: 0.7350 - auc: 0.7967 - val_loss: 0.5391 - val_accuracy: 0.7275 - val_auc: 0.8046\n",
      "Epoch 383/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5497 - accuracy: 0.7224 - auc: 0.7918 - val_loss: 0.5393 - val_accuracy: 0.7275 - val_auc: 0.8043\n",
      "Epoch 384/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5494 - accuracy: 0.7331 - auc: 0.7936 - val_loss: 0.5387 - val_accuracy: 0.7231 - val_auc: 0.8053\n",
      "Epoch 385/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5506 - accuracy: 0.7144 - auc: 0.7899 - val_loss: 0.5388 - val_accuracy: 0.7231 - val_auc: 0.8049\n",
      "Epoch 386/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5453 - accuracy: 0.7271 - auc: 0.7976 - val_loss: 0.5398 - val_accuracy: 0.7275 - val_auc: 0.8035\n",
      "Epoch 387/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5462 - accuracy: 0.7224 - auc: 0.7955 - val_loss: 0.5406 - val_accuracy: 0.7246 - val_auc: 0.8027\n",
      "Epoch 388/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5500 - accuracy: 0.7224 - auc: 0.7920 - val_loss: 0.5407 - val_accuracy: 0.7246 - val_auc: 0.8027\n",
      "Epoch 389/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5443 - accuracy: 0.7294 - auc: 0.7970 - val_loss: 0.5415 - val_accuracy: 0.7246 - val_auc: 0.8016\n",
      "Epoch 390/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5476 - accuracy: 0.7172 - auc: 0.7956 - val_loss: 0.5414 - val_accuracy: 0.7246 - val_auc: 0.8014\n",
      "Epoch 391/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5470 - accuracy: 0.7238 - auc: 0.7953 - val_loss: 0.5421 - val_accuracy: 0.7275 - val_auc: 0.8010\n",
      "Epoch 392/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5461 - accuracy: 0.7191 - auc: 0.7941 - val_loss: 0.5407 - val_accuracy: 0.7246 - val_auc: 0.8024\n",
      "Epoch 393/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5461 - accuracy: 0.7313 - auc: 0.7984 - val_loss: 0.5404 - val_accuracy: 0.7246 - val_auc: 0.8028\n",
      "Epoch 394/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5454 - accuracy: 0.7346 - auc: 0.7968 - val_loss: 0.5393 - val_accuracy: 0.7246 - val_auc: 0.8038\n",
      "Epoch 395/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5477 - accuracy: 0.7186 - auc: 0.7954 - val_loss: 0.5400 - val_accuracy: 0.7231 - val_auc: 0.8030\n",
      "Epoch 396/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5440 - accuracy: 0.7285 - auc: 0.7974 - val_loss: 0.5390 - val_accuracy: 0.7246 - val_auc: 0.8040\n",
      "Epoch 397/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5359 - accuracy: 0.7261 - auc: 0.8053 - val_loss: 0.5389 - val_accuracy: 0.7246 - val_auc: 0.8041\n",
      "Epoch 398/700\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5427 - accuracy: 0.7228 - auc: 0.7992 - val_loss: 0.5383 - val_accuracy: 0.7275 - val_auc: 0.8050\n",
      "Epoch 399/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5405 - accuracy: 0.7331 - auc: 0.8013 - val_loss: 0.5385 - val_accuracy: 0.7260 - val_auc: 0.8048\n",
      "Epoch 400/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5459 - accuracy: 0.7210 - auc: 0.7951 - val_loss: 0.5380 - val_accuracy: 0.7290 - val_auc: 0.8051\n",
      "Epoch 401/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5426 - accuracy: 0.7261 - auc: 0.7972 - val_loss: 0.5390 - val_accuracy: 0.7260 - val_auc: 0.8038\n",
      "Epoch 402/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5500 - accuracy: 0.7163 - auc: 0.7892 - val_loss: 0.5377 - val_accuracy: 0.7275 - val_auc: 0.8055\n",
      "Epoch 403/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5335 - accuracy: 0.7331 - auc: 0.8086 - val_loss: 0.5376 - val_accuracy: 0.7290 - val_auc: 0.8057\n",
      "Epoch 404/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5405 - accuracy: 0.7280 - auc: 0.8027 - val_loss: 0.5375 - val_accuracy: 0.7290 - val_auc: 0.8056\n",
      "Epoch 405/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5434 - accuracy: 0.7266 - auc: 0.7989 - val_loss: 0.5375 - val_accuracy: 0.7260 - val_auc: 0.8050\n",
      "Epoch 406/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5378 - accuracy: 0.7355 - auc: 0.8041 - val_loss: 0.5377 - val_accuracy: 0.7246 - val_auc: 0.8051\n",
      "Epoch 407/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5481 - accuracy: 0.7224 - auc: 0.7953 - val_loss: 0.5382 - val_accuracy: 0.7246 - val_auc: 0.8046\n",
      "Epoch 408/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5473 - accuracy: 0.7186 - auc: 0.7939 - val_loss: 0.5376 - val_accuracy: 0.7260 - val_auc: 0.8051\n",
      "Epoch 409/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5450 - accuracy: 0.7289 - auc: 0.7978 - val_loss: 0.5370 - val_accuracy: 0.7290 - val_auc: 0.8061\n",
      "Epoch 410/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5404 - accuracy: 0.7266 - auc: 0.8014 - val_loss: 0.5371 - val_accuracy: 0.7260 - val_auc: 0.8058\n",
      "Epoch 411/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5420 - accuracy: 0.7299 - auc: 0.7991 - val_loss: 0.5367 - val_accuracy: 0.7290 - val_auc: 0.8063\n",
      "Epoch 412/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5448 - accuracy: 0.7219 - auc: 0.7966 - val_loss: 0.5358 - val_accuracy: 0.7320 - val_auc: 0.8073\n",
      "Epoch 413/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5461 - accuracy: 0.7186 - auc: 0.7950 - val_loss: 0.5355 - val_accuracy: 0.7290 - val_auc: 0.8072\n",
      "Epoch 414/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5439 - accuracy: 0.7257 - auc: 0.7965 - val_loss: 0.5356 - val_accuracy: 0.7275 - val_auc: 0.8069\n",
      "Epoch 415/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5385 - accuracy: 0.7266 - auc: 0.8027 - val_loss: 0.5357 - val_accuracy: 0.7275 - val_auc: 0.8073\n",
      "Epoch 416/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5455 - accuracy: 0.7172 - auc: 0.7954 - val_loss: 0.5362 - val_accuracy: 0.7290 - val_auc: 0.8069\n",
      "Epoch 417/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5447 - accuracy: 0.7257 - auc: 0.7972 - val_loss: 0.5370 - val_accuracy: 0.7305 - val_auc: 0.8062\n",
      "Epoch 418/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5453 - accuracy: 0.7172 - auc: 0.7957 - val_loss: 0.5366 - val_accuracy: 0.7320 - val_auc: 0.8069\n",
      "Epoch 419/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5481 - accuracy: 0.7266 - auc: 0.7938 - val_loss: 0.5363 - val_accuracy: 0.7350 - val_auc: 0.8068\n",
      "Epoch 420/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5488 - accuracy: 0.7163 - auc: 0.7936 - val_loss: 0.5361 - val_accuracy: 0.7305 - val_auc: 0.8070\n",
      "Epoch 421/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5468 - accuracy: 0.7238 - auc: 0.7941 - val_loss: 0.5364 - val_accuracy: 0.7290 - val_auc: 0.8066\n",
      "Epoch 422/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5437 - accuracy: 0.7247 - auc: 0.7981 - val_loss: 0.5367 - val_accuracy: 0.7290 - val_auc: 0.8061\n",
      "Epoch 423/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5501 - accuracy: 0.7182 - auc: 0.7909 - val_loss: 0.5355 - val_accuracy: 0.7290 - val_auc: 0.8078\n",
      "Epoch 424/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5486 - accuracy: 0.7177 - auc: 0.7935 - val_loss: 0.5360 - val_accuracy: 0.7290 - val_auc: 0.8071\n",
      "Epoch 425/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5358 - accuracy: 0.7341 - auc: 0.8068 - val_loss: 0.5353 - val_accuracy: 0.7290 - val_auc: 0.8077\n",
      "Epoch 426/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5462 - accuracy: 0.7228 - auc: 0.7961 - val_loss: 0.5351 - val_accuracy: 0.7305 - val_auc: 0.8078\n",
      "Epoch 427/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5500 - accuracy: 0.7191 - auc: 0.7915 - val_loss: 0.5358 - val_accuracy: 0.7246 - val_auc: 0.8068\n",
      "Epoch 428/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5490 - accuracy: 0.7261 - auc: 0.7923 - val_loss: 0.5345 - val_accuracy: 0.7290 - val_auc: 0.8082\n",
      "Epoch 429/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5461 - accuracy: 0.7233 - auc: 0.7967 - val_loss: 0.5356 - val_accuracy: 0.7305 - val_auc: 0.8070\n",
      "Epoch 430/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5447 - accuracy: 0.7243 - auc: 0.7958 - val_loss: 0.5360 - val_accuracy: 0.7320 - val_auc: 0.8065\n",
      "Epoch 431/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5422 - accuracy: 0.7252 - auc: 0.7992 - val_loss: 0.5357 - val_accuracy: 0.7290 - val_auc: 0.8067\n",
      "Epoch 432/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5424 - accuracy: 0.7261 - auc: 0.7994 - val_loss: 0.5358 - val_accuracy: 0.7290 - val_auc: 0.8069\n",
      "Epoch 433/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5421 - accuracy: 0.7299 - auc: 0.8006 - val_loss: 0.5352 - val_accuracy: 0.7305 - val_auc: 0.8076\n",
      "Epoch 434/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5448 - accuracy: 0.7149 - auc: 0.7964 - val_loss: 0.5355 - val_accuracy: 0.7335 - val_auc: 0.8069\n",
      "Epoch 435/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5436 - accuracy: 0.7266 - auc: 0.7971 - val_loss: 0.5353 - val_accuracy: 0.7335 - val_auc: 0.8072\n",
      "Epoch 436/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5411 - accuracy: 0.7205 - auc: 0.7986 - val_loss: 0.5360 - val_accuracy: 0.7305 - val_auc: 0.8069\n",
      "Epoch 437/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5404 - accuracy: 0.7317 - auc: 0.7989 - val_loss: 0.5357 - val_accuracy: 0.7305 - val_auc: 0.8074\n",
      "Epoch 438/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5366 - accuracy: 0.7322 - auc: 0.8043 - val_loss: 0.5349 - val_accuracy: 0.7335 - val_auc: 0.8081\n",
      "Epoch 439/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5432 - accuracy: 0.7280 - auc: 0.7978 - val_loss: 0.5351 - val_accuracy: 0.7275 - val_auc: 0.8078\n",
      "Epoch 440/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5490 - accuracy: 0.7186 - auc: 0.7945 - val_loss: 0.5354 - val_accuracy: 0.7320 - val_auc: 0.8075\n",
      "Epoch 441/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5417 - accuracy: 0.7266 - auc: 0.7998 - val_loss: 0.5355 - val_accuracy: 0.7335 - val_auc: 0.8072\n",
      "Epoch 442/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5436 - accuracy: 0.7228 - auc: 0.7974 - val_loss: 0.5352 - val_accuracy: 0.7335 - val_auc: 0.8079\n",
      "Epoch 443/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5474 - accuracy: 0.7219 - auc: 0.7928 - val_loss: 0.5358 - val_accuracy: 0.7305 - val_auc: 0.8066\n",
      "Epoch 444/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5395 - accuracy: 0.7294 - auc: 0.8027 - val_loss: 0.5354 - val_accuracy: 0.7290 - val_auc: 0.8073\n",
      "Epoch 445/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5379 - accuracy: 0.7168 - auc: 0.8019 - val_loss: 0.5365 - val_accuracy: 0.7275 - val_auc: 0.8058\n",
      "Epoch 446/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5350 - accuracy: 0.7317 - auc: 0.8070 - val_loss: 0.5357 - val_accuracy: 0.7335 - val_auc: 0.8068\n",
      "Epoch 447/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5426 - accuracy: 0.7238 - auc: 0.8002 - val_loss: 0.5360 - val_accuracy: 0.7320 - val_auc: 0.8062\n",
      "Epoch 448/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5424 - accuracy: 0.7275 - auc: 0.7986 - val_loss: 0.5358 - val_accuracy: 0.7335 - val_auc: 0.8068\n",
      "Epoch 449/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5368 - accuracy: 0.7341 - auc: 0.8043 - val_loss: 0.5359 - val_accuracy: 0.7335 - val_auc: 0.8065\n",
      "Epoch 450/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5479 - accuracy: 0.7214 - auc: 0.7936 - val_loss: 0.5351 - val_accuracy: 0.7320 - val_auc: 0.8072\n",
      "Epoch 451/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5364 - accuracy: 0.7331 - auc: 0.8049 - val_loss: 0.5349 - val_accuracy: 0.7335 - val_auc: 0.8074\n",
      "Epoch 452/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5411 - accuracy: 0.7224 - auc: 0.7993 - val_loss: 0.5349 - val_accuracy: 0.7335 - val_auc: 0.8074\n",
      "Epoch 453/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5393 - accuracy: 0.7317 - auc: 0.8025 - val_loss: 0.5351 - val_accuracy: 0.7320 - val_auc: 0.8074\n",
      "Epoch 454/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5452 - accuracy: 0.7205 - auc: 0.7966 - val_loss: 0.5343 - val_accuracy: 0.7335 - val_auc: 0.8078\n",
      "Epoch 455/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5386 - accuracy: 0.7364 - auc: 0.8040 - val_loss: 0.5345 - val_accuracy: 0.7320 - val_auc: 0.8077\n",
      "Epoch 456/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5397 - accuracy: 0.7191 - auc: 0.8009 - val_loss: 0.5341 - val_accuracy: 0.7335 - val_auc: 0.8081\n",
      "Epoch 457/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5395 - accuracy: 0.7275 - auc: 0.7994 - val_loss: 0.5346 - val_accuracy: 0.7305 - val_auc: 0.8073\n",
      "Epoch 458/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5401 - accuracy: 0.7214 - auc: 0.8009 - val_loss: 0.5347 - val_accuracy: 0.7305 - val_auc: 0.8076\n",
      "Epoch 459/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5447 - accuracy: 0.7228 - auc: 0.7959 - val_loss: 0.5338 - val_accuracy: 0.7335 - val_auc: 0.8085\n",
      "Epoch 460/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5472 - accuracy: 0.7214 - auc: 0.7932 - val_loss: 0.5332 - val_accuracy: 0.7320 - val_auc: 0.8093\n",
      "Epoch 461/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5437 - accuracy: 0.7280 - auc: 0.7982 - val_loss: 0.5335 - val_accuracy: 0.7320 - val_auc: 0.8086\n",
      "Epoch 462/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5434 - accuracy: 0.7140 - auc: 0.7968 - val_loss: 0.5331 - val_accuracy: 0.7335 - val_auc: 0.8091\n",
      "Epoch 463/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5365 - accuracy: 0.7285 - auc: 0.8036 - val_loss: 0.5340 - val_accuracy: 0.7335 - val_auc: 0.8082\n",
      "Epoch 464/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5419 - accuracy: 0.7219 - auc: 0.7988 - val_loss: 0.5342 - val_accuracy: 0.7335 - val_auc: 0.8083\n",
      "Epoch 465/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5410 - accuracy: 0.7200 - auc: 0.7996 - val_loss: 0.5340 - val_accuracy: 0.7290 - val_auc: 0.8087\n",
      "Epoch 466/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5413 - accuracy: 0.7219 - auc: 0.7982 - val_loss: 0.5342 - val_accuracy: 0.7305 - val_auc: 0.8081\n",
      "Epoch 467/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5385 - accuracy: 0.7331 - auc: 0.8032 - val_loss: 0.5334 - val_accuracy: 0.7275 - val_auc: 0.8090\n",
      "Epoch 468/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5379 - accuracy: 0.7257 - auc: 0.8027 - val_loss: 0.5321 - val_accuracy: 0.7290 - val_auc: 0.8101\n",
      "Epoch 469/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5410 - accuracy: 0.7261 - auc: 0.7991 - val_loss: 0.5331 - val_accuracy: 0.7320 - val_auc: 0.8090\n",
      "Epoch 470/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5361 - accuracy: 0.7350 - auc: 0.8049 - val_loss: 0.5321 - val_accuracy: 0.7320 - val_auc: 0.8099\n",
      "Epoch 471/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5420 - accuracy: 0.7163 - auc: 0.7991 - val_loss: 0.5327 - val_accuracy: 0.7290 - val_auc: 0.8092\n",
      "Epoch 472/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5407 - accuracy: 0.7397 - auc: 0.8009 - val_loss: 0.5323 - val_accuracy: 0.7320 - val_auc: 0.8094\n",
      "Epoch 473/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5395 - accuracy: 0.7317 - auc: 0.8012 - val_loss: 0.5327 - val_accuracy: 0.7320 - val_auc: 0.8092\n",
      "Epoch 474/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5407 - accuracy: 0.7238 - auc: 0.8015 - val_loss: 0.5324 - val_accuracy: 0.7320 - val_auc: 0.8095\n",
      "Epoch 475/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5419 - accuracy: 0.7346 - auc: 0.8014 - val_loss: 0.5328 - val_accuracy: 0.7320 - val_auc: 0.8090\n",
      "Epoch 476/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5424 - accuracy: 0.7303 - auc: 0.7987 - val_loss: 0.5337 - val_accuracy: 0.7320 - val_auc: 0.8080\n",
      "Epoch 477/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5446 - accuracy: 0.7163 - auc: 0.7962 - val_loss: 0.5332 - val_accuracy: 0.7320 - val_auc: 0.8089\n",
      "Epoch 478/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5397 - accuracy: 0.7303 - auc: 0.8027 - val_loss: 0.5325 - val_accuracy: 0.7320 - val_auc: 0.8097\n",
      "Epoch 479/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5347 - accuracy: 0.7346 - auc: 0.8075 - val_loss: 0.5332 - val_accuracy: 0.7320 - val_auc: 0.8091\n",
      "Epoch 480/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5382 - accuracy: 0.7238 - auc: 0.8024 - val_loss: 0.5332 - val_accuracy: 0.7335 - val_auc: 0.8088\n",
      "Epoch 481/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5408 - accuracy: 0.7247 - auc: 0.7996 - val_loss: 0.5335 - val_accuracy: 0.7320 - val_auc: 0.8087\n",
      "Epoch 482/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5330 - accuracy: 0.7303 - auc: 0.8070 - val_loss: 0.5328 - val_accuracy: 0.7320 - val_auc: 0.8094\n",
      "Epoch 483/700\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5458 - accuracy: 0.7252 - auc: 0.7955 - val_loss: 0.5317 - val_accuracy: 0.7320 - val_auc: 0.8105\n",
      "Epoch 484/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5358 - accuracy: 0.7360 - auc: 0.8072 - val_loss: 0.5316 - val_accuracy: 0.7320 - val_auc: 0.8105\n",
      "Epoch 485/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5439 - accuracy: 0.7289 - auc: 0.7966 - val_loss: 0.5317 - val_accuracy: 0.7320 - val_auc: 0.8103\n",
      "Epoch 486/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5373 - accuracy: 0.7364 - auc: 0.8041 - val_loss: 0.5325 - val_accuracy: 0.7305 - val_auc: 0.8091\n",
      "Epoch 487/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5406 - accuracy: 0.7275 - auc: 0.8008 - val_loss: 0.5328 - val_accuracy: 0.7305 - val_auc: 0.8088\n",
      "Epoch 488/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5346 - accuracy: 0.7294 - auc: 0.8065 - val_loss: 0.5325 - val_accuracy: 0.7320 - val_auc: 0.8092\n",
      "Epoch 489/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5435 - accuracy: 0.7228 - auc: 0.7978 - val_loss: 0.5331 - val_accuracy: 0.7305 - val_auc: 0.8088\n",
      "Epoch 490/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5410 - accuracy: 0.7294 - auc: 0.7984 - val_loss: 0.5328 - val_accuracy: 0.7305 - val_auc: 0.8092\n",
      "Epoch 491/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5372 - accuracy: 0.7266 - auc: 0.8025 - val_loss: 0.5327 - val_accuracy: 0.7320 - val_auc: 0.8092\n",
      "Epoch 492/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5346 - accuracy: 0.7369 - auc: 0.8075 - val_loss: 0.5328 - val_accuracy: 0.7320 - val_auc: 0.8092\n",
      "Epoch 493/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5345 - accuracy: 0.7257 - auc: 0.8055 - val_loss: 0.5321 - val_accuracy: 0.7290 - val_auc: 0.8099\n",
      "Epoch 494/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5399 - accuracy: 0.7261 - auc: 0.7996 - val_loss: 0.5323 - val_accuracy: 0.7305 - val_auc: 0.8094\n",
      "Epoch 495/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5377 - accuracy: 0.7271 - auc: 0.8027 - val_loss: 0.5323 - val_accuracy: 0.7320 - val_auc: 0.8098\n",
      "Epoch 496/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5361 - accuracy: 0.7280 - auc: 0.8051 - val_loss: 0.5329 - val_accuracy: 0.7335 - val_auc: 0.8091\n",
      "Epoch 497/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5353 - accuracy: 0.7346 - auc: 0.8065 - val_loss: 0.5334 - val_accuracy: 0.7305 - val_auc: 0.8088\n",
      "Epoch 498/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5347 - accuracy: 0.7327 - auc: 0.8058 - val_loss: 0.5325 - val_accuracy: 0.7290 - val_auc: 0.8094\n",
      "Epoch 499/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5343 - accuracy: 0.7308 - auc: 0.8050 - val_loss: 0.5318 - val_accuracy: 0.7320 - val_auc: 0.8099\n",
      "Epoch 500/700\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5361 - accuracy: 0.7238 - auc: 0.8045 - val_loss: 0.5314 - val_accuracy: 0.7320 - val_auc: 0.8106\n",
      "Epoch 501/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5477 - accuracy: 0.7228 - auc: 0.7929 - val_loss: 0.5315 - val_accuracy: 0.7320 - val_auc: 0.8101\n",
      "Epoch 502/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5415 - accuracy: 0.7261 - auc: 0.7997 - val_loss: 0.5313 - val_accuracy: 0.7320 - val_auc: 0.8105\n",
      "Epoch 503/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5322 - accuracy: 0.7280 - auc: 0.8073 - val_loss: 0.5321 - val_accuracy: 0.7305 - val_auc: 0.8096\n",
      "Epoch 504/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5299 - accuracy: 0.7355 - auc: 0.8091 - val_loss: 0.5323 - val_accuracy: 0.7305 - val_auc: 0.8100\n",
      "Epoch 505/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5435 - accuracy: 0.7149 - auc: 0.7965 - val_loss: 0.5325 - val_accuracy: 0.7290 - val_auc: 0.8095\n",
      "Epoch 506/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5378 - accuracy: 0.7322 - auc: 0.8035 - val_loss: 0.5322 - val_accuracy: 0.7320 - val_auc: 0.8095\n",
      "Epoch 507/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5369 - accuracy: 0.7275 - auc: 0.8031 - val_loss: 0.5321 - val_accuracy: 0.7305 - val_auc: 0.8097\n",
      "Epoch 508/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5474 - accuracy: 0.7228 - auc: 0.7940 - val_loss: 0.5319 - val_accuracy: 0.7305 - val_auc: 0.8094\n",
      "Epoch 509/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5377 - accuracy: 0.7266 - auc: 0.8036 - val_loss: 0.5312 - val_accuracy: 0.7320 - val_auc: 0.8105\n",
      "Epoch 510/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5395 - accuracy: 0.7299 - auc: 0.8006 - val_loss: 0.5305 - val_accuracy: 0.7335 - val_auc: 0.8110\n",
      "Epoch 511/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5352 - accuracy: 0.7331 - auc: 0.8065 - val_loss: 0.5305 - val_accuracy: 0.7305 - val_auc: 0.8109\n",
      "Epoch 512/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5384 - accuracy: 0.7228 - auc: 0.8017 - val_loss: 0.5301 - val_accuracy: 0.7320 - val_auc: 0.8111\n",
      "Epoch 513/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5368 - accuracy: 0.7331 - auc: 0.8053 - val_loss: 0.5313 - val_accuracy: 0.7305 - val_auc: 0.8100\n",
      "Epoch 514/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5301 - accuracy: 0.7374 - auc: 0.8102 - val_loss: 0.5307 - val_accuracy: 0.7320 - val_auc: 0.8110\n",
      "Epoch 515/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5412 - accuracy: 0.7252 - auc: 0.7993 - val_loss: 0.5310 - val_accuracy: 0.7320 - val_auc: 0.8105\n",
      "Epoch 516/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5340 - accuracy: 0.7261 - auc: 0.8049 - val_loss: 0.5313 - val_accuracy: 0.7305 - val_auc: 0.8099\n",
      "Epoch 517/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5347 - accuracy: 0.7355 - auc: 0.8057 - val_loss: 0.5310 - val_accuracy: 0.7290 - val_auc: 0.8105\n",
      "Epoch 518/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5339 - accuracy: 0.7261 - auc: 0.8060 - val_loss: 0.5301 - val_accuracy: 0.7305 - val_auc: 0.8116\n",
      "Epoch 519/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5352 - accuracy: 0.7355 - auc: 0.8052 - val_loss: 0.5303 - val_accuracy: 0.7275 - val_auc: 0.8114\n",
      "Epoch 520/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5386 - accuracy: 0.7308 - auc: 0.8018 - val_loss: 0.5299 - val_accuracy: 0.7290 - val_auc: 0.8117\n",
      "Epoch 521/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5300 - accuracy: 0.7308 - auc: 0.8097 - val_loss: 0.5299 - val_accuracy: 0.7305 - val_auc: 0.8114\n",
      "Epoch 522/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5289 - accuracy: 0.7322 - auc: 0.8106 - val_loss: 0.5303 - val_accuracy: 0.7320 - val_auc: 0.8109\n",
      "Epoch 523/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5361 - accuracy: 0.7289 - auc: 0.8051 - val_loss: 0.5308 - val_accuracy: 0.7320 - val_auc: 0.8105\n",
      "Epoch 524/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5333 - accuracy: 0.7350 - auc: 0.8070 - val_loss: 0.5311 - val_accuracy: 0.7305 - val_auc: 0.8105\n",
      "Epoch 525/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5388 - accuracy: 0.7313 - auc: 0.8021 - val_loss: 0.5318 - val_accuracy: 0.7320 - val_auc: 0.8094\n",
      "Epoch 526/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5446 - accuracy: 0.7303 - auc: 0.7988 - val_loss: 0.5304 - val_accuracy: 0.7305 - val_auc: 0.8112\n",
      "Epoch 527/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5336 - accuracy: 0.7397 - auc: 0.8069 - val_loss: 0.5309 - val_accuracy: 0.7305 - val_auc: 0.8105\n",
      "Epoch 528/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5345 - accuracy: 0.7317 - auc: 0.8069 - val_loss: 0.5302 - val_accuracy: 0.7305 - val_auc: 0.8112\n",
      "Epoch 529/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5355 - accuracy: 0.7299 - auc: 0.8058 - val_loss: 0.5302 - val_accuracy: 0.7320 - val_auc: 0.8111\n",
      "Epoch 530/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5339 - accuracy: 0.7275 - auc: 0.8067 - val_loss: 0.5295 - val_accuracy: 0.7320 - val_auc: 0.8113\n",
      "Epoch 531/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5364 - accuracy: 0.7247 - auc: 0.8044 - val_loss: 0.5299 - val_accuracy: 0.7290 - val_auc: 0.8113\n",
      "Epoch 532/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5366 - accuracy: 0.7350 - auc: 0.8039 - val_loss: 0.5298 - val_accuracy: 0.7320 - val_auc: 0.8119\n",
      "Epoch 533/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5367 - accuracy: 0.7294 - auc: 0.8037 - val_loss: 0.5295 - val_accuracy: 0.7320 - val_auc: 0.8119\n",
      "Epoch 534/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5348 - accuracy: 0.7280 - auc: 0.8059 - val_loss: 0.5299 - val_accuracy: 0.7305 - val_auc: 0.8113\n",
      "Epoch 535/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5310 - accuracy: 0.7383 - auc: 0.8084 - val_loss: 0.5308 - val_accuracy: 0.7305 - val_auc: 0.8106\n",
      "Epoch 536/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5461 - accuracy: 0.7168 - auc: 0.7956 - val_loss: 0.5298 - val_accuracy: 0.7320 - val_auc: 0.8115\n",
      "Epoch 537/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5366 - accuracy: 0.7214 - auc: 0.8051 - val_loss: 0.5298 - val_accuracy: 0.7320 - val_auc: 0.8114\n",
      "Epoch 538/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5354 - accuracy: 0.7191 - auc: 0.8049 - val_loss: 0.5304 - val_accuracy: 0.7305 - val_auc: 0.8109\n",
      "Epoch 539/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5322 - accuracy: 0.7289 - auc: 0.8086 - val_loss: 0.5295 - val_accuracy: 0.7320 - val_auc: 0.8116\n",
      "Epoch 540/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5390 - accuracy: 0.7327 - auc: 0.8036 - val_loss: 0.5294 - val_accuracy: 0.7305 - val_auc: 0.8115\n",
      "Epoch 541/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5290 - accuracy: 0.7458 - auc: 0.8117 - val_loss: 0.5294 - val_accuracy: 0.7320 - val_auc: 0.8113\n",
      "Epoch 542/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5341 - accuracy: 0.7214 - auc: 0.8062 - val_loss: 0.5286 - val_accuracy: 0.7290 - val_auc: 0.8128\n",
      "Epoch 543/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5276 - accuracy: 0.7355 - auc: 0.8135 - val_loss: 0.5283 - val_accuracy: 0.7335 - val_auc: 0.8128\n",
      "Epoch 544/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5331 - accuracy: 0.7350 - auc: 0.8068 - val_loss: 0.5284 - val_accuracy: 0.7290 - val_auc: 0.8124\n",
      "Epoch 545/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5311 - accuracy: 0.7313 - auc: 0.8086 - val_loss: 0.5281 - val_accuracy: 0.7290 - val_auc: 0.8128\n",
      "Epoch 546/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5329 - accuracy: 0.7350 - auc: 0.8092 - val_loss: 0.5278 - val_accuracy: 0.7320 - val_auc: 0.8132\n",
      "Epoch 547/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5349 - accuracy: 0.7299 - auc: 0.8054 - val_loss: 0.5285 - val_accuracy: 0.7290 - val_auc: 0.8126\n",
      "Epoch 548/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5346 - accuracy: 0.7336 - auc: 0.8048 - val_loss: 0.5285 - val_accuracy: 0.7290 - val_auc: 0.8124\n",
      "Epoch 549/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5324 - accuracy: 0.7261 - auc: 0.8068 - val_loss: 0.5288 - val_accuracy: 0.7305 - val_auc: 0.8123\n",
      "Epoch 550/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5173 - accuracy: 0.7406 - auc: 0.8223 - val_loss: 0.5291 - val_accuracy: 0.7320 - val_auc: 0.8117\n",
      "Epoch 551/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5301 - accuracy: 0.7350 - auc: 0.8096 - val_loss: 0.5284 - val_accuracy: 0.7305 - val_auc: 0.8128\n",
      "Epoch 552/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5216 - accuracy: 0.7420 - auc: 0.8193 - val_loss: 0.5290 - val_accuracy: 0.7320 - val_auc: 0.8123\n",
      "Epoch 553/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5338 - accuracy: 0.7336 - auc: 0.8054 - val_loss: 0.5284 - val_accuracy: 0.7275 - val_auc: 0.8126\n",
      "Epoch 554/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5356 - accuracy: 0.7275 - auc: 0.8042 - val_loss: 0.5282 - val_accuracy: 0.7290 - val_auc: 0.8128\n",
      "Epoch 555/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5362 - accuracy: 0.7252 - auc: 0.8043 - val_loss: 0.5284 - val_accuracy: 0.7290 - val_auc: 0.8125\n",
      "Epoch 556/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5398 - accuracy: 0.7196 - auc: 0.7994 - val_loss: 0.5283 - val_accuracy: 0.7305 - val_auc: 0.8125\n",
      "Epoch 557/700\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5307 - accuracy: 0.7327 - auc: 0.8089 - val_loss: 0.5272 - val_accuracy: 0.7335 - val_auc: 0.8138\n",
      "Epoch 558/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5288 - accuracy: 0.7392 - auc: 0.8117 - val_loss: 0.5281 - val_accuracy: 0.7305 - val_auc: 0.8128\n",
      "Epoch 559/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5312 - accuracy: 0.7360 - auc: 0.8107 - val_loss: 0.5275 - val_accuracy: 0.7320 - val_auc: 0.8133\n",
      "Epoch 560/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5349 - accuracy: 0.7285 - auc: 0.8039 - val_loss: 0.5282 - val_accuracy: 0.7320 - val_auc: 0.8123\n",
      "Epoch 561/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5394 - accuracy: 0.7402 - auc: 0.8018 - val_loss: 0.5279 - val_accuracy: 0.7305 - val_auc: 0.8126\n",
      "Epoch 562/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5320 - accuracy: 0.7360 - auc: 0.8088 - val_loss: 0.5274 - val_accuracy: 0.7335 - val_auc: 0.8131\n",
      "Epoch 563/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5355 - accuracy: 0.7378 - auc: 0.8057 - val_loss: 0.5269 - val_accuracy: 0.7320 - val_auc: 0.8139\n",
      "Epoch 564/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5348 - accuracy: 0.7285 - auc: 0.8044 - val_loss: 0.5282 - val_accuracy: 0.7305 - val_auc: 0.8123\n",
      "Epoch 565/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5401 - accuracy: 0.7294 - auc: 0.8002 - val_loss: 0.5275 - val_accuracy: 0.7305 - val_auc: 0.8127\n",
      "Epoch 566/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5311 - accuracy: 0.7346 - auc: 0.8077 - val_loss: 0.5287 - val_accuracy: 0.7320 - val_auc: 0.8119\n",
      "Epoch 567/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5336 - accuracy: 0.7303 - auc: 0.8055 - val_loss: 0.5277 - val_accuracy: 0.7320 - val_auc: 0.8130\n",
      "Epoch 568/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5315 - accuracy: 0.7285 - auc: 0.8075 - val_loss: 0.5270 - val_accuracy: 0.7350 - val_auc: 0.8140\n",
      "Epoch 569/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5315 - accuracy: 0.7350 - auc: 0.8094 - val_loss: 0.5265 - val_accuracy: 0.7335 - val_auc: 0.8143\n",
      "Epoch 570/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5396 - accuracy: 0.7271 - auc: 0.8021 - val_loss: 0.5268 - val_accuracy: 0.7335 - val_auc: 0.8137\n",
      "Epoch 571/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5345 - accuracy: 0.7406 - auc: 0.8074 - val_loss: 0.5276 - val_accuracy: 0.7320 - val_auc: 0.8131\n",
      "Epoch 572/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5334 - accuracy: 0.7303 - auc: 0.8059 - val_loss: 0.5273 - val_accuracy: 0.7335 - val_auc: 0.8137\n",
      "Epoch 573/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5290 - accuracy: 0.7350 - auc: 0.8118 - val_loss: 0.5278 - val_accuracy: 0.7290 - val_auc: 0.8132\n",
      "Epoch 574/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5354 - accuracy: 0.7322 - auc: 0.8052 - val_loss: 0.5277 - val_accuracy: 0.7335 - val_auc: 0.8130\n",
      "Epoch 575/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5344 - accuracy: 0.7266 - auc: 0.8061 - val_loss: 0.5277 - val_accuracy: 0.7335 - val_auc: 0.8133\n",
      "Epoch 576/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5376 - accuracy: 0.7308 - auc: 0.8033 - val_loss: 0.5275 - val_accuracy: 0.7350 - val_auc: 0.8132\n",
      "Epoch 577/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5289 - accuracy: 0.7346 - auc: 0.8117 - val_loss: 0.5269 - val_accuracy: 0.7335 - val_auc: 0.8137\n",
      "Epoch 578/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5315 - accuracy: 0.7261 - auc: 0.8074 - val_loss: 0.5270 - val_accuracy: 0.7335 - val_auc: 0.8136\n",
      "Epoch 579/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5278 - accuracy: 0.7317 - auc: 0.8105 - val_loss: 0.5273 - val_accuracy: 0.7350 - val_auc: 0.8133\n",
      "Epoch 580/700\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5350 - accuracy: 0.7257 - auc: 0.8036 - val_loss: 0.5261 - val_accuracy: 0.7350 - val_auc: 0.8149\n",
      "Epoch 581/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5380 - accuracy: 0.7233 - auc: 0.8027 - val_loss: 0.5267 - val_accuracy: 0.7350 - val_auc: 0.8138\n",
      "Epoch 582/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5392 - accuracy: 0.7214 - auc: 0.8003 - val_loss: 0.5264 - val_accuracy: 0.7335 - val_auc: 0.8140\n",
      "Epoch 583/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5387 - accuracy: 0.7285 - auc: 0.8019 - val_loss: 0.5256 - val_accuracy: 0.7335 - val_auc: 0.8149\n",
      "Epoch 584/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5295 - accuracy: 0.7420 - auc: 0.8111 - val_loss: 0.5260 - val_accuracy: 0.7335 - val_auc: 0.8146\n",
      "Epoch 585/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5325 - accuracy: 0.7243 - auc: 0.8068 - val_loss: 0.5277 - val_accuracy: 0.7320 - val_auc: 0.8130\n",
      "Epoch 586/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5279 - accuracy: 0.7392 - auc: 0.8098 - val_loss: 0.5270 - val_accuracy: 0.7320 - val_auc: 0.8134\n",
      "Epoch 587/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5255 - accuracy: 0.7313 - auc: 0.8137 - val_loss: 0.5278 - val_accuracy: 0.7305 - val_auc: 0.8126\n",
      "Epoch 588/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5400 - accuracy: 0.7243 - auc: 0.8008 - val_loss: 0.5261 - val_accuracy: 0.7335 - val_auc: 0.8140\n",
      "Epoch 589/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5373 - accuracy: 0.7317 - auc: 0.8037 - val_loss: 0.5256 - val_accuracy: 0.7305 - val_auc: 0.8147\n",
      "Epoch 590/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5314 - accuracy: 0.7341 - auc: 0.8076 - val_loss: 0.5267 - val_accuracy: 0.7335 - val_auc: 0.8136\n",
      "Epoch 591/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5352 - accuracy: 0.7331 - auc: 0.8044 - val_loss: 0.5267 - val_accuracy: 0.7320 - val_auc: 0.8138\n",
      "Epoch 592/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5306 - accuracy: 0.7355 - auc: 0.8096 - val_loss: 0.5265 - val_accuracy: 0.7320 - val_auc: 0.8140\n",
      "Epoch 593/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5313 - accuracy: 0.7313 - auc: 0.8095 - val_loss: 0.5267 - val_accuracy: 0.7335 - val_auc: 0.8138\n",
      "Epoch 594/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5237 - accuracy: 0.7416 - auc: 0.8153 - val_loss: 0.5272 - val_accuracy: 0.7320 - val_auc: 0.8135\n",
      "Epoch 595/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5304 - accuracy: 0.7275 - auc: 0.8090 - val_loss: 0.5264 - val_accuracy: 0.7320 - val_auc: 0.8140\n",
      "Epoch 596/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5334 - accuracy: 0.7238 - auc: 0.8053 - val_loss: 0.5271 - val_accuracy: 0.7305 - val_auc: 0.8131\n",
      "Epoch 597/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5322 - accuracy: 0.7327 - auc: 0.8076 - val_loss: 0.5264 - val_accuracy: 0.7305 - val_auc: 0.8139\n",
      "Epoch 598/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5356 - accuracy: 0.7247 - auc: 0.8036 - val_loss: 0.5268 - val_accuracy: 0.7305 - val_auc: 0.8136\n",
      "Epoch 599/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5320 - accuracy: 0.7364 - auc: 0.8081 - val_loss: 0.5261 - val_accuracy: 0.7320 - val_auc: 0.8141\n",
      "Epoch 600/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5367 - accuracy: 0.7313 - auc: 0.8034 - val_loss: 0.5265 - val_accuracy: 0.7320 - val_auc: 0.8138\n",
      "Epoch 601/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5296 - accuracy: 0.7439 - auc: 0.8110 - val_loss: 0.5263 - val_accuracy: 0.7335 - val_auc: 0.8140\n",
      "Epoch 602/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5350 - accuracy: 0.7336 - auc: 0.8050 - val_loss: 0.5259 - val_accuracy: 0.7335 - val_auc: 0.8141\n",
      "Epoch 603/700\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5239 - accuracy: 0.7434 - auc: 0.8152 - val_loss: 0.5254 - val_accuracy: 0.7320 - val_auc: 0.8150\n",
      "Epoch 604/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5281 - accuracy: 0.7285 - auc: 0.8102 - val_loss: 0.5255 - val_accuracy: 0.7335 - val_auc: 0.8150\n",
      "Epoch 605/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5359 - accuracy: 0.7331 - auc: 0.8047 - val_loss: 0.5256 - val_accuracy: 0.7320 - val_auc: 0.8146\n",
      "Epoch 606/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5348 - accuracy: 0.7322 - auc: 0.8045 - val_loss: 0.5255 - val_accuracy: 0.7335 - val_auc: 0.8147\n",
      "Epoch 607/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5337 - accuracy: 0.7322 - auc: 0.8052 - val_loss: 0.5261 - val_accuracy: 0.7350 - val_auc: 0.8142\n",
      "Epoch 608/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5337 - accuracy: 0.7360 - auc: 0.8058 - val_loss: 0.5251 - val_accuracy: 0.7350 - val_auc: 0.8154\n",
      "Epoch 609/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5342 - accuracy: 0.7289 - auc: 0.8070 - val_loss: 0.5247 - val_accuracy: 0.7335 - val_auc: 0.8154\n",
      "Epoch 610/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5305 - accuracy: 0.7360 - auc: 0.8090 - val_loss: 0.5252 - val_accuracy: 0.7335 - val_auc: 0.8155\n",
      "Epoch 611/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5276 - accuracy: 0.7308 - auc: 0.8119 - val_loss: 0.5261 - val_accuracy: 0.7335 - val_auc: 0.8142\n",
      "Epoch 612/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5300 - accuracy: 0.7355 - auc: 0.8113 - val_loss: 0.5249 - val_accuracy: 0.7350 - val_auc: 0.8152\n",
      "Epoch 613/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5270 - accuracy: 0.7383 - auc: 0.8133 - val_loss: 0.5254 - val_accuracy: 0.7335 - val_auc: 0.8146\n",
      "Epoch 614/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5231 - accuracy: 0.7383 - auc: 0.8166 - val_loss: 0.5246 - val_accuracy: 0.7350 - val_auc: 0.8157\n",
      "Epoch 615/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5403 - accuracy: 0.7210 - auc: 0.7992 - val_loss: 0.5254 - val_accuracy: 0.7335 - val_auc: 0.8150\n",
      "Epoch 616/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5220 - accuracy: 0.7463 - auc: 0.8168 - val_loss: 0.5243 - val_accuracy: 0.7335 - val_auc: 0.8164\n",
      "Epoch 617/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5299 - accuracy: 0.7355 - auc: 0.8112 - val_loss: 0.5242 - val_accuracy: 0.7320 - val_auc: 0.8160\n",
      "Epoch 618/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5308 - accuracy: 0.7331 - auc: 0.8084 - val_loss: 0.5246 - val_accuracy: 0.7320 - val_auc: 0.8154\n",
      "Epoch 619/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5335 - accuracy: 0.7303 - auc: 0.8074 - val_loss: 0.5253 - val_accuracy: 0.7320 - val_auc: 0.8153\n",
      "Epoch 620/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5325 - accuracy: 0.7355 - auc: 0.8070 - val_loss: 0.5257 - val_accuracy: 0.7320 - val_auc: 0.8145\n",
      "Epoch 621/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5284 - accuracy: 0.7378 - auc: 0.8104 - val_loss: 0.5253 - val_accuracy: 0.7350 - val_auc: 0.8152\n",
      "Epoch 622/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5299 - accuracy: 0.7350 - auc: 0.8103 - val_loss: 0.5251 - val_accuracy: 0.7305 - val_auc: 0.8151\n",
      "Epoch 623/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5283 - accuracy: 0.7350 - auc: 0.8113 - val_loss: 0.5239 - val_accuracy: 0.7320 - val_auc: 0.8165\n",
      "Epoch 624/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5247 - accuracy: 0.7336 - auc: 0.8141 - val_loss: 0.5241 - val_accuracy: 0.7290 - val_auc: 0.8160\n",
      "Epoch 625/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5313 - accuracy: 0.7219 - auc: 0.8076 - val_loss: 0.5237 - val_accuracy: 0.7335 - val_auc: 0.8162\n",
      "Epoch 626/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5369 - accuracy: 0.7364 - auc: 0.8054 - val_loss: 0.5242 - val_accuracy: 0.7350 - val_auc: 0.8156\n",
      "Epoch 627/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5282 - accuracy: 0.7411 - auc: 0.8113 - val_loss: 0.5243 - val_accuracy: 0.7335 - val_auc: 0.8155\n",
      "Epoch 628/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5323 - accuracy: 0.7228 - auc: 0.8078 - val_loss: 0.5238 - val_accuracy: 0.7320 - val_auc: 0.8159\n",
      "Epoch 629/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5260 - accuracy: 0.7313 - auc: 0.8130 - val_loss: 0.5247 - val_accuracy: 0.7335 - val_auc: 0.8153\n",
      "Epoch 630/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5345 - accuracy: 0.7346 - auc: 0.8058 - val_loss: 0.5243 - val_accuracy: 0.7350 - val_auc: 0.8158\n",
      "Epoch 631/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5262 - accuracy: 0.7271 - auc: 0.8112 - val_loss: 0.5238 - val_accuracy: 0.7350 - val_auc: 0.8165\n",
      "Epoch 632/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5259 - accuracy: 0.7378 - auc: 0.8133 - val_loss: 0.5242 - val_accuracy: 0.7320 - val_auc: 0.8156\n",
      "Epoch 633/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5286 - accuracy: 0.7378 - auc: 0.8109 - val_loss: 0.5235 - val_accuracy: 0.7335 - val_auc: 0.8164\n",
      "Epoch 634/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5372 - accuracy: 0.7294 - auc: 0.8019 - val_loss: 0.5245 - val_accuracy: 0.7320 - val_auc: 0.8156\n",
      "Epoch 635/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5243 - accuracy: 0.7378 - auc: 0.8143 - val_loss: 0.5236 - val_accuracy: 0.7305 - val_auc: 0.8164\n",
      "Epoch 636/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5315 - accuracy: 0.7317 - auc: 0.8063 - val_loss: 0.5236 - val_accuracy: 0.7320 - val_auc: 0.8166\n",
      "Epoch 637/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5250 - accuracy: 0.7416 - auc: 0.8131 - val_loss: 0.5242 - val_accuracy: 0.7335 - val_auc: 0.8161\n",
      "Epoch 638/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5274 - accuracy: 0.7364 - auc: 0.8123 - val_loss: 0.5233 - val_accuracy: 0.7320 - val_auc: 0.8170\n",
      "Epoch 639/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5286 - accuracy: 0.7350 - auc: 0.8114 - val_loss: 0.5242 - val_accuracy: 0.7320 - val_auc: 0.8158\n",
      "Epoch 640/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5250 - accuracy: 0.7388 - auc: 0.8140 - val_loss: 0.5243 - val_accuracy: 0.7305 - val_auc: 0.8157\n",
      "Epoch 641/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5381 - accuracy: 0.7214 - auc: 0.8001 - val_loss: 0.5241 - val_accuracy: 0.7305 - val_auc: 0.8160\n",
      "Epoch 642/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5274 - accuracy: 0.7327 - auc: 0.8107 - val_loss: 0.5236 - val_accuracy: 0.7320 - val_auc: 0.8163\n",
      "Epoch 643/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5262 - accuracy: 0.7285 - auc: 0.8137 - val_loss: 0.5230 - val_accuracy: 0.7350 - val_auc: 0.8170\n",
      "Epoch 644/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5320 - accuracy: 0.7327 - auc: 0.8077 - val_loss: 0.5232 - val_accuracy: 0.7320 - val_auc: 0.8170\n",
      "Epoch 645/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5272 - accuracy: 0.7406 - auc: 0.8122 - val_loss: 0.5240 - val_accuracy: 0.7335 - val_auc: 0.8160\n",
      "Epoch 646/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5328 - accuracy: 0.7346 - auc: 0.8076 - val_loss: 0.5236 - val_accuracy: 0.7320 - val_auc: 0.8165\n",
      "Epoch 647/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5299 - accuracy: 0.7247 - auc: 0.8086 - val_loss: 0.5243 - val_accuracy: 0.7320 - val_auc: 0.8156\n",
      "Epoch 648/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5318 - accuracy: 0.7257 - auc: 0.8062 - val_loss: 0.5246 - val_accuracy: 0.7320 - val_auc: 0.8149\n",
      "Epoch 649/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5264 - accuracy: 0.7285 - auc: 0.8118 - val_loss: 0.5236 - val_accuracy: 0.7335 - val_auc: 0.8162\n",
      "Epoch 650/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5247 - accuracy: 0.7402 - auc: 0.8144 - val_loss: 0.5230 - val_accuracy: 0.7320 - val_auc: 0.8168\n",
      "Epoch 651/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5280 - accuracy: 0.7434 - auc: 0.8114 - val_loss: 0.5228 - val_accuracy: 0.7305 - val_auc: 0.8168\n",
      "Epoch 652/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5270 - accuracy: 0.7402 - auc: 0.8123 - val_loss: 0.5235 - val_accuracy: 0.7320 - val_auc: 0.8160\n",
      "Epoch 653/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5311 - accuracy: 0.7275 - auc: 0.8076 - val_loss: 0.5229 - val_accuracy: 0.7335 - val_auc: 0.8169\n",
      "Epoch 654/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5271 - accuracy: 0.7317 - auc: 0.8120 - val_loss: 0.5230 - val_accuracy: 0.7305 - val_auc: 0.8168\n",
      "Epoch 655/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5235 - accuracy: 0.7425 - auc: 0.8150 - val_loss: 0.5230 - val_accuracy: 0.7335 - val_auc: 0.8166\n",
      "Epoch 656/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5309 - accuracy: 0.7360 - auc: 0.8088 - val_loss: 0.5235 - val_accuracy: 0.7305 - val_auc: 0.8158\n",
      "Epoch 657/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5355 - accuracy: 0.7257 - auc: 0.8042 - val_loss: 0.5240 - val_accuracy: 0.7305 - val_auc: 0.8155\n",
      "Epoch 658/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5205 - accuracy: 0.7378 - auc: 0.8164 - val_loss: 0.5235 - val_accuracy: 0.7305 - val_auc: 0.8160\n",
      "Epoch 659/700\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5238 - accuracy: 0.7374 - auc: 0.8159 - val_loss: 0.5227 - val_accuracy: 0.7305 - val_auc: 0.8168\n",
      "Epoch 660/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5343 - accuracy: 0.7289 - auc: 0.8059 - val_loss: 0.5231 - val_accuracy: 0.7335 - val_auc: 0.8165\n",
      "Epoch 661/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5309 - accuracy: 0.7313 - auc: 0.8097 - val_loss: 0.5231 - val_accuracy: 0.7305 - val_auc: 0.8163\n",
      "Epoch 662/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5313 - accuracy: 0.7294 - auc: 0.8076 - val_loss: 0.5224 - val_accuracy: 0.7305 - val_auc: 0.8172\n",
      "Epoch 663/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5240 - accuracy: 0.7369 - auc: 0.8129 - val_loss: 0.5226 - val_accuracy: 0.7305 - val_auc: 0.8169\n",
      "Epoch 664/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5251 - accuracy: 0.7406 - auc: 0.8139 - val_loss: 0.5227 - val_accuracy: 0.7320 - val_auc: 0.8163\n",
      "Epoch 665/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5326 - accuracy: 0.7294 - auc: 0.8064 - val_loss: 0.5227 - val_accuracy: 0.7320 - val_auc: 0.8165\n",
      "Epoch 666/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5237 - accuracy: 0.7336 - auc: 0.8142 - val_loss: 0.5219 - val_accuracy: 0.7305 - val_auc: 0.8176\n",
      "Epoch 667/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5342 - accuracy: 0.7303 - auc: 0.8049 - val_loss: 0.5217 - val_accuracy: 0.7320 - val_auc: 0.8179\n",
      "Epoch 668/700\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5210 - accuracy: 0.7402 - auc: 0.8175 - val_loss: 0.5216 - val_accuracy: 0.7305 - val_auc: 0.8181\n",
      "Epoch 669/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5280 - accuracy: 0.7420 - auc: 0.8124 - val_loss: 0.5218 - val_accuracy: 0.7305 - val_auc: 0.8174\n",
      "Epoch 670/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5229 - accuracy: 0.7416 - auc: 0.8168 - val_loss: 0.5219 - val_accuracy: 0.7320 - val_auc: 0.8175\n",
      "Epoch 671/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5251 - accuracy: 0.7420 - auc: 0.8142 - val_loss: 0.5226 - val_accuracy: 0.7305 - val_auc: 0.8167\n",
      "Epoch 672/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5325 - accuracy: 0.7392 - auc: 0.8095 - val_loss: 0.5219 - val_accuracy: 0.7305 - val_auc: 0.8174\n",
      "Epoch 673/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5225 - accuracy: 0.7355 - auc: 0.8154 - val_loss: 0.5217 - val_accuracy: 0.7290 - val_auc: 0.8178\n",
      "Epoch 674/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5327 - accuracy: 0.7275 - auc: 0.8072 - val_loss: 0.5220 - val_accuracy: 0.7290 - val_auc: 0.8173\n",
      "Epoch 675/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5314 - accuracy: 0.7294 - auc: 0.8081 - val_loss: 0.5223 - val_accuracy: 0.7305 - val_auc: 0.8170\n",
      "Epoch 676/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5222 - accuracy: 0.7467 - auc: 0.8174 - val_loss: 0.5229 - val_accuracy: 0.7290 - val_auc: 0.8166\n",
      "Epoch 677/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5278 - accuracy: 0.7238 - auc: 0.8104 - val_loss: 0.5222 - val_accuracy: 0.7275 - val_auc: 0.8176\n",
      "Epoch 678/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5247 - accuracy: 0.7458 - auc: 0.8134 - val_loss: 0.5228 - val_accuracy: 0.7305 - val_auc: 0.8169\n",
      "Epoch 679/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5280 - accuracy: 0.7327 - auc: 0.8113 - val_loss: 0.5214 - val_accuracy: 0.7290 - val_auc: 0.8179\n",
      "Epoch 680/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5327 - accuracy: 0.7313 - auc: 0.8072 - val_loss: 0.5225 - val_accuracy: 0.7305 - val_auc: 0.8168\n",
      "Epoch 681/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5253 - accuracy: 0.7406 - auc: 0.8139 - val_loss: 0.5224 - val_accuracy: 0.7305 - val_auc: 0.8171\n",
      "Epoch 682/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5215 - accuracy: 0.7402 - auc: 0.8176 - val_loss: 0.5223 - val_accuracy: 0.7290 - val_auc: 0.8172\n",
      "Epoch 683/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5282 - accuracy: 0.7285 - auc: 0.8114 - val_loss: 0.5228 - val_accuracy: 0.7305 - val_auc: 0.8164\n",
      "Epoch 684/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5335 - accuracy: 0.7257 - auc: 0.8046 - val_loss: 0.5220 - val_accuracy: 0.7290 - val_auc: 0.8173\n",
      "Epoch 685/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5219 - accuracy: 0.7383 - auc: 0.8166 - val_loss: 0.5215 - val_accuracy: 0.7305 - val_auc: 0.8178\n",
      "Epoch 686/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5370 - accuracy: 0.7228 - auc: 0.8009 - val_loss: 0.5213 - val_accuracy: 0.7305 - val_auc: 0.8177\n",
      "Epoch 687/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5308 - accuracy: 0.7294 - auc: 0.8085 - val_loss: 0.5205 - val_accuracy: 0.7275 - val_auc: 0.8188\n",
      "Epoch 688/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5274 - accuracy: 0.7331 - auc: 0.8117 - val_loss: 0.5212 - val_accuracy: 0.7305 - val_auc: 0.8182\n",
      "Epoch 689/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5344 - accuracy: 0.7369 - auc: 0.8049 - val_loss: 0.5217 - val_accuracy: 0.7320 - val_auc: 0.8176\n",
      "Epoch 690/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5250 - accuracy: 0.7360 - auc: 0.8147 - val_loss: 0.5212 - val_accuracy: 0.7305 - val_auc: 0.8179\n",
      "Epoch 691/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5250 - accuracy: 0.7294 - auc: 0.8148 - val_loss: 0.5213 - val_accuracy: 0.7305 - val_auc: 0.8178\n",
      "Epoch 692/700\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.5298 - accuracy: 0.7266 - auc: 0.8083 - val_loss: 0.5212 - val_accuracy: 0.7320 - val_auc: 0.8178\n",
      "Epoch 693/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5213 - accuracy: 0.7355 - auc: 0.8166 - val_loss: 0.5213 - val_accuracy: 0.7305 - val_auc: 0.8177\n",
      "Epoch 694/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5268 - accuracy: 0.7360 - auc: 0.8114 - val_loss: 0.5216 - val_accuracy: 0.7320 - val_auc: 0.8175\n",
      "Epoch 695/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5284 - accuracy: 0.7378 - auc: 0.8109 - val_loss: 0.5223 - val_accuracy: 0.7320 - val_auc: 0.8167\n",
      "Epoch 696/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5293 - accuracy: 0.7406 - auc: 0.8102 - val_loss: 0.5228 - val_accuracy: 0.7320 - val_auc: 0.8164\n",
      "Epoch 697/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5187 - accuracy: 0.7411 - auc: 0.8199 - val_loss: 0.5229 - val_accuracy: 0.7290 - val_auc: 0.8162\n",
      "Epoch 698/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5251 - accuracy: 0.7336 - auc: 0.8103 - val_loss: 0.5232 - val_accuracy: 0.7335 - val_auc: 0.8159\n",
      "Epoch 699/700\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.5326 - accuracy: 0.7308 - auc: 0.8078 - val_loss: 0.5218 - val_accuracy: 0.7350 - val_auc: 0.8174\n",
      "Epoch 700/700\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.5237 - accuracy: 0.7383 - auc: 0.8153 - val_loss: 0.5209 - val_accuracy: 0.7350 - val_auc: 0.8182\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.00001, decay=1e-6), loss='categorical_crossentropy', metrics=[METRICS])\n",
    "\n",
    "# Save best model\n",
    "best_model_save = ModelCheckpoint('fearfull_ravdess_meld.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 30,  verbose=1, mode='auto')\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=700, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1596288087604,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "ddcJYxjpRmou"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('fearfull_ravdess_meld.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1596288091459,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "w4snlhBmRqz8"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_predictions_baseline = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1596288097642,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "r80aTujCRt0v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total emotions_happy: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1596288106020,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "UMYnrL7YRw65",
    "outputId": "d4eb3de8-f026-4cf4-f9f8-dca86456aaf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.520481288433075\n",
      "accuracy :  0.727544903755188\n",
      "auc :  0.8188287019729614\n",
      "\n",
      "(True Negatives):  313\n",
      "(False Positives):  104\n",
      "(False Negatives):  78\n",
      "(True Positives):  173\n",
      "Total emotions_happy:  251\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77       417\n",
      "           1       0.62      0.69      0.66       251\n",
      "\n",
      "    accuracy                           0.73       668\n",
      "   macro avg       0.71      0.72      0.72       668\n",
      "weighted avg       0.73      0.73      0.73       668\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred = np.argmax(test_predictions_baseline, axis= 1)\n",
    "yy_test = np.argmax(y_test, axis  = 1)\n",
    "plot_cm(yy_test, y_pred)\n",
    "\n",
    "print(classification_report(yy_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO7WMWQ1Aljl"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1596288119575,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "GJk2L3O8ImIn"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_predictions_baseline = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1018,
     "status": "ok",
     "timestamp": 1596288137889,
     "user": {
      "displayName": "BARRY Nene Djenaba",
      "photoUrl": "",
      "userId": "09221402848573081539"
     },
     "user_tz": -120
    },
    "id": "l1iShdfBIy_v",
    "outputId": "edd44fae-c040-4af2-cf63-4bdd62b578c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5282854437828064\n",
      "accuracy :  0.7289719581604004\n",
      "auc :  0.8118071556091309\n",
      "\n",
      "(True Negatives):  250\n",
      "(False Positives):  96\n",
      "(False Negatives):  49\n",
      "(True Positives):  140\n",
      "Total emotions_happy:  189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78       346\n",
      "           1       0.59      0.74      0.66       189\n",
      "\n",
      "    accuracy                           0.73       535\n",
      "   macro avg       0.71      0.73      0.72       535\n",
      "weighted avg       0.75      0.73      0.73       535\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "baseline_results = model.evaluate(X_val, y_val,\n",
    "                                  batch_size= 64, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "y_pred_val = np.argmax(val_predictions_baseline, axis= 1)\n",
    "yy_val = np.argmax(y_val, axis  = 1)\n",
    "plot_cm(yy_val, y_pred_val)\n",
    "\n",
    "print(classification_report(yy_val, y_pred_val))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZWn1L9vWg5zI+Xb0JLbor",
   "name": "deep_fearfull_RAVDESS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
